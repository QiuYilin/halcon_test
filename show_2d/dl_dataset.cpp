///////////////////////////////////////////////////////////////////////////////
// File generated by HDevelop for HALCON/C++ Version 23.05.0.0
// Non-ASCII strings in this file are encoded in local-8-bit encoding (cp936).
// Ensure that the interface encoding is set to locale encoding by calling
// SetHcppInterfaceStringEncodingIsUtf8(false) at the beginning of the program.
// 
// Please note that non-ASCII characters in string constants are exported
// as octal codes in order to guarantee that the strings are correctly
// created on all systems, independent on any compiler settings.
// 
// Source files with different encoding should not be mixed in one project.
///////////////////////////////////////////////////////////////////////////////

#include "HalconCpp.h"
#include "HDevThread.h"



using namespace HalconCpp;

// Procedure declarations 
// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var, and dev_update_window to 'off'. 
extern void dev_update_off ();
// Chapter: File / Misc
// Short Description: Get all image files under the given path 
extern void list_image_files (HTuple hv_ImageDirectory, HTuple hv_Extensions, HTuple hv_Options, 
    HTuple *hv_ImageFiles);
// Chapter: File / Misc
// Short Description: Get all image files under the given path 
extern void list_image_files (HTuple hv_ImageDirectory, HTuple hv_Extensions, HTuple hv_Options, 
    HTuple *hv_ImageFiles);
// Chapter: File / Misc
// Short Description: Parse a filename into directory, base filename, and extension 
extern void parse_filename (HTuple hv_FileName, HTuple *hv_BaseName, HTuple *hv_Extension, 
    HTuple *hv_Directory);
// Chapter: File / Misc
// Short Description: Parse a filename into directory, base filename, and extension 
extern void parse_filename (HTuple hv_FileName, HTuple *hv_BaseName, HTuple *hv_Extension, 
    HTuple *hv_Directory);
// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
extern void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled);
// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
extern void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled);
// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Convert a COCO runlength encoding into a HALCON region. 
void convert_coco_rle_to_region (HObject *ho_Region, HTuple hv_RunLengthEncoding, 
    HTuple hv_Width, HTuple hv_Height);
// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Convert a COCO segmentation into a HALCON region. 
void convert_coco_segmentation_to_region (HObject *ho_Region, HTuple hv_Segmentation);
// Chapter: OCR / Deep OCR
// Short Description: Convert a given ocr detection dataset to a word based recognition dataset. 
void convert_dl_dataset_ocr_detection_to_recognition (HTuple hv_DLDatasetOCRSource, 
    HTuple *hv_DLDatasetOCRRecognition);
// Chapter: Deep Learning / Model
// Short Description: Create a dict which maps class IDs to class indices. 
void create_dl_class_id_mapping (HTuple hv_ClassIDs, HTuple *hv_ClassIDsToClassIndex);
// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Create a block of 3D Gripping Point Detection samples for a DLDataset. 
void create_dl_dataset_3d_gripping_point_detection_samples (HTuple hv_ImageList, 
    HTuple hv_XYZList, HTuple hv_NormalsList, HTuple hv_SegmentationList, HTuple hv_NumSamplesPerThread, 
    HTuple hv_UniqueIndex, HTuple *hv_SamplesOutput);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Create a block of anomaly samples for a DLDataset. 
void create_dl_dataset_anomaly_samples (HTuple hv_ImageList, HTuple hv_LabelList, 
    HTuple hv_AnomalyList, HTuple hv_AnomalyDirGiven, HTuple hv_NumSamplesPerThread, 
    HTuple hv_UniqueIndex, HTuple *hv_SamplesOutput, HTuple *hv_Exception);
// Chapter: Deep Learning / Classification
// Short Description: Create a block of classification samples for a DLDataset. 
void create_dl_dataset_classification_samples (HTuple hv_ImageFiles, HTuple hv_LabelIndices, 
    HTuple hv_RawImageFolder, HTuple hv_ImageDir, HTuple hv_NumSamplesPerThread, 
    HTuple hv_UniqueIndex, HTuple *hv_SamplesOutput);
// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Create a block of samples for a given thread. 
void create_dl_dataset_from_coco_samples (HTuple hv_ImageList, HTuple hv_ImageKeys, 
    HTuple hv_ImageDir, HTuple hv_AnnotationList, HTuple hv_AnnotationKeys, HTuple hv_AnnotImageIDs, 
    HTuple hv_Purpose, HTuple hv_ReadOnlyNonCrowd, HTuple hv_ReadRawAnnotations, 
    HTuple hv_ReadMasks, HTuple hv_NumSamplesPerThread, HTuple hv_UniqueIndex, HTuple *hv_DLSamplesOutput, 
    HTuple *hv_Exception);
// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Create a block of segmentation samples for a DLDataset. 
void create_dl_dataset_segmentation_samples (HTuple hv_ImageList, HTuple hv_SegmentationList, 
    HTuple hv_NumSamplesPerThread, HTuple hv_UniqueIndex, HTuple *hv_SamplesOutput);
// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Decompress a compressed COCO runlength encoding. 
void decompress_coco_rle (HTuple hv_CompressedRLE, HTuple hv_Width, HTuple hv_Height, 
    HTuple *hv_RunLengthEncoding);
// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set. 
void find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, HTuple hv_Mode, 
    HTuple *hv_SampleIndices);
// Chapter: OCR / Deep OCR
// Short Description: Find invalid deep ocr recognition samples. 
void find_invalid_samples_dl_ocr_recognition (HTuple hv_Samples, HTuple hv_DLModelHandle, 
    HTuple hv_GenericParam, HTuple *hv_Indices, HTuple *hv_Reasons);
// Chapter: OCR / Deep OCR
// Short Description: Generate characters statistics from the dataset and the alphabet. 
void gen_dl_dataset_ocr_recognition_statistics (HTuple hv_DLDataset, HTuple *hv_CharStats);
// Chapter: Deep Learning / Model
// Short Description: Return the DLSample dictionaries for given sample indices of a DLDataset. 
void gen_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple hv_RestrictKeysDLSample, 
    HTuple hv_GenParam, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Model
// Short Description: Store the given images in a tuple of dictionaries DLSamples. 
void gen_dl_samples_from_images (HObject ho_Images, HTuple *hv_DLSampleBatch);
// Chapter: OCR / Deep OCR
// Short Description: Provide a class mapping based on a DLDataset 
void gen_ocr_detection_class_id_mapping (HTuple hv_DLDataset, HTuple *hv_ClassToClassIndex);
// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Get the 'image_id' for each annotation for a given ThreadIndex. 
void get_dl_dataset_from_coco_annotation_image_id (HTuple hv_AnnotationList, HTuple hv_AnnotationKeys, 
    HTuple hv_NumKeysPerThread, HTuple hv_UniqueIndex, HTuple *hv_AnnotImageIDsOutput, 
    HTuple *hv_Exception);
// Chapter: File / Misc
// Short Description: Find a matching file in a list of files for a given file and return the index. 
void get_matching_file_index (HTuple hv_FileNames, HTuple hv_FileDirectories, HTuple hv_FileNameToMatch, 
    HTuple hv_FileDirectoryToMatch, HTuple hv_FileExtensionToMatch, HTuple *hv_FileMatchIndex);
// Chapter: Deep Learning / Model
// Short Description: This procedure determines the common directory part CommonDir between ImageDir and ImageDirectories and places the relative part from ImageDirectories into ImageDirectoriesRelative. 
void get_relative_image_directories (HTuple hv_ImageDir, HTuple hv_ImageDirectories, 
    HTuple *hv_CommonDir, HTuple *hv_ImageDirectoriesRelative);
// Chapter: File / Misc
void images_exist (HTuple hv_ImageList);
// Chapter: Deep Learning / Model
// Short Description: Generate various image lists and corresponding annotation file list. 
void list_image_and_annotation_files (HTuple hv_Type, HTuple hv_ImageDir, HTuple hv_XYZDir, 
    HTuple hv_NormalsDir, HTuple hv_AnnotationDir, HTuple hv_ImageListIn, HTuple hv_GenParam, 
    HTuple *hv_ImageListOut, HTuple *hv_XYZListOut, HTuple *hv_NormalsListOut, HTuple *hv_AnnotationListOut, 
    HTuple *hv_LabelListOut);
// Chapter: File / Misc
// Short Description: Get the base names, extensions and directories of image files in the specified directory or image list. 
void prepare_image_lists (HTuple hv_ImageDir, HTuple hv_ImageListIn, HTuple hv_ImageSubDirs, 
    HTuple hv_FileNameImageOnly, HTuple hv_Extensions, HTuple *hv_ImageBaseNames, 
    HTuple *hv_ImageBaseNamesToMatch, HTuple *hv_ImageExtensions, HTuple *hv_ImageDirectories, 
    HTuple *hv_ImageDirectoriesRel);
// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Generate a DLDataset dictionary for 3D Gripping Point Detection. 
void read_dl_dataset_3d_gripping_point_detection (HTuple hv_ImageBaseDir, HTuple hv_SegmentationDir, 
    HTuple hv_ClassIDs, HTuple hv_GenParam, HTuple *hv_DLDataset);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Generate a DLDataset dictionary for anomaly detection or Global Context Anomaly Detection. 
void read_dl_dataset_anomaly (HTuple hv_ImageDir, HTuple hv_AnomalyDir, HTuple hv_ImageList, 
    HTuple hv_AnomalyList, HTuple hv_GenParam, HTuple *hv_DLDataset);
// Chapter: Deep Learning / Classification
// Short Description: Generate a DLDataset dictionary for classification. 
void read_dl_dataset_classification (HTuple hv_RawImageFolder, HTuple hv_LabelSource, 
    HTuple *hv_DLDataset);
// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Read the COCO file and convert it to the dictionary DLDataset. 
void read_dl_dataset_from_coco (HTuple hv_CocoFileName, HTuple hv_ImageDir, HTuple hv_GenParam, 
    HTuple *hv_DLDataset);
// Chapter: OCR / Deep OCR
// Short Description: Read a dictionary file and return a dl dataset. 
void read_dl_dataset_ocr_detection (HTuple hv_DatasetFilename, HTuple hv_ImageDir, 
    HTuple hv_GenParam, HTuple *hv_DLDataset, HTuple *hv_InvalidSamplesIndices, HTuple *hv_InvalidSamplesReasons);
// Chapter: OCR / Deep OCR
// Short Description: Read a dictionary file and return a dl dataset. 
void read_dl_dataset_ocr_recognition (HTuple hv_FileName, HTuple hv_ImageDir, HTuple hv_GenParam, 
    HTuple *hv_DLDataset);
// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Generate a DLDataset dictionary for semantic segmentation. 
void read_dl_dataset_segmentation (HTuple hv_ImageDir, HTuple hv_SegmentationDir, 
    HTuple hv_ClassNames, HTuple hv_ClassIDs, HTuple hv_ImageList, HTuple hv_SegmentationList, 
    HTuple hv_GenParam, HTuple *hv_DLDataset);
// Chapter: Deep Learning / Model
// Short Description: Read the dictionaries DLSamples from files. 
void read_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Model
// Short Description: Split the samples into training, validation, and test subsets. 
void split_dl_dataset (HTuple hv_DLDataset, HTuple hv_TrainingPercent, HTuple hv_ValidationPercent, 
    HTuple hv_GenParam);
// Chapter: Deep Learning / Model
// Short Description: Write the dictionaries of the samples in DLSampleBatch to hdict files and store the paths in DLDataset. 
void write_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple hv_DLSampleBatch, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue);

// Generated stubs for parallel procedure calls. Wrapped in name
// space to avoid name conflicts with actual procedure names
namespace HDevExportCpp
{
// Parallel execution wrapper for create_dl_dataset_3d_gripping_point_detection_samples(...) 
static void* _hcppthread_create_dl_dataset_3d_gripping_point_detection_samples(void *hcthread);
// Parallel execution wrapper for create_dl_dataset_anomaly_samples(...) 
static void* _hcppthread_create_dl_dataset_anomaly_samples(void *hcthread);
// Parallel execution wrapper for create_dl_dataset_classification_samples(...) 
static void* _hcppthread_create_dl_dataset_classification_samples(void *hcthread);
// Parallel execution wrapper for get_dl_dataset_from_coco_annotation_image_id(...) 
static void* _hcppthread_get_dl_dataset_from_coco_annotation_image_id(void *hcthread);
// Parallel execution wrapper for create_dl_dataset_from_coco_samples(...) 
static void* _hcppthread_create_dl_dataset_from_coco_samples(void *hcthread);
// Parallel execution wrapper for create_dl_dataset_segmentation_samples(...) 
static void* _hcppthread_create_dl_dataset_segmentation_samples(void *hcthread);
}

// Procedures 
// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Convert a COCO runlength encoding into a HALCON region. 
void convert_coco_rle_to_region (HObject *ho_Region, HTuple hv_RunLengthEncoding, 
    HTuple hv_Width, HTuple hv_Height)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_StartPos, hv_PosY1, hv_PosY2, hv_PosX1;
  HTuple  hv_PosX2, hv_PY1, hv_PY2, hv_PX1, hv_PX2, hv_SameLine;
  HTuple  hv_NotSplit, hv_Split, hv_RunY, hv_RunStartX, hv_RunEndX;
  HTuple  hv_Pos, hv_Index, hv_RunIdx, hv_Y;

  //Convert a COCO runlength encoding (RLE) into a HALCON region.
  //
  //Compute the start position of every run.
  hv_StartPos.Clear();
  hv_StartPos[0] = 0;
  hv_StartPos.Append(hv_RunLengthEncoding.TupleCumul());
  hv_PosY1 = hv_StartPos/hv_Height;
  hv_PosY2 = (hv_StartPos-1)/hv_Height;
  hv_PosX1 = hv_StartPos%hv_Height;
  hv_PosX2 = (hv_StartPos-1)%hv_Height;
  //
  hv_PY1 = ((const HTuple&)hv_PosY1)[HTuple::TupleGenSequence(1,(hv_RunLengthEncoding.TupleLength())-1,2)];
  hv_PY2 = ((const HTuple&)hv_PosY2)[HTuple::TupleGenSequence(2,hv_RunLengthEncoding.TupleLength(),2)];
  hv_PX1 = ((const HTuple&)hv_PosX1)[HTuple::TupleGenSequence(1,(hv_RunLengthEncoding.TupleLength())-1,2)];
  hv_PX2 = ((const HTuple&)hv_PosX2)[HTuple::TupleGenSequence(2,hv_RunLengthEncoding.TupleLength(),2)];
  //
  //Runs that cross the image boundary must be split up, since they are not
  //supported by the HALCON runlength encoding.
  hv_SameLine = hv_PY1.TupleEqualElem(hv_PY2);
  hv_NotSplit = hv_SameLine.TupleFind(1);
  hv_Split = hv_SameLine.TupleFind(0);
  //
  if (0 != (HTuple(int(hv_NotSplit!=-1)).TupleAnd(int(hv_NotSplit!=HTuple()))))
  {
    //Process runlengths that do not cross the image boundary.
    hv_RunY = HTuple(hv_PY1[hv_NotSplit]);
    hv_RunStartX = HTuple(hv_PX1[hv_NotSplit]);
    hv_RunEndX = HTuple(hv_PX2[hv_NotSplit]);
  }
  else
  {
    hv_RunY = HTuple();
    hv_RunStartX = HTuple();
    hv_RunEndX = HTuple();
  }
  hv_Pos = hv_RunY.TupleLength();
  //
  if (0 != (HTuple(int(hv_Split!=-1)).TupleAnd(int(hv_Split!=HTuple()))))
  {
    //Process runlengths that cross the image boundary by splitting them up.
    //
    //Pre-allocate the tuples.
    hv_RunY = hv_RunY.TupleConcat(HTuple(3*(hv_Split.TupleLength()),0));
    hv_RunStartX = hv_RunStartX.TupleConcat(HTuple(3*(hv_Split.TupleLength()),0));
    hv_RunEndX = hv_RunEndX.TupleConcat(HTuple(3*(hv_Split.TupleLength()),0));
    //
    {
    HTuple end_val40 = (hv_Split.TupleLength())-1;
    HTuple step_val40 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val40, step_val40); hv_Index += step_val40)
    {
      hv_RunIdx = HTuple(hv_Split[hv_Index]);
      //First run: From start of runlength to end of image.
      hv_RunY[hv_Pos] = HTuple(hv_PY1[hv_RunIdx]);
      hv_RunStartX[hv_Pos] = HTuple(hv_PX1[hv_RunIdx]);
      hv_RunEndX[hv_Pos] = hv_Height-1;
      hv_Pos += 1;
      //Mid run(s) that fill complete lines.
      {
      HTuple end_val48 = HTuple(hv_PY2[hv_RunIdx])-1;
      HTuple step_val48 = 1;
      for (hv_Y=HTuple(hv_PY1[hv_RunIdx])+1; hv_Y.Continue(end_val48, step_val48); hv_Y += step_val48)
      {
        hv_RunY[hv_Pos] = hv_Y;
        hv_RunStartX[hv_Pos] = 0;
        hv_RunEndX[hv_Pos] = hv_Height-1;
        hv_Pos += 1;
      }
      }
      //Last run: From start of image to end of runlength.
      hv_RunY[hv_Pos] = HTuple(hv_PY2[hv_RunIdx]);
      hv_RunStartX[hv_Pos] = 0;
      hv_RunEndX[hv_Pos] = HTuple(hv_PX2[hv_RunIdx]);
      hv_Pos += 1;
    }
    }
    //
    //Remove unnecessary runlengths at end of tuple.
    if (0 != (int(0==hv_Pos)))
    {
      hv_RunY = HTuple();
      hv_RunStartX = HTuple();
      hv_RunEndX = HTuple();
    }
    else if (0 != (int(hv_Pos<(hv_RunY.TupleLength()))))
    {
      hv_RunY = hv_RunY.TupleSelectRange(0,hv_Pos-1);
      hv_RunStartX = hv_RunStartX.TupleSelectRange(0,hv_Pos-1);
      hv_RunEndX = hv_RunEndX.TupleSelectRange(0,hv_Pos-1);
    }
  }
  //
  GenRegionRuns(&(*ho_Region), hv_RunY, hv_RunStartX, hv_RunEndX);
  //
  //The mask is given in column-major order, but HALCON uses row-major
  //order. To compensate, we need to transpose the region.
  MirrorRegion((*ho_Region), &(*ho_Region), "diagonal", 0);
  //
  return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Convert a COCO segmentation into a HALCON region. 
void convert_coco_segmentation_to_region (HObject *ho_Region, HTuple hv_Segmentation)
{

  // Local iconic variables
  HObject  ho_Contour, ho_CurrRegion;

  // Local control variables
  HTuple  hv_Keys, hv_Sizes, hv_Height, hv_Width;
  HTuple  hv_MaxDim, hv_CurrWidth, hv_CurrHeight, hv_Counts;
  HTuple  hv_RunLengthEncoding, hv_CountsKeys, hv_PolygonIndex;
  HTuple  hv_PolygonData, hv_PolyKeys, hv_Polygon, hv_NumPoints;
  HTuple  hv_Cols, hv_Rows, hv_OldNeighborhood;

  //This procedure converts a COCO 'segmentation' sub-Dictionary into a HALCON region.
  //
  //The segmentation field can be a runlength encoded (RLE) region or a list of polygons.
  GetDictParam(hv_Segmentation, "keys", HTuple(), &hv_Keys);
  if (0 != (int((hv_Keys.TupleIntersection("counts"))!=HTuple())))
  {
    //Run-length encoded region.
    GetDictTuple(hv_Segmentation, "size", &hv_Sizes);
    GetDictTuple(hv_Sizes, 0, &hv_Height);
    GetDictTuple(hv_Sizes, 1, &hv_Width);
    //Adapt region clipping if necessary.
    hv_MaxDim = hv_Width.TupleMax2(hv_Height);
    GetSystem("width", &hv_CurrWidth);
    if (0 != (int(hv_CurrWidth<hv_MaxDim)))
    {
      SetSystem("width", hv_MaxDim);
    }
    GetSystem("tsp_width", &hv_CurrWidth);
    if (0 != (int(hv_CurrWidth<hv_MaxDim)))
    {
      SetSystem("tsp_width", hv_MaxDim);
    }
    GetSystem("height", &hv_CurrHeight);
    if (0 != (int(hv_CurrHeight<hv_MaxDim)))
    {
      SetSystem("height", hv_MaxDim);
    }
    GetSystem("tsp_height", &hv_CurrHeight);
    if (0 != (int(hv_CurrHeight<hv_MaxDim)))
    {
      SetSystem("tsp_height", hv_MaxDim);
    }
    //Get and process region.
    GetDictTuple(hv_Segmentation, "counts", &hv_Counts);
    if (0 != (int((hv_Counts.TupleSemType())==HTuple("string"))))
    {
      //Compressed RLE string.
      decompress_coco_rle(hv_Counts, hv_Width, hv_Height, &hv_RunLengthEncoding);
      convert_coco_rle_to_region(&(*ho_Region), hv_RunLengthEncoding, hv_Width, hv_Height);
    }
    else if (0 != (int((hv_Counts.TupleSemType())==HTuple("dict"))))
    {
      //Uncompressed RLE.
      GetDictParam(hv_Counts, "keys", HTuple(), &hv_CountsKeys);
      GetDictTuple(hv_Counts, HTuple::TupleGenSequence(0,(hv_CountsKeys.TupleLength())-1,1), 
          &hv_RunLengthEncoding);
      convert_coco_rle_to_region(&(*ho_Region), hv_RunLengthEncoding, hv_Width, hv_Height);
    }
    else
    {
      throw HException("Unexpected type in segmentation-field");
    }
  }
  else if (0 != (int((hv_Keys.TupleSort())==HTuple::TupleGenSequence(0,(hv_Keys.TupleLength())-1,1))))
  {
    //A list of polygons.
    GenEmptyObj(&(*ho_Region));
    {
    HTuple end_val44 = (hv_Keys.TupleLength())-1;
    HTuple step_val44 = 1;
    for (hv_PolygonIndex=0; hv_PolygonIndex.Continue(end_val44, step_val44); hv_PolygonIndex += step_val44)
    {
      GetDictTuple(hv_Segmentation, hv_PolygonIndex, &hv_PolygonData);
      GetDictParam(hv_PolygonData, "keys", HTuple(), &hv_PolyKeys);
      GetDictTuple(hv_PolygonData, HTuple::TupleGenSequence(0,(hv_PolyKeys.TupleLength())-1,1), 
          &hv_Polygon);
      if (0 != (int((hv_Polygon.TupleLength())>0)))
      {
        //Adapt region clipping if necessary.
        hv_MaxDim = ((hv_Polygon.TupleMax()).TupleInt())+1;
        GetSystem("width", &hv_CurrWidth);
        if (0 != (int(hv_CurrWidth<hv_MaxDim)))
        {
          SetSystem("width", hv_MaxDim);
        }
        GetSystem("tsp_width", &hv_CurrWidth);
        if (0 != (int(hv_CurrWidth<hv_MaxDim)))
        {
          SetSystem("tsp_width", hv_MaxDim);
        }
        GetSystem("height", &hv_CurrHeight);
        if (0 != (int(hv_CurrHeight<hv_MaxDim)))
        {
          SetSystem("height", hv_MaxDim);
        }
        GetSystem("tsp_height", &hv_CurrHeight);
        if (0 != (int(hv_CurrHeight<hv_MaxDim)))
        {
          SetSystem("tsp_height", hv_MaxDim);
        }
        //The polygon is in the format [x0,y0,x1,y1,...,xn,yn]
        hv_NumPoints = (hv_Polygon.TupleLength())/2;
        hv_Cols = ((const HTuple&)hv_Polygon)[HTuple::TupleGenSequence(0,(hv_Polygon.TupleLength())-1,2)];
        hv_Rows = ((const HTuple&)hv_Polygon)[HTuple::TupleGenSequence(1,(hv_Polygon.TupleLength())-1,2)];
        GenContourPolygonXld(&ho_Contour, hv_Rows, hv_Cols);
        //Simulate COCO's polygon to region transformation
        GetSystem("neighborhood", &hv_OldNeighborhood);
        SetSystem("neighborhood", 4);
        GenRegionContourXld(ho_Contour, &ho_CurrRegion, "filled");
        SetSystem("neighborhood", hv_OldNeighborhood);
        ErosionCircle(ho_CurrRegion, &ho_CurrRegion, 1.0);
        //
        ConcatObj((*ho_Region), ho_CurrRegion, &(*ho_Region));
      }
    }
    }
    //
    //Multiple polygons might be used to represent a disconnected region.
    Union1((*ho_Region), &(*ho_Region));
  }
  else
  {
    throw HException("Unexpected data in segmentation-field");
  }
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Convert a given ocr detection dataset to a word based recognition dataset. 
void convert_dl_dataset_ocr_detection_to_recognition (HTuple hv_DLDatasetOCRSource, 
    HTuple *hv_DLDatasetOCRRecognition)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Source, hv_GenParamValue, hv_WordClassId;
  HTuple  hv_ClassNamedWordIdx, hv_CustomDataExists, hv_I;
  HTuple  hv_CustomData, hv_HasIsTextClass, hv_Dest, hv_TransferKeys;
  HTuple  hv_SampleIndex, hv_SampleSource, hv_LabelCustomDataExists;
  HTuple  hv_LabelCustomData, hv_J, hv_Data, hv_Index, hv_SampleDest;
  HTuple  hv_SplitExists, hv_K, hv_Key, hv_Tuple, hv_NumSamples;
  HTuple  hv___Tmp_Ctrl_0, hv___Tmp_Ctrl_Type;

  hv_Source = hv_DLDatasetOCRSource;

  GetDictParam(hv_Source, "keys", HTuple(), &hv_GenParamValue);

  //Collect all text class ids.
  hv_WordClassId = HTuple();
  TupleFind(hv_Source.TupleGetDictTuple("class_names"), "word", &hv_ClassNamedWordIdx);
  if (0 != (int(hv_ClassNamedWordIdx!=-1)))
  {
    hv_WordClassId = hv_WordClassId.TupleConcat(HTuple((hv_Source.TupleGetDictTuple("class_ids"))[hv_ClassNamedWordIdx]));
  }
  else
  {
    throw HException("The input dataset has no class named \"word\".");
  }
  //Next collect all classes that have a custom text label.
  GetDictParam(hv_Source, "key_exists", "class_custom_data", &hv_CustomDataExists);
  if (0 != hv_CustomDataExists)
  {
    {
    HTuple end_val15 = ((hv_Source.TupleGetDictTuple("class_custom_data")).TupleLength())-1;
    HTuple step_val15 = 1;
    for (hv_I=0; hv_I.Continue(end_val15, step_val15); hv_I += step_val15)
    {
      hv_CustomData = HTuple((hv_Source.TupleGetDictTuple("class_custom_data"))[hv_I]);
      GetDictParam(hv_CustomData, "key_exists", "is_text_class", &hv_HasIsTextClass);
      if (0 != (hv_HasIsTextClass.TupleNot()))
      {
        continue;
      }
      if (0 != (hv_CustomData.TupleGetDictTuple("is_text_class")))
      {
        //Add class id to the list.
        hv_WordClassId = hv_WordClassId.TupleConcat(HTuple((hv_Source.TupleGetDictTuple("class_ids"))[hv_I]));
      }
    }
    }
  }
  //Remove duplicates.
  TupleSort(hv_WordClassId, &hv_WordClassId);
  TupleUniq(hv_WordClassId, &hv_WordClassId);
  if (0 != (int((hv_WordClassId.TupleLength())==0)))
  {
    throw HException("The input dataset has no class named \"word\" or a class marked as a text class.");
  }

  CreateDict(&hv_Dest);
  GetDictParam(hv_Source, "key_data_type", "image_dir", &hv___Tmp_Ctrl_Type);
  if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
  {
    SetDictObject(hv_Source.TupleGetDictObject("image_dir"), hv_Dest, "image_dir");
  }
  else
  {
    SetDictTuple(hv_Dest, "image_dir", hv_Source.TupleGetDictTuple("image_dir"));
  }

  TupleGenConst((hv_Source.TupleGetDictTuple("samples")).TupleLength(), HTuple::TupleConstant("HNULL"), 
      &hv___Tmp_Ctrl_0);
  SetDictTuple(hv_Dest, "samples", hv___Tmp_Ctrl_0);
  hv_TransferKeys.Clear();
  hv_TransferKeys[0] = "bbox_col";
  hv_TransferKeys[1] = "bbox_row";
  hv_TransferKeys[2] = "bbox_phi";
  hv_TransferKeys[3] = "bbox_length1";
  hv_TransferKeys[4] = "bbox_length2";

  hv_SampleIndex = 0;
  {
  HTuple end_val47 = ((hv_Source.TupleGetDictTuple("samples")).TupleLength())-1;
  HTuple step_val47 = 1;
  for (hv_I=0; hv_I.Continue(end_val47, step_val47); hv_I += step_val47)
  {
    hv_SampleSource = HTuple((hv_Source.TupleGetDictTuple("samples"))[hv_I]);
    GetDictParam(hv_SampleSource, "key_exists", "label_custom_data", &hv_LabelCustomDataExists);
    if (0 != (hv_LabelCustomDataExists.TupleNot()))
    {
      continue;
    }
    GetDictTuple(hv_SampleSource, "label_custom_data", &hv_LabelCustomData);
    {
    HTuple end_val54 = ((hv_SampleSource.TupleGetDictTuple("bbox_label_id")).TupleLength())-1;
    HTuple step_val54 = 1;
    for (hv_J=0; hv_J.Continue(end_val54, step_val54); hv_J += step_val54)
    {
      hv_Data = HTuple(hv_LabelCustomData[hv_J]);
      if (0 != (int(hv_Data==HTuple::TupleConstant("HNULL"))))
      {
        continue;
      }
      TupleFindFirst(hv_WordClassId, HTuple((hv_SampleSource.TupleGetDictTuple("bbox_label_id"))[hv_J]), 
          &hv_Index);
      if (0 != (int(hv_Index==-1)))
      {
        continue;
      }
      CreateDict(&hv_SampleDest);
      GetDictParam(hv_SampleSource, "key_data_type", "image_file_name", &hv___Tmp_Ctrl_Type);
      if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
      {
        SetDictObject(hv_SampleSource.TupleGetDictObject("image_file_name"), hv_SampleDest, 
            "image_file_name");
      }
      else
      {
        SetDictTuple(hv_SampleDest, "image_file_name", hv_SampleSource.TupleGetDictTuple("image_file_name"));
      }
      GetDictParam(hv_SampleSource, "key_exists", "split", &hv_SplitExists);
      if (0 != hv_SplitExists)
      {
        GetDictParam(hv_SampleSource, "key_data_type", "split", &hv___Tmp_Ctrl_Type);
        if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
        {
          SetDictObject(hv_SampleSource.TupleGetDictObject("split"), hv_SampleDest, 
              "split");
        }
        else
        {
          SetDictTuple(hv_SampleDest, "split", hv_SampleSource.TupleGetDictTuple("split"));
        }
      }
      {
      HTuple end_val79 = (hv_TransferKeys.TupleLength())-1;
      HTuple step_val79 = 1;
      for (hv_K=0; hv_K.Continue(end_val79, step_val79); hv_K += step_val79)
      {
        hv_Key = HTuple(hv_TransferKeys[hv_K]);
        GetDictTuple(hv_SampleSource, hv_Key, &hv_Tuple);
        SetDictTuple(hv_SampleDest, hv_Key, HTuple(hv_Tuple[hv_J]));
      }
      }
      GetDictTuple(hv_Data, "text", &hv___Tmp_Ctrl_0);
      SetDictTuple(hv_SampleDest, "word", hv___Tmp_Ctrl_0);
      GetDictParam(hv_SampleSource, "key_data_type", "image_id", &hv___Tmp_Ctrl_Type);
      if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
      {
        SetDictObject(hv_SampleSource.TupleGetDictObject("image_id"), hv_SampleDest, 
            "image_id_origin");
      }
      else
      {
        SetDictTuple(hv_SampleDest, "image_id_origin", hv_SampleSource.TupleGetDictTuple("image_id"));
      }
      SetDictTuple(hv_SampleDest, "image_id", hv_SampleIndex);
      SetDictTupleAt(hv_Dest, "samples", hv_SampleIndex, hv_SampleDest);
      hv_SampleIndex += 1;
    }
    }
  }
  }
  hv_NumSamples = hv_SampleIndex;
  SetDictTuple(hv_Dest, "samples", (hv_Dest.TupleGetDictTuple("samples")).TupleSelectRange(0,hv_NumSamples-1));
  (*hv_DLDatasetOCRRecognition) = hv_Dest;

}

// Chapter: Deep Learning / Model
// Short Description: Create a dict which maps class IDs to class indices. 
void create_dl_class_id_mapping (HTuple hv_ClassIDs, HTuple *hv_ClassIDsToClassIndex)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Index, hv_ID;

  //Create a dict that maps ClassIDs to their Index
  CreateDict(&(*hv_ClassIDsToClassIndex));
  {
  HTuple end_val2 = (hv_ClassIDs.TupleLength())-1;
  HTuple step_val2 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val2, step_val2); hv_Index += step_val2)
  {
    hv_ID = HTuple(hv_ClassIDs[hv_Index]);
    SetDictTuple((*hv_ClassIDsToClassIndex), hv_ID, hv_Index);
  }
  }
  return;
}

// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Create a block of 3D Gripping Point Detection samples for a DLDataset. 
void create_dl_dataset_3d_gripping_point_detection_samples (HTuple hv_ImageList, 
    HTuple hv_XYZList, HTuple hv_NormalsList, HTuple hv_SegmentationList, HTuple hv_NumSamplesPerThread, 
    HTuple hv_UniqueIndex, HTuple *hv_SamplesOutput)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_SampleIndex, hv_Sample, hv_ImageID;

  //This procedure creates a block of samples for a given thread.
  //
  TupleGenConst(hv_NumSamplesPerThread, "", &(*hv_SamplesOutput));
  //Loop over samples.
  {
  HTuple end_val4 = hv_NumSamplesPerThread-1;
  HTuple step_val4 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val4, step_val4); hv_SampleIndex += step_val4)
  {
    //Create the dictionary Sample.
    CreateDict(&hv_Sample);
    //Set information about this sample.
    hv_ImageID = hv_UniqueIndex;
    SetDictTuple(hv_Sample, "image_id", hv_ImageID);
    hv_UniqueIndex += 1;
    SetDictTuple(hv_Sample, "image_file_name", HTuple(hv_ImageList[hv_SampleIndex]));
    SetDictTuple(hv_Sample, "xyz_file_name", HTuple(hv_XYZList[hv_SampleIndex]));
    if (0 != (int((hv_NormalsList.TupleLength())>0)))
    {
      SetDictTuple(hv_Sample, "normals_file_name", HTuple(hv_NormalsList[hv_SampleIndex]));
    }
    SetDictTuple(hv_Sample, "segmentation_file_name", HTuple(hv_SegmentationList[hv_SampleIndex]));
    //
    //Append this sample.
    (*hv_SamplesOutput)[hv_SampleIndex] = hv_Sample;
  }
  }
  //
  return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Create a block of anomaly samples for a DLDataset. 
void create_dl_dataset_anomaly_samples (HTuple hv_ImageList, HTuple hv_LabelList, 
    HTuple hv_AnomalyList, HTuple hv_AnomalyDirGiven, HTuple hv_NumSamplesPerThread, 
    HTuple hv_UniqueIndex, HTuple *hv_SamplesOutput, HTuple *hv_Exception)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_SampleIndex, hv_Sample, hv_Label, hv_AnomalyFileName;

  //This procedure creates a block of samples for a given thread.
  TupleGenConst(hv_NumSamplesPerThread, "", &(*hv_SamplesOutput));
  (*hv_Exception) = HTuple();
  //
  //Loop over samples.
  {
  HTuple end_val5 = hv_NumSamplesPerThread-1;
  HTuple step_val5 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val5, step_val5); hv_SampleIndex += step_val5)
  {
    //
    //Create the dictionary Sample.
    CreateDict(&hv_Sample);
    //
    //Set information about this sample.
    SetDictTuple(hv_Sample, "image_id", hv_UniqueIndex);
    SetDictTuple(hv_Sample, "image_file_name", HTuple(hv_ImageList[hv_SampleIndex]));
    hv_UniqueIndex += 1;
    //
    hv_Label = HTuple(hv_LabelList[hv_SampleIndex]);
    if (0 != (int(hv_Label==HTuple(""))))
    {
      (*hv_Exception) = "Could not determine label for image: "+HTuple(hv_ImageList[hv_SampleIndex]);
      return;
    }
    //
    //Match for good labels.
    if (0 != (HTuple(int((hv_Label.TupleRegexpMatch((HTuple("^ok$").Append("ignore_case"))))!=HTuple(""))).TupleOr(int((hv_Label.TupleRegexpMatch((HTuple("^good$").Append("ignore_case"))))!=HTuple("")))))
    {
      SetDictTuple(hv_Sample, "anomaly_label", "ok");
    }
    else
    {
      SetDictTuple(hv_Sample, "anomaly_label", "nok");
    }
    //
    //Check if sample has an anomaly annotation.
    if (0 != hv_AnomalyDirGiven)
    {
      hv_AnomalyFileName = HTuple(hv_AnomalyList[hv_SampleIndex]);
      if (0 != (int(hv_AnomalyFileName!=HTuple(""))))
      {
        SetDictTuple(hv_Sample, "anomaly_file_name", hv_AnomalyFileName);
      }
    }
    //
    //Append this sample.
    (*hv_SamplesOutput)[hv_SampleIndex] = hv_Sample;
  }
  }
  //
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Create a block of classification samples for a DLDataset. 
void create_dl_dataset_classification_samples (HTuple hv_ImageFiles, HTuple hv_LabelIndices, 
    HTuple hv_RawImageFolder, HTuple hv_ImageDir, HTuple hv_NumSamplesPerThread, 
    HTuple hv_UniqueIndex, HTuple *hv_SamplesOutput)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_SampleIndex, hv_Sample, hv_ImageID;
  HTuple  hv_ImageFile, hv_Positions, hv_Position, hv_ImageDirLength;
  HTuple  hv_ImageFileName;

  //This procedure creates a block of samples for a given thread.
  TupleGenConst(hv_NumSamplesPerThread, "", &(*hv_SamplesOutput));
  //
  {
  HTuple end_val3 = hv_NumSamplesPerThread-1;
  HTuple step_val3 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val3, step_val3); hv_SampleIndex += step_val3)
  {
    //Create the dictionary Sample.
    CreateDict(&hv_Sample);
    //Set information about this sample.
    hv_ImageID = hv_UniqueIndex;
    SetDictTuple(hv_Sample, "image_id", hv_ImageID);
    hv_UniqueIndex += 1;
    //'image_file_name' has to be relative to ImageDir.
    hv_ImageFile = HTuple(hv_ImageFiles[hv_SampleIndex]);
    if (0 != (int(hv_ImageDir==HTuple("."))))
    {
      TupleStrstr(hv_ImageFile, hv_RawImageFolder, &hv_Positions);
      hv_Position = HTuple(hv_Positions[(hv_Positions.TupleNotEqualElem(-1)).TupleFind(1)]);
    }
    else
    {
      TupleStrstr(hv_ImageFile, hv_ImageDir, &hv_Position);
      TupleStrlen(hv_ImageDir, &hv_ImageDirLength);
      hv_Position = (hv_Position+hv_ImageDirLength)+1;
    }
    hv_ImageFileName = hv_ImageFile.TupleStrLastN(hv_Position);
    SetDictTuple(hv_Sample, "image_file_name", hv_ImageFileName);
    //Set class ID.
    SetDictTuple(hv_Sample, "image_label_id", HTuple(hv_LabelIndices[hv_SampleIndex]));
    //
    //Append this sample.
    (*hv_SamplesOutput)[hv_SampleIndex] = hv_Sample;
  }
  }
  //
  return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Create a block of samples for a given thread. 
void create_dl_dataset_from_coco_samples (HTuple hv_ImageList, HTuple hv_ImageKeys, 
    HTuple hv_ImageDir, HTuple hv_AnnotationList, HTuple hv_AnnotationKeys, HTuple hv_AnnotImageIDs, 
    HTuple hv_Purpose, HTuple hv_ReadOnlyNonCrowd, HTuple hv_ReadRawAnnotations, 
    HTuple hv_ReadMasks, HTuple hv_NumSamplesPerThread, HTuple hv_UniqueIndex, HTuple *hv_DLSamplesOutput, 
    HTuple *hv_Exception)
{

  // Local iconic variables
  HObject  ho_Segmentations, ho_AnnotRegion;

  // Local control variables
  HTuple  hv_Index, hv_Image, hv_ImageName, hv_ImageID;
  HTuple  hv_ExceptionImage, hv_FileExists, hv_AnnotationIndicesThisImage;
  HTuple  hv_AnnotClassIDs, hv_AnnotBboxColumn1s, hv_AnnotBboxRow1s;
  HTuple  hv_AnnotBboxColumn2s, hv_AnnotBboxRow2s, hv_HaveSegmentations;
  HTuple  hv_AnnotationPerImage, hv_AnnotationKeysThisImage;
  HTuple  hv_AnnotIndexCounter, hv_AnnotIndex, hv_Annotation;
  HTuple  hv_IsCrowd, hv_ExceptionIsCrowd, hv_AnnotClassID;
  HTuple  hv_BBox, hv_AnnotBboxColumn1, hv_AnnotBboxRow1;
  HTuple  hv_AnnotBboxWidth, hv_AnnotBboxHeight, hv_ExceptionAnnot;
  HTuple  hv_Segmentation, hv_AnnotBboxRow2, hv_AnnotBboxColumn2;
  HTuple  hv_DLSample;

  //This procedure creates a block of samples for a given thread.
  TupleGenConst(hv_NumSamplesPerThread, "", &(*hv_DLSamplesOutput));
  (*hv_Exception) = HTuple();
  //
  //Iterate over the images and fill according sample.
  {
  HTuple end_val5 = hv_NumSamplesPerThread-1;
  HTuple step_val5 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val5, step_val5); hv_Index += step_val5)
  {
    //
    //Get the image information.
    try
    {
      GetDictTuple(hv_ImageList, HTuple(hv_ImageKeys[hv_Index]), &hv_Image);
      GetDictTuple(hv_Image, "file_name", &hv_ImageName);
      GetDictTuple(hv_Image, "id", &hv_ImageID);
    }
    // catch (ExceptionImage) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_ExceptionImage);
      (*hv_Exception) = ("COCO image number "+hv_UniqueIndex)+" does not contain id or file_name.";
      return;
    }
    //
    //Check that the image is found at the given location.
    FileExists(hv_ImageDir+hv_ImageName, &hv_FileExists);
    if (0 != (hv_FileExists.TupleNot()))
    {
      (*hv_Exception) = ((((("COCO image number "+hv_UniqueIndex)+" (id = ")+hv_ImageID)+") could not be found at the location ImageDir + file_name = ")+hv_ImageDir)+hv_ImageName;
      return;
    }
    //
    //Get the annotation data for the selected image.
    TupleFind(hv_AnnotImageIDs, hv_ImageID, &hv_AnnotationIndicesThisImage);
    if (0 != (int(hv_Purpose==HTuple("object_detection"))))
    {
      //For object detection, several annotations per image are possible.
      hv_AnnotClassIDs = HTuple();
      hv_AnnotBboxColumn1s = HTuple();
      hv_AnnotBboxRow1s = HTuple();
      hv_AnnotBboxColumn2s = HTuple();
      hv_AnnotBboxRow2s = HTuple();
      //0 == unknown, -1 == no segmentation annotations, 1 = with segmentation annotations.
      hv_HaveSegmentations = 0;
      GenEmptyObj(&ho_Segmentations);
    }
    if (0 != (int(hv_AnnotationIndicesThisImage==-1)))
    {
      //If no annotation was found for this image.
      hv_AnnotationPerImage = HTuple();
    }
    else
    {
      //Otherwise, process the annotations.
      hv_AnnotationKeysThisImage = HTuple(hv_AnnotationKeys[hv_AnnotationIndicesThisImage]);
      TupleGenConst(hv_AnnotationKeysThisImage.TupleLength(), HTuple::TupleConstant("HNULL"), 
          &hv_AnnotationPerImage);
      hv_AnnotIndexCounter = 0;
      {
      HTuple end_val45 = (hv_AnnotationKeysThisImage.TupleLength())-1;
      HTuple step_val45 = 1;
      for (hv_AnnotIndex=0; hv_AnnotIndex.Continue(end_val45, step_val45); hv_AnnotIndex += step_val45)
      {
        GetDictTuple(hv_AnnotationList, HTuple(hv_AnnotationKeysThisImage[hv_AnnotIndex]), 
            &hv_Annotation);
        //
        if (0 != (int(hv_Purpose==HTuple("object_detection"))))
        {
          try
          {
            GetDictTuple(hv_Annotation, "iscrowd", &hv_IsCrowd);
          }
          // catch (ExceptionIsCrowd) 
          catch (HException &HDevExpDefaultException)
          {
            HDevExpDefaultException.ToHTuple(&hv_ExceptionIsCrowd);
            //If IsCrowd is not set, we assume it is 0 and set IsCrowd=0.
            hv_IsCrowd = 0;
          }
          if (0 != (hv_ReadOnlyNonCrowd.TupleAnd(hv_IsCrowd)))
          {
            continue;
          }
          if (0 != hv_ReadRawAnnotations)
          {
            hv_AnnotationPerImage[hv_AnnotIndexCounter] = hv_Annotation;
          }
          try
          {
            GetDictTuple(hv_Annotation, "category_id", &hv_AnnotClassID);
            GetDictTuple(hv_Annotation, "bbox", &hv_BBox);
            GetDictTuple(hv_BBox, 0, &hv_AnnotBboxColumn1);
            GetDictTuple(hv_BBox, 1, &hv_AnnotBboxRow1);
            GetDictTuple(hv_BBox, 2, &hv_AnnotBboxWidth);
            GetDictTuple(hv_BBox, 3, &hv_AnnotBboxHeight);
          }
          // catch (ExceptionAnnot) 
          catch (HException &HDevExpDefaultException)
          {
            HDevExpDefaultException.ToHTuple(&hv_ExceptionAnnot);
            (*hv_Exception) = ((("A COCO annotation for the COCO image number "+hv_UniqueIndex)+" (id = ")+hv_ImageID)+") does not contain the entry category_id or correct bounding box.";
            return;
          }

          if (0 != hv_ReadMasks)
          {
            try
            {
              GetDictTuple(hv_Annotation, "segmentation", &hv_Segmentation);
              if (0 != (int(hv_HaveSegmentations==-1)))
              {
                (*hv_Exception) = ((("A COCO annotation for the COCO image number "+hv_UniqueIndex)+" (id = ")+hv_ImageID)+") has segmentation annotations only for some of its annotations.";
                return;
              }
              hv_HaveSegmentations = 1;
              try
              {
                convert_coco_segmentation_to_region(&ho_AnnotRegion, hv_Segmentation);
              }
              // catch (ExceptionAnnot) 
              catch (HException &HDevExpDefaultException)
              {
                HDevExpDefaultException.ToHTuple(&hv_ExceptionAnnot);
                (*hv_Exception) = ((("A COCO annotation for the COCO image number "+hv_UniqueIndex)+" (id = ")+hv_ImageID)+") does not contain a readable segmentation.";
                return;
              }
            }
            // catch (Exception) 
            catch (HException &HDevExpDefaultException)
            {
              HDevExpDefaultException.ToHTuple(&(*hv_Exception));
              if (0 != (int(hv_HaveSegmentations==1)))
              {
                //Some, but not all annotations have segmentations. This would mess up the indexing.
                (*hv_Exception) = ((("A COCO annotation for the COCO image number "+hv_UniqueIndex)+" (id = ")+hv_ImageID)+") has segmentation annotations only for some of its annotations.";
                return;
              }
              hv_HaveSegmentations = -1;
              (*hv_Exception) = HTuple();
            }
          }
          //Get the HALCON format for the bounding box coordinates.
          //COCO-format assumes that the origin of the coordinate-system
          //is shifted by (-.5, -.5) compared to the origin of the
          //HALCON coordinate-system.
          hv_AnnotBboxRow1 = hv_AnnotBboxRow1-0.5;
          hv_AnnotBboxColumn1 = hv_AnnotBboxColumn1-0.5;
          hv_AnnotBboxRow2 = hv_AnnotBboxRow1+hv_AnnotBboxHeight;
          hv_AnnotBboxColumn2 = hv_AnnotBboxColumn1+hv_AnnotBboxWidth;
          //Store the annotations.
          hv_AnnotClassIDs[hv_AnnotIndexCounter] = hv_AnnotClassID;
          hv_AnnotBboxColumn1s[hv_AnnotIndexCounter] = hv_AnnotBboxColumn1;
          hv_AnnotBboxRow1s[hv_AnnotIndexCounter] = hv_AnnotBboxRow1;
          hv_AnnotBboxColumn2s[hv_AnnotIndexCounter] = hv_AnnotBboxColumn2;
          hv_AnnotBboxRow2s[hv_AnnotIndexCounter] = hv_AnnotBboxRow2;
          if (0 != (int(hv_HaveSegmentations==1)))
          {
            InsertObj(ho_Segmentations, ho_AnnotRegion, &ho_Segmentations, hv_AnnotIndexCounter+1);
          }
          hv_AnnotIndexCounter += 1;
        }
      }
      }
    }
    //Generate the sample for this image.
    CreateDict(&hv_DLSample);
    SetDictTuple(hv_DLSample, "image_id", hv_ImageID);
    SetDictTuple(hv_DLSample, "image_file_name", hv_ImageName);
    if (0 != (int(hv_Purpose==HTuple("object_detection"))))
    {
      SetDictTuple(hv_DLSample, "bbox_row1", hv_AnnotBboxRow1s);
      SetDictTuple(hv_DLSample, "bbox_col1", hv_AnnotBboxColumn1s);
      SetDictTuple(hv_DLSample, "bbox_row2", hv_AnnotBboxRow2s);
      SetDictTuple(hv_DLSample, "bbox_col2", hv_AnnotBboxColumn2s);
      SetDictTuple(hv_DLSample, "bbox_label_id", hv_AnnotClassIDs);
      if (0 != hv_HaveSegmentations)
      {
        SetDictObject(ho_Segmentations, hv_DLSample, "mask");
      }
    }
    if (0 != hv_ReadRawAnnotations)
    {
      SetDictTuple(hv_DLSample, "coco_raw_annotations", hv_AnnotationPerImage);
    }
    //Remember the sample for this image.
    (*hv_DLSamplesOutput)[hv_Index] = hv_DLSample;
    hv_UniqueIndex += 1;
  }
  }
  //
  return;
}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Create a block of segmentation samples for a DLDataset. 
void create_dl_dataset_segmentation_samples (HTuple hv_ImageList, HTuple hv_SegmentationList, 
    HTuple hv_NumSamplesPerThread, HTuple hv_UniqueIndex, HTuple *hv_SamplesOutput)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_SampleIndex, hv_Sample, hv_ImageID;

  //This procedure creates a block of samples for a given thread.
  TupleGenConst(hv_NumSamplesPerThread, "", &(*hv_SamplesOutput));
  //Loop over samples.
  {
  HTuple end_val3 = hv_NumSamplesPerThread-1;
  HTuple step_val3 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val3, step_val3); hv_SampleIndex += step_val3)
  {
    //Create the dictionary Sample.
    CreateDict(&hv_Sample);
    //Set information about this sample.
    hv_ImageID = hv_UniqueIndex;
    SetDictTuple(hv_Sample, "image_id", hv_ImageID);
    hv_UniqueIndex += 1;
    SetDictTuple(hv_Sample, "image_file_name", HTuple(hv_ImageList[hv_SampleIndex]));
    SetDictTuple(hv_Sample, "segmentation_file_name", HTuple(hv_SegmentationList[hv_SampleIndex]));
    //
    //Append this sample.
    (*hv_SamplesOutput)[hv_SampleIndex] = hv_Sample;
  }
  }
  //
  return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Decompress a compressed COCO runlength encoding. 
void decompress_coco_rle (HTuple hv_CompressedRLE, HTuple hv_Width, HTuple hv_Height, 
    HTuple *hv_RunLengthEncoding)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Ords, hv_Chars, hv_HasMore, hv_IsLast;
  HTuple  hv_IsFirst, hv_BlockID, hv_BlockIDToFirst, hv_BlockIDToLast;
  HTuple  hv_k2, hv_k3, hv_k, hv_x_parts, hv_RunLengthEncoding2;
  HTuple  hv_LongerThanOne, hv_Index, hv_Block, hv_Index2;
  HTuple  hv_do_last_shift, hv_Tmp, hv_RCumulEvens, hv_RCumulOdds;
  HTuple  hv_Total;

  //Decompress a compressed COCO runlength encoding.
  TupleOrds(hv_CompressedRLE, &hv_Ords);
  hv_Chars = hv_Ords-48;
  hv_HasMore = (hv_Chars&0x20).TupleNotEqualElem(0);
  //
  //Compute the numbers encoded in the string.
  hv_IsLast = 1-hv_HasMore;
  hv_IsFirst.Clear();
  hv_IsFirst[0] = 1;
  hv_IsFirst.Append(1-(hv_HasMore.TupleSelectRange(0,(hv_HasMore.TupleLength())-2)));
  hv_BlockID = (hv_IsFirst.TupleCumul())-1;
  hv_BlockIDToFirst = hv_IsFirst.TupleFind(1);
  hv_BlockIDToLast = hv_IsLast.TupleFind(1);
  //
  hv_k2 = HTuple(hv_HasMore.TupleOr(hv_IsLast)).TupleAnd(hv_IsFirst.TupleNot());
  hv_k3 = hv_k2.TupleCumul();
  hv_k = hv_k3-HTuple(hv_k3[HTuple(hv_BlockIDToFirst[hv_BlockID])]);
  //
  hv_x_parts = ((hv_Chars&0x1f)<<(5*hv_k));
  //
  hv_RunLengthEncoding2 = HTuple(hv_x_parts[hv_BlockIDToFirst]);
  //
  //Process encodings that are longer than one character.
  hv_LongerThanOne = (hv_BlockIDToFirst.TupleNotEqualElem(hv_BlockIDToLast)).TupleFind(1);
  if (0 != (HTuple(int(hv_LongerThanOne!=HTuple())).TupleAnd(int(hv_LongerThanOne!=-1))))
  {
    {
    HTuple end_val23 = (hv_LongerThanOne.TupleLength())-1;
    HTuple step_val23 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val23, step_val23); hv_Index += step_val23)
    {
      hv_Block = HTuple(hv_LongerThanOne[hv_Index]);
      {
      HTuple end_val25 = HTuple(hv_BlockIDToLast[hv_Block]);
      HTuple step_val25 = 1;
      for (hv_Index2=HTuple(hv_BlockIDToFirst[hv_Block])+1; hv_Index2.Continue(end_val25, step_val25); hv_Index2 += step_val25)
      {
        hv_RunLengthEncoding2[hv_Block] = HTuple(hv_RunLengthEncoding2[hv_Block])|HTuple(hv_x_parts[hv_Index2]);
      }
      }
    }
    }
  }
  //
  //Apply the additional, optional - sign.
  hv_do_last_shift = (HTuple(hv_Chars[hv_BlockIDToLast])&0x10).TupleNotEqualElem(0);
  hv_RunLengthEncoding2 = hv_RunLengthEncoding2|(hv_do_last_shift*(-1<<(5*(1+HTuple(hv_k[hv_BlockIDToLast])))));
  //
  //For indices > 2, the final value is the delta to its previous value.
  hv_Tmp = ((const HTuple&)hv_RunLengthEncoding2)[0];
  hv_RunLengthEncoding2[0] = 0;
  hv_RCumulEvens = HTuple(hv_RunLengthEncoding2[HTuple::TupleGenSequence(0,(hv_RunLengthEncoding2.TupleLength())-1,2)]).TupleCumul();
  hv_RCumulOdds = HTuple(hv_RunLengthEncoding2[HTuple::TupleGenSequence(1,(hv_RunLengthEncoding2.TupleLength())-1,2)]).TupleCumul();
  (*hv_RunLengthEncoding)[HTuple::TupleGenSequence(1,(hv_RunLengthEncoding2.TupleLength())-1,2)] = hv_RCumulOdds;
  (*hv_RunLengthEncoding)[HTuple::TupleGenSequence(0,(hv_RunLengthEncoding2.TupleLength())-1,2)] = hv_RCumulEvens;
  (*hv_RunLengthEncoding)[0] = hv_Tmp;
  //
  //Sanity-check the size of the encoding
  hv_Total = (*hv_RunLengthEncoding).TupleSum();
  if (0 != (int(hv_Total>(hv_Width*hv_Height))))
  {
    throw HException("Invalid mask: Mask size exceeds image size");
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set. 
void find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, HTuple hv_Mode, 
    HTuple *hv_SampleIndices)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumKeyValues, hv_NumFound, hv_SampleIndex;
  HTuple  hv_Sample, hv_KeyExists, hv_Tuple, hv_Hit, hv_ValueIndex;
  HTuple  hv_Value;

  //
  //This procedure gets the indices of the samples that contain the
  //requested KeyName matching the requested KeyValue according to the Mode.
  //If there is no match, an empty tuple [] will be returned.
  //
  //Check input parameters.
  if (0 != (int((hv_KeyName.TupleLength())!=1)))
  {
    throw HException(HTuple("Invalid KeyName size: ")+(hv_KeyName.TupleLength()));
  }
  if (0 != (int((hv_Mode.TupleLength())!=1)))
  {
    throw HException(HTuple("Invalid Mode size: ")+(hv_Mode.TupleLength()));
  }
  if (0 != (HTuple(HTuple(int(hv_Mode!=HTuple("match"))).TupleAnd(int(hv_Mode!=HTuple("or")))).TupleAnd(int(hv_Mode!=HTuple("contain")))))
  {
    throw HException("Invalid Mode value: "+hv_Mode);
  }
  hv_NumKeyValues = hv_KeyValue.TupleLength();
  if (0 != (HTuple(int(hv_Mode==HTuple("contain"))).TupleAnd(int(hv_NumKeyValues<1))))
  {
    throw HException("Invalid KeyValue size for contain Mode: "+hv_NumKeyValues);
  }
  //
  //Find the indices.
  (*hv_SampleIndices) = HTuple(hv_Samples.TupleLength(),0);
  hv_NumFound = 0;
  //
  {
  HTuple end_val24 = (hv_Samples.TupleLength())-1;
  HTuple step_val24 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val24, step_val24); hv_SampleIndex += step_val24)
  {
    hv_Sample = HTuple(hv_Samples[hv_SampleIndex]);
    GetDictParam(hv_Sample, "key_exists", hv_KeyName, &hv_KeyExists);
    if (0 != hv_KeyExists)
    {
      GetDictTuple(hv_Sample, hv_KeyName, &hv_Tuple);
      if (0 != (int(hv_Mode==HTuple("match"))))
      {
        //Mode 'match': Tuple must be equal KeyValue.
        hv_Hit = int(hv_Tuple==hv_KeyValue);
      }
      else if (0 != (HTuple(int(hv_Mode==HTuple("or"))).TupleAnd(int((hv_Tuple.TupleLength())==1))))
      {
        //Mode 'or': Tuple must have only 1 element and it has to be equal to any of KeyValues elements.
        hv_Hit = int((hv_KeyValue.TupleFindFirst(hv_Tuple))>=0);
      }
      else if (0 != (int(hv_Mode==HTuple("contain"))))
      {
        //Mode 'contain': Tuple must contain any of the elements in KeyValue.
        {
        HTuple end_val37 = hv_NumKeyValues-1;
        HTuple step_val37 = 1;
        for (hv_ValueIndex=0; hv_ValueIndex.Continue(end_val37, step_val37); hv_ValueIndex += step_val37)
        {
          hv_Value = HTuple(hv_KeyValue[hv_ValueIndex]);
          hv_Hit = int((hv_Tuple.TupleFindFirst(hv_Value))>=0);
          if (0 != hv_Hit)
          {
            break;
          }
        }
        }
      }
      else
      {
        //Unsupported configuration.
        hv_Hit = 0;
      }
      if (0 != hv_Hit)
      {
        (*hv_SampleIndices)[hv_NumFound] = hv_SampleIndex;
        hv_NumFound += 1;
      }
    }
  }
  }
  (*hv_SampleIndices) = (*hv_SampleIndices).TupleSelectRange(0,hv_NumFound-1);
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Find invalid deep ocr recognition samples. 
void find_invalid_samples_dl_ocr_recognition (HTuple hv_Samples, HTuple hv_DLModelHandle, 
    HTuple hv_GenericParam, HTuple *hv_Indices, HTuple *hv_Reasons)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_KeyExists, hv_Alphabet, hv_ImageWidth;
  HTuple  hv_MaxWordLength, hv_InvalidSamples, hv_Words, hv_I;
  HTuple  hv_Word, hv_WordLengths, hv_Equal, hv_EmptyWordIndices;
  HTuple  hv_Greater, hv_TooLongWordIndices, hv_AlphabetDict;
  HTuple  hv_MissingCharIndices, hv_WordChars, hv_N, hv_WordCharArray;
  HTuple  hv_C, hv_CharExist, hv_MissingCharsReason, hv_TooLongWordReason;
  HTuple  hv_EmptyWordIndicesWordReason;

  if (0 != (int((hv_GenericParam.TupleLength())==0)))
  {
    //Use default values.
    CreateDict(&hv_GenericParam);
    SetDictTuple(hv_GenericParam, "pixel_per_char_estimate", 6.0);
  }
  else
  {
    GetDictParam(hv_GenericParam, "key_exists", "pixel_per_char_estimate", &hv_KeyExists);
    if (0 != (hv_KeyExists.TupleNot()))
    {
      SetDictTuple(hv_GenericParam, "pixel_per_char_estimate", 6.0);
    }
    SetDictTuple(hv_GenericParam, "pixel_per_char_estimate", (hv_GenericParam.TupleGetDictTuple("pixel_per_char_estimate")).TupleReal());
  }
  //
  GetDlModelParam(hv_DLModelHandle, "alphabet", &hv_Alphabet);
  GetDlModelParam(hv_DLModelHandle, "image_width", &hv_ImageWidth);
  hv_MaxWordLength = (((hv_ImageWidth.TupleReal())/((hv_GenericParam.TupleGetDictTuple("pixel_per_char_estimate")).TupleReal())).TupleCeil()).TupleInt();
  hv_InvalidSamples = HTuple();
  TupleGenConst(hv_Samples.TupleLength(), -1, &hv_Words);
  {
  HTuple end_val17 = (hv_Samples.TupleLength())-1;
  HTuple step_val17 = 1;
  for (hv_I=0; hv_I.Continue(end_val17, step_val17); hv_I += step_val17)
  {
    GetDictTuple(HTuple(hv_Samples[hv_I]), "word", &hv_Word);
    hv_Words[hv_I] = hv_Word;
  }
  }
  TupleStrlen(hv_Words, &hv_WordLengths);
  TupleEqualElem(hv_WordLengths, 0, &hv_Equal);
  TupleFind(hv_Equal, 1, &hv_EmptyWordIndices);
  if (0 != (int(hv_EmptyWordIndices==-1)))
  {
    hv_EmptyWordIndices = HTuple();
  }
  TupleGreaterElem(hv_WordLengths, hv_MaxWordLength, &hv_Greater);
  TupleFind(hv_Greater, 1, &hv_TooLongWordIndices);
  if (0 != (int(hv_TooLongWordIndices==-1)))
  {
    hv_TooLongWordIndices = HTuple();
  }
  CreateDict(&hv_AlphabetDict);
  {
  HTuple end_val33 = (hv_Alphabet.TupleLength())-1;
  HTuple step_val33 = 1;
  for (hv_I=0; hv_I.Continue(end_val33, step_val33); hv_I += step_val33)
  {
    SetDictTuple(hv_AlphabetDict, HTuple(hv_Alphabet[hv_I]), 1);
  }
  }
  //
  //Search for words that contain characters that are not part of the alphabet.
  TupleGenConst(hv_Words.TupleLength(), 0, &hv_MissingCharIndices);
  {
  HTuple end_val39 = (hv_Words.TupleLength())-1;
  HTuple step_val39 = 1;
  for (hv_I=0; hv_I.Continue(end_val39, step_val39); hv_I += step_val39)
  {
    hv_Word = HTuple(hv_Words[hv_I]);
    TupleUniq(hv_Word, &hv_WordChars);
    hv_N = hv_WordChars.TupleStrlen();
    if (0 != (int(hv_N==0)))
    {
      continue;
    }
    TupleGenConst(hv_N, "", &hv_WordCharArray);
    {
    HTuple end_val47 = hv_N-1;
    HTuple step_val47 = 1;
    for (hv_C=0; hv_C.Continue(end_val47, step_val47); hv_C += step_val47)
    {
      hv_WordCharArray[hv_C] = hv_WordChars.TupleStrBitSelect(hv_C);
    }
    }
    GetDictParam(hv_AlphabetDict, "key_exists", hv_WordCharArray, &hv_CharExist);
    TupleFind(hv_CharExist, 0, &(*hv_Indices));
    hv_MissingCharIndices[hv_I] = int((*hv_Indices)!=-1);
  }
  }
  TupleFind(hv_MissingCharIndices, 1, &hv_MissingCharIndices);
  if (0 != (int(hv_MissingCharIndices==-1)))
  {
    hv_MissingCharIndices = HTuple();
  }
  TupleGenConst(hv_MissingCharIndices.TupleLength(), "unknown char", &hv_MissingCharsReason);
  TupleGenConst(hv_TooLongWordIndices.TupleLength(), "word too long", &hv_TooLongWordReason);
  TupleGenConst(hv_EmptyWordIndices.TupleLength(), "empty word", &hv_EmptyWordIndicesWordReason);
  (*hv_Indices).Clear();
  (*hv_Indices).Append(hv_MissingCharIndices);
  (*hv_Indices).Append(hv_TooLongWordIndices);
  (*hv_Indices).Append(hv_EmptyWordIndices);
  (*hv_Reasons).Clear();
  (*hv_Reasons).Append(hv_MissingCharsReason);
  (*hv_Reasons).Append(hv_TooLongWordReason);
  (*hv_Reasons).Append(hv_EmptyWordIndicesWordReason);
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate characters statistics from the dataset and the alphabet. 
void gen_dl_dataset_ocr_recognition_statistics (HTuple hv_DLDataset, HTuple *hv_CharStats)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_SamplesKeyExists, hv_Samples, hv_NumSamples;
  HTuple  hv_Charset, hv_Chars, hv_CharsCount, hv_S, hv_Sample;
  HTuple  hv_WordKeyExists, hv_Word, hv_WordLength, hv_C;
  HTuple  hv_Char, hv_Pos, hv_NumChars, hv_SortIdx, hv_OccurrencesCount;
  HTuple  hv_OccurrencesAverage, hv_CharsAverageRatio, hv_Count;
  HTuple  hv_AverageRatio, hv___Tmp_Ctrl_Dict_Init_1, hv___Tmp_Ctrl_Dict_Init_2;

  //This procedure generates characters statistics from a dataset.
  //
  //Read the characters from the dataset.
  GetDictParam(hv_DLDataset, "key_exists", "samples", &hv_SamplesKeyExists);
  if (0 != (hv_SamplesKeyExists.TupleNot()))
  {
    throw HException("Key samples is missing in the dataset.");
  }
  hv_Samples = hv_DLDataset.TupleGetDictTuple("samples");
  hv_NumSamples = hv_Samples.TupleLength();
  //
  //Count all characters in all samples.
  hv_Charset = "";
  hv_Chars = HTuple();
  hv_CharsCount = HTuple();
  {
  HTuple end_val14 = hv_NumSamples-1;
  HTuple step_val14 = 1;
  for (hv_S=0; hv_S.Continue(end_val14, step_val14); hv_S += step_val14)
  {
    hv_Sample = HTuple(hv_Samples[hv_S]);
    GetDictParam(hv_Sample, "key_exists", "word", &hv_WordKeyExists);
    if (0 != (hv_WordKeyExists.TupleNot()))
    {
      throw HException("Key word is missing at least in 1 dataset sample.");
    }
    hv_Word = hv_Sample.TupleGetDictTuple("word");
    hv_WordLength = hv_Word.TupleStrlen();
    {
    HTuple end_val22 = hv_WordLength-1;
    HTuple step_val22 = 1;
    for (hv_C=0; hv_C.Continue(end_val22, step_val22); hv_C += step_val22)
    {
      hv_Char = hv_Word.TupleStrBitSelect(hv_C);
      hv_Pos = hv_Charset.TupleStrchr(hv_Char);
      if (0 != (int(hv_Pos<0)))
      {
        hv_Charset += hv_Char;
        hv_Chars[hv_Chars.TupleLength()] = hv_Char;
        hv_CharsCount[hv_CharsCount.TupleLength()] = 1;
      }
      else
      {
        hv_CharsCount[hv_Pos] = HTuple(hv_CharsCount[hv_Pos])+1;
      }
    }
    }
  }
  }
  hv_NumChars = hv_Chars.TupleLength();
  //
  //Sort characters.
  hv_SortIdx = hv_Chars.TupleSortIndex();
  hv_Chars = HTuple(hv_Chars[hv_SortIdx]);
  hv_CharsCount = HTuple(hv_CharsCount[hv_SortIdx]);
  hv_Charset = "";
  {
  HTuple end_val41 = hv_NumChars-1;
  HTuple step_val41 = 1;
  for (hv_C=0; hv_C.Continue(end_val41, step_val41); hv_C += step_val41)
  {
    hv_Charset += HTuple(hv_Chars[hv_C]);
  }
  }
  //
  //Calculate statistics from counting.
  hv_OccurrencesCount = hv_CharsCount.TupleSum();
  hv_OccurrencesAverage = (hv_OccurrencesCount.TupleReal())/hv_NumChars;
  hv_CharsAverageRatio = hv_CharsCount/hv_OccurrencesAverage;
  //
  //Fill the output dictionary with character statistics.
  CreateDict(&(*hv_CharStats));
  CreateDict(&hv___Tmp_Ctrl_Dict_Init_1);
  SetDictTuple((*hv_CharStats), "chars", hv___Tmp_Ctrl_Dict_Init_1);
  hv___Tmp_Ctrl_Dict_Init_1 = HTuple::TupleConstant("HNULL");
  SetDictTuple((*hv_CharStats), "charset", hv_Chars);
  SetDictTuple((*hv_CharStats), "charset_size", hv_NumChars);
  SetDictTuple((*hv_CharStats), "occurrences_count", hv_OccurrencesCount);
  SetDictTuple((*hv_CharStats), "occurrences_average", hv_OccurrencesAverage);
  {
  HTuple end_val59 = hv_NumChars-1;
  HTuple step_val59 = 1;
  for (hv_C=0; hv_C.Continue(end_val59, step_val59); hv_C += step_val59)
  {
    hv_Char = HTuple(hv_Chars[hv_C]);
    hv_Count = HTuple(hv_CharsCount[hv_C]);
    hv_AverageRatio = HTuple(hv_CharsAverageRatio[hv_C]);
    CreateDict(&hv___Tmp_Ctrl_Dict_Init_2);
    SetDictTuple((*hv_CharStats).TupleGetDictTuple("chars"), hv_Char, hv___Tmp_Ctrl_Dict_Init_2);
    hv___Tmp_Ctrl_Dict_Init_2 = HTuple::TupleConstant("HNULL");
    SetDictTuple(((*hv_CharStats).TupleGetDictTuple("chars")).TupleGetDictTuple(hv_Char), 
        "count", hv_Count);
    SetDictTuple(((*hv_CharStats).TupleGetDictTuple("chars")).TupleGetDictTuple(hv_Char), 
        "average_ratio", hv_Count/hv_OccurrencesAverage);
  }
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Return the DLSample dictionaries for given sample indices of a DLDataset. 
void gen_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple hv_RestrictKeysDLSample, 
    HTuple hv_GenParam, HTuple *hv_DLSampleBatch)
{

  // Local iconic variables
  HObject  ho_ImageRaw, ho_ImageAnomaly, ho_RegionAnomaly;
  HObject  ho_Object, ho_EmptyRegion, ho_ImageSegmentation;
  HObject  ho_XYZImage, ho_X, ho_Y, ho_Z, ho_NormalsImage;
  HObject  ho___Tmp_Obj_0;

  // Local control variables
  HTuple  hv_ImageDir, hv_DLSamples, hv_MinIndex;
  HTuple  hv_MaxIndex, hv_InstanceType, hv_IgnoreMissing;
  HTuple  hv_GenParamName, hv_IndexGenParam, hv_DLSamplesProc;
  HTuple  hv_Rect1BboxKeyList, hv_Rect2BboxKeyList, hv_BboxKeyList;
  HTuple  hv_KeysExist, hv_KeyExists, hv_LastReadFileName;
  HTuple  hv_ImageIndex, hv_DLSampleProc, hv_DLSample, hv_ImageID;
  HTuple  hv_ImageName, hv_FileName, hv_Exception, hv_NumObjects;
  HTuple  hv_AnomalyLabelExists, hv_AnomalyLabel, hv_AnomalyFileNameExists;
  HTuple  hv_AnomalyDir, hv_AnomalyFileName, hv_ExceptionImageAnomaly;
  HTuple  hv_ExceptionRegionAnomaly, hv_Width, hv_Height;
  HTuple  hv_ImageLabelIdExists, hv_ImageLabelID, hv_BboxExists;
  HTuple  hv_BboxLabels, hv_MIdx, hv_MissingKeyIndices, hv_IndexParam;
  HTuple  hv_BboxCoord, hv_SegKeyExists, hv_SegmentationDir;
  HTuple  hv_SegmentationName, hv_ExceptionSegmentation, hv_XYZKeyExists;
  HTuple  hv_XYZDir, hv_XYZName, hv_ExceptionXYZImage, hv_NormalsKeyExists;
  HTuple  hv_NormalsDir, hv_NormalsName, hv_ExceptionNormalsImage;
  HTuple  hv_DetectionKeyExists, hv_WordKeyExists, hv_WordBboxExists;
  HTuple  hv___Tmp_Ctrl_Type;

  //
  //This procedure creates DLSampleBatch, a tuple of DLSample dictionaries, with
  //the image data for each DLDataset sample, that was selected through SampleIndices.
  //The keys to be transferred can be restricted using RestrictKeysDLSample,
  //which is switched off ('off') by default.
  //The procedure returns all generated DLSample dictionaries in the tuple
  //DLSampleBatch.
  //Setting the GenParam 'ignore_missing_labels' controls whether an error is thrown,
  //if no ground truth annotation information is available for a given image.
  //
  //Get the image directory.
  GetDictTuple(hv_DLDataset, "image_dir", &hv_ImageDir);
  //
  //Get the samples from the DLDataset.
  GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
  //
  //Check the input values.
  //
  //Check that the given indices are valid.
  TupleMin(hv_SampleIndices, &hv_MinIndex);
  TupleMax(hv_SampleIndices, &hv_MaxIndex);
  if (0 != (HTuple(int(hv_MinIndex<0)).TupleOr(int(hv_MaxIndex>((hv_DLSamples.TupleLength())-1)))))
  {
    throw HException("The given SampleIndices are not within the range of available samples in DLDataset.");
  }
  //
  //Check if the given method is valid.
  if (0 != (int((hv_RestrictKeysDLSample.TupleLength())==1)))
  {
    if (0 != (int((HTuple((((((((((HTuple("anomaly_detection").Append("classification")).Append("detection")).Append("gc_anomaly_detection")).Append("ocr_recognition")).Append("ocr_detection")).Append("segmentation")).Append("image_only")).Append("3d_gripping_point_detection")).Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())==-1)))
    {
      throw HException("Unknown RestrictKeysDLSample : "+hv_RestrictKeysDLSample);
    }
  }
  else
  {
    throw HException("RestrictKeysDLSample must be specified by one string.");
  }
  //
  //Generic Parameters.
  //Set default values.
  hv_InstanceType = "rectangle1";
  //For missing labels an error is thrown.
  if (0 != (int(hv_RestrictKeysDLSample==HTuple("off"))))
  {
    hv_IgnoreMissing = 1;
  }
  else
  {
    hv_IgnoreMissing = 0;
  }
  //
  //Transfer generic parameters.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenParamName);
    {
    HTuple end_val47 = (hv_GenParamName.TupleLength())-1;
    HTuple step_val47 = 1;
    for (hv_IndexGenParam=0; hv_IndexGenParam.Continue(end_val47, step_val47); hv_IndexGenParam += step_val47)
    {
      if (0 != (int(HTuple(hv_GenParamName[hv_IndexGenParam])==HTuple("ignore_missing_labels"))))
      {
        GetDictTuple(hv_GenParam, "ignore_missing_labels", &hv_IgnoreMissing);
        if (0 != (HTuple(HTuple(int(hv_IgnoreMissing==1)).TupleOr(int(hv_IgnoreMissing==0))).TupleNot()))
        {
          throw HException("The GenParam ignore_missing_labels must be true or false.");
        }
      }
      else if (0 != (int(HTuple(hv_GenParamName[hv_IndexGenParam])==HTuple("instance_type"))))
      {
        if (0 != (int((HTuple((HTuple("detection").Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())==-1)))
        {
          throw HException("The GenParam instance_type can only be set for RestrictKeysDLSample detection or off.");
        }
        GetDictTuple(hv_GenParam, "instance_type", &hv_InstanceType);
        if (0 != (int((HTuple(((HTuple("rectangle1").Append("rectangle2")).Append("mask")).TupleFind(hv_InstanceType)).TupleMax())==-1)))
        {
          throw HException(HTuple("The GenParam instance_type must be either 'rectangle1', 'rectangle2' or 'mask'."));
        }
      }
      else
      {
        throw HException("Unknown GenParam key : "+HTuple(hv_GenParamName[hv_IndexGenParam]));
      }
    }
    }
  }
  //
  //Get the samples to be processed.
  hv_DLSamplesProc = HTuple(hv_DLSamples[hv_SampleIndices]);
  //
  //Initialize the tuple for collection the DLSample dictionaries.
  (*hv_DLSampleBatch) = HTuple(hv_SampleIndices.TupleLength(),HTuple::TupleConstant("HNULL"));
  //
  //Set the BboxKeyList according to the InstanceType.
  hv_Rect1BboxKeyList.Clear();
  hv_Rect1BboxKeyList[0] = "bbox_col1";
  hv_Rect1BboxKeyList[1] = "bbox_row1";
  hv_Rect1BboxKeyList[2] = "bbox_col2";
  hv_Rect1BboxKeyList[3] = "bbox_row2";
  hv_Rect2BboxKeyList.Clear();
  hv_Rect2BboxKeyList[0] = "bbox_row";
  hv_Rect2BboxKeyList[1] = "bbox_col";
  hv_Rect2BboxKeyList[2] = "bbox_length1";
  hv_Rect2BboxKeyList[3] = "bbox_length2";
  hv_Rect2BboxKeyList[4] = "bbox_phi";
  if (0 != (int((HTuple(HTuple("ocr_detection").TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
  {
    hv_InstanceType = "rectangle2";
    hv_BboxKeyList = hv_Rect2BboxKeyList;
  }
  else if (0 != (int((HTuple((HTuple("detection").Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
  {
    hv_BboxKeyList = hv_Rect1BboxKeyList;
    if (0 != (int(hv_InstanceType==HTuple("rectangle2"))))
    {
      hv_BboxKeyList = hv_Rect2BboxKeyList;
    }
    else if (0 != (int(hv_InstanceType==HTuple("mask"))))
    {
      //Check in the first sample if rectangle2-coordinates are present.
      GetDictParam(HTuple(hv_DLSamplesProc[0]), "key_exists", hv_Rect2BboxKeyList, 
          &hv_KeysExist);
      if (0 != (int((hv_KeysExist.TupleSum())==(hv_Rect2BboxKeyList.TupleLength()))))
      {
        hv_BboxKeyList = hv_Rect2BboxKeyList;
      }
    }
    //Check if we have a word specified
    GetDictParam(HTuple(hv_DLSamplesProc[0]), "key_exists", "word", &hv_KeyExists);
    if (0 != hv_KeyExists)
    {
      hv_BboxKeyList = hv_Rect2BboxKeyList;
    }
  }

  //Avoid multiple reads of the same file in adjacent samples,
  //we store the last used file name.
  //This is most relevant in case of ocr recognition where multiple samples are given on a single image.
  hv_LastReadFileName = "";
  //Loop over all selected samples and create a DLSample dictionary
  //for each dictionary in the DLDataset samples.
  {
  HTuple end_val103 = (hv_SampleIndices.TupleLength())-1;
  HTuple step_val103 = 1;
  for (hv_ImageIndex=0; hv_ImageIndex.Continue(end_val103, step_val103); hv_ImageIndex += step_val103)
  {
    //
    //Store the sample which is processed.
    hv_DLSampleProc = HTuple(hv_DLSamplesProc[hv_ImageIndex]);
    //
    //Create the DLSample dictionary
    CreateDict(&hv_DLSample);
    //
    //Set the image key.
    GetDictTuple(hv_DLSampleProc, "image_id", &hv_ImageID);
    SetDictTuple(hv_DLSample, "image_id", hv_ImageID);
    //
    //Read image.
    //The relative file path of the image is specified in image_name.
    GetDictTuple(hv_DLSampleProc, "image_file_name", &hv_ImageName);
    //
    if (0 != (int((hv_ImageDir.TupleStrlen())==0)))
    {
      hv_FileName = hv_ImageName;
    }
    else if (0 != (int((hv_ImageDir.TupleStrBitSelect((hv_ImageDir.TupleStrlen())-1))==HTuple("/"))))
    {
      hv_FileName = hv_ImageDir+hv_ImageName;
    }
    else
    {
      hv_FileName = (hv_ImageDir+"/")+hv_ImageName;
    }
    if (0 != (int(hv_LastReadFileName!=hv_FileName)))
    {
      try
      {
        ReadImage(&ho_ImageRaw, hv_FileName);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        throw HException(((((((("Error for reading/setting image "+hv_FileName)+" with ID ")+hv_ImageID)+" : Error code ")+HTuple(hv_Exception[0]))+HTuple(", \""))+HTuple(hv_Exception[2]))+"\"");
      }
      hv_LastReadFileName = hv_FileName;
      //
      //Check that the read image does not contain multiple objects.
      CountObj(ho_ImageRaw, &hv_NumObjects);
      if (0 != (int(hv_NumObjects>1)))
      {
        throw HException(((("The image "+hv_FileName)+" with ID ")+hv_ImageID)+" contains multiple objects. This is not supported.");
      }
    }
    //
    //Insert image into dictionary.
    SetDictObject(ho_ImageRaw, hv_DLSample, "image");
    //
    //Read specific data.
    //
    if (0 != (int(hv_RestrictKeysDLSample!=HTuple("image_only"))))
    {
      //
      //Transfer anomaly detection or
      //Global Context Anomaly Detection relevant data.
      if (0 != (int((HTuple(((HTuple("anomaly_detection").Append("gc_anomaly_detection")).Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
      {
        //Check the existence of the label key.
        GetDictParam(hv_DLSampleProc, "key_exists", "anomaly_label", &hv_AnomalyLabelExists);
        if (0 != hv_AnomalyLabelExists)
        {
          //Get the image label.
          GetDictTuple(hv_DLSampleProc, "anomaly_label", &hv_AnomalyLabel);
          //Check the existence of the anomaly file name key. If not found it is just ignored.
          GetDictParam(hv_DLSampleProc, "key_exists", "anomaly_file_name", &hv_AnomalyFileNameExists);
          if (0 != hv_AnomalyFileNameExists)
          {
            //Get the ground truth anomaly directory.
            GetDictTuple(hv_DLDataset, "anomaly_dir", &hv_AnomalyDir);
            //Get the image file name.
            GetDictTuple(hv_DLSampleProc, "anomaly_file_name", &hv_AnomalyFileName);
            //Read the ground truth anomaly image.
            try
            {
              ReadImage(&ho_ImageAnomaly, (hv_AnomalyDir+"/")+hv_AnomalyFileName);
            }
            // catch (ExceptionImageAnomaly) 
            catch (HException &HDevExpDefaultException)
            {
              HDevExpDefaultException.ToHTuple(&hv_ExceptionImageAnomaly);
              //If the file is not an image, try to read the ground truth anomaly region.
              //Then, convert this region to a ground truth anomaly image.
              try
              {
                ReadRegion(&ho_RegionAnomaly, (hv_AnomalyDir+"/")+hv_AnomalyFileName);
              }
              // catch (ExceptionRegionAnomaly) 
              catch (HException &HDevExpDefaultException)
              {
                HDevExpDefaultException.ToHTuple(&hv_ExceptionRegionAnomaly);
                throw HException((("Error: Could not read the anomaly ground truth information of image_id "+hv_ImageID)+" : Error code ")+HTuple(hv_ExceptionImageAnomaly[0]));
              }
              GetImageSize(ho_ImageRaw, &hv_Width, &hv_Height);
              GenImageConst(&ho_ImageAnomaly, "byte", hv_Width, hv_Height);
              OverpaintRegion(ho_ImageAnomaly, ho_ImageAnomaly, 0, "fill");
              OverpaintRegion(ho_ImageAnomaly, ho_RegionAnomaly, 1, "fill");
            }
            //Insert anomaly image into DLSample dictionary.
            SetDictObject(ho_ImageAnomaly, hv_DLSample, "anomaly_ground_truth");
          }
          //
          //Insert anomaly label into DLSample dictionary.
          SetDictTuple(hv_DLSample, "anomaly_label", hv_AnomalyLabel);
          //Insert anomaly label id into DLSample dictionary.
          if (0 != (int(hv_AnomalyLabel==HTuple("nok"))))
          {
            SetDictTuple(hv_DLSample, "anomaly_label_id", 1);
          }
          else
          {
            SetDictTuple(hv_DLSample, "anomaly_label_id", 0);
          }
        }
        else if (0 != (HTuple(hv_AnomalyLabelExists.TupleNot()).TupleAnd(hv_IgnoreMissing.TupleNot())))
        {
          throw HException(("For image_id "+hv_ImageID)+" the key 'anomaly_label' is missing. Missing keys can be ignored using the GenParam ignore_missing_labels.");
        }
      }
      //
      //Transfer classification relevant data.
      if (0 != (int((HTuple((HTuple("classification").Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
      {
        //Check the existence of the required key.
        GetDictParam(hv_DLSampleProc, "key_exists", "image_label_id", &hv_ImageLabelIdExists);
        if (0 != hv_ImageLabelIdExists)
        {
          //Transfer the image label.
          GetDictTuple(hv_DLSampleProc, "image_label_id", &hv_ImageLabelID);
          SetDictTuple(hv_DLSample, "image_label_id", hv_ImageLabelID);
        }
        else if (0 != (HTuple(hv_ImageLabelIdExists.TupleNot()).TupleAnd(hv_IgnoreMissing.TupleNot())))
        {
          throw HException(("For image_id "+hv_ImageID)+" the key 'image_label_id' is missing. Missing keys can be ignored using the GenParam ignore_missing_labels.");
        }
      }
      //
      //Transfer detection and ocr_detection relevant data.
      if (0 != (int((HTuple(((HTuple("detection").Append("ocr_detection")).Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
      {
        //Check the existence of the required key.
        GetDictParam(hv_DLSampleProc, "key_exists", "bbox_label_id", &hv_BboxExists);
        if (0 != hv_BboxExists)
        {
          //Transfer the bounding box labels.
          GetDictTuple(hv_DLSampleProc, "bbox_label_id", &hv_BboxLabels);
          SetDictTuple(hv_DLSample, "bbox_label_id", hv_BboxLabels);
          if (0 != (int(hv_InstanceType==HTuple("mask"))))
          {
            //Transfer the instance segmentation masks if available.
            GetDictParam(hv_DLSampleProc, "key_exists", "mask", &hv_KeyExists);
            if (0 != (hv_KeyExists.TupleNot()))
            {
              GenEmptyObj(&ho_Object);
              {
              HTuple end_val222 = hv_BboxLabels.TupleLength();
              HTuple step_val222 = 1;
              for (hv_MIdx=1; hv_MIdx.Continue(end_val222, step_val222); hv_MIdx += step_val222)
              {
                GenEmptyRegion(&ho_EmptyRegion);
                ConcatObj(ho_Object, ho_EmptyRegion, &ho_Object);
              }
              }
            }
            else
            {
              GetDictObject(&ho_Object, hv_DLSampleProc, "mask");
            }
            SetDictObject(ho_Object, hv_DLSample, "mask");
          }
          //Transfer the bounding box coordinates.
          GetDictParam(hv_DLSampleProc, "key_exists", hv_BboxKeyList, &hv_KeysExist);
          if (0 != (HTuple(int((hv_KeysExist.TupleSum())!=(hv_KeysExist.TupleLength()))).TupleAnd(hv_IgnoreMissing.TupleNot())))
          {
            hv_MissingKeyIndices = (hv_KeysExist.TupleEqualElem(0)).TupleFind(1);
            throw HException((("For image_id "+hv_ImageID)+HTuple(", an error has occurred when transferring the key "))+HTuple(hv_BboxKeyList[hv_MissingKeyIndices]));
          }
          else
          {
            {
            HTuple end_val237 = (hv_BboxKeyList.TupleLength())-1;
            HTuple step_val237 = 1;
            for (hv_IndexParam=0; hv_IndexParam.Continue(end_val237, step_val237); hv_IndexParam += step_val237)
            {
              GetDictTuple(hv_DLSampleProc, HTuple(hv_BboxKeyList[hv_IndexParam]), 
                  &hv_BboxCoord);
              SetDictTuple(hv_DLSample, HTuple(hv_BboxKeyList[hv_IndexParam]), hv_BboxCoord);
            }
            }
          }
        }
        else if (0 != (hv_IgnoreMissing.TupleNot()))
        {
          throw HException(("For image_id "+hv_ImageID)+" there is no key bbox_label_id. Missing keys can be ignored using the GenParam ignore_missing_labels.");
        }
      }
      //
      //Transfer segmentation relevant data.
      if (0 != (int((HTuple(((HTuple("segmentation").Append("3d_gripping_point_detection")).Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
      {
        //Check the existence of the required keys.
        GetDictParam(hv_DLSampleProc, "key_exists", "segmentation_file_name", &hv_SegKeyExists);
        if (0 != hv_SegKeyExists)
        {
          //Get the ground truth segmentation directory.
          GetDictTuple(hv_DLDataset, "segmentation_dir", &hv_SegmentationDir);
          //Get the image file name.
          GetDictTuple(hv_DLSampleProc, "segmentation_file_name", &hv_SegmentationName);
          //Read the ground truth segmentation image.
          try
          {
            ReadImage(&ho_ImageSegmentation, (hv_SegmentationDir+"/")+hv_SegmentationName);
          }
          // catch (ExceptionSegmentation) 
          catch (HException &HDevExpDefaultException)
          {
            HDevExpDefaultException.ToHTuple(&hv_ExceptionSegmentation);
            throw HException((("Error for reading segmentation file of image_id "+hv_ImageID)+" : Error code ")+HTuple(hv_ExceptionSegmentation[0]));
          }
          //Insert image into DLSample dictionary.
          SetDictObject(ho_ImageSegmentation, hv_DLSample, "segmentation_image");
        }
        else if (0 != (hv_IgnoreMissing.TupleNot()))
        {
          throw HException(("For image_id "+hv_ImageID)+" there is no key segmentation_file_name. Missing keys can be ignored using the GenParam ignore_missing_labels.");
        }
      }
      //Transfer 3d_gripping_point_detection relevant data.
      if (0 != (int((HTuple((HTuple("3d_gripping_point_detection").Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
      {
        //Check the existence of the xyz keys.
        GetDictParam(hv_DLSampleProc, "key_exists", "xyz_file_name", &hv_XYZKeyExists);
        if (0 != hv_XYZKeyExists)
        {
          //Get the xyz directory.
          GetDictTuple(hv_DLDataset, "xyz_dir", &hv_XYZDir);
          //Get the image file name.
          GetDictTuple(hv_DLSampleProc, "xyz_file_name", &hv_XYZName);
          //Read the xyz image.
          try
          {
            ReadImage(&ho_XYZImage, (hv_XYZDir+"/")+hv_XYZName);
          }
          // catch (ExceptionXYZImage) 
          catch (HException &HDevExpDefaultException)
          {
            HDevExpDefaultException.ToHTuple(&hv_ExceptionXYZImage);
            throw HException((("Error for reading XYZ file of image_id "+hv_ImageID)+" : Error code ")+HTuple(hv_ExceptionXYZImage[0]));
          }
          //Insert xyz image into DLSample dictionary.
          Decompose3(ho_XYZImage, &ho_X, &ho_Y, &ho_Z);
          SetDictObject(ho_X, hv_DLSample, "x");
          SetDictObject(ho_Y, hv_DLSample, "y");
          SetDictObject(ho_Z, hv_DLSample, "z");
        }
        else if (0 != (hv_IgnoreMissing.TupleNot()))
        {
          throw HException(("For image_id "+hv_ImageID)+" there is no key xyz_file_name. Missing keys can be ignored using the GenParam ignore_missing_labels.");
        }
        //Check the existence of the normals key.
        GetDictParam(hv_DLSampleProc, "key_exists", "normals_file_name", &hv_NormalsKeyExists);
        if (0 != hv_NormalsKeyExists)
        {
          //Get the normals directory.
          GetDictTuple(hv_DLDataset, "normals_dir", &hv_NormalsDir);
          //Get the image file name.
          GetDictTuple(hv_DLSampleProc, "normals_file_name", &hv_NormalsName);
          //Read the normals image.
          try
          {
            ReadImage(&ho_NormalsImage, (hv_NormalsDir+"/")+hv_NormalsName);
          }
          // catch (ExceptionNormalsImage) 
          catch (HException &HDevExpDefaultException)
          {
            HDevExpDefaultException.ToHTuple(&hv_ExceptionNormalsImage);
            throw HException((("Error for reading the normals file of image_id "+hv_ImageID)+" : Error code ")+HTuple(hv_ExceptionNormalsImage[0]));
          }
          //Insert normals image into DLSample dictionary.
          SetDictObject(ho_NormalsImage, hv_DLSample, "normals");
        }

      }
      //
      //Transfer ocr_recognition relevant data.
      if (0 != (int((HTuple((HTuple("ocr_recognition").Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
      {
        GetDictParam(hv_DLSampleProc, "key_exists", "bbox_label_id", &hv_DetectionKeyExists);
        GetDictParam(hv_DLSampleProc, "key_exists", "word", &hv_WordKeyExists);
        if (0 != (hv_WordKeyExists.TupleAnd(hv_DetectionKeyExists.TupleNot())))
        {
          //Check if a rectangle2 bounding box exists.
          GetDictParam(hv_DLSampleProc, "key_exists", ((((HTuple("bbox_row").Append("bbox_col")).Append("bbox_phi")).Append("bbox_length1")).Append("bbox_length2")), 
              &hv_WordBboxExists);
          hv_WordBboxExists = int((hv_WordBboxExists.TupleSum())==(hv_WordBboxExists.TupleLength()));
          //Reduce the image to the word bounding box.
          if (0 != hv_WordBboxExists)
          {
            CropRectangle2(ho_ImageRaw, &ho___Tmp_Obj_0, hv_DLSampleProc.TupleGetDictTuple("bbox_row"), 
                hv_DLSampleProc.TupleGetDictTuple("bbox_col"), hv_DLSampleProc.TupleGetDictTuple("bbox_phi"), 
                hv_DLSampleProc.TupleGetDictTuple("bbox_length1"), hv_DLSampleProc.TupleGetDictTuple("bbox_length2"), 
                "true", "constant");
            SetDictObject(ho___Tmp_Obj_0, hv_DLSample, "image");
          }
          GetDictParam(hv_DLSampleProc, "key_data_type", "word", &hv___Tmp_Ctrl_Type);
          if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
          {
            SetDictObject(hv_DLSampleProc.TupleGetDictObject("word"), hv_DLSample, 
                "word");
          }
          else
          {
            SetDictTuple(hv_DLSample, "word", hv_DLSampleProc.TupleGetDictTuple("word"));
          }
        }
        else if (0 != (hv_IgnoreMissing.TupleNot()))
        {
          throw HException(("For image_id "+hv_ImageID)+" there is no key word. Missing keys can be ignored using the GenParam ignore_missing_labels.");
        }
      }
      //Transfer ocr_detection relevant data.
      if (0 != (int((HTuple((HTuple("ocr_detection").Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
      {
        GetDictParam(hv_DLSampleProc, "key_exists", "word", &hv_WordKeyExists);
        if (0 != hv_WordKeyExists)
        {
          //Check if a rectangle2 bounding box exists.
          GetDictParam(hv_DLSampleProc, "key_exists", ((((HTuple("bbox_row").Append("bbox_col")).Append("bbox_phi")).Append("bbox_length1")).Append("bbox_length2")), 
              &hv_WordBboxExists);
          hv_WordBboxExists = int((hv_WordBboxExists.TupleSum())==(hv_WordBboxExists.TupleLength()));
          GetDictParam(hv_DLSampleProc, "key_data_type", "word", &hv___Tmp_Ctrl_Type);
          if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
          {
            SetDictObject(hv_DLSampleProc.TupleGetDictObject("word"), hv_DLSample, 
                "word");
          }
          else
          {
            SetDictTuple(hv_DLSample, "word", hv_DLSampleProc.TupleGetDictTuple("word"));
          }
        }
        else if (0 != (hv_IgnoreMissing.TupleNot()))
        {
          throw HException(("For image_id "+hv_ImageID)+" there is no key word. Missing keys can be ignored using the GenParam ignore_missing_labels.");
        }
      }
    }
    //
    //Collect all data dictionaries of all processed indices.
    (*hv_DLSampleBatch)[hv_ImageIndex] = hv_DLSample;
  }
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Store the given images in a tuple of dictionaries DLSamples. 
void gen_dl_samples_from_images (HObject ho_Images, HTuple *hv_DLSampleBatch)
{

  // Local iconic variables
  HObject  ho_Image;

  // Local control variables
  HTuple  hv_NumImages, hv_ImageIndex, hv_DLSample;

  //
  //This procedure creates DLSampleBatch, a tuple
  //containing a dictionary DLSample
  //for every image given in Images.
  //
  //Initialize output tuple.
  CountObj(ho_Images, &hv_NumImages);
  (*hv_DLSampleBatch) = HTuple(hv_NumImages,-1);
  //
  //Loop through all given images.
  {
  HTuple end_val10 = hv_NumImages-1;
  HTuple step_val10 = 1;
  for (hv_ImageIndex=0; hv_ImageIndex.Continue(end_val10, step_val10); hv_ImageIndex += step_val10)
  {
    SelectObj(ho_Images, &ho_Image, hv_ImageIndex+1);
    //Create DLSample from image.
    CreateDict(&hv_DLSample);
    SetDictObject(ho_Image, hv_DLSample, "image");
    //
    //Collect the DLSamples.
    (*hv_DLSampleBatch)[hv_ImageIndex] = hv_DLSample;
  }
  }
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Provide a class mapping based on a DLDataset 
void gen_ocr_detection_class_id_mapping (HTuple hv_DLDataset, HTuple *hv_ClassToClassIndex)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ClassCustomDataExists, hv_I, hv_IsTextClassExists;
  HTuple  hv_CustomData;

  CreateDict(&(*hv_ClassToClassIndex));
  GetDictParam(hv_DLDataset, "key_exists", "class_custom_data", &hv_ClassCustomDataExists);
  if (0 != hv_ClassCustomDataExists)
  {
    {
    HTuple end_val3 = ((hv_DLDataset.TupleGetDictTuple("class_ids")).TupleLength())-1;
    HTuple step_val3 = 1;
    for (hv_I=0; hv_I.Continue(end_val3, step_val3); hv_I += step_val3)
    {
      hv_IsTextClassExists = 0;
      if (0 != (int(HTuple((hv_DLDataset.TupleGetDictTuple("class_custom_data"))[hv_I])!=HTuple::TupleConstant("HNULL"))))
      {
        hv_CustomData = HTuple((hv_DLDataset.TupleGetDictTuple("class_custom_data"))[hv_I]);
        GetDictParam(hv_CustomData, "key_exists", "is_text_class", &hv_IsTextClassExists);
      }
      if (0 != hv_IsTextClassExists)
      {
        if (0 != (hv_CustomData.TupleGetDictTuple("is_text_class")))
        {
          SetDictTuple((*hv_ClassToClassIndex), HTuple((hv_DLDataset.TupleGetDictTuple("class_ids"))[hv_I]), 
              0);
        }
      }
      else
      {
        if (0 != (int(HTuple((hv_DLDataset.TupleGetDictTuple("class_names"))[hv_I])==HTuple("ignore"))))
        {
          SetDictTuple((*hv_ClassToClassIndex), HTuple((hv_DLDataset.TupleGetDictTuple("class_ids"))[hv_I]), 
              2);
        }
        else
        {
          //All classes other than text classes and 'ignore' are mapped to the 'char' class.
          SetDictTuple((*hv_ClassToClassIndex), HTuple((hv_DLDataset.TupleGetDictTuple("class_ids"))[hv_I]), 
              1);
        }
      }
    }
    }
  }
  else
  {
    {
    HTuple end_val23 = ((hv_DLDataset.TupleGetDictTuple("class_ids")).TupleLength())-1;
    HTuple step_val23 = 1;
    for (hv_I=0; hv_I.Continue(end_val23, step_val23); hv_I += step_val23)
    {
      if (0 != (int(HTuple((hv_DLDataset.TupleGetDictTuple("class_names"))[hv_I])==HTuple("word"))))
      {
        SetDictTuple((*hv_ClassToClassIndex), HTuple((hv_DLDataset.TupleGetDictTuple("class_ids"))[hv_I]), 
            0);
      }
      else if (0 != (int(HTuple((hv_DLDataset.TupleGetDictTuple("class_names"))[hv_I])==HTuple("ignore"))))
      {
        SetDictTuple((*hv_ClassToClassIndex), HTuple((hv_DLDataset.TupleGetDictTuple("class_ids"))[hv_I]), 
            2);
      }
      else
      {
        //All classes other than 'word' and 'ignore' are mapped to the 'char' class.
        SetDictTuple((*hv_ClassToClassIndex), HTuple((hv_DLDataset.TupleGetDictTuple("class_ids"))[hv_I]), 
            1);
      }
    }
    }
  }
  return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Get the 'image_id' for each annotation for a given ThreadIndex. 
void get_dl_dataset_from_coco_annotation_image_id (HTuple hv_AnnotationList, HTuple hv_AnnotationKeys, 
    HTuple hv_NumKeysPerThread, HTuple hv_UniqueIndex, HTuple *hv_AnnotImageIDsOutput, 
    HTuple *hv_Exception)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Index, hv_Annotation, hv_ImageIDAnnot;
  HTuple  hv_ExceptionAnnot;

  //This procedure gets the 'image_id' for each annotation for a given thread.
  TupleGenConst(hv_NumKeysPerThread, -1, &(*hv_AnnotImageIDsOutput));
  (*hv_Exception) = HTuple();
  //
  //Get the 'image_id' for each annotation for looking it up later.
  {
  HTuple end_val5 = hv_NumKeysPerThread-1;
  HTuple step_val5 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val5, step_val5); hv_Index += step_val5)
  {
    try
    {
      GetDictTuple(hv_AnnotationList, HTuple(hv_AnnotationKeys[hv_Index]), &hv_Annotation);
      GetDictTuple(hv_Annotation, "image_id", &hv_ImageIDAnnot);
    }
    // catch (ExceptionAnnot) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_ExceptionAnnot);
      (*hv_Exception) = ("COCO annotation number "+hv_UniqueIndex)+" does not contain image_id.";
      return;
    }
    (*hv_AnnotImageIDsOutput)[hv_Index] = hv_ImageIDAnnot;
    hv_UniqueIndex += 1;
  }
  }
  //
  return;
}

// Chapter: File / Misc
// Short Description: Find a matching file in a list of files for a given file and return the index. 
void get_matching_file_index (HTuple hv_FileNames, HTuple hv_FileDirectories, HTuple hv_FileNameToMatch, 
    HTuple hv_FileDirectoryToMatch, HTuple hv_FileExtensionToMatch, HTuple *hv_FileMatchIndex)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MatchIndex, hv_Match, hv_PathMatchIndex;
  HTuple  hv_FilePath;

  //
  //This procedure tries to find for a given file another file
  //from a list that has a matching name.
  //
  (*hv_FileMatchIndex) = -1;
  //
  //1: Try to match identical file names.
  hv_MatchIndex = hv_FileNames.TupleFind(hv_FileNameToMatch);
  if (0 != (HTuple(int((hv_MatchIndex.TupleLength())==1)).TupleAnd(int(hv_MatchIndex>=0))))
  {
    //Exactly one match was found.
    (*hv_FileMatchIndex) = hv_MatchIndex;
  }
  else
  {
    //2: Try to match file name subparts.
    TupleRegexpMatch(hv_FileNames, hv_FileNameToMatch, &hv_Match);
    TupleFind(hv_Match.TupleNotEqualElem(""), 1, &hv_MatchIndex);
    if (0 != (HTuple(int(hv_MatchIndex>=0)).TupleAnd(int((hv_MatchIndex.TupleLength())==1))))
    {
      //Exactly one match was found.
      (*hv_FileMatchIndex) = hv_MatchIndex;
    }
    else if (0 != (int((hv_MatchIndex.TupleLength())>1)))
    {
      //3: There are several name matches.
      //Check if one of these matches has a common relative
      //path.
      hv_PathMatchIndex = HTuple(hv_FileDirectories[hv_MatchIndex]).TupleFind(hv_FileDirectoryToMatch);
      if (0 != (HTuple(int(hv_PathMatchIndex>=0)).TupleAnd(int((hv_PathMatchIndex.TupleLength())==1))))
      {
        //Exactly one file matches path and name.
        (*hv_FileMatchIndex) = HTuple(hv_MatchIndex[hv_PathMatchIndex]);
      }
      else if (0 != (int((hv_PathMatchIndex.TupleLength())>1)))
      {
        //There should be only one file in the list matching
        //the given file.
        hv_FilePath = ((hv_FileDirectoryToMatch+hv_FileNameToMatch)+".")+hv_FileExtensionToMatch;
        throw HException("Multiple matching files for file "+hv_FilePath);
      }
    }
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: This procedure determines the common directory part CommonDir between ImageDir and ImageDirectories and places the relative part from ImageDirectories into ImageDirectoriesRelative. 
void get_relative_image_directories (HTuple hv_ImageDir, HTuple hv_ImageDirectories, 
    HTuple *hv_CommonDir, HTuple *hv_ImageDirectoriesRelative)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Slash, hv_ToFind, hv_D, hv_ImageDirectory;
  HTuple  hv_String, hv_ToFindFixed, hv_ToFindAddPrefix, hv_ToFindAddSuffix;
  HTuple  hv_StringFixed, hv_StringAddPrefix, hv_StringAddSuffix;
  HTuple  hv_PositionFixed, hv_Position, hv_CommonLastPosition;
  HTuple  hv_ImageDirectoryLen, hv_ImageDirectoriesRelativeLen;

  //This procedure determines the common directory part CommonDir
  //between ImageDir and ImageDirectories and places the relative
  //part from ImageDirectories into ImageDirectoriesRelative.
  //For multiple occurrences of ImageDir in ImageDirectories, the
  //first match determines the common directory part.
  //
  //Check inputs.
  if (0 != (int((hv_ImageDir.TupleLength())!=1)))
  {
    throw HException("Invalid size of input parameter ImageDir.");
  }
  if (0 != (int((hv_ImageDirectories.TupleLength())<1)))
  {
    throw HException("Invalid size of input parameter ImageDirectories.");
  }
  //
  //Determine the common directory part.
  (*hv_CommonDir) = "";
  hv_Slash = "/";
  hv_ToFind = hv_ImageDir;
  {
  HTuple end_val18 = (hv_ImageDirectories.TupleLength())-1;
  HTuple step_val18 = 1;
  for (hv_D=0; hv_D.Continue(end_val18, step_val18); hv_D += step_val18)
  {
    hv_ImageDirectory = HTuple(hv_ImageDirectories[hv_D]);
    hv_String = hv_ImageDirectory;
    //
    //Grant slash at the beginning and end to make the search robust.
    hv_ToFindFixed = hv_ToFind;
    hv_ToFindAddPrefix = int((hv_ToFind.TupleStrBitSelect(0))!=hv_Slash);
    hv_ToFindAddSuffix = int((hv_ToFind.TupleStrBitSelect((hv_ToFind.TupleStrlen())-1))!=hv_Slash);
    if (0 != hv_ToFindAddPrefix)
    {
      hv_ToFindFixed = hv_Slash+hv_ToFindFixed;
    }
    if (0 != hv_ToFindAddSuffix)
    {
      hv_ToFindFixed += hv_Slash;
    }
    //
    hv_StringFixed = hv_String;
    if (0 != (int(hv_String!=HTuple(""))))
    {
      hv_StringAddPrefix = int((hv_String.TupleStrBitSelect(0))!=hv_Slash);
      hv_StringAddSuffix = int((hv_String.TupleStrBitSelect((hv_String.TupleStrlen())-1))!=hv_Slash);
    }
    else
    {
      hv_StringAddPrefix = 1;
      hv_StringAddSuffix = 1;
    }
    if (0 != hv_StringAddPrefix)
    {
      hv_StringFixed = hv_Slash+hv_StringFixed;
    }
    if (0 != hv_StringAddSuffix)
    {
      hv_StringFixed += hv_Slash;
    }
    //
    //Determine the common directory part.
    hv_PositionFixed = hv_StringFixed.TupleStrstr(hv_ToFindFixed);
    if (0 != (int(hv_PositionFixed<0)))
    {
      //No common directory part.
      (*hv_CommonDir) = "";
      (*hv_ImageDirectoriesRelative) = hv_ImageDirectories;
      return;
    }
    hv_Position = (hv_PositionFixed-hv_StringAddPrefix)+hv_ToFindAddPrefix;
    //
    hv_CommonLastPosition = ((hv_Position+(hv_ToFind.TupleStrlen()))-1).TupleMin2((hv_ImageDirectory.TupleStrlen())-1);
    (*hv_CommonDir) = hv_ImageDirectory.TupleSubstr(0,hv_CommonLastPosition);
    hv_ToFind = (*hv_CommonDir);
  }
  }
  //
  //Remove the common directory part from the image directories.
  (*hv_ImageDirectoriesRelative) = HTuple(hv_ImageDirectories.TupleLength(),"");
  {
  HTuple end_val65 = (hv_ImageDirectories.TupleLength())-1;
  HTuple step_val65 = 1;
  for (hv_D=0; hv_D.Continue(end_val65, step_val65); hv_D += step_val65)
  {
    hv_ImageDirectory = HTuple(hv_ImageDirectories[hv_D]);
    hv_ImageDirectoryLen = hv_ImageDirectory.TupleStrlen();
    if (0 != (int(hv_CommonLastPosition<(hv_ImageDirectoryLen-1))))
    {
      (*hv_ImageDirectoriesRelative)[hv_D] = hv_ImageDirectory.TupleSubstr(hv_CommonLastPosition+1,hv_ImageDirectoryLen-1);
      //
      //Remove leading slash if any from relative directories.
      if (0 != (int((HTuple((*hv_ImageDirectoriesRelative)[hv_D]).TupleStrBitSelect(0))==hv_Slash)))
      {
        hv_ImageDirectoriesRelativeLen = HTuple((*hv_ImageDirectoriesRelative)[hv_D]).TupleStrlen();
        if (0 != (int(hv_ImageDirectoriesRelativeLen>1)))
        {
          (*hv_ImageDirectoriesRelative)[hv_D] = HTuple((*hv_ImageDirectoriesRelative)[hv_D]).TupleSubstr(1,hv_ImageDirectoriesRelativeLen-1);
        }
        else
        {
          (*hv_ImageDirectoriesRelative)[hv_D] = "";
        }
      }
    }
  }
  }
  //
  return;
}

// Chapter: File / Misc
void images_exist (HTuple hv_ImageList)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OS, hv_Separator, hv_HalconImages;
  HTuple  hv_Index, hv_ImageExists, hv_DirIndex;

  //
  //Get HalconImages directories.
  GetSystem("operating_system", &hv_OS);
  if (0 != (int((hv_OS.TupleSubstr(0,2))==HTuple("Win"))))
  {
    hv_Separator = ";";
  }
  else
  {
    hv_Separator = ":";
  }
  GetSystem("image_dir", &hv_HalconImages);
  TupleSplit(hv_HalconImages, hv_Separator, &hv_HalconImages);
  //
  //Loop over images and segmentations.
  {
  HTuple end_val12 = (hv_ImageList.TupleLength())-1;
  HTuple step_val12 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val12, step_val12); hv_Index += step_val12)
  {
    FileExists(HTuple(hv_ImageList[hv_Index]), &hv_ImageExists);
    if (0 != (hv_ImageExists.TupleNot()))
    {
      //Check in HalconImages directories.
      {
      HTuple end_val16 = (hv_HalconImages.TupleLength())-1;
      HTuple step_val16 = 1;
      for (hv_DirIndex=0; hv_DirIndex.Continue(end_val16, step_val16); hv_DirIndex += step_val16)
      {
        FileExists((HTuple(hv_HalconImages[hv_DirIndex])+"/")+HTuple(hv_ImageList[hv_Index]), 
            &hv_ImageExists);
        if (0 != hv_ImageExists)
        {
          break;
        }
      }
      }
      if (0 != (hv_ImageExists.TupleNot()))
      {
        throw HException(("Image "+HTuple(hv_ImageList[hv_Index]))+" does not exist");
      }
    }
  }
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Generate various image lists and corresponding annotation file list. 
void list_image_and_annotation_files (HTuple hv_Type, HTuple hv_ImageDir, HTuple hv_XYZDir, 
    HTuple hv_NormalsDir, HTuple hv_AnnotationDir, HTuple hv_ImageListIn, HTuple hv_GenParam, 
    HTuple *hv_ImageListOut, HTuple *hv_XYZListOut, HTuple *hv_NormalsListOut, HTuple *hv_AnnotationListOut, 
    HTuple *hv_LabelListOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ImageSubDirs, hv_XYZSubDirs, hv_NormalsSubDirs;
  HTuple  hv_AnnotationSubDirs, hv_FileNameImageOnly, hv_FileNameXYZOnly;
  HTuple  hv_FileNameNormalsOnly, hv_FileNameAnnoOnly, hv_IgnoreUnmatched;
  HTuple  hv_Keys, hv_KeyIndex, hv_AnnotationType, hv_ImageBaseNames;
  HTuple  hv_ImageBaseNamesToMatch, hv_ImageExtensions, hv_ImageDirectories;
  HTuple  hv_ImageDirectoriesRel, hv_XYZBaseNames, hv_XYZBaseNamesToMatch;
  HTuple  hv_XYZExtensions, hv_XYZDirectories, hv_XYZDirectoriesRel;
  HTuple  hv_Exception, hv_NormalsBaseNames, hv_NormalsBaseNamesToMatch;
  HTuple  hv_NormalsExtensions, hv_NormalsDirectories, hv_NormalsDirectoriesRel;
  HTuple  hv_GroundTruthLabels, hv_AnomalyExtensions, hv_AnnoBaseNames;
  HTuple  hv_AnnoBaseNamesToMatch, hv_AnnoExtensions, hv_AnnoDirectories;
  HTuple  hv_AnnoDirectoriesRel, hv_ImageMatchIndices, hv_XYZMatchIndices;
  HTuple  hv_NormalsMatchIndices, hv_AnnoMatchIndices, hv_ImageIndex;
  HTuple  hv_ImageNameToMatch, hv_ImageDirectoryToMatch, hv_ImageExtensionToMatch;
  HTuple  hv_XYZMatchIndex, hv_NormalsMatchIndex, hv_AnnoMatchIndex;
  HTuple  hv_ImageIndices, hv_AnnotationList;

  //
  //This procedure generates lists of images and corresponding
  //annotation files, whereby the first one can also be handed
  //over through ImageListIn.
  //The lists are generated by listing the files in the given
  //directory:
  // - ImageDir specifies the base directory for the images,
  // - XYZDir specifies the base directory for the XYZ-images,
  // - NormalsDir specifies the base directory for the normals
  //   images,
  // - AnnotationDir specifies the base directory for the
  //   annotation files.
  //
  //The file names of images and annotation files must give a
  //unique match in the sense that for each image exactly one
  //annotation is matched. To obtain a match, the following steps
  //are done (in the given order):
  //1) Exact name match.
  //2) Image name is a subpart of a single annotation file name.
  //3) Image name is a subpart of more than one annotation file
  //   names and only one of these matches has the same subfolder
  //   structure.
  //The additional image types (XYZ- and normals images) are
  //matched in a similar way.
  //
  //With the parameters specified in GenParam, the lists can be
  //limited to specific file names.
  //
  //Set defaults.
  hv_ImageSubDirs = HTuple();
  hv_XYZSubDirs = HTuple();
  hv_NormalsSubDirs = HTuple();
  hv_AnnotationSubDirs = HTuple();
  hv_FileNameImageOnly = "";
  hv_FileNameXYZOnly = "";
  hv_FileNameNormalsOnly = "";
  hv_FileNameAnnoOnly = "";
  hv_IgnoreUnmatched = 0;
  //
  //Read generic parameters and overwrite defaults.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_Keys);
    {
    HTuple end_val42 = (hv_Keys.TupleLength())-1;
    HTuple step_val42 = 1;
    for (hv_KeyIndex=0; hv_KeyIndex.Continue(end_val42, step_val42); hv_KeyIndex += step_val42)
    {
      if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("image_sub_dirs"))))
      {
        GetDictTuple(hv_GenParam, "image_sub_dirs", &hv_ImageSubDirs);
      }
      else if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("xyz_sub_dirs"))))
      {
        GetDictTuple(hv_GenParam, "xyz_sub_dirs", &hv_XYZSubDirs);
      }
      else if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("normals_sub_dirs"))))
      {
        GetDictTuple(hv_GenParam, "normals_sub_dirs", &hv_NormalsSubDirs);
      }
      else if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("segmentation_sub_dirs"))))
      {
        GetDictTuple(hv_GenParam, "segmentation_sub_dirs", &hv_AnnotationSubDirs);
      }
      else if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("anomaly_sub_dirs"))))
      {
        GetDictTuple(hv_GenParam, "anomaly_sub_dirs", &hv_AnnotationSubDirs);
      }
      else if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("file_name_image_only"))))
      {
        GetDictTuple(hv_GenParam, "file_name_image_only", &hv_FileNameImageOnly);
      }
      else if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("file_name_xyz_only"))))
      {
        GetDictTuple(hv_GenParam, "file_name_xyz_only", &hv_FileNameXYZOnly);
      }
      else if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("file_name_normals_only"))))
      {
        GetDictTuple(hv_GenParam, "file_name_normals_only", &hv_FileNameNormalsOnly);
      }
      else if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("file_name_segmentation_only"))))
      {
        GetDictTuple(hv_GenParam, "file_name_segmentation_only", &hv_FileNameAnnoOnly);
      }
      else if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("file_name_anomaly_only"))))
      {
        GetDictTuple(hv_GenParam, "file_name_anomaly_only", &hv_FileNameAnnoOnly);
      }
      else if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("ignore_unmatched_images"))))
      {
        GetDictTuple(hv_GenParam, "ignore_unmatched_images", &hv_IgnoreUnmatched);
      }
      else
      {
        throw HException(("Unknown generic parameter name : '"+HTuple(hv_Keys[hv_KeyIndex]))+"'");
      }
    }
    }
  }
  //
  //Check for model type and set corresponding annotation type
  //string to use (e.g. in error messages).
  if (0 != (HTuple(int(hv_Type==HTuple("segmentation"))).TupleOr(int(hv_Type==HTuple("3d_gripping_point_detection")))))
  {
    hv_AnnotationType = "segmentation";
  }
  else if (0 != (int(hv_Type==HTuple("anomaly_detection"))))
  {
    hv_AnnotationType = "anomaly";
  }
  else
  {
    throw HException("Unknown type "+hv_Type);
  }
  //
  //Check generic parameters.
  if (0 != (int(hv_ImageSubDirs!=HTuple())))
  {
    if (0 != (int(((hv_ImageSubDirs.TupleIsStringElem()).TupleMin())!=1)))
    {
      throw HException("'image_sub_dirs' must be a tuple of strings");
    }
  }
  if (0 != (int(hv_AnnotationSubDirs!=HTuple())))
  {
    if (0 != (int(((hv_AnnotationSubDirs.TupleIsStringElem()).TupleMin())!=1)))
    {
      throw HException(("'"+hv_AnnotationType)+"_sub_dirs' must be a tuple of strings");
    }
  }
  if (0 != (int(hv_FileNameImageOnly!=HTuple(""))))
  {
    if (0 != (int((hv_FileNameImageOnly.TupleLength())!=1)))
    {
      throw HException("'file_name_image_only' must be a single string");
    }
    else if (0 != ((hv_FileNameImageOnly.TupleIsString()).TupleNot()))
    {
      throw HException("'file_name_image_only' must be a string");
    }
  }
  if (0 != (int(hv_FileNameAnnoOnly!=HTuple(""))))
  {
    if (0 != (int((hv_FileNameAnnoOnly.TupleLength())!=1)))
    {
      throw HException(("'file_name_"+hv_AnnotationType)+"_only' must be a single string");
    }
    else if (0 != ((hv_FileNameAnnoOnly.TupleIsString()).TupleNot()))
    {
      throw HException(("'file_name_"+hv_AnnotationType)+"_only' must be a string");
    }
  }
  if (0 != (int(hv_Type==HTuple("3d_gripping_point_detection"))))
  {
    if (0 != (int(hv_XYZSubDirs!=HTuple())))
    {
      if (0 != (int(((hv_XYZSubDirs.TupleIsStringElem()).TupleMin())!=1)))
      {
        throw HException("'xyz_sub_dirs' must be a tuple of strings");
      }
    }
    if (0 != (int(hv_NormalsSubDirs!=HTuple())))
    {
      if (0 != (int(((hv_NormalsSubDirs.TupleIsStringElem()).TupleMin())!=1)))
      {
        throw HException("'normals_sub_dirs' must be a tuple of strings");
      }
    }
    if (0 != (int(hv_FileNameXYZOnly!=HTuple(""))))
    {
      if (0 != (int((hv_FileNameXYZOnly.TupleLength())!=1)))
      {
        throw HException("'file_name_xyz_only' must be a single string");
      }
      else if (0 != ((hv_FileNameXYZOnly.TupleIsString()).TupleNot()))
      {
        throw HException("'file_name_xyz_only' must be a string");
      }
    }
    if (0 != (int(hv_FileNameNormalsOnly!=HTuple(""))))
    {
      if (0 != (int((hv_FileNameNormalsOnly.TupleLength())!=1)))
      {
        throw HException("'file_name_normals_only' must be a single string");
      }
      else if (0 != ((hv_FileNameNormalsOnly.TupleIsString()).TupleNot()))
      {
        throw HException("'file_name_normals_only' must be a string");
      }
    }
  }
  if (0 != (HTuple(int(hv_IgnoreUnmatched!=0)).TupleAnd(int(hv_IgnoreUnmatched!=1))))
  {
    throw HException("Unsupported value for 'ignore_unmatched_images' : "+hv_IgnoreUnmatched);
  }
  //
  //Prepare image list.
  prepare_image_lists(hv_ImageDir, hv_ImageListIn, hv_ImageSubDirs, hv_FileNameImageOnly, 
      "default", &hv_ImageBaseNames, &hv_ImageBaseNamesToMatch, &hv_ImageExtensions, 
      &hv_ImageDirectories, &hv_ImageDirectoriesRel);
  //
  //Prepare XYZ file list.
  try
  {
    hv_XYZBaseNames = HTuple();
    hv_XYZBaseNamesToMatch = HTuple();
    hv_XYZExtensions = HTuple();
    hv_XYZDirectories = HTuple();
    hv_XYZDirectoriesRel = HTuple();
    prepare_image_lists(hv_XYZDir, HTuple(), hv_XYZSubDirs, hv_FileNameXYZOnly, "default", 
        &hv_XYZBaseNames, &hv_XYZBaseNamesToMatch, &hv_XYZExtensions, &hv_XYZDirectories, 
        &hv_XYZDirectoriesRel);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    if (0 != (int(hv_Type==HTuple("3d_gripping_point_detection"))))
    {
      //XYZ-images are required for 3D Gripping Point Detection.
      throw HException("No XYZ-images found");
    }
  }
  //
  //Prepare normals file list.
  try
  {
    hv_NormalsBaseNames = HTuple();
    hv_NormalsBaseNamesToMatch = HTuple();
    hv_NormalsExtensions = HTuple();
    hv_NormalsDirectories = HTuple();
    hv_NormalsDirectoriesRel = HTuple();
    prepare_image_lists(hv_NormalsDir, HTuple(), hv_NormalsSubDirs, hv_FileNameNormalsOnly, 
        "default", &hv_NormalsBaseNames, &hv_NormalsBaseNamesToMatch, &hv_NormalsExtensions, 
        &hv_NormalsDirectories, &hv_NormalsDirectoriesRel);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    //It is okay since normals are optional.
  }
  //
  //Get ground truth labels from the image directory names.
  TupleRegexpMatch("/"+hv_ImageDirectories, ".*/([^/]+)/$", &hv_GroundTruthLabels);
  //
  //Prepare annotation file list.
  try
  {
    if (0 != (int(hv_Type==HTuple("anomaly_detection"))))
    {
      hv_AnomalyExtensions.Clear();
      hv_AnomalyExtensions[0] = "hobj";
      hv_AnomalyExtensions[1] = "ima";
      hv_AnomalyExtensions[2] = "tif";
      hv_AnomalyExtensions[3] = "tiff";
      hv_AnomalyExtensions[4] = "gif";
      hv_AnomalyExtensions[5] = "bmp";
      hv_AnomalyExtensions[6] = "jpg";
      hv_AnomalyExtensions[7] = "jpeg";
      hv_AnomalyExtensions[8] = "jp2";
      hv_AnomalyExtensions[9] = "jxr";
      hv_AnomalyExtensions[10] = "png";
      hv_AnomalyExtensions[11] = "pcx";
      hv_AnomalyExtensions[12] = "ras";
      hv_AnomalyExtensions[13] = "xwd";
      hv_AnomalyExtensions[14] = "pbm";
      hv_AnomalyExtensions[15] = "pnm";
      hv_AnomalyExtensions[16] = "pgm";
      hv_AnomalyExtensions[17] = "ppm";
      prepare_image_lists(hv_AnnotationDir, HTuple(), hv_AnnotationSubDirs, hv_FileNameAnnoOnly, 
          hv_AnomalyExtensions, &hv_AnnoBaseNames, &hv_AnnoBaseNamesToMatch, &hv_AnnoExtensions, 
          &hv_AnnoDirectories, &hv_AnnoDirectoriesRel);
    }
    else
    {
      prepare_image_lists(hv_AnnotationDir, HTuple(), hv_AnnotationSubDirs, hv_FileNameAnnoOnly, 
          "default", &hv_AnnoBaseNames, &hv_AnnoBaseNamesToMatch, &hv_AnnoExtensions, 
          &hv_AnnoDirectories, &hv_AnnoDirectoriesRel);
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    if (0 != (int(hv_Type==HTuple("anomaly_detection"))))
    {
      (*hv_ImageListOut) = ((hv_ImageDirectoriesRel+hv_ImageBaseNames)+".")+hv_ImageExtensions;
      TupleRegexpReplace((*hv_ImageListOut), "^/", "", &(*hv_ImageListOut));
      (*hv_LabelListOut) = hv_GroundTruthLabels;
      (*hv_AnnotationListOut) = HTuple(hv_ImageBaseNames.TupleLength(),"");
      return;
    }
    else
    {
      throw HException("No annotation images found");
    }
  }
  //
  //
  //Match image, XYZ, normals and annotation lists.
  hv_ImageMatchIndices = HTuple();
  hv_XYZMatchIndices = HTuple();
  hv_NormalsMatchIndices = HTuple();
  hv_AnnoMatchIndices = HTuple();
  {
  HTuple end_val195 = (hv_ImageBaseNames.TupleLength())-1;
  HTuple step_val195 = 1;
  for (hv_ImageIndex=0; hv_ImageIndex.Continue(end_val195, step_val195); hv_ImageIndex += step_val195)
  {
    hv_ImageNameToMatch = HTuple(hv_ImageBaseNamesToMatch[hv_ImageIndex]);
    hv_ImageDirectoryToMatch = HTuple(hv_ImageDirectoriesRel[hv_ImageIndex]);
    hv_ImageExtensionToMatch = HTuple(hv_ImageExtensions[hv_ImageIndex]);
    //
    //Match to every image file a XYZ file.
    get_matching_file_index(hv_XYZBaseNamesToMatch, hv_XYZDirectoriesRel, hv_ImageNameToMatch, 
        hv_ImageDirectoryToMatch, hv_ImageExtensionToMatch, &hv_XYZMatchIndex);
    //
    //Match to every image file a normals file.
    get_matching_file_index(hv_NormalsBaseNamesToMatch, hv_NormalsDirectoriesRel, 
        hv_ImageNameToMatch, hv_ImageDirectoryToMatch, hv_ImageExtensionToMatch, 
        &hv_NormalsMatchIndex);
    //
    //Match to every image file an annotation file.
    get_matching_file_index(hv_AnnoBaseNamesToMatch, hv_AnnoDirectoriesRel, hv_ImageNameToMatch, 
        hv_ImageDirectoryToMatch, hv_ImageExtensionToMatch, &hv_AnnoMatchIndex);
    //
    //Collect found indices in case all required images were found.
    if (0 != (int(hv_AnnoMatchIndex!=-1)))
    {
      if (0 != (HTuple(int(hv_Type==HTuple("3d_gripping_point_detection"))).TupleAnd(int((hv_NormalsBaseNamesToMatch.TupleLength())>0))))
      {
        if (0 != (HTuple(int(hv_XYZMatchIndex!=-1)).TupleAnd(int(hv_NormalsMatchIndex!=-1))))
        {
          hv_ImageMatchIndices = hv_ImageMatchIndices.TupleConcat(hv_ImageIndex);
          hv_XYZMatchIndices = hv_XYZMatchIndices.TupleConcat(hv_XYZMatchIndex);
          hv_NormalsMatchIndices = hv_NormalsMatchIndices.TupleConcat(hv_NormalsMatchIndex);
          hv_AnnoMatchIndices = hv_AnnoMatchIndices.TupleConcat(hv_AnnoMatchIndex);
        }
      }
      else if (0 != (HTuple(int(hv_Type==HTuple("3d_gripping_point_detection"))).TupleAnd(int((hv_NormalsBaseNamesToMatch.TupleLength())==0))))
      {
        if (0 != (int(hv_XYZMatchIndex!=-1)))
        {
          hv_ImageMatchIndices = hv_ImageMatchIndices.TupleConcat(hv_ImageIndex);
          hv_XYZMatchIndices = hv_XYZMatchIndices.TupleConcat(hv_XYZMatchIndex);
          hv_AnnoMatchIndices = hv_AnnoMatchIndices.TupleConcat(hv_AnnoMatchIndex);
        }
      }
      else
      {
        hv_ImageMatchIndices = hv_ImageMatchIndices.TupleConcat(hv_ImageIndex);
        hv_AnnoMatchIndices = hv_AnnoMatchIndices.TupleConcat(hv_AnnoMatchIndex);
      }
    }
  }
  }
  //
  //
  //Final checks.
  //
  //Check if the corresponding matches are collected correctly.
  if (0 != (int(hv_Type==HTuple("3d_gripping_point_detection"))))
  {
    if (0 != (int((hv_XYZMatchIndices.TupleLength())!=(hv_ImageMatchIndices.TupleLength()))))
    {
      throw HException("An error occurred while trying to match XYZ and image files");
    }
    if (0 != (HTuple(int((hv_NormalsBaseNamesToMatch.TupleLength())>0)).TupleAnd(int((hv_NormalsMatchIndices.TupleLength())!=(hv_ImageMatchIndices.TupleLength())))))
    {
      throw HException("An error occurred while trying to match normals and image files");
    }
  }
  if (0 != (int((hv_AnnoMatchIndices.TupleLength())!=(hv_ImageMatchIndices.TupleLength()))))
  {
    throw HException("An error occurred while trying to match annotation and image files");
  }
  //
  //Check if each match is unique.
  if (0 != (int(((hv_XYZMatchIndices.TupleSort()).TupleUniq())!=(hv_XYZMatchIndices.TupleSort()))))
  {
    throw HException("A single XYZ file has matched with multiple images");
  }
  if (0 != (int(((hv_NormalsMatchIndices.TupleSort()).TupleUniq())!=(hv_NormalsMatchIndices.TupleSort()))))
  {
    throw HException("A single normals file has matched with multiple images");
  }
  if (0 != (int(((hv_AnnoMatchIndices.TupleSort()).TupleUniq())!=(hv_AnnoMatchIndices.TupleSort()))))
  {
    throw HException(("A single "+hv_AnnotationType)+" file has matched with multiple images");
  }
  //
  //Check if every image was collected, i.e. there is no image
  //without a match.
  hv_ImageIndices = hv_ImageMatchIndices;
  if (0 != (int(hv_Type==HTuple("anomaly_detection"))))
  {
    //For anomaly detection, images without a matching annotation
    //file are okay. So in this case, we use all images and not
    //only the ones with a match.
    hv_ImageIndices = HTuple::TupleGenSequence(0,(hv_ImageBaseNames.TupleLength())-1,1);
  }
  else if (0 != (hv_IgnoreUnmatched.TupleNot()))
  {
    if (0 != (int((hv_ImageMatchIndices.TupleLength())!=(hv_ImageBaseNames.TupleLength()))))
    {
      throw HException("Not every image has all required matching files");
    }
  }
  //
  //Create final image list.
  (*hv_ImageListOut) = ((hv_ImageDirectoriesRel+hv_ImageBaseNames)+".")+hv_ImageExtensions;
  (*hv_ImageListOut) = HTuple((*hv_ImageListOut)[hv_ImageIndices]);
  TupleRegexpReplace((*hv_ImageListOut), "^/", "", &(*hv_ImageListOut));
  //
  //Create final XYZ list.
  (*hv_XYZListOut) = ((hv_XYZDirectoriesRel+hv_XYZBaseNames)+".")+hv_XYZExtensions;
  (*hv_XYZListOut) = HTuple((*hv_XYZListOut)[hv_XYZMatchIndices]);
  TupleRegexpReplace((*hv_XYZListOut), "^/", "", &(*hv_XYZListOut));
  //
  //Create final normals list.
  (*hv_NormalsListOut) = ((hv_NormalsDirectoriesRel+hv_NormalsBaseNames)+".")+hv_NormalsExtensions;
  (*hv_NormalsListOut) = HTuple((*hv_NormalsListOut)[hv_NormalsMatchIndices]);
  TupleRegexpReplace((*hv_NormalsListOut), "^/", "", &(*hv_NormalsListOut));
  //
  //Create final ground truth label list.
  (*hv_LabelListOut) = HTuple(hv_GroundTruthLabels[hv_ImageIndices]);
  //
  //Create final annotation list.
  (*hv_AnnotationListOut) = ((hv_AnnoDirectoriesRel+hv_AnnoBaseNames)+".")+hv_AnnoExtensions;
  if (0 != (int(hv_Type==HTuple("anomaly_detection"))))
  {
    hv_AnnotationList = HTuple((*hv_ImageListOut).TupleLength(),"");
    hv_AnnotationList[hv_ImageMatchIndices] = HTuple((*hv_AnnotationListOut)[hv_AnnoMatchIndices]);
    (*hv_AnnotationListOut) = hv_AnnotationList;
  }
  else
  {
    (*hv_AnnotationListOut) = HTuple((*hv_AnnotationListOut)[hv_AnnoMatchIndices]);
  }
  TupleRegexpReplace((*hv_AnnotationListOut), "^/", "", &(*hv_AnnotationListOut));
  //
  return;
}

// Chapter: File / Misc
// Short Description: Get the base names, extensions and directories of image files in the specified directory or image list. 
void prepare_image_lists (HTuple hv_ImageDir, HTuple hv_ImageListIn, HTuple hv_ImageSubDirs, 
    HTuple hv_FileNameImageOnly, HTuple hv_Extensions, HTuple *hv_ImageBaseNames, 
    HTuple *hv_ImageBaseNamesToMatch, HTuple *hv_ImageExtensions, HTuple *hv_ImageDirectories, 
    HTuple *hv_ImageDirectoriesRel)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ImageDirs, hv_ImageDirIndex, hv_ImageFilesTmp;
  HTuple  hv_ImageBaseNamesTmp, hv_ImageExtensionsTmp, hv_ImageDirectoriesTmp;
  HTuple  hv__, hv_ImageMatches, hv_MatchIndices;

  //
  //This procedure returns for all images in ImageDir/ImageSubDirs
  //or ImageListIn:
  //- the base names,
  //- the base names prepared for matching,
  //- the extensions,
  //- the directories
  //- the paths of directories relative to ImageDir.
  //
  (*hv_ImageBaseNames) = HTuple();
  (*hv_ImageBaseNamesToMatch) = HTuple();
  (*hv_ImageExtensions) = HTuple();
  (*hv_ImageDirectories) = HTuple();
  (*hv_ImageDirectoriesRel) = HTuple();
  //
  //Get all image directories.
  if (0 != (int(hv_ImageSubDirs!=HTuple())))
  {
    hv_ImageDirs = (hv_ImageDir+"/")+hv_ImageSubDirs;
  }
  else
  {
    hv_ImageDirs = hv_ImageDir;
  }
  //
  //Get lists of parsed image files.
  if (0 != (int(hv_ImageListIn!=HTuple())))
  {
    parse_filename(hv_ImageListIn, &(*hv_ImageBaseNames), &(*hv_ImageExtensions), 
        &(*hv_ImageDirectories));
  }
  else
  {
    //List all image files if no list given in ImageListIn.
    {
    HTuple end_val27 = (hv_ImageDirs.TupleLength())-1;
    HTuple step_val27 = 1;
    for (hv_ImageDirIndex=0; hv_ImageDirIndex.Continue(end_val27, step_val27); hv_ImageDirIndex += step_val27)
    {
      list_image_files(HTuple(hv_ImageDirs[hv_ImageDirIndex]), hv_Extensions, (HTuple("recursive").Append("follow_links")), 
          &hv_ImageFilesTmp);
      parse_filename(hv_ImageFilesTmp, &hv_ImageBaseNamesTmp, &hv_ImageExtensionsTmp, 
          &hv_ImageDirectoriesTmp);
      (*hv_ImageBaseNames) = (*hv_ImageBaseNames).TupleConcat(hv_ImageBaseNamesTmp);
      (*hv_ImageExtensions) = (*hv_ImageExtensions).TupleConcat(hv_ImageExtensionsTmp);
      (*hv_ImageDirectories) = (*hv_ImageDirectories).TupleConcat(hv_ImageDirectoriesTmp);
    }
    }
  }
  //
  if (0 != (int(((*hv_ImageBaseNames).TupleLength())==0)))
  {
    throw HException(("Error: Could not find any image files in folder: \""+hv_ImageDirs)+"\"");
  }
  //
  //Get file paths of images relative to ImageDir.
  get_relative_image_directories(hv_ImageDir, (*hv_ImageDirectories), &hv__, &(*hv_ImageDirectoriesRel));
  //
  if (0 != (int(hv_FileNameImageOnly!=HTuple(""))))
  {
    //Select only the images which include the specified string.
    TupleRegexpMatch((*hv_ImageBaseNames), hv_FileNameImageOnly, &hv_ImageMatches);
    TupleFind(hv_ImageMatches.TupleNotEqualElem(""), 1, &hv_MatchIndices);
    if (0 != (int(hv_MatchIndices==-1)))
    {
      throw HException("Error: Could not find any image files with the substring: "+hv_FileNameImageOnly);
    }
    (*hv_ImageBaseNames) = HTuple((*hv_ImageBaseNames)[hv_MatchIndices]);
    (*hv_ImageExtensions) = HTuple((*hv_ImageExtensions)[hv_MatchIndices]);
    (*hv_ImageDirectories) = HTuple((*hv_ImageDirectories)[hv_MatchIndices]);
    (*hv_ImageDirectoriesRel) = HTuple((*hv_ImageDirectoriesRel)[hv_MatchIndices]);
    //Remove the substring of the image file name which should
    //be ignored for matching.
    TupleRegexpReplace((*hv_ImageBaseNames), hv_FileNameImageOnly, "", &(*hv_ImageBaseNamesToMatch));
  }
  else
  {
    (*hv_ImageBaseNamesToMatch) = (*hv_ImageBaseNames);
  }
  //
  return;
}

// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Generate a DLDataset dictionary for 3D Gripping Point Detection. 
void read_dl_dataset_3d_gripping_point_detection (HTuple hv_ImageBaseDir, HTuple hv_SegmentationDir, 
    HTuple hv_ClassIDs, HTuple hv_GenParam, HTuple *hv_DLDataset)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ClassNames, hv_ImageDirSep, hv_SegmentationDirSep;
  HTuple  hv_ImageDir, hv_XYZDir, hv_NormalsDir, hv_ImageList;
  HTuple  hv_XYZList, hv_NormalsList, hv_SegmentationList;
  HTuple  hv__, hv_NumSamples, hv_ThreadNum, hv_ThreadSys;
  HTuple  hv_NumSamplesPerThread, hv_ThreadIndex, hv_Start;
  HTuple  hv_End, hv_ThreadIds, hv_Samples;
  HTupleVector  hvec_SamplesOutput(1), hvec_VProcThreads(1);

  // +++ Threading variables 
  HDevThread*         hcppthread_handle;
  HDevThreadContext   hcppthread_context; // <-signals begin of procedure

  //
  //This procedure creates a dictionary DLDataset, which serves as an input
  //for deep-learning-based 3D Gripping Point Detection. Information needed
  //to create this dictionary is given through the input parameters.
  //
  //The output dictionary DLDataset has the following structure:
  //
  //DLDataset
  //{
  //    'image_dir'         : Common base path of all RGB or intensity images
  //    'xyz_dir'           : Common base path of all XYZ-images
  //    'normals_dir'       : Common base path of all normals images (if available)
  //    'segmentation_dir'  : Common base path of all segmentation images
  //    'class_names'[]     : Tuple of strings which is predefined as ['gripping_map', 'background']
  //    'class_ids'[]       : Tuple of integers
  //    'samples'[]         : Tuple of dictionaries
  //    {
  //        'image_id'                  : Unique image ID
  //        'image_file_name'           : File path relative to 'image_dir' (including the file name)
  //        'xyz_file_name'             : File path relative to 'xyz_dir' (including the file name)
  //        'normals_file_name'         : File path relative to 'normals_dir' (including the file name, if available)
  //        'segmentation_file_name'    : File path relative to 'segmentation_dir' (including the file name)
  //    }
  //}
  //
  //
  //Predefined class names.
  hv_ClassNames.Clear();
  hv_ClassNames[0] = "gripping_map";
  hv_ClassNames[1] = "background";
  //
  //Sanity checks of inputs.
  //
  //The length of ClassIDs has to be 2.
  if (0 != (int((hv_ClassIDs.TupleLength())!=2)))
  {
    throw HException("Number of class IDs should be 2");
  }
  //ClassIDs must be unique.
  if (0 != (int(HTuple(hv_ClassIDs[0])==HTuple(hv_ClassIDs[1]))))
  {
    throw HException("Class IDs are not unique");
  }
  if (0 != (int((hv_ImageBaseDir.TupleLength())==0)))
  {
    hv_ImageBaseDir = "";
  }
  //ImageBaseDir can only be one string.
  if (0 != (int((hv_ImageBaseDir.TupleLength())!=1)))
  {
    throw HException("Only one base path for the images can be given");
  }
  else if (0 != (int((hv_ImageBaseDir.TupleIsString())!=1)))
  {
    throw HException("ImageBaseDir is not a string");
  }
  if (0 != (int((hv_SegmentationDir.TupleLength())==0)))
  {
    hv_SegmentationDir = "";
  }
  //SegmentationDir can only be one string.
  if (0 != (int((hv_SegmentationDir.TupleLength())!=1)))
  {
    throw HException("Only one base path for the annotation images can be given");
  }
  else if (0 != (int((hv_SegmentationDir.TupleIsString())!=1)))
  {
    throw HException("SegmentationDir is not a string");
  }
  //
  //Prepare the image lists.
  //
  //Replace windows path separators
  TupleRegexpReplace(hv_ImageBaseDir, (HTuple("\\\\+").Append("replace_all")), "/", 
      &hv_ImageBaseDir);
  TupleRegexpReplace(hv_SegmentationDir, (HTuple("\\\\+").Append("replace_all")), 
      "/", &hv_SegmentationDir);
  //Replace any forward slashes at the end.
  TupleRegexpReplace(hv_ImageBaseDir, "/$", "", &hv_ImageBaseDir);
  TupleRegexpReplace(hv_SegmentationDir, "/$", "", &hv_SegmentationDir);
  //Remove possible (not starting) double slashes.
  if (0 != (int((hv_ImageBaseDir.TupleRegexpMatch("(.+)//"))!=HTuple(""))))
  {
    hv_ImageBaseDir = hv_ImageBaseDir.TupleRegexpReplace("(.+)//","$1/");
  }
  if (0 != (int((hv_SegmentationDir.TupleRegexpMatch("(.+)//"))!=HTuple(""))))
  {
    hv_SegmentationDir = hv_SegmentationDir.TupleRegexpReplace("(.+)//","$1/");
  }
  //
  //If directory is empty, we omit the path separator.
  if (0 != (int((hv_ImageBaseDir.TupleStrlen())==0)))
  {
    hv_ImageDirSep = "";
  }
  else
  {
    hv_ImageDirSep = "/";
  }
  if (0 != (int((hv_SegmentationDir.TupleStrlen())==0)))
  {
    hv_SegmentationDirSep = "";
  }
  else
  {
    hv_SegmentationDirSep = "/";
  }
  //
  //Subdirectory containing the RGB/intensity images.
  hv_ImageDir = (hv_ImageBaseDir+hv_ImageDirSep)+"images";
  //Subdirectory containing the XYZ-images.
  hv_XYZDir = (hv_ImageBaseDir+hv_ImageDirSep)+"xyz";
  //Subdirectory containing the normals images.
  hv_NormalsDir = (hv_ImageBaseDir+hv_ImageDirSep)+"normals";
  //
  //Get required image and annotation lists from given directory
  //paths.
  list_image_and_annotation_files("3d_gripping_point_detection", hv_ImageDir, hv_XYZDir, 
      hv_NormalsDir, hv_SegmentationDir, HTuple(), hv_GenParam, &hv_ImageList, &hv_XYZList, 
      &hv_NormalsList, &hv_SegmentationList, &hv__);
  //
  //Check if all images and annotation files exist.
  images_exist((hv_ImageDir+"/")+hv_ImageList);
  images_exist((hv_XYZDir+"/")+hv_XYZList);
  images_exist((hv_NormalsDir+"/")+hv_NormalsList);
  images_exist((hv_SegmentationDir+hv_SegmentationDirSep)+hv_SegmentationList);
  //
  //Initialize the dictionary dataset.
  CreateDict(&(*hv_DLDataset));
  //
  //Set general information of the dataset.
  SetDictTuple((*hv_DLDataset), "image_dir", hv_ImageDir);
  SetDictTuple((*hv_DLDataset), "xyz_dir", hv_XYZDir);
  if (0 != (int((hv_NormalsList.TupleLength())>0)))
  {
    SetDictTuple((*hv_DLDataset), "normals_dir", hv_NormalsDir);
  }
  SetDictTuple((*hv_DLDataset), "segmentation_dir", hv_SegmentationDir);
  SetDictTuple((*hv_DLDataset), "class_names", hv_ClassNames);
  SetDictTuple((*hv_DLDataset), "class_ids", hv_ClassIDs);
  //
  //Get number of samples to set unique image ID for each sample
  //according to its index in ImageList.
  hv_NumSamples = hv_ImageList.TupleLength();
  //
  //Create samples in parallel.
  //We use 8 threads, clearly less than the maximum number of
  //HDevelop subthreads.
  hv_ThreadNum = 8;
  GetSystem("thread_num", &hv_ThreadSys);
  if (0 != (int(hv_ThreadNum>hv_ThreadSys)))
  {
    hv_ThreadNum = 1;
  }
  hv_NumSamplesPerThread = ((hv_NumSamples+hv_ThreadNum)-1)/hv_ThreadNum;
  {
  HTuple end_val129 = hv_ThreadNum-1;
  HTuple step_val129 = 1;
  for (hv_ThreadIndex=0; hv_ThreadIndex.Continue(end_val129, step_val129); hv_ThreadIndex += step_val129)
  {
    hv_Start = hv_ThreadIndex*hv_NumSamplesPerThread;
    hv_End = (hv_Start+hv_NumSamplesPerThread)-1;
    if (0 != (HTuple(int(hv_End<0)).TupleOr(int(hv_Start<0))))
    {
      throw HException("Negative indices when calculating samples per thread.");
    }
    //
    //Adapt indices for very last thread.
    if (0 != (int(hv_End>=hv_NumSamples)))
    {
      hv_End = hv_NumSamples-1;
      if (0 != (int(hv_End<hv_Start)))
      {
        break;
      }
      hv_NumSamplesPerThread = (hv_End-hv_Start)+1;
    }
    if (0 != (int((hv_NormalsList.TupleLength())>0)))
    {
      // Create a thread instance
      hcppthread_handle = new HDevThread(hcppthread_context,
                  (void*)HDevExportCpp::_hcppthread_create_dl_dataset_3d_gripping_point_detection_samples,6,1);
      // Set thread procedure call arguments 
      hcppthread_handle->SetInputCtrlParamTuple(0,hv_ImageList.TupleSelectRange(hv_Start,hv_End));
      hcppthread_handle->SetInputCtrlParamTuple(1,hv_XYZList.TupleSelectRange(hv_Start,hv_End));
      hcppthread_handle->SetInputCtrlParamTuple(2,hv_NormalsList.TupleSelectRange(hv_Start,hv_End));
      hcppthread_handle->SetInputCtrlParamTuple(3,hv_SegmentationList.TupleSelectRange(hv_Start,hv_End));
      hcppthread_handle->SetInputCtrlParamTuple(4,hv_NumSamplesPerThread);
      hcppthread_handle->SetInputCtrlParamTuple(5,hv_Start);
      {HTuple at_idx;
      at_idx[0] = hv_ThreadIndex;
      hcppthread_handle->BindOutputCtrlParamVector(0,0,&hvec_SamplesOutput,at_idx);
      }

      // Start proc line in thread
      hcppthread_handle->ParStart(&hvec_VProcThreads[hv_ThreadIndex].T());

    }
    else
    {
      // Create a thread instance
      hcppthread_handle = new HDevThread(hcppthread_context,
                  (void*)HDevExportCpp::_hcppthread_create_dl_dataset_3d_gripping_point_detection_samples,6,1);
      // Set thread procedure call arguments 
      hcppthread_handle->SetInputCtrlParamTuple(0,hv_ImageList.TupleSelectRange(hv_Start,hv_End));
      hcppthread_handle->SetInputCtrlParamTuple(1,hv_XYZList.TupleSelectRange(hv_Start,hv_End));
      hcppthread_handle->SetInputCtrlParamTuple(2,HTuple());
      hcppthread_handle->SetInputCtrlParamTuple(3,hv_SegmentationList.TupleSelectRange(hv_Start,hv_End));
      hcppthread_handle->SetInputCtrlParamTuple(4,hv_NumSamplesPerThread);
      hcppthread_handle->SetInputCtrlParamTuple(5,hv_Start);
      {HTuple at_idx;
      at_idx[0] = hv_ThreadIndex;
      hcppthread_handle->BindOutputCtrlParamVector(0,0,&hvec_SamplesOutput,at_idx);
      }

      // Start proc line in thread
      hcppthread_handle->ParStart(&hvec_VProcThreads[hv_ThreadIndex].T());

    }
    if (0 != (int(hv_End==(hv_NumSamples-1))))
    {
      break;
    }
  }
  }
  hv_ThreadIds = hvec_VProcThreads.ConvertVectorToTuple();
  HDevThread::ParJoin(hv_ThreadIds);
  hvec_VProcThreads.Clear();
  hv_ThreadIds = HTuple();
  hv_Samples = hvec_SamplesOutput.ConvertVectorToTuple();
  //
  //Set the sample tuple.
  SetDictTuple((*hv_DLDataset), "samples", hv_Samples);
  //
  return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Generate a DLDataset dictionary for anomaly detection or Global Context Anomaly Detection. 
void read_dl_dataset_anomaly (HTuple hv_ImageDir, HTuple hv_AnomalyDir, HTuple hv_ImageList, 
    HTuple hv_AnomalyList, HTuple hv_GenParam, HTuple *hv_DLDataset)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_AnomalyDirGiven, hv__, hv_LabelList;
  HTuple  hv_NoAnomalyIndices, hv_ImageDirSep, hv_AnomalyDirSep;
  HTuple  hv_AnomalyFileIndices, hv_ClassNames, hv_ClassIDs;
  HTuple  hv_NumSamples, hv_ThreadNum, hv_ThreadSys, hv_NumSamplesPerThread;
  HTuple  hv_ThreadIndex, hv_Start, hv_End, hv_ThreadIds;
  HTuple  hv_Samples, hv_Index;
  HTupleVector  hvec_SamplesOutput(1), hvec_Exceptions(1);
  HTupleVector  hvec_VProcThreads(1);

  // +++ Threading variables 
  HDevThread*         hcppthread_handle;
  HDevThreadContext   hcppthread_context; // <-signals begin of procedure

  //
  //This procedure creates the dictionary DLDataset which serves as an input for
  //deep-learning-based anomaly detection or Global Context Anomaly Detection models.
  //Information needed to create this dictionary is given through the input parameters.
  //
  //The output dictionary DLDataset has the following structure:
  //
  //DLDataset
  //{
  //    'image_dir'         : Common base path of all images
  //    'anomaly_dir'       : Common base path of all anomaly annotation files (ground truth annotations indicating anomalies in the images)
  //    'class_names'[]     : Tuple of class names ['ok','nok']
  //    'class_ids'[]       : Tuple of class ids [0,1]
  //    'samples'[]         : Tuple of dictionaries
  //    {
  //        'image_file_name'           : File path relative to 'image_dir' (including the file name)
  //        'anomaly_file_name'         : File path relative to 'anomaly_dir' (including the file name), contains a file with ground truth annotations
  //        'image_id'                  : Unique image ID
  //        'anomaly_label'             : Label on image level : 'ok'/'nok'
  //    }
  //}
  //
  //Images are not required to have an anomaly ground truth file. However, images that do have a
  //corresponding annotation file can be evaluated quantitatively later. Note: Unlike in
  //read_dl_dataset_classification, the folder name is not directly converted into the
  //'anomaly_label'. For images without anomalies (images in the good/ok directory), the label
  //is set to 'ok' and for all images containing anomalies (images in any directory except for
  //good/ok), the label is set to the general label 'nok'.
  //
  //
  //Sanity checks of inputs.
  //
  //ImageDir has to be a single string.
  if (0 != (int((hv_ImageDir.TupleLength())!=1)))
  {
    throw HException("Exactly one base path is required as input for ImageDir");
  }
  else if (0 != ((hv_ImageDir.TupleIsString()).TupleNot()))
  {
    throw HException("ImageDir has to be a string");
  }
  //
  //AnomalyDir has to be a single string.
  hv_AnomalyDirGiven = 0;
  if (0 != (int((hv_AnomalyDir.TupleLength())>1)))
  {
    throw HException("Exactly one base path is required as input for AnomalyDir");
  }
  else if (0 != (int((hv_AnomalyDir.TupleLength())==1)))
  {
    if (0 != ((hv_AnomalyDir.TupleIsString()).TupleNot()))
    {
      throw HException("AnomalyDir has to be a string");
    }
    hv_AnomalyDirGiven = 1;
  }
  //
  //Check AnomalyList in case it is not empty.
  if (0 != (int(hv_AnomalyList!=HTuple())))
  {
    //Check if ImageList and AnomalyList have the same length.
    if (0 != (int((hv_ImageList.TupleLength())!=(hv_AnomalyList.TupleLength()))))
    {
      throw HException("AnomalyList must be empty or have the same length as ImageList");
    }
    else if (0 != (int(((hv_AnomalyList.TupleNotEqualElem("")).TupleMax())==0)))
    {
      throw HException("Please provide at least one valid anomaly file in AnomalyList or set the parameter to []");
    }
  }
  //
  //Prepare the image lists.
  //
  //Convert backslashes to forward slashes for unified processing.
  TupleRegexpReplace(hv_ImageDir, (HTuple("\\\\+").Append("replace_all")), "/", &hv_ImageDir);
  TupleRegexpReplace(hv_AnomalyDir, (HTuple("\\\\+").Append("replace_all")), "/", 
      &hv_AnomalyDir);
  TupleRegexpReplace(hv_ImageList, (HTuple("\\\\+").Append("replace_all")), "/", 
      &hv_ImageList);
  TupleRegexpReplace(hv_AnomalyList, (HTuple("\\\\+").Append("replace_all")), "/", 
      &hv_AnomalyList);
  //
  //Replace any forward slashes at the end.
  TupleRegexpReplace(hv_ImageDir, "/$", "", &hv_ImageDir);
  TupleRegexpReplace(hv_AnomalyDir, "/$", "", &hv_AnomalyDir);
  //Remove possible (not starting) double slashes.
  if (0 != (int((hv_ImageDir.TupleRegexpMatch("(.+)//"))!=HTuple(""))))
  {
    hv_ImageDir = hv_ImageDir.TupleRegexpReplace("(.+)//","$1/");
  }
  if (0 != (int((hv_AnomalyDir.TupleRegexpMatch("(.+)//"))!=HTuple(""))))
  {
    hv_AnomalyDir = hv_AnomalyDir.TupleRegexpReplace("(.+)//","$1/");
  }
  //
  //If no AnomalyList is given, create it out of the given ImageList or create both lists.
  if (0 != (int(hv_AnomalyList==HTuple())))
  {
    //List given images (or all images if none given) and their corresponding labels,
    //as well as their anomaly annotation files (if present).
    list_image_and_annotation_files("anomaly_detection", hv_ImageDir, HTuple(), HTuple(), 
        hv_AnomalyDir, hv_ImageList, hv_GenParam, &hv_ImageList, &hv__, &hv__, &hv_AnomalyList, 
        &hv_LabelList);
  }
  else
  {
    //Make sure that ImageList does not contain ImageDir.
    TupleRegexpReplace(hv_ImageList, ".*?"+hv_ImageDir, "", &hv_ImageList);
    TupleRegexpReplace(hv_ImageList, "^/", "", &hv_ImageList);
    //Get ground truth labels from the image directory names.
    TupleRegexpMatch("/"+hv_ImageList, ".*/([^/]+)/[^/]*$", &hv_LabelList);
    //Make sure that AnomalyList does not contain AnomalyDir.
    TupleRegexpReplace(hv_AnomalyList, ".*?"+hv_AnomalyDir, "", &hv_AnomalyList);
    TupleRegexpReplace(hv_AnomalyList, "^/", "", &hv_AnomalyList);
  }
  //
  //Check that for a given anomaly directory at least one annotation file is found.
  hv_NoAnomalyIndices = hv_AnomalyList.TupleFind("");
  if (0 != (HTuple(int((hv_NoAnomalyIndices.TupleLength())==(hv_ImageList.TupleLength()))).TupleAnd(hv_AnomalyDirGiven)))
  {
    throw HException(("Error: Could not find any matching anomaly regions in folder: \""+hv_AnomalyDir)+"\"");
  }
  //
  //If ImageDir or AnomalyDir is empty, we omit the path separator.
  if (0 != (int((hv_ImageDir.TupleStrlen())==0)))
  {
    hv_ImageDirSep = "";
  }
  else
  {
    hv_ImageDirSep = "/";
  }
  if (0 != (int((hv_AnomalyDir.TupleStrlen())==0)))
  {
    hv_AnomalyDirSep = "";
  }
  else
  {
    hv_AnomalyDirSep = "/";
  }
  //
  //Check if all images exist.
  images_exist((hv_ImageDir+hv_ImageDirSep)+hv_ImageList);
  //Check if all anomaly files exist.
  hv_AnomalyFileIndices = (hv_AnomalyList.TupleNotEqualElem("")).TupleFind(1);
  if (0 != (int(hv_AnomalyFileIndices!=-1)))
  {
    images_exist((hv_AnomalyDir+hv_AnomalyDirSep)+HTuple(hv_AnomalyList[hv_AnomalyFileIndices]));
  }
  //
  //Initialize the dictionary dataset.
  CreateDict(&(*hv_DLDataset));
  //
  //Set general information of the dataset.
  SetDictTuple((*hv_DLDataset), "image_dir", hv_ImageDir);
  if (0 != hv_AnomalyDirGiven)
  {
    SetDictTuple((*hv_DLDataset), "anomaly_dir", hv_AnomalyDir);
  }
  //We have the two anomaly labels 'ok' and 'nok'.
  hv_ClassNames.Clear();
  hv_ClassNames[0] = "ok";
  hv_ClassNames[1] = "nok";
  TupleGenSequence(0, (hv_ClassNames.TupleLength())-1, 1, &hv_ClassIDs);
  SetDictTuple((*hv_DLDataset), "class_names", hv_ClassNames);
  SetDictTuple((*hv_DLDataset), "class_ids", hv_ClassIDs);
  //
  //Get number of samples to set unique image ID for each sample according to its index in ImageList.
  hv_NumSamples = hv_ImageList.TupleLength();
  //
  //Create samples in parallel.
  //We use 8 threads, clearly less than the maximum number of HDevelop subthreads.
  hv_ThreadNum = 8;
  GetSystem("thread_num", &hv_ThreadSys);
  if (0 != (int(hv_ThreadNum>hv_ThreadSys)))
  {
    hv_ThreadNum = 1;
  }
  hv_NumSamplesPerThread = ((hv_NumSamples+hv_ThreadNum)-1)/hv_ThreadNum;
  {
  HTuple end_val146 = hv_ThreadNum-1;
  HTuple step_val146 = 1;
  for (hv_ThreadIndex=0; hv_ThreadIndex.Continue(end_val146, step_val146); hv_ThreadIndex += step_val146)
  {
    hv_Start = hv_ThreadIndex*hv_NumSamplesPerThread;
    hv_End = (hv_Start+hv_NumSamplesPerThread)-1;
    if (0 != (HTuple(int(hv_End<0)).TupleOr(int(hv_Start<0))))
    {
      throw HException("Negative indices when calculating samples per thread.");
    }
    //
    //Adapt indices for very last thread.
    if (0 != (int(hv_End>=hv_NumSamples)))
    {
      hv_End = hv_NumSamples-1;
      if (0 != (int(hv_End<hv_Start)))
      {
        break;
      }
      hv_NumSamplesPerThread = (hv_End-hv_Start)+1;
    }
    // Create a thread instance
    hcppthread_handle = new HDevThread(hcppthread_context,
                (void*)HDevExportCpp::_hcppthread_create_dl_dataset_anomaly_samples,6,2);
    // Set thread procedure call arguments 
    hcppthread_handle->SetInputCtrlParamTuple(0,hv_ImageList.TupleSelectRange(hv_Start,hv_End));
    hcppthread_handle->SetInputCtrlParamTuple(1,hv_LabelList.TupleSelectRange(hv_Start,hv_End));
    hcppthread_handle->SetInputCtrlParamTuple(2,hv_AnomalyList.TupleSelectRange(hv_Start,hv_End));
    hcppthread_handle->SetInputCtrlParamTuple(3,hv_AnomalyDirGiven);
    hcppthread_handle->SetInputCtrlParamTuple(4,hv_NumSamplesPerThread);
    hcppthread_handle->SetInputCtrlParamTuple(5,hv_Start);
    {HTuple at_idx;
    at_idx[0] = hv_ThreadIndex;
    hcppthread_handle->BindOutputCtrlParamVector(0,0,&hvec_SamplesOutput,at_idx);
    }
    {HTuple at_idx;
    at_idx[0] = hv_ThreadIndex;
    hcppthread_handle->BindOutputCtrlParamVector(1,0,&hvec_Exceptions,at_idx);
    }

    // Start proc line in thread
    hcppthread_handle->ParStart(&hvec_VProcThreads[hv_ThreadIndex].T());

    if (0 != (int(hv_End==(hv_NumSamples-1))))
    {
      break;
    }
  }
  }
  hv_ThreadIds = hvec_VProcThreads.ConvertVectorToTuple();
  HDevThread::ParJoin(hv_ThreadIds);
  hvec_VProcThreads.Clear();
  hv_ThreadIds = HTuple();
  hv_Samples = hvec_SamplesOutput.ConvertVectorToTuple();
  //
  //Check if create_dl_dataset_anomaly_samples returned
  //any exceptions, if yes then throw
  {
  HTuple end_val174 = HTuple(hvec_Exceptions.Length())-1;
  HTuple step_val174 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val174, step_val174); hv_Index += step_val174)
  {
    if (0 != (int(hvec_Exceptions[hv_Index].T()!=HTuple())))
    {
      throw HException(hvec_Exceptions[hv_Index].T());
    }
  }
  }
  //
  //
  //Set the sample tuple.
  SetDictTuple((*hv_DLDataset), "samples", hv_Samples);
  //
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Generate a DLDataset dictionary for classification. 
void read_dl_dataset_classification (HTuple hv_RawImageFolder, HTuple hv_LabelSource, 
    HTuple *hv_DLDataset)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_IndexFolder, hv_LabelSourceValidOptions;
  HTuple  hv_Index, hv_ImageFiles, hv_GroundTruthLabels, hv_LabelsTmp;
  HTuple  hv_ClassNames, hv_ClassIDs, hv_LabelIndices, hv_ClassIndex;
  HTuple  hv_ImageDir, hv_LeadingSlash, hv_RawFolderIndex;
  HTuple  hv_CurrentRawFolder, hv_CurrentLeadingSlash, hv_ImageDirSubstrings;
  HTuple  hv_CurrentSubstrings, hv_Length, hv_Common, hv_ImageDirTmp;
  HTuple  hv_NumSamples, hv_ThreadNum, hv_ThreadSys, hv_NumSamplesPerThread;
  HTuple  hv_ThreadIndex, hv_Start, hv_End, hv_ThreadIds;
  HTuple  hv_Samples;
  HTupleVector  hvec_SamplesOutput(1), hvec_VProcThreads(1);

  // +++ Threading variables 
  HDevThread*         hcppthread_handle;
  HDevThreadContext   hcppthread_context; // <-signals begin of procedure

  //
  //This procedure creates a dictionary DLDataset,
  //which serves as an input for deep-learning-based classification models.
  //Information needed to create this dictionary is given through the input parameters.
  //
  //The output dictionary DLDataset has the following structure:
  //
  //DLDataset
  //{
  //    'image_dir'         : Common base path of all images
  //    'class_names'[]     : Tuple of strings
  //    'class_ids'[]       : Tuple of integers [0, ..., |ClassNames|-1]
  //    'samples'[]         : Tuple of dictionaries
  //    {
  //        'image_file_name'    : File path relative to 'image_dir' (including the file name)
  //        'image_id'           : Unique image ID
  //        'image_label_id'     : Class ID assigned to the image
  //    }
  //}
  //
  //Sanity checks of inputs.
  //
  //Check the parameter RawImageFolder.
  {
  HTuple end_val23 = (hv_RawImageFolder.TupleLength())-1;
  HTuple step_val23 = 1;
  for (hv_IndexFolder=0; hv_IndexFolder.Continue(end_val23, step_val23); hv_IndexFolder += step_val23)
  {
    if (0 != ((HTuple(hv_RawImageFolder[hv_IndexFolder]).TupleIsString()).TupleNot()))
    {
      throw HException(("RawImageFolder "+HTuple(hv_RawImageFolder[hv_IndexFolder]))+" is not a string.");
    }
  }
  }
  //Check options of LabelSource.
  if (0 != (int((hv_LabelSource.TupleLength())!=1)))
  {
    throw HException("Parameter \"LabelSource\" has to be of length 1.");
  }
  hv_LabelSourceValidOptions.Clear();
  hv_LabelSourceValidOptions[0] = "last_folder";
  hv_LabelSourceValidOptions[1] = "file_name";
  hv_LabelSourceValidOptions[2] = "file_name_remove_index";
  TupleFind(hv_LabelSourceValidOptions, hv_LabelSource, &hv_Index);
  if (0 != (int(hv_Index==-1)))
  {
    throw HException(("Unknown option for LabelSource: \""+hv_LabelSource)+"\".");
  }
  //
  //Prepare the image lists and get class names and image folders.
  //
  TupleUniq(hv_RawImageFolder, &hv_RawImageFolder);
  //Replace doubled backward slashes by forward slashes.
  TupleRegexpReplace(hv_RawImageFolder, (HTuple("\\\\+").Append("replace_all")), 
      "/", &hv_RawImageFolder);
  //Replace any forward slashes at the end.
  TupleRegexpReplace(hv_RawImageFolder, "/$", "", &hv_RawImageFolder);
  //Replace windows path separators
  TupleRegexpReplace(hv_RawImageFolder, (HTuple("\\\\+").Append("replace_all")), 
      "/", &hv_RawImageFolder);

  //
  //List all images in the provided image folders
  //and its subfolders ('recursive').
  list_image_files(hv_RawImageFolder, ((((((((((((((HTuple("hobj").Append("ima")).Append("bmp")).Append("jpg")).Append("png")).Append("tiff")).Append("tif")).Append("gif")).Append("jpeg")).Append("pcx")).Append("pgm")).Append("ppm")).Append("pbm")).Append("xwd")).Append("pnm")), 
      (HTuple("recursive").Append("follow_links")), &hv_ImageFiles);
  if (0 != (int((hv_ImageFiles.TupleLength())==0)))
  {
    throw HException(("Error: Could not find any image files in folder: \""+hv_RawImageFolder)+"\"");
  }
  //
  //Get the ground truth labels and with them the classes to be distinguished.
  //Note that when configuring your own LabelSource mode,
  //you might find the procedure parse_filename helpful.
  if (0 != (int(hv_LabelSource==HTuple(hv_LabelSourceValidOptions[0]))))
  {
    //The name of the last folder containing the image is used as label.
    TupleRegexpMatch(hv_ImageFiles, "([^/]+)/[^/]*$", &hv_GroundTruthLabels);
  }
  else if (0 != (int(hv_LabelSource==HTuple(hv_LabelSourceValidOptions[1]))))
  {
    //The file name of each image is used as label.
    TupleRegexpMatch(hv_ImageFiles, ".*/([^/]+)[.][^/]*$", &hv_GroundTruthLabels);
  }
  else if (0 != (int(hv_LabelSource==HTuple(hv_LabelSourceValidOptions[2]))))
  {
    //The file name of each image is used as label.
    //All consecutive digits and underscores
    //at the end of the file name are removed.
    TupleRegexpMatch(hv_ImageFiles, ".*/([^/]+)[.][^/]*$", &hv_LabelsTmp);
    TupleRegexpReplace(hv_LabelsTmp, "[0-9_]*$", "", &hv_GroundTruthLabels);
  }
  else if (0 != (int(hv_LabelSource==HTuple())))
  {
    hv_GroundTruthLabels = HTuple();
  }
  //Get the unique elements of GroundTruthLabels.
  hv_ClassNames = (hv_GroundTruthLabels.TupleSort()).TupleUniq();
  TupleGenSequence(0, (hv_ClassNames.TupleLength())-1, 1, &hv_ClassIDs);
  //Assign indices to the class labels.
  hv_LabelIndices = hv_GroundTruthLabels;
  {
  HTuple end_val79 = (hv_ClassNames.TupleLength())-1;
  HTuple step_val79 = 1;
  for (hv_ClassIndex=0; hv_ClassIndex.Continue(end_val79, step_val79); hv_ClassIndex += step_val79)
  {
    hv_LabelIndices[hv_LabelIndices.TupleFind(HTuple(hv_ClassNames[hv_ClassIndex]))] = hv_ClassIndex;
  }
  }
  //
  //Set the common parent folder of entries in RawImageFolder as image folders.
  hv_ImageDir = ((const HTuple&)hv_RawImageFolder)[0];
  TupleRegexpMatch(hv_ImageDir, "^/", &hv_LeadingSlash);
  {
  HTuple end_val86 = (hv_RawImageFolder.TupleLength())-1;
  HTuple step_val86 = 1;
  for (hv_RawFolderIndex=1; hv_RawFolderIndex.Continue(end_val86, step_val86); hv_RawFolderIndex += step_val86)
  {
    hv_CurrentRawFolder = HTuple(hv_RawImageFolder[hv_RawFolderIndex]);
    TupleRegexpMatch(hv_CurrentRawFolder, "^/", &hv_CurrentLeadingSlash);
    TupleSplit(hv_ImageDir, "/", &hv_ImageDirSubstrings);
    TupleSplit(hv_CurrentRawFolder, "/", &hv_CurrentSubstrings);
    hv_Length = HTuple(hv_ImageDirSubstrings.TupleLength()).TupleMin2(hv_CurrentSubstrings.TupleLength());
    if (0 != (HTuple(int(hv_LeadingSlash!=hv_CurrentLeadingSlash)).TupleOr(int(hv_Length<1))))
    {
      hv_ImageDir = ".";
      break;
    }
    //Get common parent folder of both paths.
    hv_Common = (hv_ImageDirSubstrings.TupleSelectRange(0,hv_Length-1)).TupleEqualElem(hv_CurrentSubstrings.TupleSelectRange(0,hv_Length-1));
    hv_ImageDirTmp = "";
    hv_Index = 0;
    while (0 != (int(hv_Index<(hv_Common.TupleLength()))))
    {
      if (0 != (int(HTuple(hv_Common[hv_Index])==1)))
      {
        hv_ImageDirTmp = (hv_ImageDirTmp+"/")+HTuple(hv_ImageDirSubstrings[hv_Index]);
      }
      else
      {
        break;
      }
      hv_Index += 1;
    }
    if (0 != (int(hv_Index==0)))
    {
      hv_ImageDir = ".";
      break;
    }
    //Set correct leading slash.
    TupleRegexpReplace(hv_ImageDirTmp, "^/", "", &hv_ImageDirTmp);
    hv_ImageDir = hv_LeadingSlash+hv_ImageDirTmp;
  }
  }
  //
  //Initialize the dictionary dataset.
  CreateDict(&(*hv_DLDataset));
  //
  //Set general information of the dataset.
  SetDictTuple((*hv_DLDataset), "image_dir", hv_ImageDir);
  SetDictTuple((*hv_DLDataset), "class_names", hv_ClassNames);
  SetDictTuple((*hv_DLDataset), "class_ids", hv_ClassIDs);
  //
  //Get number of samples to set unique image ID for each sample according to its index in ImageList.
  hv_NumSamples = hv_ImageFiles.TupleLength();
  //Create samples in parallel.
  //We use 8 threads, clearly less than the maximum number of HDevelop subthreads.
  hv_ThreadNum = 8;
  GetSystem("thread_num", &hv_ThreadSys);
  if (0 != (int(hv_ThreadNum>hv_ThreadSys)))
  {
    hv_ThreadNum = 1;
  }
  hv_NumSamplesPerThread = ((hv_NumSamples+hv_ThreadNum)-1)/hv_ThreadNum;
  {
  HTuple end_val135 = hv_ThreadNum-1;
  HTuple step_val135 = 1;
  for (hv_ThreadIndex=0; hv_ThreadIndex.Continue(end_val135, step_val135); hv_ThreadIndex += step_val135)
  {
    hv_Start = hv_ThreadIndex*hv_NumSamplesPerThread;
    hv_End = (hv_Start+hv_NumSamplesPerThread)-1;
    if (0 != (HTuple(int(hv_End<0)).TupleOr(int(hv_Start<0))))
    {
      throw HException("Negative indices when calculating samples per thread.");
    }
    //
    //Adapt indices for very last thread.
    if (0 != (int(hv_End>=hv_NumSamples)))
    {
      hv_End = hv_NumSamples-1;
      if (0 != (int(hv_End<hv_Start)))
      {
        break;
      }
      hv_NumSamplesPerThread = (hv_End-hv_Start)+1;
    }
    // Create a thread instance
    hcppthread_handle = new HDevThread(hcppthread_context,
                (void*)HDevExportCpp::_hcppthread_create_dl_dataset_classification_samples,6,1);
    // Set thread procedure call arguments 
    hcppthread_handle->SetInputCtrlParamTuple(0,hv_ImageFiles.TupleSelectRange(hv_Start,hv_End));
    hcppthread_handle->SetInputCtrlParamTuple(1,hv_LabelIndices.TupleSelectRange(hv_Start,hv_End));
    hcppthread_handle->SetInputCtrlParamTuple(2,hv_RawImageFolder);
    hcppthread_handle->SetInputCtrlParamTuple(3,hv_ImageDir);
    hcppthread_handle->SetInputCtrlParamTuple(4,hv_NumSamplesPerThread);
    hcppthread_handle->SetInputCtrlParamTuple(5,hv_Start);
    {HTuple at_idx;
    at_idx[0] = hv_ThreadIndex;
    hcppthread_handle->BindOutputCtrlParamVector(0,0,&hvec_SamplesOutput,at_idx);
    }

    // Start proc line in thread
    hcppthread_handle->ParStart(&hvec_VProcThreads[hv_ThreadIndex].T());

    if (0 != (int(hv_End==(hv_NumSamples-1))))
    {
      break;
    }
  }
  }
  hv_ThreadIds = hvec_VProcThreads.ConvertVectorToTuple();
  HDevThread::ParJoin(hv_ThreadIds);
  hvec_VProcThreads.Clear();
  hv_ThreadIds = HTuple();
  hv_Samples = hvec_SamplesOutput.ConvertVectorToTuple();
  //
  //Set the sample tuple.
  SetDictTuple((*hv_DLDataset), "samples", hv_Samples);
  //
  return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Read the COCO file and convert it to the dictionary DLDataset. 
void read_dl_dataset_from_coco (HTuple hv_CocoFileName, HTuple hv_ImageDir, HTuple hv_GenParam, 
    HTuple *hv_DLDataset)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ReadOnlyNonCrowd, hv_ReadRawAnnotations;
  HTuple  hv_ReadMasks, hv_GenParamNames, hv_ParamIndex, hv_GenParamName;
  HTuple  hv_GenParamValue, hv_DictCocoJson, hv_ExceptionTopmostLevel;
  HTuple  hv_CategoryKeys, hv_CategoryList, hv_ImageKeys;
  HTuple  hv_ImageList, hv_AnnotationKeys, hv_AnnotationList;
  HTuple  hv_Purpose, hv_Annotation, hv_BBox, hv_ExceptionBBox;
  HTuple  hv_Index, hv_Category, hv_ID, hv_Name, hv_ExceptionCategory;
  HTuple  hv_ClassIDs, hv_ClassNames, hv_ThreadNum, hv_ThreadSys;
  HTuple  hv_NumKeys, hv_NumKeysPerThread, hv_ThreadIndex;
  HTuple  hv_Start, hv_End, hv_AnnotationListTuple, hv_AnnotationListItem;
  HTuple  hv_AnnotationListPerThread, hv_ThreadIds, hv_AnnotImageIDs;
  HTuple  hv_NumSamples, hv_NumSamplesPerThread, hv_ImageListTuple;
  HTuple  hv_ImageListTupleItem, hv_ImageListPerThread, hv_DLSamples;
  HTupleVector  hvec_AnnotImageIDsOutput(1), hvec_AnnotationExceptions(1);
  HTupleVector  hvec_VProcThreads(1), hvec_DLSamplesOutput(1), hvec_SamplesExceptions(1);

  // +++ Threading variables 
  HDevThread*         hcppthread_handle;
  HDevThreadContext   hcppthread_context; // <-signals begin of procedure

  //
  //This procedure reads a COCO file and creates a DLDataset dictionary out of it.
  //Note, only the COCO annotation type 'Object Detection' is supported.
  //The bounding boxes are parametrized for instance_type 'rectangle1'.
  //
  dev_update_off();
  //
  //Sanity checks of procedure inputs.
  //Check the given input for the COCO file CocoFileName.
  if (0 != (int((hv_CocoFileName.TupleLength())!=1)))
  {
    throw HException("Only one COCO file can be given.");
  }
  else if (0 != (int((hv_CocoFileName.TupleIsString())!=1)))
  {
    throw HException("CocoFileName is not a string.");
  }
  if (0 != (int((hv_ImageDir.TupleLength())!=1)))
  {
    throw HException("Only one base path for the images can be given.");
  }
  else if (0 != (int((hv_ImageDir.TupleIsString())!=1)))
  {
    throw HException("ImageDir is not a string.");
  }
  //Make sure, ImageDir ends with a '/'.
  if (0 != (hv_ImageDir.TupleRegexpTest("[^/]$")))
  {
    hv_ImageDir += HTuple("/");
  }
  //
  //Check the dictionary GenParam and transfer the given values.
  //
  //Default values.
  //Per default, do not read annotations which have the attribute 'iscrowd'.
  hv_ReadOnlyNonCrowd = 1;
  //Per default, do not transfer the raw format of the annotations.
  hv_ReadRawAnnotations = 0;
  //Pre default, read masks (segmentations), if present.
  hv_ReadMasks = 1;
  //
  //Transfer the given GenParam entries.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenParamNames);
    {
    HTuple end_val37 = (hv_GenParamNames.TupleLength())-1;
    HTuple step_val37 = 1;
    for (hv_ParamIndex=0; hv_ParamIndex.Continue(end_val37, step_val37); hv_ParamIndex += step_val37)
    {
      hv_GenParamName = HTuple(hv_GenParamNames[hv_ParamIndex]);
      GetDictTuple(hv_GenParam, hv_GenParamName, &hv_GenParamValue);
      if (0 != (int(hv_GenParamName==HTuple("read_only_non_crowd_detection"))))
      {
        if (0 != (HTuple(int(hv_GenParamValue==HTuple("true"))).TupleOr(int(hv_GenParamValue==1))))
        {
          hv_ReadOnlyNonCrowd = 1;
        }
        else if (0 != (HTuple(int(hv_GenParamValue==HTuple("false"))).TupleOr(int(hv_GenParamValue==0))))
        {
          hv_ReadOnlyNonCrowd = 0;
        }
        else
        {
          throw HException("GenParamValue for GenParamName read_only_non_crowd_detection is not supported.");
        }
      }
      else if (0 != (int(hv_GenParamName==HTuple("coco_raw_annotations"))))
      {
        if (0 != (HTuple(int(hv_GenParamValue==HTuple("true"))).TupleOr(int(hv_GenParamValue==1))))
        {
          hv_ReadRawAnnotations = 1;
        }
        else if (0 != (HTuple(int(hv_GenParamValue==HTuple("false"))).TupleOr(int(hv_GenParamValue==0))))
        {
          hv_ReadRawAnnotations = 0;
        }
        else
        {
          throw HException("GenParamValue for GenParamName coco_raw_annotations is not supported.");
        }
      }
      else if (0 != (int(hv_GenParamName==HTuple("read_segmentation_masks"))))
      {
        if (0 != (HTuple(int(hv_GenParamValue==HTuple("true"))).TupleOr(int(hv_GenParamValue==1))))
        {
          hv_ReadMasks = 1;
        }
        else if (0 != (HTuple(int(hv_GenParamValue==HTuple("false"))).TupleOr(int(hv_GenParamValue==0))))
        {
          hv_ReadMasks = 0;
        }
        else
        {
          throw HException("GenParamValue for GenParamName read_segmentation_masks is not supported.");
        }
      }
      else
      {
        throw HException(("Unknown generic parameter: "+hv_GenParamName)+".");
      }
    }
    }
  }
  //
  //Read the COCO file into a dictionary.
  ReadDict(hv_CocoFileName, HTuple(), HTuple(), &hv_DictCocoJson);
  //
  //Check topmost content of JSON file for categories.
  hv_ExceptionTopmostLevel = HTuple();
  hv_CategoryKeys = HTuple();
  try
  {
    GetDictTuple(hv_DictCocoJson, "categories", &hv_CategoryList);
    GetDictParam(hv_CategoryList, "keys", HTuple(), &hv_CategoryKeys);
  }
  // catch (ExceptionTopmostLevel) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_ExceptionTopmostLevel);
  }
  if (0 != (HTuple(int(hv_ExceptionTopmostLevel!=HTuple())).TupleOr(int((hv_CategoryKeys.TupleLength())==0))))
  {
    throw HException("The COCO file has to contain categories on the topmost level.");
  }
  //Check topmost content of JSON file for images.
  hv_ExceptionTopmostLevel = HTuple();
  hv_ImageKeys = HTuple();
  try
  {
    GetDictTuple(hv_DictCocoJson, "images", &hv_ImageList);
    GetDictParam(hv_ImageList, "keys", HTuple(), &hv_ImageKeys);
  }
  // catch (ExceptionTopmostLevel) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_ExceptionTopmostLevel);
  }

  if (0 != (HTuple(int(hv_ExceptionTopmostLevel!=HTuple())).TupleOr(int((hv_ImageKeys.TupleLength())==0))))
  {
    throw HException("The COCO file has to contain images on the topmost level.");
  }
  //Check topmost content of JSON file for annotations.
  hv_ExceptionTopmostLevel = HTuple();
  hv_AnnotationKeys = HTuple();
  try
  {
    GetDictTuple(hv_DictCocoJson, "annotations", &hv_AnnotationList);
    GetDictParam(hv_AnnotationList, "keys", HTuple(), &hv_AnnotationKeys);
  }
  // catch (ExceptionTopmostLevel) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_ExceptionTopmostLevel);
  }
  //
  if (0 != (HTuple(int(hv_ExceptionTopmostLevel!=HTuple())).TupleOr(int((hv_AnnotationKeys.TupleLength())==0))))
  {
    throw HException("The first COCO annotation does not contain the entries bounding box. This COCO format is not supported.");
  }
  //
  //Determine the purpose of this Dataset according to the content.
  hv_Purpose = HTuple();
  GetDictTuple(hv_AnnotationList, HTuple(hv_AnnotationKeys[0]), &hv_Annotation);
  try
  {
    GetDictTuple(hv_Annotation, "bbox", &hv_BBox);
    hv_Purpose = "object_detection";
  }
  // catch (ExceptionBBox) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_ExceptionBBox);
    throw HException("The first COCO annotation does not contain the entries bounding box. This COCO format is not supported.");
  }
  //
  //Create the DLDataset dictionary.
  CreateDict(&(*hv_DLDataset));
  //
  //Set the base image directory.
  SetDictTuple((*hv_DLDataset), "image_dir", hv_ImageDir);
  //
  //Set the class information.
  {
  HTuple end_val126 = (hv_CategoryKeys.TupleLength())-1;
  HTuple step_val126 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val126, step_val126); hv_Index += step_val126)
  {
    try
    {
      GetDictTuple(hv_CategoryList, HTuple(hv_CategoryKeys[hv_Index]), &hv_Category);
      GetDictTuple(hv_Category, "id", &hv_ID);
      GetDictTuple(hv_Category, "name", &hv_Name);
    }
    // catch (ExceptionCategory) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_ExceptionCategory);
      throw HException(("COCO category number "+hv_Index)+" does not contain the entry id or name.");
    }
    hv_ClassIDs[hv_Index] = hv_ID;
    hv_ClassNames[hv_Index] = hv_Name;
  }
  }
  SetDictTuple((*hv_DLDataset), "class_ids", hv_ClassIDs);
  SetDictTuple((*hv_DLDataset), "class_names", hv_ClassNames);
  //
  //Get annotation image_id in parallel.
  //We use 8 threads, clearly less than the maximum number of HDevelop subthreads.
  hv_ThreadNum = 8;
  GetSystem("thread_num", &hv_ThreadSys);
  if (0 != (int(hv_ThreadNum>hv_ThreadSys)))
  {
    hv_ThreadNum = 1;
  }
  hv_NumKeys = hv_AnnotationKeys.TupleLength();
  hv_NumKeysPerThread = ((hv_NumKeys+hv_ThreadNum)-1)/hv_ThreadNum;
  {
  HTuple end_val149 = hv_ThreadNum-1;
  HTuple step_val149 = 1;
  for (hv_ThreadIndex=0; hv_ThreadIndex.Continue(end_val149, step_val149); hv_ThreadIndex += step_val149)
  {
    hv_Start = hv_ThreadIndex*hv_NumKeysPerThread;
    hv_End = (hv_Start+hv_NumKeysPerThread)-1;
    if (0 != (HTuple(int(hv_End<0)).TupleOr(int(hv_Start<0))))
    {
      throw HException("Negative indices when calculating keys per thread.");
    }
    //Adapt indices for very last thread
    if (0 != (int(hv_End>=hv_NumKeys)))
    {
      hv_End = hv_NumKeys-1;
      if (0 != (int(hv_End<hv_Start)))
      {
        break;
      }
      hv_NumKeysPerThread = (hv_End-hv_Start)+1;
    }
    //Generate dict of dictionaries per given thread
    TupleGenConst(hv_NumKeysPerThread, "", &hv_AnnotationListTuple);
    {
    HTuple end_val165 = hv_End;
    HTuple step_val165 = 1;
    for (hv_Index=hv_Start; hv_Index.Continue(end_val165, step_val165); hv_Index += step_val165)
    {
      GetDictTuple(hv_AnnotationList, hv_Index, &hv_AnnotationListItem);
      hv_AnnotationListTuple[hv_Index] = hv_AnnotationListItem;
    }
    }
    CreateDict(&hv_AnnotationListPerThread);
    {
    HTuple end_val170 = hv_End;
    HTuple step_val170 = 1;
    for (hv_Index=hv_Start; hv_Index.Continue(end_val170, step_val170); hv_Index += step_val170)
    {
      SetDictTuple(hv_AnnotationListPerThread, hv_Index, HTuple(hv_AnnotationListTuple[hv_Index]));
    }
    }
    //Do parallelization.
    // Create a thread instance
    hcppthread_handle = new HDevThread(hcppthread_context,
                (void*)HDevExportCpp::_hcppthread_get_dl_dataset_from_coco_annotation_image_id,4,2);
    // Set thread procedure call arguments 
    hcppthread_handle->SetInputCtrlParamTuple(0,hv_AnnotationListPerThread);
    hcppthread_handle->SetInputCtrlParamTuple(1,hv_AnnotationKeys.TupleSelectRange(hv_Start,hv_End));
    hcppthread_handle->SetInputCtrlParamTuple(2,hv_NumKeysPerThread);
    hcppthread_handle->SetInputCtrlParamTuple(3,hv_Start);
    {HTuple at_idx;
    at_idx[0] = hv_ThreadIndex;
    hcppthread_handle->BindOutputCtrlParamVector(0,0,&hvec_AnnotImageIDsOutput,at_idx);
    }
    {HTuple at_idx;
    at_idx[0] = hv_ThreadIndex;
    hcppthread_handle->BindOutputCtrlParamVector(1,0,&hvec_AnnotationExceptions,at_idx);
    }

    // Start proc line in thread
    hcppthread_handle->ParStart(&hvec_VProcThreads[hv_ThreadIndex].T());

    if (0 != (int(hv_End==(hv_NumKeys-1))))
    {
      break;
    }
  }
  }
  hv_ThreadIds = hvec_VProcThreads.ConvertVectorToTuple();
  HDevThread::ParJoin(hv_ThreadIds);
  hvec_VProcThreads.Clear();
  hv_ThreadIds = HTuple();
  hv_AnnotImageIDs = hvec_AnnotImageIDsOutput.ConvertVectorToTuple();
  //
  //Check if get_dl_dataset_from_coco_annotation_image_id returned
  //any exceptions, if yes then trow
  {
  HTuple end_val187 = HTuple(hvec_AnnotationExceptions.Length())-1;
  HTuple step_val187 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val187, step_val187); hv_Index += step_val187)
  {
    if (0 != (int(hvec_AnnotationExceptions[hv_Index].T()!=HTuple())))
    {
      throw HException(hvec_AnnotationExceptions[hv_Index].T());
    }
  }
  }
  //
  //Generate the samples in parallel.
  hv_NumSamples = hv_ImageKeys.TupleLength();
  hv_NumSamplesPerThread = ((hv_NumSamples+hv_ThreadNum)-1)/hv_ThreadNum;
  {
  HTuple end_val196 = hv_ThreadNum-1;
  HTuple step_val196 = 1;
  for (hv_ThreadIndex=0; hv_ThreadIndex.Continue(end_val196, step_val196); hv_ThreadIndex += step_val196)
  {
    hv_Start = hv_ThreadIndex*hv_NumSamplesPerThread;
    hv_End = (hv_Start+hv_NumSamplesPerThread)-1;
    if (0 != (HTuple(int(hv_End<0)).TupleOr(int(hv_Start<0))))
    {
      throw HException("Negative indices when calculating samples per thread.");
    }
    //
    //Adapt indices for very last thread.
    if (0 != (int(hv_End>=hv_NumSamples)))
    {
      hv_End = hv_NumSamples-1;
      if (0 != (int(hv_End<hv_Start)))
      {
        break;
      }
      hv_NumSamplesPerThread = (hv_End-hv_Start)+1;
    }
    //Generate dict of dictionaries per given thread.
    TupleGenConst(hv_NumSamplesPerThread, "", &hv_ImageListTuple);
    {
    HTuple end_val213 = hv_End;
    HTuple step_val213 = 1;
    for (hv_Index=hv_Start; hv_Index.Continue(end_val213, step_val213); hv_Index += step_val213)
    {
      GetDictTuple(hv_ImageList, hv_Index, &hv_ImageListTupleItem);
      hv_ImageListTuple[hv_Index] = hv_ImageListTupleItem;
    }
    }
    CreateDict(&hv_ImageListPerThread);
    {
    HTuple end_val218 = hv_End;
    HTuple step_val218 = 1;
    for (hv_Index=hv_Start; hv_Index.Continue(end_val218, step_val218); hv_Index += step_val218)
    {
      SetDictTuple(hv_ImageListPerThread, hv_Index, HTuple(hv_ImageListTuple[hv_Index]));
    }
    }
    //Do parallelization.
    // Create a thread instance
    hcppthread_handle = new HDevThread(hcppthread_context,
                (void*)HDevExportCpp::_hcppthread_create_dl_dataset_from_coco_samples,12,2);
    // Set thread procedure call arguments 
    hcppthread_handle->SetInputCtrlParamTuple(0,hv_ImageListPerThread);
    hcppthread_handle->SetInputCtrlParamTuple(1,hv_ImageKeys.TupleSelectRange(hv_Start,hv_End));
    hcppthread_handle->SetInputCtrlParamTuple(2,hv_ImageDir);
    hcppthread_handle->SetInputCtrlParamTuple(3,hv_AnnotationList);
    hcppthread_handle->SetInputCtrlParamTuple(4,hv_AnnotationKeys);
    hcppthread_handle->SetInputCtrlParamTuple(5,hv_AnnotImageIDs);
    hcppthread_handle->SetInputCtrlParamTuple(6,hv_Purpose);
    hcppthread_handle->SetInputCtrlParamTuple(7,hv_ReadOnlyNonCrowd);
    hcppthread_handle->SetInputCtrlParamTuple(8,hv_ReadRawAnnotations);
    hcppthread_handle->SetInputCtrlParamTuple(9,hv_ReadMasks);
    hcppthread_handle->SetInputCtrlParamTuple(10,hv_NumSamplesPerThread);
    hcppthread_handle->SetInputCtrlParamTuple(11,hv_Start);
    {HTuple at_idx;
    at_idx[0] = hv_ThreadIndex;
    hcppthread_handle->BindOutputCtrlParamVector(0,0,&hvec_DLSamplesOutput,at_idx);
    }
    {HTuple at_idx;
    at_idx[0] = hv_ThreadIndex;
    hcppthread_handle->BindOutputCtrlParamVector(1,0,&hvec_SamplesExceptions,at_idx);
    }

    // Start proc line in thread
    hcppthread_handle->ParStart(&hvec_VProcThreads[hv_ThreadIndex].T());

    if (0 != (int(hv_End==(hv_NumSamples-1))))
    {
      break;
    }
  }
  }
  hv_ThreadIds = hvec_VProcThreads.ConvertVectorToTuple();
  HDevThread::ParJoin(hv_ThreadIds);
  hvec_VProcThreads.Clear();
  hv_ThreadIds = HTuple();
  hv_DLSamples = hvec_DLSamplesOutput.ConvertVectorToTuple();
  //
  //Check if create_dl_dataset_from_coco_samples returned
  //any exceptions, if yes then trow
  {
  HTuple end_val235 = HTuple(hvec_SamplesExceptions.Length())-1;
  HTuple step_val235 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val235, step_val235); hv_Index += step_val235)
  {
    if (0 != (int(hvec_SamplesExceptions[hv_Index].T()!=HTuple())))
    {
      throw HException(hvec_SamplesExceptions[hv_Index].T());
    }
  }
  }
  //
  //Set the samples in the DLDataset dictionary.
  SetDictTuple((*hv_DLDataset), "samples", hv_DLSamples);
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Read a dictionary file and return a dl dataset. 
void read_dl_dataset_ocr_detection (HTuple hv_DatasetFilename, HTuple hv_ImageDir, 
    HTuple hv_GenParam, HTuple *hv_DLDataset, HTuple *hv_InvalidSamplesIndices, HTuple *hv_InvalidSamplesReasons)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ErrorMessage, hv_EmptyWordLabelIndices;
  HTuple  hv_RequiredKeysExist, hv_ClassToClassIndex, hv_ClassCustomDataExists;
  HTuple  hv_SampleIndex, hv_Sample, hv_RequiredKeys, hv_MissingKeys;
  HTuple  hv_Msg, hv_WordExists, hv_LabelCustomDataExists;
  HTuple  hv_LabelIndex, hv_IsWord, hv_LabelInvalid, hv_CustomData;
  HTuple  hv_TextExists, hv_EmptyWordLabelReason, hv___Tmp_Ctrl_Dict_Init_0;
  HTuple  hv___Tmp_Ctrl_0;

  //
  //Read dataset from dict
  ReadDict(hv_DatasetFilename, HTuple(), HTuple(), &(*hv_DLDataset));
  //If no ImageDir is passed we use the image dir of the dataset
  if (0 != (int((hv_ImageDir.TupleLength())==0)))
  {
    hv_ImageDir = (*hv_DLDataset).TupleGetDictTuple("image_dir");
  }
  else if (0 != (int((hv_ImageDir.TupleLength())>1)))
  {
    throw HException("Only one base path for the images can be given.");
  }
  else if (0 != (HTuple(int((hv_ImageDir.TupleLength())==1)).TupleAnd(int((hv_ImageDir.TupleIsString())!=1))))
  {
    throw HException("ImageDir is not a string.");
  }
  else if (0 != (int(hv_ImageDir==HTuple(""))))
  {
    hv_ImageDir = (*hv_DLDataset).TupleGetDictTuple("image_dir");
  }
  //Make sure, ImageDir ends with a '/'.
  if (0 != (hv_ImageDir.TupleRegexpTest("[^/]$")))
  {
    hv_ImageDir += HTuple("/");
  }
  //
  SetDictTuple((*hv_DLDataset), "image_dir", hv_ImageDir);
  //
  //Error message if the dataset is not supported
  hv_ErrorMessage = ("The given file "+hv_DatasetFilename)+" cannot be used as an ocr detection dataset.";
  //
  //Initialize return variables
  hv_EmptyWordLabelIndices = HTuple();
  //
  //Determine the given format of the dataset.
  GetDictParam((*hv_DLDataset), "key_exists", (HTuple("class_ids").Append("class_names")), 
      &hv_RequiredKeysExist);
  if (0 != (int((hv_RequiredKeysExist.TupleSum())!=(hv_RequiredKeysExist.TupleLength()))))
  {
    //The dataset is of a format which can not be used for ocr detection.
    throw HException(hv_ErrorMessage);
  }
  //
  //Create mapping to ocr detection class format (0: word, 1: char, 2: ignore)
  gen_ocr_detection_class_id_mapping((*hv_DLDataset), &hv_ClassToClassIndex);
  //Class custom data is not needed.
  GetDictParam((*hv_DLDataset), "key_exists", "class_custom_data", &hv_ClassCustomDataExists);
  if (0 != hv_ClassCustomDataExists)
  {
    RemoveDictKey((*hv_DLDataset), "class_custom_data");
  }
  //
  //Loop through samples and convert all labels to ocr detection format (0: word, 1: char, 2: ignore)
  {
  HTuple end_val42 = (((*hv_DLDataset).TupleGetDictTuple("samples")).TupleLength())-1;
  HTuple step_val42 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val42, step_val42); hv_SampleIndex += step_val42)
  {
    hv_Sample = HTuple(((*hv_DLDataset).TupleGetDictTuple("samples"))[hv_SampleIndex]);
    //Check if required keys exist in each sample
    hv_RequiredKeys.Clear();
    hv_RequiredKeys[0] = "image_id";
    hv_RequiredKeys[1] = "image_file_name";
    hv_RequiredKeys[2] = "bbox_label_id";
    hv_RequiredKeys[3] = "bbox_col";
    hv_RequiredKeys[4] = "bbox_row";
    hv_RequiredKeys[5] = "bbox_phi";
    hv_RequiredKeys[6] = "bbox_length1";
    hv_RequiredKeys[7] = "bbox_length2";
    GetDictParam(hv_Sample, "key_exists", hv_RequiredKeys, &hv_RequiredKeysExist);
    if (0 != (int((hv_RequiredKeysExist.TupleSum())!=(hv_RequiredKeysExist.TupleLength()))))
    {
      //The Dataset contains a sample which is not suitable for detection
      TupleJoin(HTuple(hv_RequiredKeys[hv_RequiredKeysExist.TupleFind(0)]), HTuple(", "), 
          &hv_MissingKeys);
      hv_Msg = (((hv_ErrorMessage+" Sample ")+hv_SampleIndex)+" does not fit the format. Missing: ")+hv_MissingKeys;
      throw HException(hv_Msg);
    }
    //Check if format is already suitable for ocr_detection
    GetDictParam(hv_Sample, "key_exists", "word", &hv_WordExists);
    if (0 != (hv_WordExists.TupleNot()))
    {
      //Create word entry
      TupleGenConst((hv_Sample.TupleGetDictTuple("bbox_label_id")).TupleLength(), 
          "", &hv___Tmp_Ctrl_0);
      SetDictTuple(hv_Sample, "word", hv___Tmp_Ctrl_0);
    }
    //
    //Ground truth is stored in 'label_custom_data' if 'word' does not exist
    GetDictParam(hv_Sample, "key_exists", "label_custom_data", &hv_LabelCustomDataExists);
    //
    //Loop through and convert every label
    {
    HTuple end_val65 = ((hv_Sample.TupleGetDictTuple("bbox_label_id")).TupleLength())-1;
    HTuple step_val65 = 1;
    for (hv_LabelIndex=0; hv_LabelIndex.Continue(end_val65, step_val65); hv_LabelIndex += step_val65)
    {
      //Set the mapped class id
      SetDictTupleAt(hv_Sample, "bbox_label_id", hv_LabelIndex, hv_ClassToClassIndex.TupleGetDictTuple(HTuple((hv_Sample.TupleGetDictTuple("bbox_label_id"))[hv_LabelIndex])));
      //Char or Ignore label: continue
      hv_IsWord = int(HTuple((hv_Sample.TupleGetDictTuple("bbox_label_id"))[hv_LabelIndex])==0);
      if (0 != (hv_IsWord.TupleNot()))
      {
        continue;
      }
      //Word label: ground truth already in the right place, just check if valid
      if (0 != hv_WordExists)
      {
        if (0 != (int(HTuple((hv_Sample.TupleGetDictTuple("word"))[hv_LabelIndex])==HTuple(""))))
        {
          hv_LabelInvalid = 1;
        }
        continue;
      }
      //Word label: look for a ground truth. sample->label_custom_data->text
      hv_LabelInvalid = 1;
      if (0 != hv_LabelCustomDataExists)
      {
        if (0 != (int(HTuple((hv_Sample.TupleGetDictTuple("label_custom_data"))[hv_LabelIndex])!=HTuple::TupleConstant("HNULL"))))
        {
          hv_CustomData = HTuple((hv_Sample.TupleGetDictTuple("label_custom_data"))[hv_LabelIndex]);
          GetDictParam(hv_CustomData, "key_exists", "text", &hv_TextExists);
          if (0 != hv_TextExists)
          {
            CreateDict(&hv___Tmp_Ctrl_Dict_Init_0);
            SetDictTuple(hv___Tmp_Ctrl_Dict_Init_0, "comp", "");
            if (0 != (((hv_CustomData.TupleConcat(hv___Tmp_Ctrl_Dict_Init_0)).TupleTestEqualDictItem("text","comp")).TupleNot()))
            {
              //We found a ground truth!
              hv_LabelInvalid = 0;
              SetDictTupleAt(hv_Sample, "word", hv_LabelIndex, hv_CustomData.TupleGetDictTuple("text"));
            }
            hv___Tmp_Ctrl_Dict_Init_0 = HTuple::TupleConstant("HNULL");
          }
        }
      }
      //Change label to ignore if invalid and note sample index
      if (0 != hv_LabelInvalid)
      {
        SetDictTupleAt(hv_Sample, "bbox_label_id", hv_LabelIndex, 2);
        hv_EmptyWordLabelIndices = hv_EmptyWordLabelIndices.TupleConcat(hv_SampleIndex);
      }
    }
    }
    //Cleanup
    if (0 != hv_LabelCustomDataExists)
    {
      RemoveDictKey(hv_Sample, "label_custom_data");
    }
  }
  }
  //
  //All entries have been converted to the schema below.
  SetDictTuple((*hv_DLDataset), "class_ids", ((HTuple(0).Append(1)).Append(2)));
  SetDictTuple((*hv_DLDataset), "class_names", ((HTuple("word").Append("char")).Append("ignore")));
  //
  //Generate tuple with reasons for invalid samples
  TupleGenConst(hv_EmptyWordLabelIndices.TupleLength(), "empty word", &hv_EmptyWordLabelReason);
  (*hv_InvalidSamplesIndices) = hv_EmptyWordLabelIndices;
  (*hv_InvalidSamplesReasons) = hv_EmptyWordLabelReason;
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Read a dictionary file and return a dl dataset. 
void read_dl_dataset_ocr_recognition (HTuple hv_FileName, HTuple hv_ImageDir, HTuple hv_GenParam, 
    HTuple *hv_DLDataset)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Format, hv_I, hv_Sample, hv_RequiredKeysExist;
  HTuple  hv_J;

  if (0 != (int((hv_ImageDir.TupleLength())>1)))
  {
    throw HException("Only one base path for the images can be given.");
  }
  else if (0 != (HTuple(int((hv_ImageDir.TupleLength())==1)).TupleAnd(int((hv_ImageDir.TupleIsString())!=1))))
  {
    throw HException("ImageDir is not a string.");
  }
  //Make sure, ImageDir ends with a '/'.
  if (0 != (hv_ImageDir.TupleRegexpTest("[^/]$")))
  {
    hv_ImageDir += HTuple("/");
  }
  //
  ReadDict(hv_FileName, HTuple(), HTuple(), &(*hv_DLDataset));
  //
  //Determine the given format of the dataset.
  hv_Format = "unknown";
  if (0 != (int((((*hv_DLDataset).TupleGetDictTuple("samples")).TupleLength())>0)))
  {
    {
    HTuple end_val15 = (((*hv_DLDataset).TupleGetDictTuple("samples")).TupleLength())-1;
    HTuple step_val15 = 1;
    for (hv_I=0; hv_I.Continue(end_val15, step_val15); hv_I += step_val15)
    {
      hv_Sample = HTuple(((*hv_DLDataset).TupleGetDictTuple("samples"))[hv_I]);
      GetDictParam(hv_Sample, "key_exists", ((HTuple("word").Append("image_id")).Append("image_file_name")), 
          &hv_RequiredKeysExist);
      if (0 != (int((hv_RequiredKeysExist.TupleSum())==(hv_RequiredKeysExist.TupleLength()))))
      {
        hv_Format = "simple";
        break;
      }
      else
      {
        GetDictParam(hv_Sample, "key_exists", (((((HTuple("label_custom_data").Append("bbox_col")).Append("bbox_row")).Append("bbox_phi")).Append("bbox_length1")).Append("bbox_length2")), 
            &hv_RequiredKeysExist);
        if (0 != (int((hv_RequiredKeysExist.TupleSum())==(hv_RequiredKeysExist.TupleLength()))))
        {
          if (0 != (int(((hv_Sample.TupleGetDictTuple("label_custom_data")).TupleLength())>0)))
          {
            {
            HTuple end_val25 = ((hv_Sample.TupleGetDictTuple("label_custom_data")).TupleLength())-1;
            HTuple step_val25 = 1;
            for (hv_J=0; hv_J.Continue(end_val25, step_val25); hv_J += step_val25)
            {
              if (0 != (int(HTuple((hv_Sample.TupleGetDictTuple("label_custom_data"))[hv_J])==HTuple::TupleConstant("HNULL"))))
              {
                continue;
              }
              GetDictParam(HTuple((hv_Sample.TupleGetDictTuple("label_custom_data"))[hv_J]), 
                  "key_exists", "text", &hv_RequiredKeysExist);
              if (0 != hv_RequiredKeysExist)
              {
                hv_Format = "detection";
                break;
              }
            }
            }
            if (0 != (int(hv_Format!=HTuple("unknown"))))
            {
              break;
            }
          }
        }
      }
    }
    }
  }
  //
  if (0 != (int(hv_Format==HTuple("unknown"))))
  {
    throw HException(("The given file "+hv_FileName)+" cannot be used as an ocr recognition dataset.");
  }
  //
  //A detection dataset has to be converted.
  if (0 != (int(hv_Format==HTuple("detection"))))
  {
    convert_dl_dataset_ocr_detection_to_recognition((*hv_DLDataset), &(*hv_DLDataset));
  }
  //
  if (0 != (int((hv_ImageDir.TupleLength())>0)))
  {
    SetDictTuple((*hv_DLDataset), "image_dir", hv_ImageDir);
  }
  //
  return;
}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Generate a DLDataset dictionary for semantic segmentation. 
void read_dl_dataset_segmentation (HTuple hv_ImageDir, HTuple hv_SegmentationDir, 
    HTuple hv_ClassNames, HTuple hv_ClassIDs, HTuple hv_ImageList, HTuple hv_SegmentationList, 
    HTuple hv_GenParam, HTuple *hv_DLDataset)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv__, hv_LabelList, hv_ImageDirSep, hv_SegmentationDirSep;
  HTuple  hv_NumSamples, hv_ThreadNum, hv_ThreadSys, hv_NumSamplesPerThread;
  HTuple  hv_ThreadIndex, hv_Start, hv_End, hv_ThreadIds;
  HTuple  hv_Samples;
  HTupleVector  hvec_SamplesOutput(1), hvec_VProcThreads(1);

  // +++ Threading variables 
  HDevThread*         hcppthread_handle;
  HDevThreadContext   hcppthread_context; // <-signals begin of procedure

  //
  //This procedure creates a dictionary DLDataset,
  //which serves as an input for deep-learning-based semantic segmentation models.
  //Information needed to create this dictionary is given through the input parameters.
  //
  //The output dictionary DLDataset has the following structure:

  //DLDataset
  //{
  //    'image_dir'         : Common base path of all images
  //    'segmentation_dir'  : Common base path of all segmentation images
  //    'class_names'[]     : Tuple of strings
  //    'class_ids'[]       : Tuple of integers
  //    'samples'[]         : Tuple of dictionaries
  //    {
  //        'image_file_name'           : File path relative to 'image_dir' (including the file name)
  //        'segmentation_file_name'    : File path relative to 'segmentation_dir' (including the file name)
  //        'image_id'                  : Unique image ID
  //    }
  //}
  //
  //
  //Sanity checks of inputs.
  //
  //The length of Classes has to match the length of ClassIDs.
  if (0 != (int((hv_ClassNames.TupleLength())!=(hv_ClassIDs.TupleLength()))))
  {
    throw HException("Number of class names does not match number of class IDs");
  }
  //ClassIDs must be unique.
  if (0 != (int(((hv_ClassIDs.TupleSort()).TupleUniq())!=(hv_ClassIDs.TupleSort()))))
  {
    throw HException("Class IDs are not unique");
  }
  //ImageDir can only be one string.
  if (0 != (int((hv_ImageDir.TupleLength())==0)))
  {
    hv_ImageDir = "";
  }
  if (0 != (int((hv_ImageDir.TupleLength())!=1)))
  {
    throw HException("Only one base path for the images can be given");
  }
  else if (0 != (int((hv_ImageDir.TupleIsString())!=1)))
  {
    throw HException("ImageDir is not a string");
  }
  if (0 != (int((hv_SegmentationDir.TupleLength())==0)))
  {
    hv_SegmentationDir = "";
  }
  //SegmentationDir can only be one string.
  if (0 != (int((hv_SegmentationDir.TupleLength())!=1)))
  {
    throw HException("Only one base path for the annotation images can be given");
  }
  else if (0 != (int((hv_SegmentationDir.TupleIsString())!=1)))
  {
    throw HException("SegmentationDir is not a string");
  }
  //Check if ImageList and SegmentationList have the same length or if SegmentationList is empty.
  if (0 != (HTuple(int(hv_SegmentationList!=HTuple())).TupleAnd(int((hv_ImageList.TupleLength())!=(hv_SegmentationList.TupleLength())))))
  {
    throw HException("SegmentationList must be empty or have the same length as ImageList");
  }
  //
  //Prepare the image lists.
  //
  //Replace windows path separators
  TupleRegexpReplace(hv_ImageDir, (HTuple("\\\\+").Append("replace_all")), "/", &hv_ImageDir);
  TupleRegexpReplace(hv_SegmentationDir, (HTuple("\\\\+").Append("replace_all")), 
      "/", &hv_SegmentationDir);
  //Replace any forward slashes at the end.
  TupleRegexpReplace(hv_ImageDir, "/$", "", &hv_ImageDir);
  TupleRegexpReplace(hv_SegmentationDir, "/$", "", &hv_SegmentationDir);
  //Remove possible (not starting) double slashes.
  if (0 != (int((hv_ImageDir.TupleRegexpMatch("(.+)//"))!=HTuple(""))))
  {
    hv_ImageDir = hv_ImageDir.TupleRegexpReplace("(.+)//","$1/");
  }
  if (0 != (int((hv_SegmentationDir.TupleRegexpMatch("(.+)//"))!=HTuple(""))))
  {
    hv_SegmentationDir = hv_SegmentationDir.TupleRegexpReplace("(.+)//","$1/");
  }
  //
  //If no SegmentationList is given, create it out of the given ImageList or create both lists.
  if (0 != (int(hv_SegmentationList==HTuple())))
  {
    //Create the matching file lists for images and segmentations.
    list_image_and_annotation_files("segmentation", hv_ImageDir, HTuple(), HTuple(), 
        hv_SegmentationDir, hv_ImageList, hv_GenParam, &hv_ImageList, &hv__, &hv__, 
        &hv_SegmentationList, &hv_LabelList);
  }
  else
  {
    //Replace windows path separators
    TupleRegexpReplace(hv_ImageList, (HTuple("\\\\+").Append("replace_all")), "/", 
        &hv_ImageList);
    TupleRegexpReplace(hv_SegmentationList, (HTuple("\\\\+").Append("replace_all")), 
        "/", &hv_SegmentationList);
    //Make sure that ImageList does not contain ImageDir.
    TupleRegexpReplace(hv_ImageList, ".*?"+hv_ImageDir, "", &hv_ImageList);
    TupleRegexpReplace(hv_ImageList, "^/", "", &hv_ImageList);
    //Make sure that SegmentationList does not contain SegmentationDir.
    TupleRegexpReplace(hv_SegmentationList, ".*?"+hv_SegmentationDir, "", &hv_SegmentationList);
    TupleRegexpReplace(hv_SegmentationList, "^/", "", &hv_SegmentationList);
  }
  //If ImageDir is empty, we omit the path separator.
  if (0 != (int((hv_ImageDir.TupleStrlen())==0)))
  {
    hv_ImageDirSep = "";
  }
  else
  {
    hv_ImageDirSep = "/";
  }
  if (0 != (int((hv_SegmentationDir.TupleStrlen())==0)))
  {
    hv_SegmentationDirSep = "";
  }
  else
  {
    hv_SegmentationDirSep = "/";
  }
  //
  //Check if all images exist.
  images_exist((hv_ImageDir+hv_ImageDirSep)+hv_ImageList);
  //Check if all segmentation images exist.
  images_exist((hv_SegmentationDir+hv_SegmentationDirSep)+hv_SegmentationList);
  //
  //Initialize the dictionary dataset.
  CreateDict(&(*hv_DLDataset));
  //
  //Set general information of the dataset.
  SetDictTuple((*hv_DLDataset), "image_dir", hv_ImageDir);
  SetDictTuple((*hv_DLDataset), "segmentation_dir", hv_SegmentationDir);
  SetDictTuple((*hv_DLDataset), "class_names", hv_ClassNames);
  SetDictTuple((*hv_DLDataset), "class_ids", hv_ClassIDs);
  //
  //Get number of samples to set unique image ID for each sample according to its index in ImageList.
  hv_NumSamples = hv_ImageList.TupleLength();
  //
  //Create samples in parallel.
  //We use 8 threads, clearly less than the maximum number of HDevelop subthreads.
  hv_ThreadNum = 8;
  GetSystem("thread_num", &hv_ThreadSys);
  if (0 != (int(hv_ThreadNum>hv_ThreadSys)))
  {
    hv_ThreadNum = 1;
  }
  hv_NumSamplesPerThread = ((hv_NumSamples+hv_ThreadNum)-1)/hv_ThreadNum;
  {
  HTuple end_val123 = hv_ThreadNum-1;
  HTuple step_val123 = 1;
  for (hv_ThreadIndex=0; hv_ThreadIndex.Continue(end_val123, step_val123); hv_ThreadIndex += step_val123)
  {
    hv_Start = hv_ThreadIndex*hv_NumSamplesPerThread;
    hv_End = (hv_Start+hv_NumSamplesPerThread)-1;
    if (0 != (HTuple(int(hv_End<0)).TupleOr(int(hv_Start<0))))
    {
      throw HException("Negative indices when calculating samples per thread.");
    }
    //
    //Adapt indices for very last thread.
    if (0 != (int(hv_End>=hv_NumSamples)))
    {
      hv_End = hv_NumSamples-1;
      if (0 != (int(hv_End<hv_Start)))
      {
        break;
      }
      hv_NumSamplesPerThread = (hv_End-hv_Start)+1;
    }
    // Create a thread instance
    hcppthread_handle = new HDevThread(hcppthread_context,
                (void*)HDevExportCpp::_hcppthread_create_dl_dataset_segmentation_samples,4,1);
    // Set thread procedure call arguments 
    hcppthread_handle->SetInputCtrlParamTuple(0,hv_ImageList.TupleSelectRange(hv_Start,hv_End));
    hcppthread_handle->SetInputCtrlParamTuple(1,hv_SegmentationList.TupleSelectRange(hv_Start,hv_End));
    hcppthread_handle->SetInputCtrlParamTuple(2,hv_NumSamplesPerThread);
    hcppthread_handle->SetInputCtrlParamTuple(3,hv_Start);
    {HTuple at_idx;
    at_idx[0] = hv_ThreadIndex;
    hcppthread_handle->BindOutputCtrlParamVector(0,0,&hvec_SamplesOutput,at_idx);
    }

    // Start proc line in thread
    hcppthread_handle->ParStart(&hvec_VProcThreads[hv_ThreadIndex].T());

    if (0 != (int(hv_End==(hv_NumSamples-1))))
    {
      break;
    }
  }
  }
  hv_ThreadIds = hvec_VProcThreads.ConvertVectorToTuple();
  HDevThread::ParJoin(hv_ThreadIds);
  hvec_VProcThreads.Clear();
  hv_ThreadIds = HTuple();
  hv_Samples = hvec_SamplesOutput.ConvertVectorToTuple();
  //
  //Set the sample tuple.
  SetDictTuple((*hv_DLDataset), "samples", hv_Samples);
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Read the dictionaries DLSamples from files. 
void read_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple *hv_DLSampleBatch)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_DatasetSamples, hv_MinIndex, hv_MaxIndex;
  HTuple  hv_KeyDirExists, hv_DictDir, hv_DLSamplesProc, hv_ImageIndex;
  HTuple  hv_KeyFileExists, hv_ImageID, hv_FileNameRelative;
  HTuple  hv_FileNameSample, hv_FileExists, hv_DictPath, hv_DLSample;
  HTuple  hv_Exception;

  //
  //This procedure reads a batch of DLSample dictionaries from disk.
  //The wanted samples are selected from a DLDataset by their indices.
  //The indices of the wanted samples are handed over in SampleIndices.
  //It returns the tuple of read-in dictionaries in DLSampleBatch.
  //
  //Sanity checks of inputs.
  //
  if (0 != (int((hv_SampleIndices.TupleLength())<=0)))
  {
    //Check the length of selected indices.
    throw HException(HTuple("Invalid length of SelectedIndices: ")+(hv_SampleIndices.TupleLength()));
  }
  else
  {
    //Get the samples from the DLDataset.
    GetDictTuple(hv_DLDataset, "samples", &hv_DatasetSamples);
    //Get min and max value of given indices.
    TupleMin(hv_SampleIndices, &hv_MinIndex);
    TupleMax(hv_SampleIndices, &hv_MaxIndex);
    if (0 != (HTuple(int(hv_MinIndex<0)).TupleOr(int(hv_MaxIndex>((hv_DatasetSamples.TupleLength())-1)))))
    {
      //Check the value range of the provided indices.
      throw HException("The given SampleIndices are not within the range of available samples in DLDataset.");
    }
  }
  //
  //Check if the key dlsample_dir is given.
  GetDictParam(hv_DLDataset, "key_exists", "dlsample_dir", &hv_KeyDirExists);
  //
  if (0 != hv_KeyDirExists)
  {
    //
    //Get the dlsample_dir.
    GetDictTuple(hv_DLDataset, "dlsample_dir", &hv_DictDir);
    //Get the samples to be processed.
    hv_DLSamplesProc = HTuple(hv_DatasetSamples[hv_SampleIndices]);
    //
    //Initialize DLSampleBatch tuple.
    (*hv_DLSampleBatch) = HTuple();
    //
    //Read in all DLSamples into the batch.
    {
    HTuple end_val37 = (hv_SampleIndices.TupleLength())-1;
    HTuple step_val37 = 1;
    for (hv_ImageIndex=0; hv_ImageIndex.Continue(end_val37, step_val37); hv_ImageIndex += step_val37)
    {
      //Check if dlsample key exist.
      GetDictParam(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "key_exists", "dlsample_file_name", 
          &hv_KeyFileExists);
      //
      if (0 != (hv_KeyFileExists.TupleNot()))
      {
        //
        //If the key does not exist, check if a corresponding file exists.
        GetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "image_id", &hv_ImageID);
        hv_FileNameRelative = hv_ImageID+"_dlsample.hdict";
        hv_FileNameSample = (hv_DictDir+"/")+hv_FileNameRelative;
        //
        FileExists(hv_FileNameSample, &hv_FileExists);
        if (0 != hv_FileExists)
        {
          //If it exists, create corresponding key.
          SetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "dlsample_file_name", 
              hv_FileNameRelative);
        }
        else
        {
          //If not, throw an error.
          throw HException("No 'dlsample_file_name' and hdict file available for image ID "+hv_ImageID);
        }
        //
      }
      //
      //If dlsample dictionary is available for reading, read it.
      GetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "dlsample_file_name", 
          &hv_DictPath);
      try
      {
        ReadDict((hv_DictDir+"/")+hv_DictPath, HTuple(), HTuple(), &hv_DLSample);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        throw HException((((("An error has occurred while reading "+hv_DictDir)+"/")+hv_DictPath)+HTuple(" , HALCON error # "))+HTuple(hv_Exception[0]));
      }
      //Add it to the DLSampleBatch.
      (*hv_DLSampleBatch) = (*hv_DLSampleBatch).TupleConcat(hv_DLSample);
      //
    }
    }
  }
  else
  {
    throw HException("The dataset needs to include the key 'dlsample_dir' for reading a DLSample from file.");
  }

  return;
}

// Chapter: Deep Learning / Model
// Short Description: Split the samples into training, validation, and test subsets. 
void split_dl_dataset (HTuple hv_DLDataset, HTuple hv_TrainingPercent, HTuple hv_ValidationPercent, 
    HTuple hv_GenParam)
{

  // Local iconic variables
  HObject  ho_SegmImage;

  // Local control variables
  HTuple  hv_OverwriteSplit, hv_ModelType, hv_SplitNames;
  HTuple  hv_GenParamName, hv_GenParamIndex, hv_Type, hv_DLSamples;
  HTuple  hv_DLSample, hv_AnomalyDetectionLabelExists, hv_BBoxLabelIdExists;
  HTuple  hv_ImageLabelIdExists, hv_SegmFileExists, hv_WordExists;
  HTuple  hv_XYZExists, hv_ClassIDs, hv_ClassNames, hv_ClassIDsToClassIndex;
  HTuple  hv_TrainingRatio, hv_ValidationRatio, hv_SplitRatios;
  HTuple  hv_SplitRatiosInvSortIndices, hv_NotYetSplit, hv_IndexSample;
  HTuple  hv_SplitExists, hv_ImageIndicesAllClass, hv_NumImagesPerClass;
  HTuple  hv_ImageIndices, hv_AnomalyLabel, hv_Labels, hv_ImageLabelID;
  HTuple  hv_BboxLabels, hv_SegmDir, hv_SegmFileName, hv_AbsoluteHisto;
  HTuple  hv_LabelIndices, hv_LabelIndex, hv_Index, hv_ClassIndex;
  HTuple  hv_ImageIndicesPerClass, hv_SplitImageIndices, hv_AssignedImageIndices;
  HTuple  hv_ClassSortIndices, hv_ImageIndicesClass, hv_ImageIndicesClassToBeAssigned;
  HTuple  hv_SplitIndex, hv_NumToBeAssignedToThisSplit, hv_AssignedImageIndicesToThisSplit;
  HTuple  hv_NumAlreadyAssignedToThisSplit, hv_NumStillToBeAssigned;
  HTuple  hv_ImageIndex, hv_Rand, hv_RatioIndex, hv_CurrentSplitIndex;
  HTuple  hv_CurrentSplitRatio, hv_ImageIndicesWithoutLabel;
  HTuple  hv_NumImageIndicesWithoutLabel, hv_NumToBeAssigned;
  HTuple  hv_MaxRatioIndex, hv_SplitNameIndex, hv_SplitName;
  HTuple  hv_SplitIndices, hv_SampleSplitIndex, hv_ErrorDict;

  //
  //This procedure divides the samples in DLDataset
  //into three disjoint subsets: train, validation, and test.
  //The number of samples in each subset is defined
  //by the given percentages TrainingPercent and ValidationPercent.
  //As a result, every sample has a new key named 'split'
  //with an associated value 'train', 'validation', or 'test'.
  //Thereby the classes of every image are taken
  //into consideration, in order to avoid accidental predominance
  //of certain classes in one of the subsets. In the case of a
  //dataset used for anomaly detection or
  //Global Context Anomaly Detection, all images of type 'nok'
  //are sorted into the 'test' split.
  //
  //Check input data.
  if (0 != (int(hv_TrainingPercent<0)))
  {
    throw HException("TrainingPercent must not be smaller than zero.");
  }
  if (0 != (int(hv_ValidationPercent<0)))
  {
    throw HException("ValidationPercent must not be smaller than zero.");
  }
  if (0 != (int((hv_TrainingPercent+hv_ValidationPercent)>100)))
  {
    throw HException("The sum of TrainingPercent and ValidationPercent must not be greater than 100.");
  }
  //
  //** Set the default values ***
  //
  //Overwrite an existing split?
  hv_OverwriteSplit = 0;
  //Initialize model_type of the DLDataset.
  hv_ModelType = "";
  //Names for split subsets.
  hv_SplitNames.Clear();
  hv_SplitNames[0] = "train";
  hv_SplitNames[1] = "validation";
  hv_SplitNames[2] = "test";
  //
  //Get input for generic parameters.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenParamName);
    {
    HTuple end_val37 = (hv_GenParamName.TupleLength())-1;
    HTuple step_val37 = 1;
    for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val37, step_val37); hv_GenParamIndex += step_val37)
    {
      if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("overwrite_split"))))
      {
        GetDictTuple(hv_GenParam, "overwrite_split", &hv_OverwriteSplit);
        hv_Type = hv_OverwriteSplit.TupleType();
        if (0 != (HTuple(int(hv_Type==4)).TupleAnd(int(hv_OverwriteSplit==HTuple("true")))))
        {
          hv_OverwriteSplit = 1;
        }
        if (0 != (HTuple(int(hv_Type==4)).TupleAnd(int(hv_OverwriteSplit==HTuple("false")))))
        {
          hv_OverwriteSplit = 0;
        }
      }
      else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("model_type"))))
      {
        GetDictTuple(hv_GenParam, "model_type", &hv_ModelType);
      }
      else
      {
        throw HException("Unknown GenParam entry: "+HTuple(hv_GenParamName[hv_GenParamIndex]));
      }
    }
    }
  }
  //
  //Read in the samples.
  GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
  //
  //Try to guess the ModelType if not set by GenParam.
  if (0 != (int(hv_ModelType==HTuple(""))))
  {
    hv_DLSample = ((const HTuple&)hv_DLSamples)[0];
    //Check for relevant keys.
    //The 'anomaly_label' applies to the model types 'anomaly_detection'
    //and 'gc_anomaly_detection'. It cannot be clearly determined here
    //which model type is used for the samples.
    GetDictParam(hv_DLSample, "key_exists", "anomaly_label", &hv_AnomalyDetectionLabelExists);
    GetDictParam(hv_DLSample, "key_exists", "bbox_label_id", &hv_BBoxLabelIdExists);
    GetDictParam(hv_DLSample, "key_exists", "image_label_id", &hv_ImageLabelIdExists);
    GetDictParam(hv_DLSample, "key_exists", "segmentation_file_name", &hv_SegmFileExists);
    GetDictParam(hv_DLSample, "key_exists", "word", &hv_WordExists);
    GetDictParam(hv_DLSample, "key_exists", "xyz_file_name", &hv_XYZExists);
    //
    if (0 != hv_AnomalyDetectionLabelExists)
    {
      hv_ModelType = "anomaly_detection";
    }
    else if (0 != hv_ImageLabelIdExists)
    {
      hv_ModelType = "classification";
    }
    else if (0 != hv_BBoxLabelIdExists)
    {
      hv_ModelType = "detection";
    }
    else if (0 != hv_SegmFileExists)
    {
      if (0 != hv_XYZExists)
      {
        hv_ModelType = "3d_gripping_point_detection";
      }
      else
      {
        hv_ModelType = "segmentation";
      }
    }
    else if (0 != hv_WordExists)
    {
      hv_ModelType = "ocr_recognition";
    }
    else
    {
      throw HException("Parameter 'model_type' cannot be determined.");
    }
  }
  //
  //Get data from DLDataset.
  if (0 != (HTuple(int(hv_ModelType==HTuple("anomaly_detection"))).TupleOr(int(hv_ModelType==HTuple("gc_anomaly_detection")))))
  {
    hv_ClassIDs.Clear();
    hv_ClassIDs[0] = 0;
    hv_ClassIDs[1] = 1;
    hv_ClassNames.Clear();
    hv_ClassNames[0] = "ok";
    hv_ClassNames[1] = "nok";
  }
  else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
  {
    //Classes are not used in ocr_recognition split.
    hv_ClassIDs.Clear();
    hv_ClassIDs[0] = 0;
    hv_ClassIDs[1] = 1;
    hv_ClassNames.Clear();
    hv_ClassNames[0] = "class1";
    hv_ClassNames[1] = "class2";
  }
  else
  {
    GetDictTuple(hv_DLDataset, "class_ids", &hv_ClassIDs);
    GetDictTuple(hv_DLDataset, "class_names", &hv_ClassNames);
  }
  //
  //Define mapping from class ID to class index.
  create_dl_class_id_mapping(hv_ClassIDs, &hv_ClassIDsToClassIndex);
  //
  //Calculate ratios of training and validation datasets.
  hv_TrainingRatio = hv_TrainingPercent*0.01;
  hv_ValidationRatio = hv_ValidationPercent*0.01;
  hv_SplitRatios.Clear();
  hv_SplitRatios.Append(hv_TrainingRatio);
  hv_SplitRatios.Append(hv_ValidationRatio);
  hv_SplitRatios.Append((1.0-hv_TrainingRatio)-hv_ValidationRatio);
  hv_SplitRatiosInvSortIndices = HTuple(hv_SplitRatios.TupleSortIndex()).TupleInverse();
  //
  //Test whether the dataset is already split.
  hv_NotYetSplit = 1;
  {
  HTuple end_val115 = (hv_DLSamples.TupleLength())-1;
  HTuple step_val115 = 1;
  for (hv_IndexSample=0; hv_IndexSample.Continue(end_val115, step_val115); hv_IndexSample += step_val115)
  {
    GetDictParam(HTuple(hv_DLSamples[hv_IndexSample]), "key_exists", "split", &hv_SplitExists);
    if (0 != hv_SplitExists)
    {
      hv_NotYetSplit = 0;
      break;
    }
  }
  }
  //
  //Split the dataset if no split is present
  //or split should be overwritten.
  if (0 != (hv_NotYetSplit.TupleOr(hv_OverwriteSplit)))
  {
    //
    //Initialize a tuple to collect the indices
    //of images that contain a class.
    hv_ImageIndicesAllClass = HTuple((hv_ClassNames.TupleLength())*(hv_DLSamples.TupleLength()),0);
    //
    //Get labels of every sample image
    //and count how many images per class there are.
    //
    hv_NumImagesPerClass = HTuple(hv_ClassIDs.TupleLength(),0);
    hv_ImageIndices = HTuple::TupleGenSequence(0,(hv_DLSamples.TupleLength())-1,1);
    {
    HTuple end_val136 = (hv_DLSamples.TupleLength())-1;
    HTuple step_val136 = 1;
    for (hv_IndexSample=0; hv_IndexSample.Continue(end_val136, step_val136); hv_IndexSample += step_val136)
    {
      hv_DLSample = HTuple(hv_DLSamples[hv_IndexSample]);
      if (0 != (HTuple(int(hv_ModelType==HTuple("anomaly_detection"))).TupleOr(int(hv_ModelType==HTuple("gc_anomaly_detection")))))
      {
        //Get labels - anomaly detection and
        //Global Context Anomaly Detection.
        GetDictTuple(hv_DLSample, "anomaly_label", &hv_AnomalyLabel);
        hv_Labels = int(hv_AnomalyLabel!=HTuple("ok"));
      }
      else if (0 != (int(hv_ModelType==HTuple("classification"))))
      {
        //Get labels - classification.
        GetDictTuple(hv_DLSample, "image_label_id", &hv_ImageLabelID);
        hv_Labels = hv_ImageLabelID;
      }
      else if (0 != (int(hv_ModelType==HTuple("detection"))))
      {
        //Get labels - object detection.
        GetDictTuple(hv_DLSample, "bbox_label_id", &hv_BboxLabels);
        hv_Labels = (hv_BboxLabels.TupleSort()).TupleUniq();
      }
      else if (0 != (HTuple(int(hv_ModelType==HTuple("segmentation"))).TupleOr(int(hv_ModelType==HTuple("3d_gripping_point_detection")))))
      {
        //Get labels - semantic segmentation and
        //3d gripping point detection.
        GetDictTuple(hv_DLDataset, "segmentation_dir", &hv_SegmDir);
        GetDictTuple(hv_DLSample, "segmentation_file_name", &hv_SegmFileName);
        ReadImage(&ho_SegmImage, (hv_SegmDir+"/")+hv_SegmFileName);
        //
        GrayHistoAbs(ho_SegmImage, ho_SegmImage, 1, &hv_AbsoluteHisto);
        hv_Labels = (hv_AbsoluteHisto.TupleGreaterElem(0)).TupleFind(1);
      }
      else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
      {
        //Get labels - ocr_recognition.
        //Labels are not used in ocr_recognition split.
        hv_Labels = 0;
      }
      //
      //Add up images per class.
      hv_LabelIndices = HTuple();
      {
      HTuple end_val168 = (hv_Labels.TupleLength())-1;
      HTuple step_val168 = 1;
      for (hv_LabelIndex=0; hv_LabelIndex.Continue(end_val168, step_val168); hv_LabelIndex += step_val168)
      {
        hv_LabelIndices[hv_LabelIndex] = hv_ClassIDsToClassIndex.TupleGetDictTuple(HTuple(hv_Labels[hv_LabelIndex]));
      }
      }
      hv_NumImagesPerClass[hv_LabelIndices] = HTuple(hv_NumImagesPerClass[hv_LabelIndices])+1;
      {
      HTuple end_val172 = (hv_Labels.TupleLength())-1;
      HTuple step_val172 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val172, step_val172); hv_Index += step_val172)
      {
        //Add image index to ImageIndicesAllClass.
        hv_ClassIndex = HTuple(hv_LabelIndices[hv_Index]);
        hv_ImageIndicesAllClass[((hv_ClassIndex*(hv_DLSamples.TupleLength()))+HTuple(hv_NumImagesPerClass[hv_ClassIndex]))-1] = hv_IndexSample;
      }
      }
    }
    }
    //
    //Write the image indices per class to a dictionary.
    CreateDict(&hv_ImageIndicesPerClass);
    {
    HTuple end_val181 = (hv_ClassNames.TupleLength())-1;
    HTuple step_val181 = 1;
    for (hv_ClassIndex=0; hv_ClassIndex.Continue(end_val181, step_val181); hv_ClassIndex += step_val181)
    {
      SetDictTuple(hv_ImageIndicesPerClass, HTuple(hv_ClassNames[hv_ClassIndex]), 
          hv_ImageIndicesAllClass.TupleSelectRange(hv_ClassIndex*(hv_DLSamples.TupleLength()),((hv_ClassIndex*(hv_DLSamples.TupleLength()))+HTuple(hv_NumImagesPerClass[hv_ClassIndex]))-1));
    }
    }
    //
    //** Start splitting. ***
    //
    //Create a dictionary where the image indices
    //for the three subsets are saved.
    CreateDict(&hv_SplitImageIndices);
    {
    HTuple end_val190 = (hv_SplitNames.TupleLength())-1;
    HTuple step_val190 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val190, step_val190); hv_Index += step_val190)
    {
      SetDictTuple(hv_SplitImageIndices, HTuple(hv_SplitNames[hv_Index]), HTuple());
    }
    }
    //We split based on classes,
    //starting with the smallest class.
    hv_AssignedImageIndices = HTuple();
    hv_ClassSortIndices = hv_NumImagesPerClass.TupleSortIndex();
    {
    HTuple end_val197 = (hv_NumImagesPerClass.TupleLength())-1;
    HTuple step_val197 = 1;
    for (hv_ClassIndex=0; hv_ClassIndex.Continue(end_val197, step_val197); hv_ClassIndex += step_val197)
    {
      //Get all image indices where this class is present.
      GetDictTuple(hv_ImageIndicesPerClass, HTuple(hv_ClassNames[HTuple(hv_ClassSortIndices[hv_ClassIndex])]), 
          &hv_ImageIndicesClass);
      hv_ImageIndicesClass = hv_ImageIndicesClass.TupleUniq();
      //Remove image indices that have already been assigned.
      hv_ImageIndicesClassToBeAssigned = hv_ImageIndicesClass.TupleDifference(hv_AssignedImageIndices);
      tuple_shuffle(hv_ImageIndicesClassToBeAssigned, &hv_ImageIndicesClassToBeAssigned);
      //
      {
      HTuple end_val205 = (hv_SplitNames.TupleLength())-1;
      HTuple step_val205 = 1;
      for (hv_SplitIndex=0; hv_SplitIndex.Continue(end_val205, step_val205); hv_SplitIndex += step_val205)
      {
        //Check how many of the indices have already been assigned
        //and how many should be assigned.
        if (0 != (HTuple(HTuple(int(hv_ModelType==HTuple("anomaly_detection"))).TupleOr(int(hv_ModelType==HTuple("gc_anomaly_detection")))).TupleAnd(int(HTuple(hv_ClassNames[HTuple(hv_ClassSortIndices[hv_ClassIndex])])==HTuple("nok")))))
        {
          //All 'nok' images for anomaly detection or Global Context Anomaly Detection
          //are sorted into the test set.
          if (0 != (int(HTuple(hv_SplitNames[hv_SplitIndex])==HTuple("test"))))
          {
            hv_NumToBeAssignedToThisSplit = hv_ImageIndicesClass.TupleLength();
          }
          else
          {
            hv_NumToBeAssignedToThisSplit = 0;
          }
        }
        else
        {
          hv_NumToBeAssignedToThisSplit = ((HTuple(hv_SplitRatios[hv_SplitIndex])*(hv_ImageIndicesClass.TupleLength())).TupleFloor()).TupleInt();
        }
        GetDictTuple(hv_SplitImageIndices, HTuple(hv_SplitNames[hv_SplitIndex]), 
            &hv_AssignedImageIndicesToThisSplit);
        hv_NumAlreadyAssignedToThisSplit = (hv_ImageIndicesClass.TupleIntersection(hv_AssignedImageIndicesToThisSplit)).TupleLength();
        hv_NumStillToBeAssigned = hv_NumToBeAssignedToThisSplit-hv_NumAlreadyAssignedToThisSplit;
        //
        if (0 != (int(hv_NumStillToBeAssigned>0)))
        {
          if (0 != (int(hv_NumStillToBeAssigned>(hv_ImageIndicesClassToBeAssigned.TupleLength()))))
          {
            hv_NumStillToBeAssigned = hv_ImageIndicesClassToBeAssigned.TupleLength();
          }
          hv_AssignedImageIndicesToThisSplit = hv_AssignedImageIndicesToThisSplit.TupleConcat(hv_ImageIndicesClassToBeAssigned.TupleSelectRange(0,hv_NumStillToBeAssigned-1));
          SetDictTuple(hv_SplitImageIndices, HTuple(hv_SplitNames[hv_SplitIndex]), 
              hv_AssignedImageIndicesToThisSplit);
          //Update the remaining image indices of this class.
          hv_ImageIndicesClassToBeAssigned = hv_ImageIndicesClassToBeAssigned.TupleSelectRange(hv_NumStillToBeAssigned,(hv_ImageIndicesClassToBeAssigned.TupleLength())-1);
        }
      }
      }
      //The remaining image indices are assigned to random subsets
      //according to the defined ratios.
      if (0 != (int((hv_ImageIndicesClassToBeAssigned.TupleLength())>0)))
      {
        {
        HTuple end_val236 = (hv_ImageIndicesClassToBeAssigned.TupleLength())-1;
        HTuple step_val236 = 1;
        for (hv_ImageIndex=0; hv_ImageIndex.Continue(end_val236, step_val236); hv_ImageIndex += step_val236)
        {
          hv_Rand = HTuple::TupleRand(1);
          {
          HTuple end_val238 = (hv_SplitRatios.TupleLength())-1;
          HTuple step_val238 = 1;
          for (hv_RatioIndex=0; hv_RatioIndex.Continue(end_val238, step_val238); hv_RatioIndex += step_val238)
          {
            hv_CurrentSplitIndex = HTuple(hv_SplitRatiosInvSortIndices[hv_RatioIndex]);
            hv_CurrentSplitRatio = HTuple(hv_SplitRatios[hv_CurrentSplitIndex]);
            if (0 != (int(hv_Rand<=hv_CurrentSplitRatio)))
            {
              GetDictTuple(hv_SplitImageIndices, HTuple(hv_SplitNames[hv_CurrentSplitIndex]), 
                  &hv_AssignedImageIndicesToThisSplit);
              hv_AssignedImageIndicesToThisSplit = hv_AssignedImageIndicesToThisSplit.TupleConcat(HTuple(hv_ImageIndicesClassToBeAssigned[hv_ImageIndex]));
              SetDictTuple(hv_SplitImageIndices, HTuple(hv_SplitNames[hv_CurrentSplitIndex]), 
                  hv_AssignedImageIndicesToThisSplit);
              break;
            }
            else
            {
              hv_Rand = hv_Rand-hv_CurrentSplitRatio;
            }
          }
          }
        }
        }
      }
      hv_AssignedImageIndices = ((hv_AssignedImageIndices.TupleConcat(hv_ImageIndicesClass)).TupleUniq()).TupleSort();
    }
    }
    //
    //There might be images not having any labels:
    //Assign them based on the ratio.
    hv_ImageIndicesWithoutLabel = hv_ImageIndices.TupleDifference(hv_AssignedImageIndices);
    hv_NumImageIndicesWithoutLabel = hv_ImageIndicesWithoutLabel.TupleLength();
    if (0 != (int(hv_NumImageIndicesWithoutLabel>0)))
    {
      tuple_shuffle(hv_ImageIndicesWithoutLabel, &hv_ImageIndicesWithoutLabel);
      {
      HTuple end_val261 = (hv_SplitRatios.TupleLength())-1;
      HTuple step_val261 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val261, step_val261); hv_Index += step_val261)
      {
        hv_NumToBeAssigned = (HTuple(hv_SplitRatios[hv_Index])*hv_NumImageIndicesWithoutLabel).TupleInt();
        GetDictTuple(hv_SplitImageIndices, HTuple(hv_SplitNames[hv_Index]), &hv_AssignedImageIndicesToThisSplit);
        hv_AssignedImageIndicesToThisSplit = hv_AssignedImageIndicesToThisSplit.TupleConcat(hv_ImageIndicesWithoutLabel.TupleSelectRange(0,hv_NumToBeAssigned-1));
        SetDictTuple(hv_SplitImageIndices, HTuple(hv_SplitNames[hv_Index]), hv_AssignedImageIndicesToThisSplit.TupleSort());
        hv_ImageIndicesWithoutLabel = hv_ImageIndicesWithoutLabel.TupleSelectRange(hv_NumToBeAssigned,(hv_ImageIndicesWithoutLabel.TupleLength())-1);
      }
      }
      //If there are still image indices, assign them to split with highest ratio.
      hv_MaxRatioIndex = hv_SplitRatiosInvSortIndices.TupleFind(0);
      if (0 != (int((hv_ImageIndicesWithoutLabel.TupleLength())>0)))
      {
        GetDictTuple(hv_SplitImageIndices, HTuple(hv_SplitNames[hv_MaxRatioIndex]), 
            &hv_AssignedImageIndicesToThisSplit);
        hv_AssignedImageIndicesToThisSplit = hv_AssignedImageIndicesToThisSplit.TupleConcat(hv_ImageIndicesWithoutLabel);
        SetDictTuple(hv_SplitImageIndices, HTuple(hv_SplitNames[hv_MaxRatioIndex]), 
            hv_AssignedImageIndicesToThisSplit.TupleSort());
      }
    }
    //
    //Assign 'split' entries to samples.
    {
    HTuple end_val278 = (hv_SplitNames.TupleLength())-1;
    HTuple step_val278 = 1;
    for (hv_SplitNameIndex=0; hv_SplitNameIndex.Continue(end_val278, step_val278); hv_SplitNameIndex += step_val278)
    {
      hv_SplitName = HTuple(hv_SplitNames[hv_SplitNameIndex]);
      GetDictTuple(hv_SplitImageIndices, hv_SplitName, &hv_SplitIndices);
      {
      HTuple end_val281 = (hv_SplitIndices.TupleLength())-1;
      HTuple step_val281 = 1;
      for (hv_SplitIndex=0; hv_SplitIndex.Continue(end_val281, step_val281); hv_SplitIndex += step_val281)
      {
        hv_SampleSplitIndex = HTuple(hv_SplitIndices[hv_SplitIndex]);
        SetDictTuple(HTuple(hv_DLSamples[hv_SampleSplitIndex]), "split", hv_SplitName);
      }
      }
    }
    }
  }
  else
  {
    hv_ErrorDict = "The dataset is already split. You can overwrite the existing split using the generic parameter 'overwrite_split'.";
    throw HException(hv_ErrorDict);
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Write the dictionaries of the samples in DLSampleBatch to hdict files and store the paths in DLDataset. 
void write_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple hv_DLSampleBatch, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_RaiseErrorWriteDict, hv_IndexGenParam;
  HTuple  hv_DLSampleDirExists, hv_OutDir, hv_DatasetSamples;
  HTuple  hv_I, hv_DLDatasetIndex, hv_DatasetSample, hv_DLSample;
  HTuple  hv_DatasetImageID, hv_SampleImageID, hv_FileNameOut;

  //
  //This procedure writes all given DLSamples in DLSampleBatch to hdict files
  //and stores the file paths in the respective samples of the DLDataset.
  //The directory needs to be given in dlsample_dir, before calling this procedure.
  //
  //The output filename is created in the following way: image_id + '_dlsample.hdict'
  //
  //Set the default values.
  //Raise error when writing dictionary.
  hv_RaiseErrorWriteDict = "true";
  //
  //Transfer generic parameters.
  if (0 != (int((hv_GenParamName.TupleLength())!=(hv_GenParamValue.TupleLength()))))
  {
    throw HException("GenParamName and GenParamValue have to be of equal length.");
  }
  //
  if (0 != (int(hv_GenParamName!=HTuple())))
  {
    {
    HTuple end_val17 = (hv_GenParamName.TupleLength())-1;
    HTuple step_val17 = 1;
    for (hv_IndexGenParam=0; hv_IndexGenParam.Continue(end_val17, step_val17); hv_IndexGenParam += step_val17)
    {
      if (0 != (int(HTuple(hv_GenParamName[hv_IndexGenParam])==HTuple("raise_error_if_content_not_serializable"))))
      {
        //Set 'raise_error_if_content_not_serializable' for writing write_dict.
        hv_RaiseErrorWriteDict = HTuple(hv_GenParamValue[hv_IndexGenParam]);
      }
      else
      {
        throw HException("Unknown GenParam key : "+HTuple(hv_GenParamName[hv_IndexGenParam]));
      }
    }
    }
  }
  //
  //Check the parameters.
  //Check that the base path is available in the DLDataset.
  GetDictParam(hv_DLDataset, "key_exists", "dlsample_dir", &hv_DLSampleDirExists);
  if (0 != (hv_DLSampleDirExists.TupleNot()))
  {
    throw HException("The dataset needs to include the key 'dlsample_dir'.");
    return;
  }

  if (0 != (int((hv_DLSampleBatch.TupleLength())!=(hv_SampleIndices.TupleLength()))))
  {
    throw HException("The input tuples DLSampleBatch and SampleIndices need to match in length.");
    return;
  }
  //
  //Write preprocessed data.
  //
  //Get the base path for the outputs.
  GetDictTuple(hv_DLDataset, "dlsample_dir", &hv_OutDir);
  //
  //Get the samples.
  GetDictTuple(hv_DLDataset, "samples", &hv_DatasetSamples);
  //
  //Loop over all samples in the batch.
  {
  HTuple end_val49 = (hv_DLSampleBatch.TupleLength())-1;
  HTuple step_val49 = 1;
  for (hv_I=0; hv_I.Continue(end_val49, step_val49); hv_I += step_val49)
  {
    //Get the sample dictionaries.
    hv_DLDatasetIndex = HTuple(hv_SampleIndices[hv_I]);
    hv_DatasetSample = HTuple(hv_DatasetSamples[hv_DLDatasetIndex]);
    hv_DLSample = HTuple(hv_DLSampleBatch[hv_I]);
    //
    //Check that image IDs match.
    GetDictTuple(hv_DatasetSample, "image_id", &hv_DatasetImageID);
    GetDictTuple(HTuple(hv_DLSampleBatch[hv_I]), "image_id", &hv_SampleImageID);
    if (0 != (int(hv_DatasetImageID!=hv_SampleImageID)))
    {
      throw HException("Image IDs do not match. Please use correct indexing in input argument SampleIndices.");
      return;
    }
    //
    //Generate the output file name.
    hv_FileNameOut = hv_SampleImageID+"_dlsample.hdict";
    //
    //Write output dictionary.
    WriteDict(hv_DLSample, (hv_OutDir+"/")+hv_FileNameOut, "raise_error_if_content_not_serializable", 
        hv_RaiseErrorWriteDict);
    //Add output path to DLDataset sample dictionary.
    SetDictTuple(HTuple(hv_DatasetSamples[hv_DLDatasetIndex]), "dlsample_file_name", 
        hv_FileNameOut);
    //
  }
  }

  return;
}

// Generated stubs for parallel procedure calls. Wrapped in name
// space to avoid name conflicts with actual procedure names
namespace HDevExportCpp
{
// Parallel execution wrapper for create_dl_dataset_3d_gripping_point_detection_samples(...) 
static void* _hcppthread_create_dl_dataset_3d_gripping_point_detection_samples(void *hcthread)
{
  // +++ define thread context for this procedure
  HDevThread*  hcppthread = (HDevThread*) hcthread;
  try
  {
    // Input parameters
    const HTuple        &cbhv_ImageList = hcppthread->GetInputCtrlParamTuple(0);
    const HTuple        &cbhv_XYZList = hcppthread->GetInputCtrlParamTuple(1);
    const HTuple        &cbhv_NormalsList = hcppthread->GetInputCtrlParamTuple(2);
    const HTuple        &cbhv_SegmentationList = hcppthread->GetInputCtrlParamTuple(3);
    const HTuple        &cbhv_NumSamplesPerThread = hcppthread->GetInputCtrlParamTuple(4);
    const HTuple        &cbhv_UniqueIndex = hcppthread->GetInputCtrlParamTuple(5);

    // Output parameters
    HTuple        cbhv_SamplesOutput;

    // Call create_dl_dataset_3d_gripping_point_detection_samples
    create_dl_dataset_3d_gripping_point_detection_samples(cbhv_ImageList, cbhv_XYZList, 
        cbhv_NormalsList, cbhv_SegmentationList, cbhv_NumSamplesPerThread, cbhv_UniqueIndex, 
        &cbhv_SamplesOutput);

    // Store output parameters in thread object
    hcppthread->StoreOutputCtrlParamTuple(0,cbhv_SamplesOutput);

    // Reduce reference counter of thread object
    hcppthread->Exit();
    delete hcppthread;

  }
  catch (HException& exc)
  {
    // No exceptions may be raised from stub in parallel case,
    // so we need to store this information prior to cleanup
    bool is_direct_call = hcppthread->IsDirectCall();
    // Attempt to clean up in error case, too
    hcppthread->Exit();
    delete hcppthread;
    // Propagate exception if called directly
    if (is_direct_call)
      throw exc;
  }
  return NULL;
}

// Parallel execution wrapper for create_dl_dataset_anomaly_samples(...) 
static void* _hcppthread_create_dl_dataset_anomaly_samples(void *hcthread)
{
  // +++ define thread context for this procedure
  HDevThread*  hcppthread = (HDevThread*) hcthread;
  try
  {
    // Input parameters
    const HTuple        &cbhv_ImageList = hcppthread->GetInputCtrlParamTuple(0);
    const HTuple        &cbhv_LabelList = hcppthread->GetInputCtrlParamTuple(1);
    const HTuple        &cbhv_AnomalyList = hcppthread->GetInputCtrlParamTuple(2);
    const HTuple        &cbhv_AnomalyDirGiven = hcppthread->GetInputCtrlParamTuple(3);
    const HTuple        &cbhv_NumSamplesPerThread = hcppthread->GetInputCtrlParamTuple(4);
    const HTuple        &cbhv_UniqueIndex = hcppthread->GetInputCtrlParamTuple(5);

    // Output parameters
    HTuple        cbhv_SamplesOutput;
    HTuple        cbhv_Exception;

    // Call create_dl_dataset_anomaly_samples
    create_dl_dataset_anomaly_samples(cbhv_ImageList, cbhv_LabelList, cbhv_AnomalyList, 
        cbhv_AnomalyDirGiven, cbhv_NumSamplesPerThread, cbhv_UniqueIndex, &cbhv_SamplesOutput, 
        &cbhv_Exception);

    // Store output parameters in thread object
    hcppthread->StoreOutputCtrlParamTuple(0,cbhv_SamplesOutput);
    hcppthread->StoreOutputCtrlParamTuple(1,cbhv_Exception);

    // Reduce reference counter of thread object
    hcppthread->Exit();
    delete hcppthread;

  }
  catch (HException& exc)
  {
    // No exceptions may be raised from stub in parallel case,
    // so we need to store this information prior to cleanup
    bool is_direct_call = hcppthread->IsDirectCall();
    // Attempt to clean up in error case, too
    hcppthread->Exit();
    delete hcppthread;
    // Propagate exception if called directly
    if (is_direct_call)
      throw exc;
  }
  return NULL;
}

// Parallel execution wrapper for create_dl_dataset_classification_samples(...) 
static void* _hcppthread_create_dl_dataset_classification_samples(void *hcthread)
{
  // +++ define thread context for this procedure
  HDevThread*  hcppthread = (HDevThread*) hcthread;
  try
  {
    // Input parameters
    const HTuple        &cbhv_ImageFiles = hcppthread->GetInputCtrlParamTuple(0);
    const HTuple        &cbhv_LabelIndices = hcppthread->GetInputCtrlParamTuple(1);
    const HTuple        &cbhv_RawImageFolder = hcppthread->GetInputCtrlParamTuple(2);
    const HTuple        &cbhv_ImageDir = hcppthread->GetInputCtrlParamTuple(3);
    const HTuple        &cbhv_NumSamplesPerThread = hcppthread->GetInputCtrlParamTuple(4);
    const HTuple        &cbhv_UniqueIndex = hcppthread->GetInputCtrlParamTuple(5);

    // Output parameters
    HTuple        cbhv_SamplesOutput;

    // Call create_dl_dataset_classification_samples
    create_dl_dataset_classification_samples(cbhv_ImageFiles, cbhv_LabelIndices, 
        cbhv_RawImageFolder, cbhv_ImageDir, cbhv_NumSamplesPerThread, cbhv_UniqueIndex, 
        &cbhv_SamplesOutput);

    // Store output parameters in thread object
    hcppthread->StoreOutputCtrlParamTuple(0,cbhv_SamplesOutput);

    // Reduce reference counter of thread object
    hcppthread->Exit();
    delete hcppthread;

  }
  catch (HException& exc)
  {
    // No exceptions may be raised from stub in parallel case,
    // so we need to store this information prior to cleanup
    bool is_direct_call = hcppthread->IsDirectCall();
    // Attempt to clean up in error case, too
    hcppthread->Exit();
    delete hcppthread;
    // Propagate exception if called directly
    if (is_direct_call)
      throw exc;
  }
  return NULL;
}

// Parallel execution wrapper for get_dl_dataset_from_coco_annotation_image_id(...) 
static void* _hcppthread_get_dl_dataset_from_coco_annotation_image_id(void *hcthread)
{
  // +++ define thread context for this procedure
  HDevThread*  hcppthread = (HDevThread*) hcthread;
  try
  {
    // Input parameters
    const HTuple        &cbhv_AnnotationList = hcppthread->GetInputCtrlParamTuple(0);
    const HTuple        &cbhv_AnnotationKeys = hcppthread->GetInputCtrlParamTuple(1);
    const HTuple        &cbhv_NumKeysPerThread = hcppthread->GetInputCtrlParamTuple(2);
    const HTuple        &cbhv_UniqueIndex = hcppthread->GetInputCtrlParamTuple(3);

    // Output parameters
    HTuple        cbhv_AnnotImageIDsOutput;
    HTuple        cbhv_Exception;

    // Call get_dl_dataset_from_coco_annotation_image_id
    get_dl_dataset_from_coco_annotation_image_id(cbhv_AnnotationList, cbhv_AnnotationKeys, 
        cbhv_NumKeysPerThread, cbhv_UniqueIndex, &cbhv_AnnotImageIDsOutput, &cbhv_Exception);

    // Store output parameters in thread object
    hcppthread->StoreOutputCtrlParamTuple(0,cbhv_AnnotImageIDsOutput);
    hcppthread->StoreOutputCtrlParamTuple(1,cbhv_Exception);

    // Reduce reference counter of thread object
    hcppthread->Exit();
    delete hcppthread;

  }
  catch (HException& exc)
  {
    // No exceptions may be raised from stub in parallel case,
    // so we need to store this information prior to cleanup
    bool is_direct_call = hcppthread->IsDirectCall();
    // Attempt to clean up in error case, too
    hcppthread->Exit();
    delete hcppthread;
    // Propagate exception if called directly
    if (is_direct_call)
      throw exc;
  }
  return NULL;
}

// Parallel execution wrapper for create_dl_dataset_from_coco_samples(...) 
static void* _hcppthread_create_dl_dataset_from_coco_samples(void *hcthread)
{
  // +++ define thread context for this procedure
  HDevThread*  hcppthread = (HDevThread*) hcthread;
  try
  {
    // Input parameters
    const HTuple        &cbhv_ImageList = hcppthread->GetInputCtrlParamTuple(0);
    const HTuple        &cbhv_ImageKeys = hcppthread->GetInputCtrlParamTuple(1);
    const HTuple        &cbhv_ImageDir = hcppthread->GetInputCtrlParamTuple(2);
    const HTuple        &cbhv_AnnotationList = hcppthread->GetInputCtrlParamTuple(3);
    const HTuple        &cbhv_AnnotationKeys = hcppthread->GetInputCtrlParamTuple(4);
    const HTuple        &cbhv_AnnotImageIDs = hcppthread->GetInputCtrlParamTuple(5);
    const HTuple        &cbhv_Purpose = hcppthread->GetInputCtrlParamTuple(6);
    const HTuple        &cbhv_ReadOnlyNonCrowd = hcppthread->GetInputCtrlParamTuple(7);
    const HTuple        &cbhv_ReadRawAnnotations = hcppthread->GetInputCtrlParamTuple(8);
    const HTuple        &cbhv_ReadMasks = hcppthread->GetInputCtrlParamTuple(9);
    const HTuple        &cbhv_NumSamplesPerThread = hcppthread->GetInputCtrlParamTuple(10);
    const HTuple        &cbhv_UniqueIndex = hcppthread->GetInputCtrlParamTuple(11);

    // Output parameters
    HTuple        cbhv_DLSamplesOutput;
    HTuple        cbhv_Exception;

    // Call create_dl_dataset_from_coco_samples
    create_dl_dataset_from_coco_samples(cbhv_ImageList, cbhv_ImageKeys, cbhv_ImageDir, 
        cbhv_AnnotationList, cbhv_AnnotationKeys, cbhv_AnnotImageIDs, cbhv_Purpose, 
        cbhv_ReadOnlyNonCrowd, cbhv_ReadRawAnnotations, cbhv_ReadMasks, cbhv_NumSamplesPerThread, 
        cbhv_UniqueIndex, &cbhv_DLSamplesOutput, &cbhv_Exception);

    // Store output parameters in thread object
    hcppthread->StoreOutputCtrlParamTuple(0,cbhv_DLSamplesOutput);
    hcppthread->StoreOutputCtrlParamTuple(1,cbhv_Exception);

    // Reduce reference counter of thread object
    hcppthread->Exit();
    delete hcppthread;

  }
  catch (HException& exc)
  {
    // No exceptions may be raised from stub in parallel case,
    // so we need to store this information prior to cleanup
    bool is_direct_call = hcppthread->IsDirectCall();
    // Attempt to clean up in error case, too
    hcppthread->Exit();
    delete hcppthread;
    // Propagate exception if called directly
    if (is_direct_call)
      throw exc;
  }
  return NULL;
}

// Parallel execution wrapper for create_dl_dataset_segmentation_samples(...) 
static void* _hcppthread_create_dl_dataset_segmentation_samples(void *hcthread)
{
  // +++ define thread context for this procedure
  HDevThread*  hcppthread = (HDevThread*) hcthread;
  try
  {
    // Input parameters
    const HTuple        &cbhv_ImageList = hcppthread->GetInputCtrlParamTuple(0);
    const HTuple        &cbhv_SegmentationList = hcppthread->GetInputCtrlParamTuple(1);
    const HTuple        &cbhv_NumSamplesPerThread = hcppthread->GetInputCtrlParamTuple(2);
    const HTuple        &cbhv_UniqueIndex = hcppthread->GetInputCtrlParamTuple(3);

    // Output parameters
    HTuple        cbhv_SamplesOutput;

    // Call create_dl_dataset_segmentation_samples
    create_dl_dataset_segmentation_samples(cbhv_ImageList, cbhv_SegmentationList, 
        cbhv_NumSamplesPerThread, cbhv_UniqueIndex, &cbhv_SamplesOutput);

    // Store output parameters in thread object
    hcppthread->StoreOutputCtrlParamTuple(0,cbhv_SamplesOutput);

    // Reduce reference counter of thread object
    hcppthread->Exit();
    delete hcppthread;

  }
  catch (HException& exc)
  {
    // No exceptions may be raised from stub in parallel case,
    // so we need to store this information prior to cleanup
    bool is_direct_call = hcppthread->IsDirectCall();
    // Attempt to clean up in error case, too
    hcppthread->Exit();
    delete hcppthread;
    // Propagate exception if called directly
    if (is_direct_call)
      throw exc;
  }
  return NULL;
}

}


