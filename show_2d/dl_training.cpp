///////////////////////////////////////////////////////////////////////////////
// File generated by HDevelop for HALCON/C++ Version 23.05.0.0
// Non-ASCII strings in this file are encoded in local-8-bit encoding (cp936).
// Ensure that the interface encoding is set to locale encoding by calling
// SetHcppInterfaceStringEncodingIsUtf8(false) at the beginning of the program.
// 
// Please note that non-ASCII characters in string constants are exported
// as octal codes in order to guarantee that the strings are correctly
// created on all systems, independent on any compiler settings.
// 
// Source files with different encoding should not be mixed in one project.
///////////////////////////////////////////////////////////////////////////////

#include "HalconCpp.h"
#include "HDevThread.h"



using namespace HalconCpp;

// Procedure declarations 
// Chapter: Deep Learning / Model
// Short Description: Perform data augmentation on the given samples. 
extern void augment_dl_samples (HTuple hv_DLSampleBatch, HTuple hv_GenParam);
// Chapter: Deep Learning / Model
// Short Description: Visualize for a given number of samples the raw image, ground truth annotation, and inferred results. 
extern void dev_display_dl_data_tiled (HTuple hv_DLDataset, HTuple hv_DLModelHandle, 
    HTuple hv_NumSamples, HTuple hv_Split, HTuple hv_GenParam, HTuple hv_WindowHandle, 
    HTuple *hv_WindowHandleOut);
// Chapter: System / Operating System
// Short Description: Estimate the remaining time for a task given the current progress. 
extern void estimate_progress (HTuple hv_SecondsStart, HTuple hv_ProgressMin, HTuple hv_ProgressCurrent, 
    HTuple hv_ProgressMax, HTuple *hv_SecondsElapsed, HTuple *hv_SecondsRemaining, 
    HTuple *hv_ProgressPercent, HTuple *hv_ProgressPerSecond);
// Chapter: Deep Learning / Model
// Short Description: Evaluate the model given by DLModelHandle on the selected samples of DLDataset. 
extern void evaluate_dl_model (HTuple hv_DLDataset, HTuple hv_DLModelHandle, HTuple hv_SampleSelectMethod, 
    HTuple hv_SampleSelectValues, HTuple hv_GenParam, HTuple *hv_EvaluationResult, 
    HTuple *hv_EvalParams);
// Chapter: Deep Learning / Model
// Short Description: Evaluate the model given by DLModelHandle on the selected samples of DLDataset. 
extern void evaluate_dl_model (HTuple hv_DLDataset, HTuple hv_DLModelHandle, HTuple hv_SampleSelectMethod, 
    HTuple hv_SampleSelectValues, HTuple hv_GenParam, HTuple *hv_EvaluationResult, 
    HTuple *hv_EvalParams);
// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set. 
extern void find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, 
    HTuple hv_Mode, HTuple *hv_SampleIndices);
// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set. 
extern void find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, 
    HTuple hv_Mode, HTuple *hv_SampleIndices);
// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set. 
extern void find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, 
    HTuple hv_Mode, HTuple *hv_SampleIndices);
// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set. 
extern void find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, 
    HTuple hv_Mode, HTuple *hv_SampleIndices);
// Chapter: XLD / Creation
// Short Description: Create an arrow shaped XLD contour. 
extern void gen_arrow_contour_xld (HObject *ho_Arrow, HTuple hv_Row1, HTuple hv_Column1, 
    HTuple hv_Row2, HTuple hv_Column2, HTuple hv_HeadLength, HTuple hv_HeadWidth);
// Chapter: XLD / Creation
// Short Description: Create an arrow shaped XLD contour. 
extern void gen_arrow_contour_xld (HObject *ho_Arrow, HTuple hv_Row1, HTuple hv_Column1, 
    HTuple hv_Row2, HTuple hv_Column2, HTuple hv_HeadLength, HTuple hv_HeadWidth);
// Chapter: Deep Learning / Model
// Short Description: Return the intended optimization method based on given evaluation key(s). 
extern void get_dl_evaluation_optimization_method (HTuple hv_EvaluationKeys, HTuple *hv_OptimizationMethod);
// Chapter: Deep Learning / Model
// Short Description: Return the intended optimization method based on given evaluation key(s). 
extern void get_dl_evaluation_optimization_method (HTuple hv_EvaluationKeys, HTuple *hv_OptimizationMethod);
// Chapter: Deep Learning / Model
// Short Description: Read the dictionaries DLSamples from files. 
extern void read_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Model
// Short Description: Read the dictionaries DLSamples from files. 
extern void read_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Model
// Short Description: Read the dictionaries DLSamples from files. 
extern void read_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Model
// Short Description: Read the dictionaries DLSamples from files. 
extern void read_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple *hv_DLSampleBatch);
// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
extern void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, 
    HTuple hv_Bold, HTuple hv_Slant);
// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
extern void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, 
    HTuple hv_Bold, HTuple hv_Slant);
// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
extern void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, 
    HTuple hv_Bold, HTuple hv_Slant);
// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
extern void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, 
    HTuple hv_Bold, HTuple hv_Slant);
// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
extern void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, 
    HTuple hv_Bold, HTuple hv_Slant);
// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
extern void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, 
    HTuple hv_Bold, HTuple hv_Slant);
// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
extern void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, 
    HTuple hv_Bold, HTuple hv_Slant);
// Chapter: System / Operating System
// Short Description: Create a formatted string of a time span. 
extern void timespan_string (HTuple hv_TotalSeconds, HTuple hv_Format, HTuple *hv_TimeString);
// Chapter: System / Operating System
// Short Description: Create a formatted string of a time span. 
extern void timespan_string (HTuple hv_TotalSeconds, HTuple hv_Format, HTuple *hv_TimeString);
// Chapter: System / Operating System
// Short Description: Create a formatted string of a time span. 
extern void timespan_string (HTuple hv_TotalSeconds, HTuple hv_Format, HTuple *hv_TimeString);
// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
extern void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled);
// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
extern void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled);
// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
extern void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Calculate quantiles of pixel anomaly scores. 
void calculate_dl_anomaly_quantiles (HTuple hv_DLModelHandle, HTuple hv_LayerName, 
    HTuple hv_DLSamples, HTuple hv_Ps, HTuple *hv_Quantiles);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Calculate the channel-wise mean and standard deviation of a DL model layer. 
void calculate_dl_model_layer_mean_stddev (HTuple hv_DLModelHandle, HTuple hv_LayerName, 
    HTuple hv_DLSamples, HTuple *hv_Mean, HTuple *hv_StdDev);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Check if scores of a Global Context Anomaly Detection model have been normalized 
void check_dl_gc_anomaly_scores_normalization (HTuple hv_DLModelHandle, HTuple hv_GenParam);
// Chapter: Deep Learning / Model
void check_train_dl_model_params (HTuple hv_DLDataset, HTuple hv_DLModelHandle, HTuple hv_NumTrainSamples, 
    HTuple hv_StartEpoch, HTuple hv_TrainParam);
// Chapter: Deep Learning / Model
// Short Description: Collect the information required for displaying the training progress update. 
void collect_train_dl_model_info (HTuple hv_DLModelHandle, HTuple hv_TrainResults, 
    HTuple hv_EvaluationInfos, HTuple hv_EvaluationComparisonKeys, HTuple hv_EvaluationOptimizationMethod, 
    HTuple hv_Iteration, HTuple hv_NumIterations, HTuple hv_NumIterationsPerEpoch, 
    HTuple hv_NumSamplesMeanLoss, HTuple *hv_TrainInfo);
// Chapter: Deep Learning / Model
// Short Description: Create a training parameter dictionary which is used in train_dl_model. 
void create_dl_train_param (HTuple hv_DLModelHandle, HTuple hv_NumEpochs, HTuple hv_EvaluationIntervalEpochs, 
    HTuple hv_EnableDisplay, HTuple hv_RandomSeed, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple *hv_TrainParam);
// Chapter: Deep Learning / Model
// Short Description: Plot the training progress out of the dictionary containing the final training summary. 
void dev_display_dl_model_train_info (HTuple hv_FinalTrainingInfo, HTuple hv_GenParam);
// Chapter: Deep Learning / Model
// Short Description: Initialize the visualization of the training progress. This includes setting default values for visualization parameters. 
void dev_display_init_train_dl_model (HTuple hv_DLModelHandle, HTuple hv_TrainParam, 
    HTuple *hv_DisplayData);
// Chapter: Deep Learning / Model
// Short Description: Display a legend according to the generic parameters. 
void dev_display_tiled_legend (HTuple hv_WindowImages, HTuple hv_GenParam);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Display information about the training of an anomaly detection model. 
void dev_display_train_info_anomaly_detection (HTuple hv_TrainParam, HTuple *hv_WindowHandleInfo);
// Chapter: Deep Learning / Model
// Short Description: Update the various texts and plots during training. 
void dev_display_update_train_dl_model (HTuple hv_TrainParam, HTuple hv_DisplayData, 
    HTuple hv_TrainInfo, HTuple hv_Epochs, HTuple hv_Loss, HTuple hv_LearningRate, 
    HTuple hv_EvalEpochs, HTuple hv_EvalValues, HTuple hv_EvalValuesTrain);
// Chapter: Deep Learning / Model
// Short Description: Get a parameter value from GenParamValue with the name RequestedGenParamName. 
void get_genparam_single_value (HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_RequestedGenParamName, HTuple *hv_FoundGenParamValue);
// Chapter: Deep Learning / Model
// Short Description: Initialize change strategies data. 
void init_train_dl_model_change_strategies (HTuple hv_TrainParam, HTuple *hv_ChangeStrategyData);
// Chapter: Deep Learning / Model
// Short Description: Initialize the dictionary setting for serialization strategies. 
void init_train_dl_model_serialization_strategies (HTuple hv_TrainParam, HTuple *hv_SerializationData);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Normalize the output features of the Global Context Anomaly Detection model before training. 
void normalize_dl_gc_anomaly_features (HTuple hv_DLDataset, HTuple hv_DLModelHandle, 
    HTuple hv_GenParam);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Normalize the anomaly scores on the validation set. 
void normalize_dl_gc_anomaly_scores (HTuple hv_DLDataset, HTuple hv_DLModelHandle, 
    HTuple hv_GenParam);
// Chapter: Graphics / Output
// Short Description: Plot tuples representing functions or curves in a coordinate system. 
void plot_tuple_no_window_handling (HTuple hv_WindowHandle, HTuple hv_XValues, HTuple hv_YValues, 
    HTuple hv_XLabel, HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue);
// Chapter: Tuple / Conversion
// Short Description: Print a tuple of values to a string. 
void pretty_print_tuple (HTuple hv_Tuple, HTuple *hv_TupleStr);
// Chapter: Deep Learning / Model
// Short Description: Reduce the evaluation result to a single value. 
void reduce_dl_evaluation_result (HTuple hv_EvaluationResult, HTuple hv_EvaluationComparisonKeys, 
    HTuple *hv_Value, HTuple *hv_ValidEvaluationKeys);
// Chapter: Deep Learning / Model
// Short Description: Restore serialized DL train information to resume the training. 
void restore_dl_train_info_for_resuming (HTuple hv_StartEpoch, HTuple hv_SerializationData, 
    HTuple hv_TrainParam, HTuple hv_DisplayData, HTuple *hv_EvaluationInfos, HTuple *hv_TrainInfos, 
    HTuple *hv_DisplayEvaluationEpochs, HTuple *hv_DisplayValidationEvaluationValues, 
    HTuple *hv_DisplayTrainEvaluationValues, HTuple *hv_DisplayLossEpochs, HTuple *hv_DisplayLoss, 
    HTuple *hv_DisplayLearningRates, HTuple *hv_TrainResultsRestored, HTuple *hv_StartEpochNumber);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Scale and shift a DL model layer. 
void scale_and_shift_dl_model_layer (HTuple hv_DLModelHandle, HTuple hv_LayerName, 
    HTuple hv_Scale, HTuple hv_Shift);
// Chapter: Deep Learning / Model
// Short Description: Serialize a DLModelHandle with current meta information. 
void serialize_train_dl_model_intermediate (HTuple hv_DLModelHandle, HTuple hv_Epoch, 
    HTuple hv_EvaluationValueReduced, HTuple hv_Strategy, HTuple hv_TrainInfos, HTuple hv_EvaluationInfos, 
    HTuple *hv_FilenameModel, HTuple *hv_FilenameMetaData);
// Chapter: Deep Learning / Model
// Short Description: Set the model parameters based on preprocessing parameters. 
void set_dl_model_param_based_on_preprocessing (HTuple hv_DLModelHandle, HTuple hv_DLPreprocessParam, 
    HTuple hv_ClassIDs);
// Chapter: Deep Learning / Model
// Short Description: Train a deep-learning-based model on a dataset. 
void train_dl_model (HTuple hv_DLDataset, HTuple hv_DLModelHandle, HTuple hv_TrainParam, 
    HTuple hv_StartEpoch, HTuple *hv_TrainResults, HTuple *hv_TrainInfos, HTuple *hv_EvaluationInfos);
// Chapter: Deep Learning / Model
// Short Description: Update model parameters according to the change strategies. 
void update_train_dl_model_change_strategies (HTuple hv_DLModelHandle, HTuple hv_ChangeStrategyData, 
    HTuple hv_Epoch);
// Chapter: Deep Learning / Model
// Short Description: Serialize the model if a strategy applies to the current training status. 
void update_train_dl_model_serialization (HTuple hv_TrainParam, HTuple hv_SerializationData, 
    HTuple hv_Iteration, HTuple hv_NumIterations, HTuple hv_Epoch, HTuple hv_EvaluationResult, 
    HTuple hv_EvaluationOptimizationMethod, HTuple hv_DLModelHandle, HTuple hv_TrainInfos, 
    HTuple hv_EvaluationInfos);

// Procedures 
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Calculate quantiles of pixel anomaly scores. 
void calculate_dl_anomaly_quantiles (HTuple hv_DLModelHandle, HTuple hv_LayerName, 
    HTuple hv_DLSamples, HTuple hv_Ps, HTuple *hv_Quantiles)
{

  // Local iconic variables
  HObject  ho_LayerOutput;

  // Local control variables
  HTuple  hv_Shape, hv_N, hv_C, hv_H, hv_W, hv_PixelScores;
  HTuple  hv_NumIterations, hv_Index, hv_FirstSampleIdx, hv_LastSampleIdx;
  HTuple  hv_DLSamplesBatch, hv_DLResultBatch, hv_IndexSamples;
  HTuple  hv_Iteration, hv_SampleDict, hv_Rows, hv_Columns;
  HTuple  hv_LayerOutputValues, hv_SliceStart, hv_SliceEnd;
  HTuple  hv_IndexP;

  //This procedure calculates quantiles of unnormalized pixel anomaly
  //scores returned by a given GC-AD model.
  //
  //The layer output has the shape N x C x H x W, where
  //- N is the batch size,
  //- C is number of channels, and
  //- H and W are the height and width, respectively.
  //
  GetDlModelLayerParam(hv_DLModelHandle, hv_LayerName, "shape", &hv_Shape);
  hv_N = ((const HTuple&)hv_Shape)[3];
  hv_C = ((const HTuple&)hv_Shape)[2];
  if (0 != (int(hv_C!=1)))
  {
    throw HException("Only layers with a single output channel are supported.");
  }
  hv_H = ((const HTuple&)hv_Shape)[1];
  hv_W = ((const HTuple&)hv_Shape)[0];
  hv_PixelScores = HTuple(((hv_DLSamples.TupleLength())*hv_H)*hv_W,0.0);
  hv_NumIterations = ((hv_DLSamples.TupleLength())/(hv_N.TupleReal())).TupleCeil();
  {
  HTuple end_val18 = hv_NumIterations-1;
  HTuple step_val18 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val18, step_val18); hv_Index += step_val18)
  {
    hv_FirstSampleIdx = hv_Index*hv_N;
    hv_LastSampleIdx = (((hv_Index+1)*hv_N)-1).TupleMin2((hv_DLSamples.TupleLength())-1);
    hv_DLSamplesBatch = hv_DLSamples.TupleSelectRange(hv_FirstSampleIdx,hv_LastSampleIdx);
    ApplyDlModel(hv_DLModelHandle, hv_DLSamplesBatch, hv_LayerName, &hv_DLResultBatch);
    //
    {
    HTuple end_val24 = (hv_DLResultBatch.TupleLength())-1;
    HTuple step_val24 = 1;
    for (hv_IndexSamples=0; hv_IndexSamples.Continue(end_val24, step_val24); hv_IndexSamples += step_val24)
    {
      hv_Iteration = (hv_Index*hv_N)+hv_IndexSamples;
      //
      hv_SampleDict = HTuple(hv_DLResultBatch[hv_IndexSamples]);
      ho_LayerOutput = hv_SampleDict.TupleGetDictObject(hv_LayerName);
      //
      GetRegionPoints(ho_LayerOutput, &hv_Rows, &hv_Columns);
      GetGrayval(ho_LayerOutput, hv_Rows, hv_Columns, &hv_LayerOutputValues);
      hv_SliceStart = (hv_Iteration*hv_H)*hv_W;
      hv_SliceEnd = (hv_SliceStart+(hv_H*hv_W))-1;
      hv_PixelScores[HTuple::TupleGenSequence(hv_SliceStart,hv_SliceEnd,1)] = hv_LayerOutputValues;
    }
    }
  }
  }
  hv_PixelScores = hv_PixelScores.TupleSort();
  //
  (*hv_Quantiles) = HTuple(hv_Ps.TupleLength(),0.0);
  {
  HTuple end_val40 = (hv_Ps.TupleLength())-1;
  HTuple step_val40 = 1;
  for (hv_IndexP=0; hv_IndexP.Continue(end_val40, step_val40); hv_IndexP += step_val40)
  {
    (*hv_Quantiles)[hv_IndexP] = HTuple(hv_PixelScores[(HTuple(hv_Ps[hv_IndexP])*((hv_PixelScores.TupleLength())-1)).TupleRound()]);
  }
  }
  //
  return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Calculate the channel-wise mean and standard deviation of a DL model layer. 
void calculate_dl_model_layer_mean_stddev (HTuple hv_DLModelHandle, HTuple hv_LayerName, 
    HTuple hv_DLSamples, HTuple *hv_Mean, HTuple *hv_StdDev)
{

  // Local iconic variables
  HObject  ho_LayerOutput, ho_SquaredLayerOutput;
  HObject  ho_MeanOfFeatureMaps, ho_MeanOfSquaredFeatureMaps;
  HObject  ho_UpdateScaled, ho_MeanOfFeatureMap, ho_MeanOfSquaredFeatureMap;

  // Local control variables
  HTuple  hv_Shape, hv_N, hv_C, hv_NumIterations;
  HTuple  hv_Index, hv_FirstSampleIdx, hv_LastSampleIdx, hv_DLSamplesBatch;
  HTuple  hv_DLResultBatch, hv_IndexSamples, hv_Iteration;
  HTuple  hv_SampleDict, hv_Var, hv_IndexC, hv_FeatureMapMean;
  HTuple  hv__, hv_FeatureMapSquaredMean;

  //Calculate the running mean and standard deviation of a
  //DL model layer. The layer output has the shape
  //N x C x H x W, where
  //- N is the batch size,
  //- C is number of channels, and
  //- H and W are the height and width, respectively.
  //
  GetDlModelLayerParam(hv_DLModelHandle, hv_LayerName, "shape", &hv_Shape);
  hv_N = ((const HTuple&)hv_Shape)[3];
  hv_C = ((const HTuple&)hv_Shape)[2];
  //Compute the average of the layer output and its square
  //over all samples.
  hv_NumIterations = ((hv_DLSamples.TupleLength())/(hv_N.TupleReal())).TupleCeil();
  {
  HTuple end_val13 = hv_NumIterations-1;
  HTuple step_val13 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val13, step_val13); hv_Index += step_val13)
  {
    hv_FirstSampleIdx = hv_Index*hv_N;
    hv_LastSampleIdx = (((hv_Index+1)*hv_N)-1).TupleMin2((hv_DLSamples.TupleLength())-1);
    hv_DLSamplesBatch = hv_DLSamples.TupleSelectRange(hv_FirstSampleIdx,hv_LastSampleIdx);
    ApplyDlModel(hv_DLModelHandle, hv_DLSamplesBatch, hv_LayerName, &hv_DLResultBatch);
    //
    {
    HTuple end_val19 = (hv_DLResultBatch.TupleLength())-1;
    HTuple step_val19 = 1;
    for (hv_IndexSamples=0; hv_IndexSamples.Continue(end_val19, step_val19); hv_IndexSamples += step_val19)
    {
      hv_Iteration = (hv_Index*hv_N)+hv_IndexSamples;
      //
      hv_SampleDict = HTuple(hv_DLResultBatch[hv_IndexSamples]);
      ho_LayerOutput = hv_SampleDict.TupleGetDictObject(hv_LayerName);
      MultImage(ho_LayerOutput, ho_LayerOutput, &ho_SquaredLayerOutput, 1, 0);
      //
      if (0 != (int(hv_Iteration==0)))
      {
        ScaleImage(ho_LayerOutput, &ho_MeanOfFeatureMaps, 1.0/(hv_DLSamples.TupleLength()), 
            0);
        ScaleImage(ho_SquaredLayerOutput, &ho_MeanOfSquaredFeatureMaps, 1.0/(hv_DLSamples.TupleLength()), 
            0);
      }
      else
      {
        ScaleImage(ho_LayerOutput, &ho_UpdateScaled, 1.0/(hv_DLSamples.TupleLength()), 
            0);
        AddImage(ho_MeanOfFeatureMaps, ho_UpdateScaled, &ho_MeanOfFeatureMaps, 1, 
            0);
        //
        ScaleImage(ho_SquaredLayerOutput, &ho_UpdateScaled, 1.0/(hv_DLSamples.TupleLength()), 
            0);
        AddImage(ho_MeanOfSquaredFeatureMaps, ho_UpdateScaled, &ho_MeanOfSquaredFeatureMaps, 
            1, 0);
      }
    }
    }
  }
  }
  //
  (*hv_Mean) = HTuple(hv_C,0.0);
  hv_Var = HTuple(hv_C,0.0);
  //
  {
  HTuple end_val42 = hv_C-1;
  HTuple step_val42 = 1;
  for (hv_IndexC=0; hv_IndexC.Continue(end_val42, step_val42); hv_IndexC += step_val42)
  {
    //Compute Var[X] as E[X^2] - (E[X])^2.
    AccessChannel(ho_MeanOfFeatureMaps, &ho_MeanOfFeatureMap, hv_IndexC+1);
    Intensity(ho_MeanOfFeatureMap, ho_MeanOfFeatureMap, &hv_FeatureMapMean, &hv__);
    AccessChannel(ho_MeanOfSquaredFeatureMaps, &ho_MeanOfSquaredFeatureMap, hv_IndexC+1);
    Intensity(ho_MeanOfSquaredFeatureMap, ho_MeanOfSquaredFeatureMap, &hv_FeatureMapSquaredMean, 
        &hv__);
    (*hv_Mean)[hv_IndexC] = hv_FeatureMapMean;
    hv_Var[hv_IndexC] = hv_FeatureMapSquaredMean-(hv_FeatureMapMean*hv_FeatureMapMean);
  }
  }
  (*hv_StdDev) = hv_Var.TupleSqrt();
  return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Check if scores of a Global Context Anomaly Detection model have been normalized 
void check_dl_gc_anomaly_scores_normalization (HTuple hv_DLModelHandle, HTuple hv_GenParam)
{

  // Local iconic variables
  HObject  ho_Weights, ho_Bias;

  // Local control variables
  HTuple  hv_DLModelIsConverted, hv_Networks, hv_HasLocalNetwork;
  HTuple  hv_HasGlobalNetwork, hv_NormalizationLayers, hv_Index;
  HTuple  hv_LayerName, hv_Rows, hv_Columns, hv_WeightsValues;
  HTuple  hv_HasDefaultWeights, hv_BiasValues, hv_HasDefaultBias;

  //This procedure checks if all gc anomaly scores have been normalized.
  //
  //Make sure GenParam is an empty tuple.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    throw HException("The parameter GenParam must be an empty tuple.");
  }
  //
  //For models using an AI accelerator interface for inference, the
  //weights of internal layers are no longer available. They are
  //removed to reduce the memory footprint of the model. Therefore
  //we have no means to check if the gc anomaly scores have been
  //normalized, and thus we assume that this is already the case.
  GetDlModelParam(hv_DLModelHandle, "precision_is_converted", &hv_DLModelIsConverted);
  if (0 != (int(hv_DLModelIsConverted==HTuple("true"))))
  {
    return;
  }
  //
  //Find networks to be normalized.
  GetDlModelParam(hv_DLModelHandle, "gc_anomaly_networks", &hv_Networks);
  hv_HasLocalNetwork = int((hv_Networks.TupleFind("local"))!=-1);
  hv_HasGlobalNetwork = int((hv_Networks.TupleFind("global"))!=-1);
  hv_NormalizationLayers = HTuple();
  if (0 != hv_HasLocalNetwork)
  {
    hv_NormalizationLayers = hv_NormalizationLayers.TupleConcat("local_normalization");
  }
  if (0 != hv_HasGlobalNetwork)
  {
    hv_NormalizationLayers = hv_NormalizationLayers.TupleConcat("global_normalization");
  }
  //
  {
  HTuple end_val29 = (hv_NormalizationLayers.TupleLength())-1;
  HTuple step_val29 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val29, step_val29); hv_Index += step_val29)
  {
    hv_LayerName = HTuple(hv_NormalizationLayers[hv_Index]);
    GetDlModelLayerWeights(&ho_Weights, hv_DLModelHandle, hv_LayerName, "weights");
    GetRegionPoints(ho_Weights, &hv_Rows, &hv_Columns);
    GetGrayval(ho_Weights, hv_Rows, hv_Columns, &hv_WeightsValues);
    //Calculate if weights are equal since some floating point arithmetic
    //is involved in their creation.
    hv_HasDefaultWeights = int(((((hv_WeightsValues.TupleLength())*hv_WeightsValues)-HTuple(hv_WeightsValues.TupleLength(),1.0)).TupleAbs())<((hv_WeightsValues.TupleLength())*1e-6));
    //
    GetDlModelLayerWeights(&ho_Bias, hv_DLModelHandle, hv_LayerName, "bias");
    GetRegionPoints(ho_Bias, &hv_Rows, &hv_Columns);
    GetGrayval(ho_Bias, hv_Rows, hv_Columns, &hv_BiasValues);
    //The bias is set directly, hence an equality check is sufficient.
    hv_HasDefaultBias = int(hv_BiasValues==HTuple(hv_BiasValues.TupleLength(),0.0));
    //
    if (0 != (hv_HasDefaultWeights.TupleAnd(hv_HasDefaultBias)))
    {
      throw HException(HTuple("For a model of type gc_anomaly_detection, the anomaly scores must be normalized first."));
    }
  }
  }
  //
  return;
}

// Chapter: Deep Learning / Model
void check_train_dl_model_params (HTuple hv_DLDataset, HTuple hv_DLModelHandle, HTuple hv_NumTrainSamples, 
    HTuple hv_StartEpoch, HTuple hv_TrainParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ModelType, hv_PreprocessedDataset;
  HTuple  hv_PreprocessParam, hv_Exception, hv_ImageRangeMin;
  HTuple  hv_ImageRangeMax, hv_DLPreprocessParams, hv_DLPreprocessImageRange;
  HTuple  hv_DLPreprocessNormalizationType, hv_TrainParamAnomaly;
  HTuple  hv_DomainRatio, hv_ErrorThreshold, hv_RegularizationNoise;
  HTuple  hv_NumEpochs, hv_BatchSizeDevice, hv_BatchSizeMultiplier;
  HTuple  hv_BatchSize, hv_ClassIdsExist, hv_ClassIDsModel;
  HTuple  hv_ClassIDsDataset, hv_Index, hv_IndexFind, hv_ClassIDsModelStr;
  HTuple  hv_ClassIDsDatasetStr, hv_DisplayParam, hv_DisplayKeys;
  HTuple  hv_KeyName, hv_KeyValue, hv_KeyExists, hv_EvaluationComparisonKeys;
  HTuple  hv_OptimizationMethod, hv_EvaluationComparisonKeysString;
  HTuple  hv_TrainParamCopy, hv__;

  //
  //This procedure checks the parameters used in the procedure train_dl_model for consistency.
  //
  GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
  //
  //Check the NumEpochs parameter.
  if (0 != (hv_StartEpoch.TupleIsNumber()))
  {
    if (0 != (int(hv_StartEpoch<0.0)))
    {
      throw HException("Error: StartEpoch < 0 is not allowed.");
    }
  }
  //
  //Check if the dataset is already preprocessed.
  hv_PreprocessedDataset = 0;
  try
  {
    GetDictTuple(hv_DLDataset, "preprocess_param", &hv_PreprocessParam);
    hv_PreprocessedDataset = 1;
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }
  if (0 != (hv_PreprocessedDataset.TupleNot()))
  {
    throw HException("Error: The supplied dataset needs to be preprocessed already. Use the standard procedure preprocess_dl_dataset.");
  }
  //
  //Check if the dataset preprocessing parameters fit
  //to the parameters required by the model.
  GetDlModelParam(hv_DLModelHandle, "image_range_min", &hv_ImageRangeMin);
  GetDlModelParam(hv_DLModelHandle, "image_range_max", &hv_ImageRangeMax);
  hv_DLPreprocessParams = hv_DLDataset.TupleGetDictTuple("preprocess_param");
  hv_DLPreprocessImageRange.Clear();
  hv_DLPreprocessImageRange.Append((hv_DLDataset.TupleGetDictTuple("preprocess_param")).TupleGetDictTuple("image_range_min"));
  hv_DLPreprocessImageRange.Append((hv_DLDataset.TupleGetDictTuple("preprocess_param")).TupleGetDictTuple("image_range_max"));
  hv_DLPreprocessNormalizationType = (hv_DLDataset.TupleGetDictTuple("preprocess_param")).TupleGetDictTuple("normalization_type");
  if (0 != (HTuple(int(hv_ModelType==HTuple("gc_anomaly_detection"))).TupleAnd(HTuple(int(hv_DLPreprocessImageRange!=(hv_ImageRangeMin.TupleConcat(hv_ImageRangeMax)))).TupleOr(int(hv_DLPreprocessNormalizationType!=HTuple("none"))))))
  {
    throw HException(HTuple("Error: For models of type 'gc_anomaly_detection' the dataset must be preprocessed with 'normalization_type' set to 'none' and default image range [-127, 128]."));
  }
  //
  //Check parameters for anomaly detection
  if (0 != (int(hv_ModelType==HTuple("anomaly_detection"))))
  {
    GetDictTuple(hv_TrainParam, "anomaly_param", &hv_TrainParamAnomaly);
    GetDictTuple(hv_TrainParamAnomaly, "domain_ratio", &hv_DomainRatio);
    if (0 != (HTuple(int(hv_DomainRatio<=0)).TupleOr(int(hv_DomainRatio>1.0))))
    {
      throw HException("Error: The anomaly detection parameter 'domain_ratio' must be between 0 and 1.");
    }
    GetDictTuple(hv_TrainParamAnomaly, "error_threshold", &hv_ErrorThreshold);
    if (0 != (HTuple(int(hv_ErrorThreshold<0)).TupleOr(int(hv_ErrorThreshold>1))))
    {
      throw HException("Error: The anomaly detection parameter 'error_threshold' must be between 0 and 1.");
    }
    GetDictTuple(hv_TrainParamAnomaly, "regularization_noise", &hv_RegularizationNoise);
    if (0 != (int(hv_RegularizationNoise<0)))
    {
      throw HException("Error: The anomaly detection parameter 'regularization_noise' must be greater than or equal to 0.");
    }
    return;
  }
  //
  //Check parameters for other models.
  //
  //Check the NumEpochs parameter.
  if (0 != (hv_StartEpoch.TupleIsNumber()))
  {
    GetDictTuple(hv_TrainParam, "num_epochs", &hv_NumEpochs);
    if (0 != (int(hv_StartEpoch>hv_NumEpochs)))
    {
      throw HException("Error: StartEpoch > NumEpochs is not allowed.");
    }
  }
  else
  {
    if (0 != (int(hv_StartEpoch!=HTuple("resume"))))
    {
      throw HException("Error: StartEpoch has to be a number or equal to 'resume'.");
    }
  }
  //
  //Check that the number of training samples is at least as big as the total batch size.
  GetDlModelParam(hv_DLModelHandle, "batch_size", &hv_BatchSizeDevice);
  GetDlModelParam(hv_DLModelHandle, "batch_size_multiplier", &hv_BatchSizeMultiplier);
  hv_BatchSize = hv_BatchSizeDevice*hv_BatchSizeMultiplier;
  if (0 != (int(hv_NumTrainSamples<hv_BatchSize)))
  {
    throw HException("Error: Number of training samples is smaller than the batch size.");
  }
  //
  //Check that all model class IDs are a part of the DLDataset class IDs.
  GetHandleParam(hv_PreprocessParam, "key_exists", "class_ids", &hv_ClassIdsExist);
  if (0 != hv_ClassIdsExist)
  {
    GetDlModelParam(hv_DLModelHandle, "class_ids", &hv_ClassIDsModel);
    GetDictTuple(hv_DLDataset, "class_ids", &hv_ClassIDsDataset);
    {
    HTuple end_val79 = (hv_ClassIDsModel.TupleLength())-1;
    HTuple step_val79 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val79, step_val79); hv_Index += step_val79)
    {
      TupleFindFirst(hv_ClassIDsDataset, HTuple(hv_ClassIDsModel[hv_Index]), &hv_IndexFind);
      if (0 != (int(hv_IndexFind<0)))
      {
        hv_ClassIDsModelStr = (" "+hv_ClassIDsModel).TupleSum();
        hv_ClassIDsDatasetStr = (" "+hv_ClassIDsDataset).TupleSum();
        throw HException((((("Error: A model class ID is not part of the DLDataset class IDs. DLModelHandle class ID: "+hv_ClassIDsModelStr)+". ")+"DLDataset class IDs: ")+hv_ClassIDsDatasetStr)+".");
      }
    }
    }
  }
  //
  //Check display parameters.
  GetDictTuple(hv_TrainParam, "display_param", &hv_DisplayParam);
  GetDictParam(hv_DisplayParam, "keys", HTuple(), &hv_DisplayKeys);
  {
  HTuple end_val92 = (hv_DisplayKeys.TupleLength())-1;
  HTuple step_val92 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val92, step_val92); hv_Index += step_val92)
  {
    hv_KeyName = HTuple(hv_DisplayKeys[hv_Index]);
    if (0 != (int(hv_KeyName==HTuple("enabled"))))
    {
      GetDictTuple(hv_DisplayParam, hv_KeyName, &hv_KeyValue);
      if (0 != (HTuple(int(hv_KeyValue!=1)).TupleAnd(int(hv_KeyValue!=0))))
      {
        throw HException("The value for 'enabled' is not supported.");
      }
    }
    else if (0 != (int(hv_KeyName==HTuple("change_plot_interval_seconds"))))
    {
      GetDictTuple(hv_DisplayParam, hv_KeyName, &hv_KeyValue);
      if (0 != (HTuple((hv_KeyValue.TupleIsInt()).TupleOr(hv_KeyValue.TupleIsReal())).TupleNot()))
      {
        throw HException("The value of 'change_plot_interval_seconds' has to be of type integer or real");
      }
    }
    else if (0 != (int(hv_KeyName==HTuple("num_images"))))
    {
      GetDictTuple(hv_DisplayParam, hv_KeyName, &hv_KeyValue);
      if (0 != (HTuple((hv_KeyValue.TupleIsInt()).TupleNot()).TupleOr(int(hv_KeyValue<1))))
      {
        throw HException("The value of 'num_images' has to be of type integer and larger or equal to one");
      }
    }
    else if (0 != (int(hv_KeyName==HTuple("selected_percentage_train_samples"))))
    {
      GetDictTuple(hv_DisplayParam, hv_KeyName, &hv_KeyValue);
      if (0 != (HTuple((hv_KeyValue.TupleIsInt()).TupleOr(hv_KeyValue.TupleIsReal())).TupleNot()))
      {
        throw HException("The value of 'selected_percentage_train_samples' has to be of type integer or real");
      }
      if (0 != (HTuple(int(hv_KeyValue<0)).TupleOr(int(hv_KeyValue>100))))
      {
        throw HException(HTuple("The value of 'selected_percentage_train_samples' has to be in [0,100]"));
      }
    }
    else if (0 != (int(hv_KeyName==HTuple("update_images_interval_epochs"))))
    {
      GetDictTuple(hv_DisplayParam, hv_KeyName, &hv_KeyValue);
      if (0 != (HTuple((hv_KeyValue.TupleIsInt()).TupleOr(hv_KeyValue.TupleIsReal())).TupleNot()))
      {
        throw HException("The value of 'update_images_interval_epochs' has to be of type integer or real");
      }
      if (0 != (int(hv_KeyValue<=0)))
      {
        throw HException("The value of 'update_images_interval_epochs' has to be larger than zero");
      }
    }
    else if (0 != (int(hv_KeyName==HTuple("x_axis_label"))))
    {
      GetDictTuple(hv_DisplayParam, hv_KeyName, &hv_KeyValue);
      if (0 != (HTuple(int(hv_KeyValue!=HTuple("epochs"))).TupleAnd(int(hv_KeyValue!=HTuple("iterations")))))
      {
        throw HException("The value for 'x_axis_label' is not supported.");
      }
    }
    else if (0 != (HTuple(HTuple(int(hv_KeyName==HTuple("status_model_params"))).TupleOr(int(hv_KeyName==HTuple("tiled_param")))).TupleOr(int(hv_KeyName==HTuple("randomize_images")))))
    {
      //No check for these advanced settings.
      //No check for randomize_images for backward compatibility.
      continue;
    }
    else
    {
      throw HException(("The provided key "+hv_KeyName)+" for 'display' is invalid.");
    }
  }
  }
  //
  //Check evaluation related train parameters.
  GetDictParam(hv_TrainParam, "key_exists", "evaluation_comparison_keys", &hv_KeyExists);
  if (0 != hv_KeyExists)
  {
    GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
    //Check optimization method based on provided evaluation comparison keys.
    get_dl_evaluation_optimization_method(hv_EvaluationComparisonKeys, &hv_OptimizationMethod);
    if (0 != (int(hv_OptimizationMethod==HTuple("mixed"))))
    {
      hv_EvaluationComparisonKeysString = (hv_EvaluationComparisonKeys+" ").TupleSum();
      throw HException(HTuple("Comparison keys invalid. No useful combination of values possible that are compared differently (\"<\", \">\"). EvaluationComparisonKeys: ")+hv_EvaluationComparisonKeysString);
    }
  }
  //
  //Initialize change and serialization strategies in order to test for valid values.
  CopyDict(hv_TrainParam, HTuple(), HTuple(), &hv_TrainParamCopy);
  init_train_dl_model_change_strategies(hv_TrainParamCopy, &hv__);
  init_train_dl_model_serialization_strategies(hv_TrainParamCopy, &hv__);
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Collect the information required for displaying the training progress update. 
void collect_train_dl_model_info (HTuple hv_DLModelHandle, HTuple hv_TrainResults, 
    HTuple hv_EvaluationInfos, HTuple hv_EvaluationComparisonKeys, HTuple hv_EvaluationOptimizationMethod, 
    HTuple hv_Iteration, HTuple hv_NumIterations, HTuple hv_NumIterationsPerEpoch, 
    HTuple hv_NumSamplesMeanLoss, HTuple *hv_TrainInfo)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_EpochReal, hv_NumEpochs, hv_TrainResultsStored;
  HTuple  hv_Exception, hv_PossibleParamNames, hv_ModelParams;
  HTuple  hv_Index, hv_ParamName, hv_DeviceHandles, hv_DeviceLength;
  HTuple  hv_DeviceTypes, hv_DeviceNames, hv_DeviceIndex;
  HTuple  hv_DeviceType, hv_DeviceName, hv_GenParamValue;
  HTuple  hv_LossSamplesTrainResults, hv_Indices, hv_TrainResultsUsed;
  HTuple  hv_BatchSizeDevice, hv_BatchSizeMultiplier, hv_BatchSize;
  HTuple  hv_NumIterationsMean, hv_LossParam, hv_LossValues;
  HTuple  hv_TrainResult, hv_LossValue, hv_LossMean, hv_BestEvaluationInfo;
  HTuple  hv_BestEvaluationInfoTrain, hv_BestEvaluationValue;
  HTuple  hv_BestEvaluationValueTrain, hv_BestEvaluationKeys;
  HTuple  hv_BestEvaluationKeysTrain, hv_EvaluationInfo, hv_ValidationEvaluationResult;
  HTuple  hv_TrainEvaluationResult, hv_Value, hv_ValidEvaluationKeys;
  HTuple  hv_ValueTrain, hv_ValidEvaluationKeysTrain, hv_BestEvaluationData;

  //
  //This procedure computes training information for the given iteration.
  //
  CreateDict(&(*hv_TrainInfo));
  //
  //General iteration and epoch status.
  hv_EpochReal = (hv_Iteration+1)/(hv_NumIterationsPerEpoch.TupleReal());
  //Important note:
  //Inside of this procedure, we compute iterations like that:
  //*  IterationTmp := int(round(EpochReal * (NumIterationsPerEpoch))-1)
  //If a caller of this procedure supplies a value we should use:
  //*  IterationTmp := int(floor(EpochReal * NumIterationsPerEpoch))
  //
  hv_NumEpochs = hv_NumIterations/(hv_NumIterationsPerEpoch.TupleReal());
  //
  //Note, iterations depend on a specific batch size,
  //hence only epochs are expressive.
  SetDictTuple((*hv_TrainInfo), "epoch", hv_EpochReal);
  SetDictTuple((*hv_TrainInfo), "num_epochs", hv_NumEpochs);
  SetDictTuple((*hv_TrainInfo), "num_iterations_per_epoch", hv_NumIterationsPerEpoch);
  //
  try
  {
    hv_TrainResultsStored = HTuple(hv_TrainResults[(hv_TrainResults.TupleNotEqualElem(-1)).TupleFind(1)]);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_TrainResultsStored = HTuple();
  }
  //
  //Collect all model parameters.
  GetParamInfo("get_dl_model_param", "GenParamName", "value_list", &hv_PossibleParamNames);
  CreateDict(&hv_ModelParams);
  SetDictTuple((*hv_TrainInfo), "model_params", hv_ModelParams);
  {
  HTuple end_val31 = (hv_PossibleParamNames.TupleLength())-1;
  HTuple step_val31 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val31, step_val31); hv_Index += step_val31)
  {
    hv_ParamName = HTuple(hv_PossibleParamNames[hv_Index]);
    //Do not collect summary as it cannot change during training and consumes much space.
    if (0 != (int(hv_ParamName==HTuple("summary"))))
    {
      continue;
    }
    //
    try
    {
      if (0 != (int(hv_ParamName==HTuple("device"))))
      {
        //The device handle cannot be serialized. Therefore we get the
        //information via keys and serialize them.
        GetDlModelParam(hv_DLModelHandle, hv_ParamName, &hv_DeviceHandles);
        TupleLength(hv_DeviceHandles, &hv_DeviceLength);
        hv_DeviceTypes = HTuple();
        hv_DeviceNames = HTuple();
        TupleGenConst(hv_DeviceLength, "", &hv_DeviceTypes);
        TupleGenConst(hv_DeviceLength, "", &hv_DeviceNames);
        {
        HTuple end_val48 = (hv_DeviceLength.TupleLength())-1;
        HTuple step_val48 = 1;
        for (hv_DeviceIndex=0; hv_DeviceIndex.Continue(end_val48, step_val48); hv_DeviceIndex += step_val48)
        {
          GetHandleTuple(HTuple(hv_DeviceHandles[hv_DeviceIndex]), "type", &hv_DeviceType);
          GetHandleTuple(HTuple(hv_DeviceHandles[hv_DeviceIndex]), "name", &hv_DeviceName);
          hv_DeviceTypes[hv_DeviceIndex] = hv_DeviceType;
          hv_DeviceNames[hv_DeviceIndex] = hv_DeviceName;
        }
        }
      }
      else
      {
        GetDlModelParam(hv_DLModelHandle, hv_ParamName, &hv_GenParamValue);
      }
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      continue;
    }
    //
    if (0 != (int(hv_ParamName==HTuple("device"))))
    {
      SetDictTuple(hv_ModelParams, "device_type", hv_DeviceTypes);
      SetDictTuple(hv_ModelParams, "device_name", hv_DeviceNames);
    }
    else
    {
      SetDictTuple(hv_ModelParams, hv_ParamName, hv_GenParamValue);
    }
  }
  }
  //
  //Calculate a mean loss value.
  SetDictTuple((*hv_TrainInfo), "mean_loss", HTuple());
  SetDictTuple((*hv_TrainInfo), "mean_loss_samples", 0);
  //
  hv_LossSamplesTrainResults = HTuple();
  TupleFind(hv_TrainResults.TupleNotEqualElem(-1), 1, &hv_Indices);
  if (0 != (int(hv_Indices!=-1)))
  {
    hv_TrainResultsUsed = HTuple(hv_TrainResults[hv_Indices]);
  }
  else
  {
    hv_TrainResultsUsed = HTuple();
  }
  if (0 != (int((hv_TrainResultsUsed.TupleLength())>0)))
  {
    GetDlModelParam(hv_DLModelHandle, "batch_size", &hv_BatchSizeDevice);
    GetDlModelParam(hv_DLModelHandle, "batch_size_multiplier", &hv_BatchSizeMultiplier);
    hv_BatchSize = hv_BatchSizeDevice*hv_BatchSizeMultiplier;
    hv_NumIterationsMean = ((hv_NumSamplesMeanLoss/(hv_BatchSize.TupleReal())).TupleCeil()).TupleInt();
    //
    if (0 != (int(hv_NumIterationsMean==0)))
    {
      hv_TrainResultsUsed = ((const HTuple&)hv_TrainResultsUsed)[(hv_TrainResultsUsed.TupleLength())-1];
    }
    else
    {
      hv_TrainResultsUsed = hv_TrainResultsUsed.TupleSelectRange(((hv_TrainResultsUsed.TupleLength())-hv_NumIterationsMean).TupleMax2(0),(hv_TrainResultsUsed.TupleLength())-1);
    }
    //
    hv_LossParam = "total_loss";
    TupleGenConst(hv_TrainResultsUsed.TupleLength(), -1, &hv_LossValues);
    {
    HTuple end_val94 = (hv_TrainResultsUsed.TupleLength())-1;
    HTuple step_val94 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val94, step_val94); hv_Index += step_val94)
    {
      hv_TrainResult = HTuple(hv_TrainResultsUsed[hv_Index]);
      GetDictTuple(hv_TrainResult, hv_LossParam, &hv_LossValue);
      hv_LossValues[hv_Index] = hv_LossValue;
    }
    }
    hv_LossMean = hv_LossValues.TupleMean();
    SetDictTuple((*hv_TrainInfo), "mean_loss", hv_LossMean);
    SetDictTuple((*hv_TrainInfo), "mean_loss_samples", hv_LossValues.TupleLength());
  }
  //
  //Collect the best evaluation information.
  hv_BestEvaluationInfo = HTuple();
  hv_BestEvaluationInfoTrain = HTuple();
  hv_BestEvaluationValue = HTuple();
  hv_BestEvaluationValueTrain = HTuple();
  hv_BestEvaluationKeys = HTuple();
  hv_BestEvaluationKeysTrain = HTuple();
  {
  HTuple end_val111 = (hv_EvaluationInfos.TupleLength())-1;
  HTuple step_val111 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val111, step_val111); hv_Index += step_val111)
  {
    hv_EvaluationInfo = HTuple(hv_EvaluationInfos[hv_Index]);
    //Ignore missing information
    if (0 != (int(hv_EvaluationInfo==-1)))
    {
      continue;
    }
    //
    GetDictTuple(hv_EvaluationInfo, "result", &hv_ValidationEvaluationResult);
    GetDictTuple(hv_EvaluationInfo, "result_train", &hv_TrainEvaluationResult);
    //
    //Reduce the result to a single (mean) value.
    reduce_dl_evaluation_result(hv_ValidationEvaluationResult, hv_EvaluationComparisonKeys, 
        &hv_Value, &hv_ValidEvaluationKeys);
    reduce_dl_evaluation_result(hv_TrainEvaluationResult, hv_EvaluationComparisonKeys, 
        &hv_ValueTrain, &hv_ValidEvaluationKeysTrain);
    //
    //Compare current evaluation result with the best one.
    if (0 != (int(hv_EvaluationOptimizationMethod==HTuple("min"))))
    {
      //Validation.
      if (0 != (HTuple(int((hv_BestEvaluationInfo.TupleLength())==0)).TupleOr(int(hv_Value<=hv_BestEvaluationValue))))
      {
        hv_BestEvaluationInfo = hv_EvaluationInfo;
        hv_BestEvaluationValue = hv_Value;
        hv_BestEvaluationKeys = hv_ValidEvaluationKeys;
      }
      //Training.
      if (0 != (HTuple(int((hv_BestEvaluationInfoTrain.TupleLength())==0)).TupleOr(int(hv_ValueTrain<=hv_BestEvaluationValueTrain))))
      {
        hv_BestEvaluationInfoTrain = hv_EvaluationInfo;
        hv_BestEvaluationValueTrain = hv_ValueTrain;
        hv_BestEvaluationKeysTrain = hv_ValidEvaluationKeysTrain;
      }
    }
    else if (0 != (int(hv_EvaluationOptimizationMethod==HTuple("max"))))
    {
      //Validation.
      if (0 != (HTuple(int((hv_BestEvaluationInfo.TupleLength())==0)).TupleOr(int(hv_Value>=hv_BestEvaluationValue))))
      {
        hv_BestEvaluationInfo = hv_EvaluationInfo;
        hv_BestEvaluationValue = hv_Value;
        hv_BestEvaluationKeys = hv_ValidEvaluationKeys;
      }
      //Training.
      if (0 != (HTuple(int((hv_BestEvaluationInfoTrain.TupleLength())==0)).TupleOr(int(hv_ValueTrain>=hv_BestEvaluationValueTrain))))
      {
        hv_BestEvaluationInfoTrain = hv_EvaluationInfo;
        hv_BestEvaluationValueTrain = hv_ValueTrain;
        hv_BestEvaluationKeysTrain = hv_ValidEvaluationKeysTrain;
      }
    }
    else
    {
      throw HException(("Invalid optimization method "+hv_EvaluationOptimizationMethod)+". Choose either \"min\" or \"max\".");
    }
  }
  }
  //
  //Store best evaluation information.
  if (0 != (int((hv_BestEvaluationInfo.TupleLength())>0)))
  {
    CreateDict(&hv_BestEvaluationData);
    SetDictTuple(hv_BestEvaluationData, "comparison_keys", hv_BestEvaluationKeys);
    SetDictTuple(hv_BestEvaluationData, "best_info", hv_BestEvaluationInfo);
    SetDictTuple(hv_BestEvaluationData, "best_value", hv_BestEvaluationValue);
    SetDictTuple(hv_BestEvaluationData, "comparison_keys_train", hv_BestEvaluationKeysTrain);
    SetDictTuple(hv_BestEvaluationData, "best_info_train", hv_BestEvaluationInfoTrain);
    SetDictTuple(hv_BestEvaluationData, "best_value_train", hv_BestEvaluationValueTrain);
    SetDictTuple((*hv_TrainInfo), "best_evaluation", hv_BestEvaluationData);
  }
  else
  {
    SetDictTuple((*hv_TrainInfo), "best_evaluation", HTuple());
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Create a training parameter dictionary which is used in train_dl_model. 
void create_dl_train_param (HTuple hv_DLModelHandle, HTuple hv_NumEpochs, HTuple hv_EvaluationIntervalEpochs, 
    HTuple hv_EnableDisplay, HTuple hv_RandomSeed, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple *hv_TrainParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ModelType, hv_AvailableGenParam, hv_IndexGenParam;
  HTuple  hv_IndexFind, hv_IsString, hv_TrainParamAnomaly;
  HTuple  hv_DomainRatioKeyExists, hv_ErrorThresholdKeyExists;
  HTuple  hv_RegularizationNoiseKeyExists, hv_DisplayParam;
  HTuple  hv_EvaluateBeforeTrain, hv_EvaluationParam, hv_AugmentationParam;
  HTuple  hv_ClassIDsNoOrientation, hv_Exception, hv_ChangeStrategies;
  HTuple  hv_Indices, hv_SerializationStrategy, hv_SerializationStrategies;
  HTuple  hv_Seconds, hv_SetDisplayParam, hv_EvaluationComparisonKeys;
  HTuple  hv_ConvertToMean, hv_Index, hv_FoundIndices;

  //
  //This procedure creates a dictionary with all needed training parameters,
  //as required by train_dl_model as input.
  //
  //Check length of input GenParam tuple.
  if (0 != (int((hv_GenParamName.TupleLength())!=(hv_GenParamValue.TupleLength()))))
  {
    throw HException("GenParamName and GenParamValue have to have the same length.");
  }
  //
  //Some default parameters depend on model type.
  GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
  if (0 != (HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(int(hv_ModelType!=HTuple("anomaly_detection"))).TupleAnd(int(hv_ModelType!=HTuple("classification")))).TupleAnd(int(hv_ModelType!=HTuple("detection")))).TupleAnd(int(hv_ModelType!=HTuple("gc_anomaly_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_recognition")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_detection")))).TupleAnd(int(hv_ModelType!=HTuple("segmentation")))).TupleAnd(int(hv_ModelType!=HTuple("3d_gripping_point_detection")))))
  {
    throw HException(("Current model type is not supported: \""+hv_ModelType)+"\"");
  }
  //
  //Check if the given GenParamName strings are available.
  if (0 != (int(hv_ModelType!=HTuple("anomaly_detection"))))
  {
    hv_AvailableGenParam.Clear();
    hv_AvailableGenParam[0] = "evaluate";
    hv_AvailableGenParam[1] = "augment";
    hv_AvailableGenParam[2] = "change";
    hv_AvailableGenParam[3] = "serialize";
    hv_AvailableGenParam[4] = "display";
    hv_AvailableGenParam[5] = "evaluate_before_train";
    if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
    {
      hv_AvailableGenParam.Clear();
      hv_AvailableGenParam[0] = "augment";
      hv_AvailableGenParam[1] = "change";
      hv_AvailableGenParam[2] = "serialize";
      hv_AvailableGenParam[3] = "display";
    }
  }
  else
  {
    hv_AvailableGenParam = "anomaly";
  }
  {
  HTuple end_val24 = (hv_GenParamName.TupleLength())-1;
  HTuple step_val24 = 1;
  for (hv_IndexGenParam=0; hv_IndexGenParam.Continue(end_val24, step_val24); hv_IndexGenParam += step_val24)
  {
    hv_IndexFind = hv_AvailableGenParam.TupleFind(HTuple(hv_GenParamName[hv_IndexGenParam]));
    if (0 != (int(hv_IndexFind==-1)))
    {
      throw HException(("The provided GenParamName "+HTuple(hv_GenParamName[hv_IndexGenParam]))+" is invalid.");
    }
  }
  }
  //
  //Check if display is enabled.
  TupleIsString(hv_EnableDisplay, &hv_IsString);
  if (0 != hv_IsString)
  {
    hv_EnableDisplay = int(hv_EnableDisplay==HTuple("true"));
  }
  else
  {
    hv_EnableDisplay = int(hv_EnableDisplay==1);
  }
  //
  //Initialize the dictionary holding the training parameters.
  CreateDict(&(*hv_TrainParam));
  //
  //** User supplied parameters: ***
  //
  //Set training parameters for anomaly detection models.
  if (0 != (int(hv_ModelType==HTuple("anomaly_detection"))))
  {
    get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "anomaly", &hv_TrainParamAnomaly);
    //Set default values in case no values are provided.
    if (0 != (int(hv_TrainParamAnomaly==HTuple())))
    {
      CreateDict(&hv_TrainParamAnomaly);
    }
    GetDictParam(hv_TrainParamAnomaly, "key_exists", "domain_ratio", &hv_DomainRatioKeyExists);
    if (0 != (hv_DomainRatioKeyExists.TupleNot()))
    {
      SetDictTuple(hv_TrainParamAnomaly, "domain_ratio", 0.1);
    }
    GetDictParam(hv_TrainParamAnomaly, "key_exists", "error_threshold", &hv_ErrorThresholdKeyExists);
    if (0 != (hv_ErrorThresholdKeyExists.TupleNot()))
    {
      SetDictTuple(hv_TrainParamAnomaly, "error_threshold", 0.001);
    }
    GetDictParam(hv_TrainParamAnomaly, "key_exists", "regularization_noise", &hv_RegularizationNoiseKeyExists);
    if (0 != (hv_RegularizationNoiseKeyExists.TupleNot()))
    {
      SetDictTuple(hv_TrainParamAnomaly, "regularization_noise", 0.0001);
    }
    //
    SetDictTuple(hv_TrainParamAnomaly, "max_num_epochs", hv_NumEpochs);
    SetDictTuple((*hv_TrainParam), "anomaly_param", hv_TrainParamAnomaly);
    CreateDict(&hv_DisplayParam);
    SetDictTuple(hv_DisplayParam, "enabled", hv_EnableDisplay);
    SetDictTuple((*hv_TrainParam), "display_param", hv_DisplayParam);
    return;
  }
  //
  //Set training parameters for all model types except 'anomaly_detection'.
  //
  //Number of epochs to train the model on the train split of the dataset.
  SetDictTuple((*hv_TrainParam), "num_epochs", hv_NumEpochs);
  //
  //Interval (in epochs) to evaluate the model on the validation split of the dataset.
  if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
  {
    //For models of type 'gc_anomaly_detection' no evaluation can be done.
    SetDictTuple((*hv_TrainParam), "evaluation_interval_epochs", 0);
  }
  else
  {
    SetDictTuple((*hv_TrainParam), "evaluation_interval_epochs", hv_EvaluationIntervalEpochs);
  }
  //
  //Transfer the parameter defining if an evaluation before training is to be done.
  get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "evaluate_before_train", 
      &hv_EvaluateBeforeTrain);
  SetDictTuple((*hv_TrainParam), "evaluate_before_train", hv_EvaluateBeforeTrain);
  //
  //Transfer evaluation parameters used in further steps.
  get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "evaluate", &hv_EvaluationParam);
  SetDictTuple((*hv_TrainParam), "evaluation_param", hv_EvaluationParam);
  //
  //Transfer augmentation parameters used in further steps.
  get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "augment", &hv_AugmentationParam);
  if (0 != (int(hv_ModelType==HTuple("detection"))))
  {
    //In addition, add class IDs without orientation, since these classes require
    //special treatment during the augmentation.
    try
    {
      GetDlModelParam(hv_DLModelHandle, "class_ids_no_orientation", &hv_ClassIDsNoOrientation);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      hv_ClassIDsNoOrientation = HTuple();
    }
    if (0 != (int((hv_ClassIDsNoOrientation.TupleLength())>0)))
    {
      if (0 != (int(hv_AugmentationParam==HTuple())))
      {
        CreateDict(&hv_AugmentationParam);
      }
      SetDictTuple(hv_AugmentationParam, "class_ids_no_orientation", hv_ClassIDsNoOrientation);
    }
  }
  SetDictTuple((*hv_TrainParam), "augmentation_param", hv_AugmentationParam);
  //
  //Change strategies for any parameters that need to be changed during training.
  get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "change", &hv_ChangeStrategies);
  SetDictTuple((*hv_TrainParam), "change_strategies", hv_ChangeStrategies);
  //
  //Serialization strategies used during training.
  hv_Indices = hv_GenParamName.TupleFind("serialize");
  if (0 != (HTuple(int((hv_Indices.TupleLength())==0)).TupleOr(int(hv_Indices==-1))))
  {
    //Set a default in case no value is provided.
    CreateDict(&hv_SerializationStrategy);
    SetDictTuple(hv_SerializationStrategy, "type", "best");
    SetDictTuple(hv_SerializationStrategy, "basename", "model_best");
    hv_SerializationStrategies = hv_SerializationStrategy;
  }
  else
  {
    //Set user provided values.
    hv_SerializationStrategies = HTuple(hv_GenParamValue[hv_Indices]);
  }
  SetDictTuple((*hv_TrainParam), "serialization_strategies", hv_SerializationStrategies);
  //
  //Get random seed or set a useful default value.
  if (0 != (int((hv_RandomSeed.TupleLength())>0)))
  {
    SetDictTuple((*hv_TrainParam), "seed_rand", hv_RandomSeed);
  }
  else
  {
    //If no random seed is given we will use system time as a default.
    CountSeconds(&hv_Seconds);
    hv_RandomSeed = hv_Seconds.TupleInt();
    SetDictTuple((*hv_TrainParam), "seed_rand", hv_RandomSeed);
  }
  //
  //** Display parameters: ***
  //
  //Create display parameter dictionary.
  get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "display", &hv_SetDisplayParam);
  if (0 != (int(hv_SetDisplayParam!=HTuple())))
  {
    hv_DisplayParam = hv_SetDisplayParam;
  }
  else
  {
    CreateDict(&hv_DisplayParam);
  }
  //
  SetDictTuple(hv_DisplayParam, "enabled", hv_EnableDisplay);
  SetDictTuple((*hv_TrainParam), "display_param", hv_DisplayParam);
  //
  //** Generic internal defaults: ***
  //
  //Default update interval (in seconds) of TrainInfo calculation and text/plot updates
  //in case display is enabled.
  SetDictTuple((*hv_TrainParam), "update_interval_seconds", 2);
  //
  //Evaluation comparison keys. Note, that internally only those keys apply which
  //are really available. No error is thrown as long as a valid key is given.
  //Hence, we use the major defaults here for classification ('top1_error'),
  //for detection ('mean_ap'), and for segmentation ('mean_iou') if no valid key
  //is given.
  hv_EvaluationComparisonKeys = HTuple();
  //
  try
  {
    GetDictTuple(hv_EvaluationParam, "measures", &hv_EvaluationComparisonKeys);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }
  //
  if (0 != (int(hv_EvaluationComparisonKeys==HTuple())))
  {
    if (0 != (int(hv_ModelType==HTuple("classification"))))
    {
      hv_EvaluationComparisonKeys = "top1_error";
    }
    else if (0 != (int(hv_ModelType==HTuple("detection"))))
    {
      hv_EvaluationComparisonKeys = "mean_ap";
    }
    else if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
    {
      hv_EvaluationComparisonKeys = "none";
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_detection"))))
    {
      hv_EvaluationComparisonKeys = "f_score";
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
    {
      hv_EvaluationComparisonKeys = "accuracy";
    }
    else if (0 != (int(hv_ModelType==HTuple("segmentation"))))
    {
      hv_EvaluationComparisonKeys = "mean_iou";
    }
    else if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
    {
      hv_EvaluationComparisonKeys = "mean_iou";
    }
  }

  if (0 != (int(hv_ModelType!=HTuple("ocr_detection"))))
  {
    //If the evaluation metric is 'precision', 'recall', 'f_score', or
    //'soap' we always take the mean value.
    hv_ConvertToMean.Clear();
    hv_ConvertToMean[0] = "precision";
    hv_ConvertToMean[1] = "recall";
    hv_ConvertToMean[2] = "f_score";
    hv_ConvertToMean[3] = "soap";
    {
    HTuple end_val193 = (hv_ConvertToMean.TupleLength())-1;
    HTuple step_val193 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val193, step_val193); hv_Index += step_val193)
    {
      hv_FoundIndices = (hv_EvaluationComparisonKeys.TupleEqualElem(HTuple(hv_ConvertToMean[hv_Index]))).TupleFind(1);
      if (0 != (int(hv_FoundIndices!=-1)))
      {
        hv_EvaluationComparisonKeys[hv_FoundIndices] = "mean_"+HTuple(hv_EvaluationComparisonKeys[hv_FoundIndices]);
        if (0 != (int(HTuple(hv_ConvertToMean[hv_Index])==HTuple("soap"))))
        {
          hv_EvaluationComparisonKeys[hv_FoundIndices] = HTuple(hv_EvaluationComparisonKeys[hv_FoundIndices])+"_tp";
        }
      }
    }
    }
  }
  //
  SetDictTuple((*hv_TrainParam), "evaluation_comparison_keys", hv_EvaluationComparisonKeys);
  //
  //Number of samples used to average the loss during training. Note, this is used for display
  //and information calculation only and does not have an effect on training the model.
  SetDictTuple((*hv_TrainParam), "num_samples_mean_loss", 1000);
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Plot the training progress out of the dictionary containing the final training summary. 
void dev_display_dl_model_train_info (HTuple hv_FinalTrainingInfo, HTuple hv_GenParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_PlotFunction, hv_PlotFunctionExists;
  HTuple  hv_TrainInfos, hv_EvaluationInfos, hv_Epochs, hv_Loss;
  HTuple  hv_LearningRates, hv_Index, hv_TrainInfo, hv_Epoch;
  HTuple  hv_MeanLoss, hv_ModelParams, hv_LearningRate, hv_TimeElapsedExists;
  HTuple  hv_TimeElapsed, hv_TimeElapsedString, hv_EvalEpochs;
  HTuple  hv_EvalValues, hv_EvalValuesTrain, hv_BestEvaluation;
  HTuple  hv_EvaluationComparisonKeys, hv_EvaluationComparisonKeysTrain;
  HTuple  hv_EvaluationInfo, hv_ValidationEvaluationResult;
  HTuple  hv_TrainEvaluationResult, hv_ValueValidation, hv__;
  HTuple  hv_ValueTrain, hv_TrainParam, hv_ModelType, hv_ChangeStrategy;
  HTuple  hv_DisplayParam, hv_DisplayIntervalSeconds, hv_DisplayData;

  //Plot the training progress out of the dictionary
  //containing the final training summary.
  //
  //Note, such a plot is only possible for models of the following types:
  //- classification
  //- detection
  //- segmentation
  //
  //Determine which function shall be plotted.
  //Currently supported:
  //- loss (plot shown as 1/2)
  //- evaluation values (plot shown as 2/2)
  //Set default plot type.
  hv_PlotFunction = "loss";
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    GetDictParam(hv_GenParam, "key_exists", "plot_function", &hv_PlotFunctionExists);
    if (0 != hv_PlotFunctionExists)
    {
      GetDictTuple(hv_GenParam, "plot_function", &hv_PlotFunction);
    }
  }
  //
  //Get the data written after training.
  GetDictTuple(hv_FinalTrainingInfo, "train_infos", &hv_TrainInfos);
  GetDictTuple(hv_FinalTrainingInfo, "evaluation_infos", &hv_EvaluationInfos);
  //Accumulate training data.
  //TrainInfos is a tuple of dictionaries,
  //collecting information about the current training step.
  hv_Epochs = HTuple();
  hv_Loss = HTuple();
  hv_LearningRates = HTuple();
  {
  HTuple end_val30 = (hv_TrainInfos.TupleLength())-1;
  HTuple step_val30 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val30, step_val30); hv_Index += step_val30)
  {
    hv_TrainInfo = HTuple(hv_TrainInfos[hv_Index]);
    GetDictTuple(hv_TrainInfo, "epoch", &hv_Epoch);
    hv_Epochs = hv_Epochs.TupleConcat(hv_Epoch);
    GetDictTuple(hv_TrainInfo, "mean_loss", &hv_MeanLoss);
    hv_Loss = hv_Loss.TupleConcat(hv_MeanLoss);
    GetDictTuple(hv_TrainInfo, "model_params", &hv_ModelParams);
    GetDictTuple(hv_ModelParams, "learning_rate", &hv_LearningRate);
    hv_LearningRates = hv_LearningRates.TupleConcat(hv_LearningRate);
  }
  }
  //Use last training information to display status information
  //and determine the time used.
  GetDictParam(hv_TrainInfo, "key_exists", "time_elapsed", &hv_TimeElapsedExists);
  if (0 != hv_TimeElapsedExists)
  {
    GetDictTuple(hv_TrainInfo, "time_elapsed", &hv_TimeElapsed);
    timespan_string(hv_TimeElapsed, "auto", &hv_TimeElapsedString);
  }
  else
  {
    //No value is known and so no value shall be plotted.
    hv_TimeElapsedString = "";
  }
  //
  //Accumulate evaluation data.
  hv_EvalEpochs = HTuple();
  hv_EvalValues = HTuple();
  hv_EvalValuesTrain = HTuple();
  //Evaluation values are only used in case of plot function 'evaluation'.
  if (0 != (int(hv_PlotFunction==HTuple("evaluation"))))
  {
    //During training, some data has been evaluated for comparison.
    //Get the name of the used measure.
    GetDictTuple(hv_TrainInfo, "best_evaluation", &hv_BestEvaluation);
    GetDictTuple(hv_BestEvaluation, "comparison_keys", &hv_EvaluationComparisonKeys);
    GetDictTuple(hv_BestEvaluation, "comparison_keys_train", &hv_EvaluationComparisonKeysTrain);
    {
    HTuple end_val62 = (hv_EvaluationInfos.TupleLength())-1;
    HTuple step_val62 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val62, step_val62); hv_Index += step_val62)
    {
      hv_EvaluationInfo = HTuple(hv_EvaluationInfos[hv_Index]);
      GetDictTuple(hv_EvaluationInfo, "epoch", &hv_Epoch);
      hv_EvalEpochs = hv_EvalEpochs.TupleConcat(hv_Epoch);
      GetDictTuple(hv_EvaluationInfo, "result", &hv_ValidationEvaluationResult);
      GetDictTuple(hv_EvaluationInfo, "result_train", &hv_TrainEvaluationResult);
      //For model comparison, the evaluation parameter/result are reduced to single value.
      reduce_dl_evaluation_result(hv_ValidationEvaluationResult, hv_EvaluationComparisonKeys, 
          &hv_ValueValidation, &hv__);
      reduce_dl_evaluation_result(hv_TrainEvaluationResult, hv_EvaluationComparisonKeysTrain, 
          &hv_ValueTrain, &hv__);
      hv_EvalValues = hv_EvalValues.TupleConcat(hv_ValueValidation);
      hv_EvalValuesTrain = hv_EvalValuesTrain.TupleConcat(hv_ValueTrain);
    }
    }
  }
  //
  //Set some parameters and initialize further display parameters.
  //They are nested in TrainParam.
  CreateDict(&hv_TrainParam);
  GetDictTuple(hv_TrainInfo, "model_params", &hv_ModelParams);
  GetDictTuple(hv_ModelParams, "type", &hv_ModelType);
  if (0 != (HTuple(HTuple(HTuple(int(hv_ModelType==HTuple("classification"))).TupleOr(int(hv_ModelType==HTuple("detection")))).TupleOr(int(hv_ModelType==HTuple("segmentation")))).TupleNot()))
  {
    throw HException(("This procedure is not supported for models of type "+hv_ModelType)+".");
  }
  SetDictTuple(hv_TrainParam, "type", hv_ModelType);
  //Add the used learning rate as change strategy.
  //Currently, the display procedure supports only one change strategy.
  //As a consequence, use directly the learning rate.
  CreateDict(&hv_ChangeStrategy);
  SetDictTuple(hv_ChangeStrategy, "model_param", "learning_rate");
  SetDictTuple(hv_ChangeStrategy, "initial_value", HTuple(hv_LearningRates[0]));
  SetDictTuple(hv_ChangeStrategy, "epochs", hv_Epochs);
  SetDictTuple(hv_ChangeStrategy, "values", hv_LearningRates);
  SetDictTuple(hv_TrainParam, "change_strategies", hv_ChangeStrategy);
  //Add part display parameters.
  CreateDict(&hv_DisplayParam);
  SetDictTuple(hv_DisplayParam, "enabled", 1);
  SetDictTuple(hv_TrainParam, "display_param", hv_DisplayParam);
  hv_DisplayIntervalSeconds = 10;
  SetDictTuple(hv_TrainParam, "update_interval_seconds", hv_DisplayIntervalSeconds);
  //Initialize display parameters as done for training.
  dev_display_init_train_dl_model(HTuple(), hv_TrainParam, &hv_DisplayData);
  //
  //Add the plot function and the elapsed time to the display parameters.
  SetDictTuple(hv_DisplayData, "plot_function", hv_PlotFunction);
  SetDictTuple(hv_DisplayData, "time_elapsed", hv_TimeElapsedString);
  //
  //Call the procedure displaying the training process.
  dev_display_update_train_dl_model(hv_TrainParam, hv_DisplayData, hv_TrainInfo, 
      hv_Epochs, hv_Loss, hv_LearningRates, hv_EvalEpochs, hv_EvalValues, hv_EvalValuesTrain);
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Initialize the visualization of the training progress. This includes setting default values for visualization parameters. 
void dev_display_init_train_dl_model (HTuple hv_DLModelHandle, HTuple hv_TrainParam, 
    HTuple *hv_DisplayData)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ModelType, hv_DisplayParam, hv_DisplayEnabled;
  HTuple  hv_UpdateImagesIntervalEpochs, hv_NumImagesPreview;
  HTuple  hv_ChangePlotIntervalSeconds, hv_SelectedPercentageTrainSamples;
  HTuple  hv_XAxisLabel, hv_DisplayParamNames, hv_DisplayDefaultValues;
  HTuple  hv_Index, hv_KeyExists, hv_DisplayIntervalSeconds;
  HTuple  hv_Time, hv_StatusModelParamNames, hv_WindowTextWidth;
  HTuple  hv_WindowTextHeight, hv_WindowImagesWidth, hv_WindowImagesHeight;
  HTuple  hv_WindowBGColor, hv_WindowHandleText, hv_WindowImagesRow;
  HTuple  hv_WindowImagesCol, hv_TiledParam, hv_Exception;
  HTuple  hv_TiledParamNames, hv_TiledDefaultValues;

  //
  //This procedure initializes the visualization of the training progress.
  //This includes setting default values for visualization parameters.
  //
  //Get the actual model type.
  if (0 != (int(hv_DLModelHandle!=HTuple())))
  {
    GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
  }
  else
  {
    GetDictTuple(hv_TrainParam, "type", &hv_ModelType);
  }
  //
  //Initialize display data.
  CreateDict(&(*hv_DisplayData));
  GetDictTuple(hv_TrainParam, "display_param", &hv_DisplayParam);
  SetDictTuple((*hv_DisplayData), "display_param", hv_DisplayParam);
  GetDictTuple(hv_DisplayParam, "enabled", &hv_DisplayEnabled);
  SetDictTuple((*hv_DisplayData), "enabled", hv_DisplayEnabled);
  //
  //Set default values if not set by the user.
  //
  //Default interval (in epochs) for the preview update
  //depending on the model type.
  if (0 != (int(hv_ModelType==HTuple("classification"))))
  {
    hv_UpdateImagesIntervalEpochs = 4;
  }
  else
  {
    hv_UpdateImagesIntervalEpochs = 0.5;
  }
  //
  //Default number of images to display in the images preview.
  if (0 != (int(hv_ModelType==HTuple("classification"))))
  {
    hv_NumImagesPreview = 6;
  }
  else if (0 != (int(hv_ModelType==HTuple("detection"))))
  {
    hv_NumImagesPreview = 2;
  }
  else if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
  {
    //No images are displayed in case of
    //model type 'gc_anomaly_detection'.
    hv_NumImagesPreview = 0;
  }
  else if (0 != (int(hv_ModelType==HTuple("ocr_detection"))))
  {
    hv_NumImagesPreview = 2;
  }
  else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
  {
    hv_NumImagesPreview = 12;
  }
  else if (0 != (int(hv_ModelType==HTuple("segmentation"))))
  {
    hv_NumImagesPreview = 4;
  }
  else if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
  {
    hv_NumImagesPreview = 4;
  }
  //
  //Default interval (in seconds) to switch between plots.
  hv_ChangePlotIntervalSeconds = 10;
  //
  //Default percentage of images that is used for evaluation on training set.
  //If set to zero no evaluation on training set is done.
  hv_SelectedPercentageTrainSamples = 0;
  //
  //Default x_axis_label: Show 'iterations' or 'epochs' as x-values in plots.
  hv_XAxisLabel = "epochs";
  //
  //Collect all display params and overwrite if user values are given.
  //Note, some parameters are also used for the evaluation.
  //Thus, write its value even for DisplayEnabled = false.
  hv_DisplayParamNames.Clear();
  hv_DisplayParamNames[0] = "change_plot_interval_seconds";
  hv_DisplayParamNames[1] = "num_images";
  hv_DisplayParamNames[2] = "selected_percentage_train_samples";
  hv_DisplayParamNames[3] = "update_images_interval_epochs";
  hv_DisplayParamNames[4] = "x_axis_label";
  hv_DisplayDefaultValues.Clear();
  hv_DisplayDefaultValues.Append(hv_ChangePlotIntervalSeconds);
  hv_DisplayDefaultValues.Append(hv_NumImagesPreview);
  hv_DisplayDefaultValues.Append(hv_SelectedPercentageTrainSamples);
  hv_DisplayDefaultValues.Append(hv_UpdateImagesIntervalEpochs);
  hv_DisplayDefaultValues.Append(hv_XAxisLabel);
  {
  HTuple end_val62 = (hv_DisplayParamNames.TupleLength())-1;
  HTuple step_val62 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val62, step_val62); hv_Index += step_val62)
  {
    GetDictParam(hv_DisplayParam, "key_exists", HTuple(hv_DisplayParamNames[hv_Index]), 
        &hv_KeyExists);
    if (0 != (hv_KeyExists.TupleNot()))
    {
      SetDictTuple(hv_DisplayParam, HTuple(hv_DisplayParamNames[hv_Index]), HTuple(hv_DisplayDefaultValues[hv_Index]));
    }
  }
  }
  //
  //Set last_update, which is needed to determine when updates are needed.
  GetDictTuple(hv_TrainParam, "update_interval_seconds", &hv_DisplayIntervalSeconds);
  CountSeconds(&hv_Time);
  SetDictTuple((*hv_DisplayData), "last_update", hv_Time-(hv_DisplayIntervalSeconds*2));
  //
  //Some entries in DisplayParam are also needed in case of disabled display.
  //They are all set yet.
  if (0 != (hv_DisplayEnabled.TupleNot()))
  {
    return;
  }
  //
  //Separate handling for parameters that are specified by tuples.
  //
  //These model parameters are displayed in the text window if available.
  hv_StatusModelParamNames.Clear();
  hv_StatusModelParamNames[0] = "learning_rate";
  hv_StatusModelParamNames[1] = "batch_size";
  hv_StatusModelParamNames[2] = "batch_size_multiplier";
  hv_StatusModelParamNames[3] = "momentum";
  hv_StatusModelParamNames[4] = "weight_prior";
  hv_StatusModelParamNames[5] = "image_dimensions";
  GetDictParam(hv_DisplayParam, "key_exists", "status_model_params", &hv_KeyExists);
  if (0 != (hv_KeyExists.TupleNot()))
  {
    SetDictTuple(hv_DisplayParam, "status_model_params", hv_StatusModelParamNames);
  }
  //
  //
  //Setup and open text window.
  hv_WindowTextWidth = 700;
  hv_WindowTextHeight = 750;
  hv_WindowImagesWidth = 1200-hv_WindowTextWidth;
  hv_WindowImagesHeight = hv_WindowTextHeight;
  hv_WindowBGColor = "light gray";
  //
  SetWindowAttr("background_color",hv_WindowBGColor);
  OpenWindow(0,0,hv_WindowTextWidth,hv_WindowTextHeight,0,"visible","",&hv_WindowHandleText);
  HDevWindowStack::Push(hv_WindowHandleText);
  set_display_font(hv_WindowHandleText, 16, "mono", "true", "false");
  SetDictTuple((*hv_DisplayData), "window_text", hv_WindowHandleText);
  SetDictTuple((*hv_DisplayData), "window_text_width", hv_WindowTextWidth);
  SetDictTuple((*hv_DisplayData), "window_text_height", hv_WindowTextHeight);
  //
  //Configure images window, which is opened later by another procedure.
  hv_WindowImagesRow = 0;
  hv_WindowImagesCol = hv_WindowTextWidth+10;
  SetDictTuple((*hv_DisplayData), "window_images", HTuple());
  //
  //Set user specified parameters used for the display of tiled images.
  try
  {
    GetDictTuple(hv_DisplayParam, "tiled_param", &hv_TiledParam);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    CreateDict(&hv_TiledParam);
    SetDictTuple(hv_DisplayParam, "tiled_param", hv_TiledParam);
  }
  //
  //Only set values if they are not already given.
  if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
  {
    hv_WindowImagesHeight = 500;
  }
  hv_TiledParamNames.Clear();
  hv_TiledParamNames[0] = "window_row";
  hv_TiledParamNames[1] = "window_col";
  hv_TiledParamNames[2] = "window_width";
  hv_TiledParamNames[3] = "window_height";
  hv_TiledDefaultValues.Clear();
  hv_TiledDefaultValues.Append(hv_WindowImagesRow);
  hv_TiledDefaultValues.Append(hv_WindowImagesCol);
  hv_TiledDefaultValues.Append(hv_WindowImagesWidth);
  hv_TiledDefaultValues.Append(hv_WindowImagesHeight);
  {
  HTuple end_val122 = (hv_TiledParamNames.TupleLength())-1;
  HTuple step_val122 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val122, step_val122); hv_Index += step_val122)
  {
    GetDictParam(hv_TiledParam, "key_exists", HTuple(hv_TiledParamNames[hv_Index]), 
        &hv_KeyExists);
    if (0 != (hv_KeyExists.TupleNot()))
    {
      SetDictTuple(hv_TiledParam, HTuple(hv_TiledParamNames[hv_Index]), HTuple(hv_TiledDefaultValues[hv_Index]));
    }
  }
  }
  //
  //Set specific display parameters for all available model types.
  if (0 != (int(hv_ModelType==HTuple("classification"))))
  {
    SetDictTuple(hv_TiledParam, "display_input", 0);
    SetDictTuple(hv_TiledParam, "display_ground_truth", 0);
    SetDictTuple(hv_TiledParam, "display_legend", 0);
  }
  else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
  {
    SetDictTuple(hv_TiledParam, "display_input", 0);
    SetDictTuple(hv_TiledParam, "display_ground_truth", 0);
    SetDictTuple(hv_TiledParam, "display_legend", 0);
  }
  //
  //
  //Start with loss plot since usually no evaluation is available in the beginning.
  SetDictTuple((*hv_DisplayData), "last_change_plot", hv_Time);
  SetDictTuple((*hv_DisplayData), "plot_eval", 0);
  HDevWindowStack::SetActive(hv_WindowHandleText);
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Display a legend according to the generic parameters. 
void dev_display_tiled_legend (HTuple hv_WindowImages, HTuple hv_GenParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_DisplayLegend, hv_Exception, hv_LegendText;
  HTuple  hv_Flag, hv_PosTexts, hv_Text;

  //
  //This procedure displays a legend of dev_display_dl_data_tiled
  //according to the generic parameters.
  //
  try
  {
    GetDictTuple(hv_GenParam, "display_legend", &hv_DisplayLegend);
    if (0 != (hv_DisplayLegend.TupleNot()))
    {
      return;
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }
  //
  hv_LegendText = HTuple();
  try
  {
    GetDictTuple(hv_GenParam, "display_input", &hv_Flag);
    if (0 != hv_Flag)
    {
      hv_LegendText = hv_LegendText.TupleConcat("input");
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_LegendText = hv_LegendText.TupleConcat("input");
  }
  try
  {
    GetDictTuple(hv_GenParam, "display_ground_truth", &hv_Flag);
    if (0 != hv_Flag)
    {
      hv_LegendText = hv_LegendText.TupleConcat("ground truth");
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_LegendText = hv_LegendText.TupleConcat("ground truth");
  }
  try
  {
    GetDictTuple(hv_GenParam, "display_result", &hv_Flag);
    if (0 != hv_Flag)
    {
      hv_LegendText = hv_LegendText.TupleConcat("result");
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_LegendText = hv_LegendText.TupleConcat("result");
  }
  if (0 != (int((hv_LegendText.TupleLength())==3)))
  {
    hv_PosTexts.Clear();
    hv_PosTexts[0] = "Top:    ";
    hv_PosTexts[1] = "Center: ";
    hv_PosTexts[2] = "Bottom: ";
  }
  else if (0 != (int((hv_LegendText.TupleLength())==2)))
  {
    hv_PosTexts.Clear();
    hv_PosTexts[0] = "Top:    ";
    hv_PosTexts[1] = "Bottom: ";
  }
  else
  {
    hv_PosTexts = "";
  }
  HDevWindowStack::SetActive(hv_WindowImages);
  hv_Text = hv_PosTexts+hv_LegendText;
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "right", "black", 
        HTuple(), HTuple());
  return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Display information about the training of an anomaly detection model. 
void dev_display_train_info_anomaly_detection (HTuple hv_TrainParam, HTuple *hv_WindowHandleInfo)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_DisplayParam, hv_DisplayEnabled, hv_WindowWidth;
  HTuple  hv_WindowHeight, hv_WindowBGColor, hv_TrainParamAnomaly;
  HTuple  hv_DomainRatio, hv_ErrorThreshold, hv_RegularizationNoise;
  HTuple  hv_MaxNumEpochs, hv_TrainInformationLeft, hv_TrainInformationRight;

  //
  //This procedure displays information about the training parameters of an anomaly detection model.
  //
  //Initialize display data.
  GetDictTuple(hv_TrainParam, "display_param", &hv_DisplayParam);
  GetDictTuple(hv_DisplayParam, "enabled", &hv_DisplayEnabled);
  //
  if (0 != (hv_DisplayEnabled.TupleNot()))
  {
    return;
  }
  //
  hv_WindowWidth = 500;
  hv_WindowHeight = 230;
  hv_WindowBGColor = "light gray";
  //
  //Open and setup text window.
  SetWindowAttr("background_color",hv_WindowBGColor);
  OpenWindow(0,0,hv_WindowWidth,hv_WindowHeight,0,"visible","",&(*hv_WindowHandleInfo));
  HDevWindowStack::Push((*hv_WindowHandleInfo));
  set_display_font((*hv_WindowHandleInfo), 16, "mono", "true", "false");
  HDevWindowStack::SetActive((*hv_WindowHandleInfo));
  //
  //Display information.
  GetDictTuple(hv_TrainParam, "anomaly_param", &hv_TrainParamAnomaly);
  GetDictTuple(hv_TrainParamAnomaly, "domain_ratio", &hv_DomainRatio);
  GetDictTuple(hv_TrainParamAnomaly, "error_threshold", &hv_ErrorThreshold);
  GetDictTuple(hv_TrainParamAnomaly, "regularization_noise", &hv_RegularizationNoise);
  GetDictTuple(hv_TrainParamAnomaly, "max_num_epochs", &hv_MaxNumEpochs);
  hv_TrainInformationLeft.Clear();
  hv_TrainInformationLeft[0] = "Training anomaly detection model.";
  hv_TrainInformationLeft[1] = "";
  hv_TrainInformationLeft[2] = "Max. number of epochs:";
  hv_TrainInformationLeft[3] = "Domain ratio:";
  hv_TrainInformationLeft[4] = "Error threshold:";
  hv_TrainInformationLeft[5] = "Regularization noise:";
  hv_TrainInformationLeft[6] = "";
  hv_TrainInformationLeft[7] = "This may take some time...";
  hv_TrainInformationRight.Clear();
  hv_TrainInformationRight[0] = "";
  hv_TrainInformationRight[1] = "";
  hv_TrainInformationRight.Append(hv_MaxNumEpochs);
  hv_TrainInformationRight.Append(hv_DomainRatio.TupleString(".4f"));
  hv_TrainInformationRight.Append(hv_ErrorThreshold.TupleString(".4f"));
  hv_TrainInformationRight.Append(hv_RegularizationNoise.TupleString(".4f"));
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_TrainInformationLeft, "window", "top", 
        "left", "black", "box", "false");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_TrainInformationRight, "window", "top", 
        "right", "black", "box", "false");
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Update the various texts and plots during training. 
void dev_display_update_train_dl_model (HTuple hv_TrainParam, HTuple hv_DisplayData, 
    HTuple hv_TrainInfo, HTuple hv_Epochs, HTuple hv_Loss, HTuple hv_LearningRate, 
    HTuple hv_EvalEpochs, HTuple hv_EvalValues, HTuple hv_EvalValuesTrain)
{

  // Local iconic variables
  HObject  ho_PlotBackground;

  // Local control variables
  HTuple  hv_DisplayEnabled, hv_DisplayParam, hv_WindowText;
  HTuple  hv_WindowHandle, hv_ChangePlotIntervalSeconds, hv_LastChange;
  HTuple  hv_Seconds, hv_PlotEval, hv_PlotFunctionExists;
  HTuple  hv_PlotFunction, hv_ModelType, hv_TextPlot, hv_PlotTrainEval;
  HTuple  hv_HeadlineText, hv_Indices, hv_Index, hv_PartRow1;
  HTuple  hv_PartColumn1, hv_PartRow2, hv_PartColumn2, hv__;
  HTuple  hv_Width, hv_Height, hv_ClipRegionValue, hv_PlotHeight;
  HTuple  hv_LegendRow, hv_LegendDistanceLeft, hv_LegendDistanceRight;
  HTuple  hv_PlotLearningRateStrategy, hv_RightMargin, hv_ChangeStrategies;
  HTuple  hv_Idx, hv_ChangeStrategy, hv_ChangeStrategyName;
  HTuple  hv_ChangeStrategiesValues, hv_ChangeStrategiesInitial;
  HTuple  hv_StrategyMin, hv_StrategyMax, hv_LogLRMin, hv_LogLRMax;
  HTuple  hv_LRScale, hv_LROffset, hv_LogLROffset, hv_StartYLearningRate;
  HTuple  hv_EndYLearningRate, hv_TicksYLearningRate, hv_LogYLearningRate;
  HTuple  hv_LRColor, hv_LRLineWidth, hv_LRTextLegend, hv_TopMarginPlots;
  HTuple  hv_NumIterationsPerEpoch, hv_Iterations, hv_NumEpochs;
  HTuple  hv_NumIterations, hv_CurrentIteration, hv_XAxisLabel;
  HTuple  hv_ValuesX, hv_TicksX, hv_EvalValuesX, hv_EvalTicksX;
  HTuple  hv_TitleX, hv_EvalIterations, hv_EvalValuesMin;
  HTuple  hv_EvalValuesMax, hv_TicksY, hv_StartY, hv_EndY;
  HTuple  hv_YAxisLabel, hv_BestEvaluationData, hv_BestEvaluationComparisonKeys;
  HTuple  hv_StringExtendsLegendRight, hv_Bullet, hv_Line;
  HTuple  hv_YAxisTitle, hv_Offset, hv_LogMin, hv_LogMax;
  HTuple  hv_Scale, hv_LogOffset, hv_LogY, hv_TextModelParams;
  HTuple  hv_ModelParams, hv_StatusModelParamsLeft, hv_StatusModelParamsRight;
  HTuple  hv_ParName, hv_Tuple, hv_Exception, hv_TupleStr;
  HTuple  hv_StatusEvaluationLeft, hv_StatusEvaluationRight;
  HTuple  hv_BestEvaluationValue, hv_BestEvaluationInfo, hv_BestEvaluationEpoch;
  HTuple  hv_BestTrainEvaluationValue, hv_BestTrainEvaluationInfo;
  HTuple  hv_BestTrainEvaluationEpoch, hv_BestEvaluationComparisonKeysStr;
  HTuple  hv_StatusTrainLeft, hv_StatusTrainRight, hv_EpochReal;
  HTuple  hv_MeanLoss, hv_MeanLossStr, hv_TimeElapsedExists;
  HTuple  hv_StartEpoch, hv_StartTime, hv_SecondsElapsed;
  HTuple  hv_SecondsRemaining, hv_ProgressPercent, hv_ProgressPerSecond;
  HTuple  hv_TimeElapsedString, hv_TimeRemainingString, hv_DeviceNameExists;
  HTuple  hv_DeviceName, hv_StatusLeft, hv_StatusRight, hv_MaxChars;
  HTuple  hv_Str, hv_IsString, hv_Length, hv_SubStr, hv_Row1;
  HTuple  hv_Column1, hv_Row2, hv_Column2, hv_WindowTextWidth;
  HTuple  hv_WindowTextHeight;

  //
  //This procedure updates the various texts and plots.
  //It uses precomputed information (TrainInfo, EvaluationInfos,...).
  //
  GetDictTuple(hv_DisplayData, "enabled", &hv_DisplayEnabled);
  if (0 != (hv_DisplayEnabled.TupleNot()))
  {
    return;
  }
  //
  GetDictTuple(hv_DisplayData, "display_param", &hv_DisplayParam);
  //
  GetDictTuple(hv_DisplayData, "window_text", &hv_WindowText);
  SetWindowParam(hv_WindowText, "flush", "false");
  //Only switch to window if the current window is not the text window (performance).
  if (HDevWindowStack::IsOpen())
    hv_WindowHandle = HDevWindowStack::GetActive();
  if (0 != (int(hv_WindowHandle!=hv_WindowText)))
  {
    HDevWindowStack::SetActive(hv_WindowText);
    hv_WindowHandle = hv_WindowText;
  }
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  //
  GetDictTuple(hv_DisplayParam, "change_plot_interval_seconds", &hv_ChangePlotIntervalSeconds);
  GetDictTuple(hv_DisplayData, "last_change_plot", &hv_LastChange);
  CountSeconds(&hv_Seconds);
  GetDictTuple(hv_DisplayData, "plot_eval", &hv_PlotEval);
  if (0 != (int((hv_Seconds-hv_LastChange)>=hv_ChangePlotIntervalSeconds)))
  {
    hv_PlotEval = HTuple(hv_PlotEval.TupleNot()).TupleAnd(int((hv_EvalEpochs.TupleLength())>=2));
    SetDictTuple(hv_DisplayData, "plot_eval", hv_PlotEval);
    SetDictTuple(hv_DisplayData, "last_change_plot", hv_Seconds);
  }
  //This procedure can also be called after a training.
  //In such a case the parameter plot_function can be set to determine,
  //which plot shall be displayed.
  GetDictParam(hv_DisplayData, "key_exists", "plot_function", &hv_PlotFunctionExists);
  if (0 != hv_PlotFunctionExists)
  {
    GetDictTuple(hv_DisplayData, "plot_function", &hv_PlotFunction);
    hv_PlotEval = hv_PlotEval.TupleOr(int(hv_PlotFunction==HTuple("evaluation")));
  }
  //
  hv_ModelType = (hv_TrainInfo.TupleGetDictTuple("model_params")).TupleGetDictTuple("type");
  if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
  {
    //For models of type 'gc_anomaly_detection'
    //no evaluation is shown.
    hv_TextPlot = "1/1";
  }
  else
  {
    if (0 != hv_PlotEval)
    {
      hv_TextPlot = "2/2";
    }
    else
    {
      hv_TextPlot = "1/2";
      hv_PlotTrainEval = 0;
    }
  }

  hv_HeadlineText = ("Showing plot "+hv_TextPlot)+":";
  //
  //Shall the training evaluation be plotted?
  hv_PlotTrainEval = 0;
  //
  //In case there are missing evaluation values (-1),
  //we just reuse the previous values.
  if (0 != (hv_EvalValuesTrain.TupleLength()))
  {
    hv_PlotTrainEval = int((hv_EvalValuesTrain.TupleMax())!=-1);
    if (0 != hv_PlotTrainEval)
    {
      TupleFind(hv_EvalValuesTrain, -1, &hv_Indices);
      if (0 != (HTuple(int(hv_Indices!=-1)).TupleAnd(int(hv_Indices!=HTuple()))))
      {
        {
        HTuple end_val65 = (hv_Indices.TupleLength())-1;
        HTuple step_val65 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val65, step_val65); hv_Index += step_val65)
        {
          if (0 != (int(HTuple(hv_Indices[hv_Index])==0)))
          {
            hv_EvalValuesTrain[0] = 0.0;
          }
          else
          {
            hv_EvalValuesTrain[HTuple(hv_Indices[hv_Index])] = HTuple(hv_EvalValuesTrain[HTuple(hv_Indices[hv_Index])-1]);
          }
        }
        }
      }
    }
  }
  //
  GetPart(hv_WindowText, &hv_PartRow1, &hv_PartColumn1, &hv_PartRow2, &hv_PartColumn2);
  GetWindowExtents(hv_WindowHandle, &hv__, &hv__, &hv_Width, &hv_Height);
  //Generate a background rectangle for the plot.
  //For a correct visualization of the rectangle, the region
  //may not be cut off.
  GetSystem("clip_region", &hv_ClipRegionValue);
  SetSystem("clip_region", "false");
  GenRectangle1(&ho_PlotBackground, 470, 9, hv_PartRow2-6, hv_PartColumn2-10);
  SetSystem("clip_region", hv_ClipRegionValue);
  //
  hv_PlotHeight = (((hv_PartRow2-30)-480)*hv_Height)/((hv_PartRow2-hv_PartRow1)+1);
  hv_LegendRow = 479;
  hv_LegendDistanceLeft = 65;
  hv_LegendDistanceRight = 85;
  //
  //Get change strategy parameters and check if a learning rate strategy exits
  hv_PlotLearningRateStrategy = 0;
  hv_RightMargin = 35;
  GetDictTuple(hv_TrainParam, "change_strategies", &hv_ChangeStrategies);
  if (0 != (int((hv_ChangeStrategies.TupleLength())>0)))
  {
    {
    HTuple end_val96 = (hv_ChangeStrategies.TupleLength())-1;
    HTuple step_val96 = 1;
    for (hv_Idx=0; hv_Idx.Continue(end_val96, step_val96); hv_Idx += step_val96)
    {
      hv_ChangeStrategy = HTuple(hv_ChangeStrategies[hv_Idx]);
      GetDictTuple(hv_ChangeStrategy, "model_param", &hv_ChangeStrategyName);
      if (0 != (int(hv_ChangeStrategyName==HTuple("learning_rate"))))
      {
        hv_PlotLearningRateStrategy = 1;
        GetDictTuple(hv_ChangeStrategy, "values", &hv_ChangeStrategiesValues);
        GetDictTuple(hv_ChangeStrategy, "initial_value", &hv_ChangeStrategiesInitial);
        //
        //Plot parameters for the learning rate
        hv_StrategyMin = hv_LearningRate.TupleMin();
        hv_StrategyMax = hv_LearningRate.TupleMax();
        hv_LogLRMin = (HTuple(1e-8).TupleMax2(hv_StrategyMin)).TupleLog10();
        hv_LogLRMax = (HTuple(1e-8).TupleMax2(hv_StrategyMax)).TupleLog10();
        //
        if (0 != (int(((hv_LogLRMax-hv_LogLRMin).TupleFabs())<1e-4)))
        {
          hv_LogLRMin = hv_LogLRMin-5e-5;
          hv_LogLRMax += 5e-5;
        }
        //
        hv_LRScale = (hv_LogLRMax-hv_LogLRMin)/hv_PlotHeight;
        hv_LROffset = 15;
        hv_LogLROffset = hv_LROffset*hv_LRScale;
        //
        hv_StartYLearningRate = HTuple(10).TuplePow(hv_LogLRMin-(1.0*hv_LogLROffset));
        hv_EndYLearningRate = HTuple(10).TuplePow(hv_LogLRMax+(1.0*hv_LogLROffset));
        hv_TicksYLearningRate = (hv_PlotHeight/5)*hv_LRScale;
        //
        hv_LogYLearningRate = "true";
        hv_RightMargin = 75;
      }
    }
    }
  }
  hv_LRColor = "#1332ffdd";
  hv_LRLineWidth = 2;
  hv_LRTextLegend = "'learning_rate'";
  //Space for legends
  hv_TopMarginPlots = 480+20;
  //
  //Determine current number of iterations.
  GetDictTuple(hv_TrainInfo, "num_iterations_per_epoch", &hv_NumIterationsPerEpoch);
  hv_Iterations = ((hv_Epochs*hv_NumIterationsPerEpoch).TupleCeil()).TupleInt();
  GetDictTuple(hv_TrainInfo, "num_epochs", &hv_NumEpochs);
  hv_NumIterations = ((hv_NumEpochs*hv_NumIterationsPerEpoch).TupleCeil()).TupleInt();
  hv_CurrentIteration = ((const HTuple&)hv_Iterations)[(hv_Iterations.TupleLength())-1];
  //
  //Determine x-axis values.
  GetDictTuple(hv_DisplayParam, "x_axis_label", &hv_XAxisLabel);
  if (0 != (int(hv_XAxisLabel==HTuple("epochs"))))
  {
    hv_ValuesX = hv_Epochs;
    hv_TicksX = HTuple(0.1).TupleMax2(((hv_Epochs.TupleMax())-(hv_Epochs.TupleMin()))*0.15);
    if (0 != (int(hv_EvalEpochs!=HTuple())))
    {
      hv_EvalValuesX = hv_EvalEpochs;
      hv_EvalTicksX = HTuple(0.1).TupleMax2(((hv_EvalEpochs.TupleMax())-(hv_EvalEpochs.TupleMin()))*0.15);
    }
    hv_TitleX = "Epochs";
  }
  else if (0 != (int(hv_XAxisLabel==HTuple("iterations"))))
  {
    hv_ValuesX = hv_Iterations;
    hv_TicksX = (HTuple(2).TupleMax2(((hv_Iterations.TupleMax())-(hv_Iterations.TupleMin()))*0.15)).TupleInt();
    if (0 != (int(hv_EvalEpochs!=HTuple())))
    {
      hv_EvalIterations = (hv_EvalEpochs*hv_NumIterationsPerEpoch).TupleCeil();
      hv_EvalValuesX = hv_EvalIterations;
      hv_EvalTicksX = (HTuple(2).TupleMax2(((hv_EvalIterations.TupleMax())-(hv_EvalIterations.TupleMin()))*0.15)).TupleInt();
    }
    hv_TitleX = "Iterations";
  }
  //
  //Determine y-axis values and plot the function as well as its texts.
  if (0 != hv_PlotEval)
  {
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),"white");
    if (HDevWindowStack::IsOpen())
      SetDraw(HDevWindowStack::GetActive(),"fill");
    if (HDevWindowStack::IsOpen())
      DispObj(ho_PlotBackground, HDevWindowStack::GetActive());
    hv_EvalValuesMin = (hv_EvalValues.TupleConcat(HTuple(0.0).TupleMax2(hv_EvalValuesTrain))).TupleMin();
    hv_EvalValuesMax = (hv_EvalValues.TupleConcat(hv_EvalValuesTrain)).TupleMax();
    if (0 != (int(((hv_EvalValuesMax-hv_EvalValuesMin).TupleAbs())<1e-3)))
    {
      hv_EvalValuesMin = hv_EvalValuesMin-5e-4;
      hv_EvalValuesMax += 5e-4;
    }
    hv_TicksY = (hv_EvalValuesMax-hv_EvalValuesMin)*0.1;
    hv_StartY = hv_EvalValuesMin-((hv_EvalValuesMax-hv_EvalValuesMin)*0.1);
    hv_EndY = hv_EvalValuesMax+((hv_EvalValuesMax-hv_EvalValuesMin)*0.1);
    //
    hv_YAxisLabel = "Evaluation value";
    GetDictTuple(hv_TrainInfo, "best_evaluation", &hv_BestEvaluationData);
    if (0 != (int((hv_BestEvaluationData.TupleLength())>0)))
    {
      GetDictTuple(hv_BestEvaluationData, "comparison_keys", &hv_BestEvaluationComparisonKeys);
      hv_YAxisLabel = "Evaluation value";
      if (0 != (int((hv_BestEvaluationComparisonKeys.TupleLength())>1)))
      {
        pretty_print_tuple(hv_BestEvaluationComparisonKeys, &hv_YAxisLabel);
        hv_YAxisLabel = ("mean("+hv_YAxisLabel)+")";
      }
      else
      {
        hv_YAxisLabel = hv_BestEvaluationComparisonKeys;
      }
    }
    //Use a smaller, non-bold font for the plot.
    set_display_font(hv_WindowText, 12, "mono", "false", "false");
    //Plot learning rate if the corresponding strategy exists.
    if (0 != hv_PlotLearningRateStrategy)
    {
      //
      //Display current values in appropriate colors.
      GetStringExtents(hv_WindowText, hv_LRTextLegend, &hv__, &hv__, &hv_StringExtendsLegendRight, 
          &hv__);
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_LRTextLegend, "image", hv_LegendRow, 
            (hv_Width-hv_StringExtendsLegendRight)-hv_LegendDistanceRight, hv_LRColor, 
            "box", "false");
      plot_tuple_no_window_handling(hv_WindowText, hv_ValuesX, hv_LearningRate, "", 
          "", hv_LRColor, ((((((((((((HTuple("log_y").Append("axes_color")).Append("start_y")).Append("end_y")).Append("ticks_y")).Append("margin_top")).Append("margin_bottom")).Append("margin_left")).Append("margin_right")).Append("line_width")).Append("axes_color")).Append("axis_location_y")).Append("format_y")), 
          ((((((((hv_LogYLearningRate.TupleConcat("black")).TupleConcat(hv_StartYLearningRate)).TupleConcat(hv_EndYLearningRate)).TupleConcat(hv_TicksYLearningRate)).TupleConcat(hv_TopMarginPlots)).TupleConcat((HTuple(30).Append(65)))).TupleConcat(hv_RightMargin)).TupleConcat(hv_LRLineWidth)).TupleConcat(((HTuple("#898b8f").Append("right")).Append(".1e"))));
    }
    //Plot validation evaluation values.
    plot_tuple_no_window_handling(hv_WindowText, hv_EvalValuesX, hv_EvalValues, hv_TitleX, 
        "", "#36a2eb", ((((((((((HTuple("axes_color").Append("ticks_x")).Append("ticks_y")).Append("start_y")).Append("end_y")).Append("margin_top")).Append("margin_bottom")).Append("margin_left")).Append("margin_right")).Append("line_width")).Append("axes_color")), 
        (((((((HTuple("black").TupleConcat(hv_EvalTicksX)).TupleConcat(hv_TicksY)).TupleConcat(hv_StartY)).TupleConcat(hv_EndY)).TupleConcat(hv_TopMarginPlots)).TupleConcat((HTuple(30).Append(65)))).TupleConcat(hv_RightMargin)).TupleConcat((HTuple(3).Append("#898b8f"))));
    //Plot train evaluation values.
    if (0 != hv_PlotTrainEval)
    {
      hv_Bullet = //''
      "\241\361";
      hv_Line = //'D'
      "\250D";
      hv_YAxisTitle = ((((("  '"+hv_YAxisLabel)+"' (")+hv_Line)+HTuple(" validation, "))+hv_Bullet)+"-- training)";
      plot_tuple_no_window_handling(hv_WindowText, hv_EvalValuesX, hv_EvalValuesTrain, 
          hv_TitleX, "", "#36a2eb", (((((((((((HTuple("style").Append("axes_color")).Append("ticks_x")).Append("ticks_y")).Append("start_y")).Append("end_y")).Append("margin_top")).Append("margin_bottom")).Append("margin_left")).Append("margin_right")).Append("line_width")).Append("axes_color")), 
          ((((((((HTuple(20).Append("black")).TupleConcat(hv_EvalTicksX)).TupleConcat(hv_TicksY)).TupleConcat(hv_StartY)).TupleConcat(hv_EndY)).TupleConcat(hv_TopMarginPlots)).TupleConcat((HTuple(30).Append(65)))).TupleConcat(hv_RightMargin)).TupleConcat((HTuple(3).Append("#898b8f"))));
      plot_tuple_no_window_handling(hv_WindowText, hv_EvalValuesX, hv_EvalValuesTrain, 
          hv_TitleX, "", "#36a2eb", (((((((((((HTuple("style").Append("axes_color")).Append("ticks_x")).Append("ticks_y")).Append("start_y")).Append("end_y")).Append("margin_top")).Append("margin_bottom")).Append("margin_left")).Append("margin_right")).Append("line_width")).Append("axes_color")), 
          ((((((((HTuple("circle").Append("black")).TupleConcat(hv_EvalTicksX)).TupleConcat(hv_TicksY)).TupleConcat(hv_StartY)).TupleConcat(hv_EndY)).TupleConcat(hv_TopMarginPlots)).TupleConcat((HTuple(30).Append(65)))).TupleConcat(hv_RightMargin)).TupleConcat((HTuple(3).Append("#898b8f"))));
    }
    else
    {
      hv_YAxisTitle = ("  '"+hv_YAxisLabel)+"'";
    }
    //Display title of y-axis.
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),hv_YAxisTitle, "image", hv_LegendRow, 
          hv_LegendDistanceLeft, "#36a2eb", "box", "false");
    //Reset font.
    set_display_font(hv_WindowText, 16, "mono", "true", "false");
  }
  else
  {
    if (0 != (int((hv_Epochs.TupleLength())>3)))
    {
      if (HDevWindowStack::IsOpen())
        SetColor(HDevWindowStack::GetActive(),"white");
      if (HDevWindowStack::IsOpen())
        SetDraw(HDevWindowStack::GetActive(),"fill");
      if (HDevWindowStack::IsOpen())
        DispObj(ho_PlotBackground, HDevWindowStack::GetActive());
      //
      //Set StartY and EndY, such that there is a margin on top and bottom to
      //avoid that the plot overlaps with the axis captions. (With respect to
      //the logarithmic plotting of the Loss function)
      //Set this offset in window coordinates:
      hv_Offset = 15;
      //Calculate min max values to determine the correct offset in log
      //coordinates.
      hv_LogMin = (HTuple(0.00001).TupleMax2(hv_Loss.TupleMin())).TupleLog10();
      hv_LogMax = (HTuple(0.00001).TupleMax2(hv_Loss.TupleMax())).TupleLog10();
      //
      if (0 != (int(((hv_LogMax-hv_LogMin).TupleFabs())<0.0001)))
      {
        hv_LogMin = hv_LogMin-0.00005;
        hv_LogMax += 0.00005;
      }
      //
      hv_Scale = (hv_LogMax-hv_LogMin)/hv_PlotHeight;
      hv_LogOffset = hv_Offset*hv_Scale;
      hv_StartY = HTuple(10).TuplePow(hv_LogMin-hv_LogOffset);
      hv_EndY = HTuple(10).TuplePow(hv_LogMax+hv_LogOffset);
      hv_TicksY = (hv_PlotHeight/10)*hv_Scale;
      //
      //Use a smaller, non-bold font for the plot.
      set_display_font(hv_WindowText, 12, "mono", "false", "false");
      hv_LogY = "true";
      //Plot learning rate if the corresponding strategy exists.
      if (0 != hv_PlotLearningRateStrategy)
      {
        //
        //Display current values in appropriate colors.
        GetStringExtents(hv_WindowText, hv_LRTextLegend, &hv__, &hv__, &hv_StringExtendsLegendRight, 
            &hv__);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_LRTextLegend, "image", hv_LegendRow, 
              (hv_Width-hv_StringExtendsLegendRight)-hv_LegendDistanceRight, hv_LRColor, 
              "box", "false");
        plot_tuple_no_window_handling(hv_WindowText, hv_ValuesX, hv_LearningRate, 
            "", "", hv_LRColor, ((((((((((((HTuple("log_y").Append("axes_color")).Append("start_y")).Append("end_y")).Append("ticks_y")).Append("margin_top")).Append("margin_bottom")).Append("margin_left")).Append("margin_right")).Append("line_width")).Append("axes_color")).Append("axis_location_y")).Append("format_y")), 
            ((((((((hv_LogY.TupleConcat("black")).TupleConcat(hv_StartYLearningRate)).TupleConcat(hv_EndYLearningRate)).TupleConcat(hv_TicksYLearningRate)).TupleConcat(hv_TopMarginPlots)).TupleConcat((HTuple(30).Append(65)))).TupleConcat(hv_RightMargin)).TupleConcat(hv_LRLineWidth)).TupleConcat(((HTuple("#898b8f").Append("right")).Append(".1e"))));
      }
      hv_YAxisLabel = "Loss";
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"  "+hv_YAxisLabel, "image", hv_LegendRow, 
            hv_LegendDistanceLeft, "#ff6384", "box", "false");
      plot_tuple_no_window_handling(hv_WindowText, hv_ValuesX, hv_Loss, hv_TitleX, 
          "", "#ff6384", (((((((((((HTuple("log_y").Append("axes_color")).Append("ticks_x")).Append("ticks_y")).Append("start_y")).Append("end_y")).Append("margin_top")).Append("margin_bottom")).Append("margin_left")).Append("margin_right")).Append("line_width")).Append("axes_color")), 
          ((((((((hv_LogY.TupleConcat("black")).TupleConcat(hv_TicksX)).TupleConcat(hv_TicksY)).TupleConcat(hv_StartY)).TupleConcat(hv_EndY)).TupleConcat(hv_TopMarginPlots)).TupleConcat((HTuple(30).Append(65)))).TupleConcat(hv_RightMargin)).TupleConcat((HTuple(3).Append("#898b8f"))));
      set_display_font(hv_WindowText, 16, "mono", "true", "false");
    }
    else
    {
      hv_HeadlineText = "Waiting for data to initialize the plot...";
    }
  }

  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_HeadlineText, "image", 445, 9, "black", 
        "box", "false");
  //
  //Model parameter status.
  GetDictTuple(hv_DisplayParam, "status_model_params", &hv_TextModelParams);
  GetDictTuple(hv_TrainInfo, "model_params", &hv_ModelParams);
  hv_StatusModelParamsLeft = HTuple();
  hv_StatusModelParamsRight = HTuple();
  {
  HTuple end_val269 = (hv_TextModelParams.TupleLength())-1;
  HTuple step_val269 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val269, step_val269); hv_Index += step_val269)
  {
    hv_ParName = HTuple(hv_TextModelParams[hv_Index]);
    try
    {
      GetDictTuple(hv_ModelParams, hv_ParName, &hv_Tuple);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      continue;
    }
    if (0 != (HTuple(int(hv_ParName==HTuple("batch_size_multiplier"))).TupleAnd(int(hv_Tuple==1))))
    {
      continue;
    }
    hv_StatusModelParamsLeft = hv_StatusModelParamsLeft.TupleConcat(("'"+hv_ParName)+"'");

    pretty_print_tuple(hv_Tuple, &hv_TupleStr);
    hv_StatusModelParamsRight = hv_StatusModelParamsRight.TupleConcat(hv_TupleStr);
  }
  }
  if (0 != (int((hv_StatusModelParamsLeft.TupleLength())>0)))
  {
    hv_StatusModelParamsLeft = HTuple("Model parameters:").TupleConcat("  "+hv_StatusModelParamsLeft);
    hv_StatusModelParamsRight = HTuple(" ").TupleConcat(hv_StatusModelParamsRight);
  }
  //
  //Evaluation status.
  hv_StatusEvaluationLeft = HTuple();
  hv_StatusEvaluationRight = HTuple();
  GetDictTuple(hv_TrainInfo, "best_evaluation", &hv_BestEvaluationData);
  if (0 != (int((hv_BestEvaluationData.TupleLength())>0)))
  {
    GetDictTuple(hv_BestEvaluationData, "comparison_keys", &hv_BestEvaluationComparisonKeys);
    GetDictTuple(hv_BestEvaluationData, "best_value", &hv_BestEvaluationValue);
    GetDictTuple(hv_BestEvaluationData, "best_info", &hv_BestEvaluationInfo);
    GetDictTuple(hv_BestEvaluationInfo, "epoch", &hv_BestEvaluationEpoch);
    GetDictTuple(hv_BestEvaluationData, "best_value_train", &hv_BestTrainEvaluationValue);
    GetDictTuple(hv_BestEvaluationData, "best_info_train", &hv_BestTrainEvaluationInfo);
    GetDictTuple(hv_BestTrainEvaluationInfo, "epoch", &hv_BestTrainEvaluationEpoch);
    if (0 != (int((hv_BestEvaluationComparisonKeys.TupleLength())>1)))
    {
      hv_StatusEvaluationLeft = hv_StatusEvaluationLeft.TupleConcat("Measures");
      hv_BestEvaluationComparisonKeysStr = HTuple(HTuple("multiple (")+(hv_BestEvaluationComparisonKeys.TupleLength()))+")";
    }
    else
    {
      hv_StatusEvaluationLeft = hv_StatusEvaluationLeft.TupleConcat("Measure");
      hv_BestEvaluationComparisonKeysStr = ("'"+hv_BestEvaluationComparisonKeys)+"'";
    }
    //
    hv_StatusEvaluationRight = hv_StatusEvaluationRight.TupleConcat(hv_BestEvaluationComparisonKeysStr);
    //Validation value.
    hv_StatusEvaluationLeft = hv_StatusEvaluationLeft.TupleConcat("Best validation (value / epoch)");
    hv_StatusEvaluationRight = hv_StatusEvaluationRight.TupleConcat(((hv_BestEvaluationValue.TupleString("0.3f"))+" / ")+(hv_BestEvaluationEpoch.TupleString("0.1f")));
    //Training value.
    if (0 != hv_PlotTrainEval)
    {
      hv_StatusEvaluationLeft = hv_StatusEvaluationLeft.TupleConcat("Best training (value / epoch)");
      hv_StatusEvaluationRight = hv_StatusEvaluationRight.TupleConcat(((hv_BestTrainEvaluationValue.TupleString("0.3f"))+" / ")+(hv_BestTrainEvaluationEpoch.TupleString("0.1f")));
    }
    //
    hv_StatusEvaluationLeft = HTuple("Evaluation:").TupleConcat("  "+hv_StatusEvaluationLeft);
    hv_StatusEvaluationRight = HTuple(" ").TupleConcat(hv_StatusEvaluationRight);
  }
  //
  //Train status.
  hv_StatusTrainLeft = HTuple();
  hv_StatusTrainRight = HTuple();
  GetDictTuple(hv_TrainInfo, "epoch", &hv_EpochReal);
  GetDictTuple(hv_TrainInfo, "num_epochs", &hv_NumEpochs);
  hv_StatusTrainLeft = hv_StatusTrainLeft.TupleConcat("Epoch");
  hv_StatusTrainRight = hv_StatusTrainRight.TupleConcat(((hv_EpochReal.TupleString(".1f"))+" of ")+(hv_NumEpochs.TupleString(".1f")));
  hv_StatusTrainLeft = hv_StatusTrainLeft.TupleConcat("Iteration");
  hv_StatusTrainRight = hv_StatusTrainRight.TupleConcat((hv_CurrentIteration+" of ")+hv_NumIterations);
  GetDictTuple(hv_TrainInfo, "mean_loss", &hv_MeanLoss);
  if (0 != (int((hv_MeanLoss.TupleLength())==0)))
  {
    hv_MeanLossStr = "";
  }
  else
  {
    hv_MeanLossStr = hv_MeanLoss.TupleString("0.4f");
  }
  hv_StatusTrainLeft = hv_StatusTrainLeft.TupleConcat("Loss");
  hv_StatusTrainRight = hv_StatusTrainRight.TupleConcat(hv_MeanLossStr);
  //
  //Elapsed and remaining time.
  GetDictParam(hv_DisplayData, "key_exists", "time_elapsed", &hv_TimeElapsedExists);
  if (0 != (hv_TimeElapsedExists.TupleNot()))
  {
    //During training the key is not set and the time has to be determined.
    GetDictTuple(hv_TrainInfo, "start_epoch", &hv_StartEpoch);
    GetDictTuple(hv_TrainInfo, "start_time", &hv_StartTime);
    estimate_progress(hv_StartTime, hv_StartEpoch, hv_EpochReal, hv_NumEpochs, &hv_SecondsElapsed, 
        &hv_SecondsRemaining, &hv_ProgressPercent, &hv_ProgressPerSecond);
    timespan_string(hv_SecondsElapsed, "auto", &hv_TimeElapsedString);
    timespan_string(hv_SecondsRemaining, "top2", &hv_TimeRemainingString);
    hv_StatusTrainLeft = hv_StatusTrainLeft.TupleConcat((HTuple("Time elapsed").Append("Time left")));
    hv_StatusTrainRight = (hv_StatusTrainRight.TupleConcat(hv_TimeElapsedString)).TupleConcat(hv_TimeRemainingString);
  }
  else
  {
    //For display after the finished training the key may be set.
    //In case of a given value, display it.
    GetDictTuple(hv_DisplayData, "time_elapsed", &hv_TimeElapsedString);
    if (0 != (int(hv_TimeElapsedString!=HTuple(""))))
    {
      hv_StatusTrainLeft = hv_StatusTrainLeft.TupleConcat("Time elapsed");
      hv_StatusTrainRight = hv_StatusTrainRight.TupleConcat(hv_TimeElapsedString);
    }
  }
  //
  //Check if Device Status is there and combine it all together.
  GetDictParam(hv_ModelParams, "key_exists", "device_name", &hv_DeviceNameExists);
  if (0 != hv_DeviceNameExists)
  {
    GetDictTuple(hv_ModelParams, "device_name", &hv_DeviceName);
    //Combine all with device name.
    hv_StatusLeft.Clear();
    hv_StatusLeft[0] = "train_dl_model";
    hv_StatusLeft[1] = " ";
    hv_StatusLeft[2] = " ";
    hv_StatusLeft.Append(hv_StatusTrainLeft);
    hv_StatusLeft.Append(" ");
    hv_StatusLeft.Append(hv_StatusEvaluationLeft);
    hv_StatusLeft.Append(" ");
    hv_StatusLeft.Append(hv_StatusModelParamsLeft);
    hv_StatusLeft.Append(" ");
    hv_StatusRight.Clear();
    hv_StatusRight[0] = "Used Device:";
    hv_StatusRight.Append(hv_DeviceName);
    hv_StatusRight.Append(" ");
    hv_StatusRight.Append(hv_StatusTrainRight);
    hv_StatusRight.Append(" ");
    hv_StatusRight.Append(hv_StatusEvaluationRight);
    hv_StatusRight.Append(" ");
    hv_StatusRight.Append(hv_StatusModelParamsRight);
    hv_StatusRight.Append(" ");
  }
  else
  {
    //Combine all without device name.
    hv_StatusLeft.Clear();
    hv_StatusLeft[0] = "train_dl_model";
    hv_StatusLeft[1] = " ";
    hv_StatusLeft[2] = " ";
    hv_StatusLeft.Append(hv_StatusTrainLeft);
    hv_StatusLeft.Append(" ");
    hv_StatusLeft.Append(hv_StatusEvaluationLeft);
    hv_StatusLeft.Append(" ");
    hv_StatusLeft.Append(hv_StatusModelParamsLeft);
    hv_StatusLeft.Append(" ");
    hv_StatusRight.Clear();
    hv_StatusRight[0] = " ";
    hv_StatusRight[1] = " ";
    hv_StatusRight[2] = " ";
    hv_StatusRight.Append(hv_StatusTrainRight);
    hv_StatusRight.Append(" ");
    hv_StatusRight.Append(hv_StatusEvaluationRight);
    hv_StatusRight.Append(" ");
    hv_StatusRight.Append(hv_StatusModelParamsRight);
    hv_StatusRight.Append(" ");
  }
  //
  //Cut strings with too many chars.
  hv_MaxChars = 20;
  {
  HTuple end_val377 = (hv_StatusRight.TupleLength())-1;
  HTuple step_val377 = 1;
  for (hv_Index=1; hv_Index.Continue(end_val377, step_val377); hv_Index += step_val377)
  {
    hv_Str = HTuple(hv_StatusRight[hv_Index]);
    TupleIsString(hv_Str, &hv_IsString);
    if (0 != hv_IsString)
    {
      TupleStrlen(hv_Str, &hv_Length);
      if (0 != (int(hv_Length>hv_MaxChars)))
      {
        hv_SubStr = (hv_Str.TupleSubstr(0,hv_MaxChars-3))+"...";
        hv_StatusRight[hv_Index] = hv_SubStr;
      }
    }
  }
  }
  //
  //Display the text.
  GetDictTuple(hv_DisplayData, "window_text", &hv_WindowText);
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_StatusLeft, "window", "top", "left", 
        "black", "box", "false");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_StatusRight, "window", "top", "right", 
        "black", "box", "false");
  FlushBuffer(hv_WindowText);
  SetWindowParam(hv_WindowText, "flush", "true");
  GetPart(hv_WindowText, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
  GetDictTuple(hv_DisplayData, "window_text_width", &hv_WindowTextWidth);
  GetDictTuple(hv_DisplayData, "window_text_height", &hv_WindowTextHeight);
  if (0 != (HTuple(int((hv_WindowTextWidth-1)!=(hv_Column2-hv_Column1))).TupleOr(int((hv_WindowTextHeight-1)!=(hv_Row2-hv_Row1)))))
  {
    if (HDevWindowStack::IsOpen())
      SetPart(HDevWindowStack::GetActive(),hv_Row1, hv_Column1, (hv_Row1+hv_WindowTextHeight)-1, 
          (hv_Column1+hv_WindowTextWidth)-1);
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Get a parameter value from GenParamValue with the name RequestedGenParamName. 
void get_genparam_single_value (HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_RequestedGenParamName, HTuple *hv_FoundGenParamValue)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Indices;

  //
  //Get a parameter value from GenParamValue with the name RequestedGenParamName,
  //which is allowed to appear only once in GenParamName.
  //
  //Set a default in case no value is provided.
  (*hv_FoundGenParamValue) = HTuple();
  //Set user provided values, if provided.
  hv_Indices = hv_GenParamName.TupleFind(hv_RequestedGenParamName);
  if (0 != (HTuple(int((hv_Indices.TupleLength())==1)).TupleAnd(int(hv_Indices!=-1))))
  {
    (*hv_FoundGenParamValue) = HTuple(hv_GenParamValue[hv_Indices]);
  }
  else if (0 != (int((hv_Indices.TupleLength())>1)))
  {
    //Throw an error if more than one value was provided for RequestedGenParamName.
    throw HException(("Only a single parameter dictionary or none is allowed for '"+hv_RequestedGenParamName)+"'.");
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Initialize change strategies data. 
void init_train_dl_model_change_strategies (HTuple hv_TrainParam, HTuple *hv_ChangeStrategyData)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ChangeStrategies, hv_Enabled, hv_Index;
  HTuple  hv_ChangeStrategy, hv_ModelParam, hv_Epochs, hv_Values;
  HTuple  hv_Initial, hv_Indices, hv_ScaleThresholdExists;

  //
  //Initialize a dictionary with the change strategies data.
  CreateDict(&(*hv_ChangeStrategyData));
  GetDictTuple(hv_TrainParam, "change_strategies", &hv_ChangeStrategies);
  hv_Enabled = int((hv_ChangeStrategies.TupleLength())>0);
  SetDictTuple((*hv_ChangeStrategyData), "enabled", hv_Enabled);
  if (0 != (hv_Enabled.TupleNot()))
  {
    return;
  }
  //
  //Sort all epochs in all change strategies.
  {
  HTuple end_val11 = (hv_ChangeStrategies.TupleLength())-1;
  HTuple step_val11 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val11, step_val11); hv_Index += step_val11)
  {
    hv_ChangeStrategy = HTuple(hv_ChangeStrategies[hv_Index]);
    GetDictTuple(hv_ChangeStrategy, "model_param", &hv_ModelParam);
    GetDictTuple(hv_ChangeStrategy, "epochs", &hv_Epochs);
    GetDictTuple(hv_ChangeStrategy, "values", &hv_Values);
    GetDictTuple(hv_ChangeStrategy, "initial_value", &hv_Initial);
    //Check that the length are equal.
    if (0 != (int((hv_Epochs.TupleLength())!=(hv_Values.TupleLength()))))
    {
      throw HException("ChangeStrategy parameter error: 'epochs' and 'values' need to have same length.");
    }
    //We need sorted arrays for faster access.
    TupleSortIndex(hv_Epochs, &hv_Indices);
    SetDictTuple(hv_ChangeStrategy, "epochs", HTuple(hv_Epochs[hv_Indices]));
    SetDictTuple(hv_ChangeStrategy, "values", HTuple(hv_Values[hv_Indices]));
    //
    //For the learning rate, there can be an additional parameter
    //indicating if the momentum should be scaled as well.
    if (0 != (int(hv_ModelParam==HTuple("learning_rate"))))
    {
      GetDictParam(hv_ChangeStrategy, "key_exists", "scale_momentum_threshold", &hv_ScaleThresholdExists);
      if (0 != (hv_ScaleThresholdExists.TupleNot()))
      {
        //If not given, the threshold is set to an empty tuple such that no scaling is performed.
        SetDictTuple(hv_ChangeStrategy, "scale_momentum_threshold", HTuple());
      }
    }
  }
  }
  SetDictTuple((*hv_ChangeStrategyData), "strategies", hv_ChangeStrategies);
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Initialize the dictionary setting for serialization strategies. 
void init_train_dl_model_serialization_strategies (HTuple hv_TrainParam, HTuple *hv_SerializationData)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_SerializationStrategies, hv_RawData;
  HTuple  hv_Types, hv_SerializeFinal, hv_Index, hv_Strategy;
  HTuple  hv_Type, hv_Data, hv_Epochs, hv_NumEpochs;

  //
  //This procedure initializes the dictionary setting the serialization strategies.
  //
  //Initialize each serialization strategy.
  GetDictTuple(hv_TrainParam, "serialization_strategies", &hv_SerializationStrategies);
  CreateDict(&(*hv_SerializationData));
  SetDictTuple((*hv_SerializationData), "strategies", hv_SerializationStrategies);
  hv_RawData = HTuple();
  hv_Types = HTuple();
  hv_SerializeFinal = 0;
  {
  HTuple end_val10 = (hv_SerializationStrategies.TupleLength())-1;
  HTuple step_val10 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val10, step_val10); hv_Index += step_val10)
  {
    hv_Strategy = HTuple(hv_SerializationStrategies[hv_Index]);
    GetDictTuple(hv_Strategy, "type", &hv_Type);
    CreateDict(&hv_Data);
    if (0 != (int(hv_Type==HTuple("best"))))
    {
      SetDictTuple(hv_Data, "best_value", -1);
    }
    else if (0 != (int(hv_Type==HTuple("epochs"))))
    {
      GetDictTuple(hv_Strategy, "epochs", &hv_Epochs);
      //Store sorted values in order to search faster during updates.
      TupleSort(hv_Epochs, &hv_Epochs);
      SetDictTuple(hv_Data, "epochs", hv_Epochs);
      SetDictTuple(hv_Data, "last_epoch_index", -1);
    }
    else if (0 != (int(hv_Type==HTuple("current"))))
    {
      GetDictTuple(hv_TrainParam, "num_epochs", &hv_NumEpochs);
      SetDictTuple(hv_Data, "epochs", HTuple::TupleGenSequence(1,hv_NumEpochs,1));
      SetDictTuple(hv_Data, "last_epoch_index", -1);
    }
    else if (0 != (int(hv_Type==HTuple("final"))))
    {
      SetDictTuple(hv_Data, "serialize_final", 1);
    }
    else
    {
      throw HException(("Unknown serialization strategy type: '"+hv_Type)+"'");
    }
    hv_Types = hv_Types.TupleConcat(hv_Type);
    hv_RawData = hv_RawData.TupleConcat(hv_Data);
  }
  }
  SetDictTuple((*hv_SerializationData), "raw_data", hv_RawData);
  SetDictTuple((*hv_SerializationData), "types", hv_Types);
  return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Normalize the output features of the Global Context Anomaly Detection model before training. 
void normalize_dl_gc_anomaly_features (HTuple hv_DLDataset, HTuple hv_DLModelHandle, 
    HTuple hv_GenParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_DLSamples, hv_TrainSampleIndices, hv_OriginalSeed;
  HTuple  hv_ShuffledIndices, hv_NumNormalizationIndices;
  HTuple  hv_NormalizationIndices, hv_DLSamplesNormalization;
  HTuple  hv_NormalizationLayerNames, hv_ModelLayerNames;
  HTuple  hv_Index, hv_LayerName, hv_Mean, hv_StdDev, hv_Normalizer;

  //To normalize the output of the feature extractor E_loc its
  //output channels are normalized to have zero mean and a
  //standard deviation of 1.0 on the training samples.
  //
  //Make sure GenParam is an empty tuple.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    throw HException("The parameter GenParam must be an empty tuple.");
  }
  //
  GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
  find_dl_samples(hv_DLSamples, "split", "train", "match", &hv_TrainSampleIndices);
  //Make sure we use the same samples given the same dataset,
  //so that repeatedly calling this procedure with the same dataset does not
  //update the normalization of E_loc.
  GetSystem("seed_rand", &hv_OriginalSeed);
  SetSystem("seed_rand", 0);
  tuple_shuffle(hv_TrainSampleIndices, &hv_ShuffledIndices);
  SetSystem("seed_rand", hv_OriginalSeed);
  hv_NumNormalizationIndices = HTuple(100).TupleMin2(hv_ShuffledIndices.TupleLength());
  hv_NormalizationIndices = hv_ShuffledIndices.TupleSelectRange(0,hv_NumNormalizationIndices-1);
  read_dl_samples(hv_DLDataset, hv_NormalizationIndices, &hv_DLSamplesNormalization);

  hv_NormalizationLayerNames.Clear();
  hv_NormalizationLayerNames[0] = "eloc_output";
  hv_NormalizationLayerNames[1] = "tglo_output";
  GetDlModelParam(hv_DLModelHandle, "layer_names", &hv_ModelLayerNames);
  {
  HTuple end_val24 = (hv_NormalizationLayerNames.TupleLength())-1;
  HTuple step_val24 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val24, step_val24); hv_Index += step_val24)
  {
    hv_LayerName = HTuple(hv_NormalizationLayerNames[hv_Index]);
    if (0 != (int((hv_ModelLayerNames.TupleFindFirst(hv_LayerName))!=-1)))
    {
      calculate_dl_model_layer_mean_stddev(hv_DLModelHandle, hv_LayerName, hv_DLSamplesNormalization, 
          &hv_Mean, &hv_StdDev);
      //Clip the standard deviation to avoid numerical issues.
      hv_Normalizer = hv_StdDev.TupleMax2(0.001);
      scale_and_shift_dl_model_layer(hv_DLModelHandle, hv_LayerName, 1.0/(hv_Normalizer.TupleReal()), 
          (-hv_Mean)/(hv_Normalizer.TupleReal()));
    }
  }
  }
  return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Normalize the anomaly scores on the validation set. 
void normalize_dl_gc_anomaly_scores (HTuple hv_DLDataset, HTuple hv_DLModelHandle, 
    HTuple hv_GenParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_DLSamples, hv_ValidationSampleIndices;
  HTuple  hv_OKSampleIndices, hv_SampleIndices, hv_DLSamplesValidation;
  HTuple  hv_LowerQuantileP, hv_UpperQuantileP, hv_LowerQuantileLocation;
  HTuple  hv_UpperQuantileLocation, hv_Networks, hv_HasLocalNetwork;
  HTuple  hv_HasGlobalNetwork, hv_NormalizationLayers, hv_Index;
  HTuple  hv_NormalizationLayer, hv_Quantiles, hv_Scale, hv_LowerQuantileScaled;
  HTuple  hv_Shift;

  //This procedure normalizes the anomaly scores of the local and the global network of
  //a gc_anomaly_detection model to the same scale.
  //It is crucial to perform this step after the actual training of the model DLDataset.
  //
  //Make sure GenParam is an empty tuple.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    throw HException("The parameter GenParam must be an empty tuple.");
  }
  //
  GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
  find_dl_samples(hv_DLSamples, "split", "validation", "match", &hv_ValidationSampleIndices);
  find_dl_samples(hv_DLSamples, "anomaly_label", "ok", "match", &hv_OKSampleIndices);
  TupleIntersection(hv_ValidationSampleIndices, hv_OKSampleIndices, &hv_SampleIndices);
  read_dl_samples(hv_DLDataset, hv_SampleIndices, &hv_DLSamplesValidation);
  //
  //Based on the 'good'/'ok' samples, select normalization scale such that 99.5%
  //of the anomaly image pixel values are smaller or equal to 0.1.
  hv_LowerQuantileP = 0.9;
  hv_UpperQuantileP = 0.995;
  hv_LowerQuantileLocation = 0;
  hv_UpperQuantileLocation = 0.1;
  //
  //Find networks to be normalized.
  GetDlModelParam(hv_DLModelHandle, "gc_anomaly_networks", &hv_Networks);
  hv_HasLocalNetwork = int((hv_Networks.TupleFind("local"))!=-1);
  hv_HasGlobalNetwork = int((hv_Networks.TupleFind("global"))!=-1);
  hv_NormalizationLayers = HTuple();
  if (0 != hv_HasLocalNetwork)
  {
    hv_NormalizationLayers = hv_NormalizationLayers.TupleConcat("local_normalization");
  }
  if (0 != hv_HasGlobalNetwork)
  {
    hv_NormalizationLayers = hv_NormalizationLayers.TupleConcat("global_normalization");
  }
  //
  {
  HTuple end_val34 = (hv_NormalizationLayers.TupleLength())-1;
  HTuple step_val34 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val34, step_val34); hv_Index += step_val34)
  {
    //Calculate quantiles for requested normalization layer.
    hv_NormalizationLayer = HTuple(hv_NormalizationLayers[hv_Index]);
    calculate_dl_anomaly_quantiles(hv_DLModelHandle, hv_NormalizationLayer, hv_DLSamplesValidation, 
        hv_LowerQuantileP.TupleConcat(hv_UpperQuantileP), &hv_Quantiles);
    hv_Scale = (hv_UpperQuantileLocation-hv_LowerQuantileLocation)/(HTuple(hv_Quantiles[1])-HTuple(hv_Quantiles[0]));
    //Scale the lower quantile.
    hv_LowerQuantileScaled = HTuple(hv_Quantiles[0])*hv_Scale;
    //Compute the shift required to map it to LowerQuantileLocation.
    hv_Shift = hv_LowerQuantileLocation-hv_LowerQuantileScaled;
    scale_and_shift_dl_model_layer(hv_DLModelHandle, hv_NormalizationLayer, hv_Scale, 
        hv_Shift);
  }
  }
  //
  return;
}

// Chapter: Graphics / Output
// Short Description: Plot tuples representing functions or curves in a coordinate system. 
void plot_tuple_no_window_handling (HTuple hv_WindowHandle, HTuple hv_XValues, HTuple hv_YValues, 
    HTuple hv_XLabel, HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamName, 
    HTuple hv_GenParamValue)
{

  // Local iconic variables
  HObject  ho_ContourXGrid, ho_ContourYGrid, ho_XArrow;
  HObject  ho_YArrow, ho_ContourXTick, ho_ContourYTick, ho_Contour;
  HObject  ho_Cross, ho_Circle, ho_Filled, ho_Stair, ho_StairTmp;

  // Local control variables
  HTuple  hv_ClipRegion, hv_Row, hv_Column, hv_Width;
  HTuple  hv_Height, hv_PartRow1, hv_PartColumn1, hv_PartRow2;
  HTuple  hv_PartColumn2, hv_Red, hv_Green, hv_Blue, hv_DrawMode;
  HTuple  hv_OriginStyle, hv_PartDiffers, hv_PlotYLog, hv_YLogIndices;
  HTuple  hv_PlotYLogUser, hv_IsString, hv_YInd, hv_Indices1;
  HTuple  hv_XAxisEndValue, hv_YAxisEndValue, hv_XAxisStartValue;
  HTuple  hv_YAxisStartValue, hv_XValuesAreStrings, hv_XTickValues;
  HTuple  hv_XTicks, hv_YAxisPosition, hv_XAxisPosition, hv_LeftBorder;
  HTuple  hv_RightBorder, hv_UpperBorder, hv_LowerBorder;
  HTuple  hv_AxesColor, hv_Style, hv_Clip, hv_YTicks, hv_XGrid;
  HTuple  hv_YGrid, hv_GridColor, hv_YPosition, hv_FormatX;
  HTuple  hv_FormatY, hv_LineWidth, hv_NumGenParamNames, hv_NumGenParamValues;
  HTuple  hv_GenParamIndex, hv_XGridTicks, hv_YTickDirection;
  HTuple  hv_XTickDirection, hv_XAxisWidthPx, hv_XAxisWidth;
  HTuple  hv_XScaleFactor, hv_YAxisHeightPx, hv_YAxisHeight;
  HTuple  hv_YScaleFactor, hv_YAxisOffsetPx, hv_XAxisOffsetPx;
  HTuple  hv_DotStyle, hv_XGridValues, hv_XGridStart, hv_XCoord;
  HTuple  hv_IndexGrid, hv_YGridValues, hv_YGridStart, hv_YCoord;
  HTuple  hv_Ascent, hv_Descent, hv_TextWidthXLabel, hv_TextHeightXLabel;
  HTuple  hv_TextWidthYLabel, hv_TextHeightYLabel, hv_XTickStart;
  HTuple  hv_Indices, hv_TypeTicks, hv_IndexTicks, hv_Ascent1;
  HTuple  hv_Descent1, hv_TextWidthXTicks, hv_TextHeightXTicks;
  HTuple  hv_YTickValues, hv_YTickStart, hv_TextWidthYTicks;
  HTuple  hv_TextHeightYTicks, hv_Num, hv_I, hv_YSelected;
  HTuple  hv_StyleOriginal, hv_OldLineWidth, hv_Radii, hv_OldContourStyle;
  HTuple  hv_Y1Selected, hv_X1Selected, hv_Index, hv_Row1;
  HTuple  hv_Row2, hv_Col1, hv_Col2;

  //
  //This procedure plots tuples representing functions
  //or curves in a coordinate system.

  //In the following, the possible values are listed for the parameters:
  //
  //- XValues: X values of the function to be plotted. Thereby you have the following options:
  //  -- []: XValues are internally set to 0,1,2,...,|YValues|-1.
  //  -- a tuple of strings: These values are taken as categories.
  //
  //- YValues: Y values of the function(s) to be plotted. Thereby you have the following options:
  //  -- []: YValues are internally set to 0,1,2,...,|XValues|-1.
  //  -- a tuple of values: The number of y values must be equal to the number of x values or an integral multiple.
  //     In the latter case, multiple functions are plotted, that share the same x values.
  //
  //- XLabel: X-axis label.
  //
  //- YLabel: Y-axis label.
  //
  //- Color: Color of the plotted function. Thereby you have the following options:
  //  -- []: The currently set display color is used.
  //  -- 'none': The function is not plotted, but only the coordinate axes as specified.
  //  -- string: Defining the color of the plotted function.
  //  -- tuple of strings: -multiple functions can be displayed in different colors.
  //
  //- GenParamName: Generic parameter names to control the presentation.
  // The corresponding values are taken from GenParamValue. Possible Values string/value pairs:
  //  -- 'axes_color': Color of the coordinate axes. The default value is 'white'.
  //     If 'none' is given, no coordinate axes are shown.
  //  -- 'style': Graph style. Possible values:
  //     --- 'line' (default)
  //     --- 'cross'
  //     --- 'circle'
  //     --- 'step'
  //     --- 'filled'
  //  -- 'clip': Clip graph to coordinate system area. Possible values:
  //     --- 'no' (default)
  //     --- 'yes''
  //  -- 'ticks': Control display of ticks on the axes. Thereby you have the following options:
  //     --- 'min_max_origin' (default): Ticks are shown at the minimum and maximum values
  //         of the axes and at the intercept point of x- and y-axis.
  //     --- 'none': No ticks are shown.
  //     --- any number != 0: This number specifies the distance between the ticks.
  //  -- 'ticks_x': Control display of ticks on x-axis only. You have the same options as for 'ticks'.
  //  -- 'ticks_y': Control display of ticks on y-axis only. You have the same options as for 'ticks'.
  //  -- 'format_x': Format of the values next to the ticks of the x-axis (see tuple_string for more details).
  //  -- 'format_y': Format of the values next to the ticks of the y-axis (see tuple_string for more details).
  //  -- 'grid': Control display of grid lines within the coordinate system.
  //     Thereby you have the following options:
  //    --- 'min_max_origin' (default): Grid lines are shown at the minimum and maximum values of the axes.
  //    --- 'none': No grid lines are shown.
  //    --- If any number != 0: This number specifies the distance between the grid lines.
  //  -- 'grid_x': Control display of grid lines for the x-axis only.
  //  -- 'grid_y': Control display of grid lines for the y-axis only.
  //  -- 'grid_color': Color of the grid (default: 'dim gray').
  //  -- 'margin': The distance in pixels of the plot area to all four window borders.
  //  -- 'margin_left': The distance in pixels of the plot area to the left window border.
  //  -- 'margin_right': The distance in pixels of the plot area to the right window border.
  //  -- 'margin_top': The distance in pixels of the plot area to the upper window border.
  //  -- 'margin_bottom'': The distance in pixels of the plot area to the lower window border.
  //  -- 'start_x': Lowest x value of the x-axis. The default value is min(XValues).
  //  -- 'end_x': Highest x value of the x-axis. The default value is max(XValues).
  //  -- 'start_y': Lowest y value of the y-axis. The default value is min(YValues).
  //  -- 'end_y': Highest y value of the y-axis. The default value is max(YValues).
  //  -- 'axis_location_x': Position of the x-axis (Used to be called 'origin_y').
  //     Thereby you have the following options:
  //     --- 'bottom' (default)
  //     --- 'origin'
  //     --- 'top'
  //     --- Y coordinate of the intercept point of x- and y-axis.
  //  -- 'axis_location_y': Position of the y-axis (Used to be called 'origin_x').
  //     Thereby you have the following options:
  //     --- 'left' (default)
  //     --- 'right'
  //     --- 'origin'
  //     --- X coordinate of the intercept point of x- and y-axis.
  //  -- 'line_width': Line width of the plot.
  //  -- 'log_y': If 'true', plot the YValue in logarithmic scale. Default is 'false'.
  //
  //
  GetSystem("clip_region", &hv_ClipRegion);
  GetWindowExtents(hv_WindowHandle, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  GetPart(hv_WindowHandle, &hv_PartRow1, &hv_PartColumn1, &hv_PartRow2, &hv_PartColumn2);
  hv_Width = (hv_PartColumn2-hv_PartColumn1)+1;
  hv_Height = (hv_PartRow2-hv_PartRow1)+1;
  GetRgb(hv_WindowHandle, &hv_Red, &hv_Green, &hv_Blue);
  GetDraw(hv_WindowHandle, &hv_DrawMode);
  GetLineStyle(hv_WindowHandle, &hv_OriginStyle);
  //
  //Set the display parameters.
  SetLineStyle(hv_WindowHandle, HTuple());
  SetSystem("clip_region", "false");

  hv_PartDiffers = HTuple(HTuple(HTuple(int(0!=hv_PartRow1)).TupleOr(int(0!=hv_Column))).TupleOr(int((hv_Width-1)!=hv_PartColumn2))).TupleOr(int((hv_Height-1)!=hv_PartRow2));
  //Only use set part if it differs.
  if (0 != hv_PartDiffers)
  {
    if (HDevWindowStack::IsOpen())
      SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  }
  //
  //Check if we need to plot y-values logarithmically.
  //It is checked here because we want to convert the YValues tuple
  //immediately so that derived values will be correct.
  hv_PlotYLog = 0;
  if (0 != (HTuple(int((hv_GenParamName.TupleLength())>0)).TupleAnd(int((hv_GenParamName.TupleLength())==(hv_GenParamValue.TupleLength())))))
  {
    TupleFind(hv_GenParamName, "log_y", &hv_YLogIndices);
    if (0 != (int(hv_YLogIndices>=0)))
    {
      hv_PlotYLogUser = HTuple(hv_GenParamValue[HTuple(hv_YLogIndices[0])]);
      TupleIsString(hv_PlotYLogUser, &hv_IsString);
      if (0 != hv_IsString)
      {
        if (0 != (int(hv_PlotYLogUser==HTuple("true"))))
        {
          hv_PlotYLog = 1;
        }
        else if (0 != (int(hv_PlotYLogUser==HTuple("false"))))
        {
          hv_PlotYLog = 0;
        }
        else
        {
          throw HException(("Unknown generic parameter value: '"+hv_PlotYLogUser)+"' for value: 'log_y'");
        }
        hv_PlotYLog = int(hv_PlotYLogUser==HTuple("true"));
      }
      else
      {
        hv_PlotYLog = int(hv_PlotYLogUser==1);
      }
    }
  }
  if (0 != hv_PlotYLog)
  {
    //Clamp values to be >= 0.00001.
    hv_YInd = hv_YValues.TupleLessEqualElem(0);
    TupleFind(hv_YInd, 1, &hv_Indices1);
    if (0 != (int(hv_Indices1>=0)))
    {
      hv_YValues[hv_Indices1] = 0.00001;
    }
    hv_YValues = hv_YValues.TupleLog10();
  }
  //
  //Check input coordinate values.
  //
  if (0 != (HTuple(int(hv_XValues==HTuple())).TupleAnd(int(hv_YValues==HTuple()))))
  {
    //Neither XValues nor YValues are given:
    //Set axes to interval [0,1]
    hv_XAxisEndValue = 1;
    hv_YAxisEndValue = 1;
    hv_XAxisStartValue = 0;
    hv_YAxisStartValue = 0;
    hv_XValuesAreStrings = 0;
  }
  else
  {
    if (0 != (int(hv_XValues==HTuple())))
    {
      //XValues are omitted: Set equidistant XValues.
      hv_XValues = HTuple::TupleGenSequence(0,(hv_YValues.TupleLength())-1,1);
      hv_XValuesAreStrings = 0;
    }
    else if (0 != (int(hv_YValues==HTuple())))
    {
      //YValues are omitted: Set equidistant YValues.
      hv_YValues = HTuple::TupleGenSequence(0,(hv_XValues.TupleLength())-1,1);
    }
    if (0 != (int(((hv_YValues.TupleLength())%(hv_XValues.TupleLength()))!=0)))
    {
      //Number of YValues does not match number of XValues.
      throw HException("Number of YValues is no multiple of the number of XValues.");
      return;
    }

    hv_XValuesAreStrings = hv_XValues.TupleIsStringElem();
    hv_XValuesAreStrings = int((hv_XValuesAreStrings.TupleSum())==(hv_XValuesAreStrings.TupleLength()));
    if (0 != hv_XValuesAreStrings)
    {
      //XValues are given as strings: Show XValues as ticks.
      hv_XTickValues = hv_XValues;
      hv_XTicks = 1;
      //Set x-axis dimensions.
      hv_XValues = HTuple::TupleGenSequence(1,hv_XValues.TupleLength(),1);
    }
    //Set default x-axis dimensions.
    if (0 != (int((hv_XValues.TupleLength())>1)))
    {
      hv_XAxisStartValue = hv_XValues.TupleMin();
      hv_XAxisEndValue = hv_XValues.TupleMax();
    }
    else
    {
      hv_XAxisEndValue = HTuple(hv_XValues[0])+0.5;
      hv_XAxisStartValue = HTuple(hv_XValues[0])-0.5;
    }
  }
  //Set default y-axis dimensions.
  if (0 != (int((hv_YValues.TupleLength())>1)))
  {
    hv_YAxisStartValue = hv_YValues.TupleMin();
    hv_YAxisEndValue = hv_YValues.TupleMax();
  }
  else if (0 != (int((hv_YValues.TupleLength())==1)))
  {
    hv_YAxisStartValue = HTuple(hv_YValues[0])-0.5;
    hv_YAxisEndValue = HTuple(hv_YValues[0])+0.5;
  }
  else
  {
    hv_YAxisStartValue = 0;
    hv_YAxisEndValue = 1;
  }
  //Set default interception point of x- and y- axis.
  hv_YAxisPosition = "default";
  hv_XAxisPosition = "default";
  //
  //Set further default values:
  hv_LeftBorder = hv_Width*0.1;
  hv_RightBorder = hv_Width*0.1;
  hv_UpperBorder = hv_Height*0.1;
  hv_LowerBorder = hv_Height*0.1;
  hv_AxesColor = "white";
  hv_Style = "line";
  hv_Clip = "no";
  hv_XTicks = "min_max_origin";
  hv_YTicks = "min_max_origin";
  hv_XGrid = "none";
  hv_YGrid = "none";
  hv_GridColor = "dim gray";
  hv_YPosition = "left";
  hv_FormatX = "default";
  hv_FormatY = "default";
  hv_LineWidth = 1;
  //
  //Parse generic parameters.
  //
  hv_NumGenParamNames = hv_GenParamName.TupleLength();
  hv_NumGenParamValues = hv_GenParamValue.TupleLength();
  if (0 != (int(hv_NumGenParamNames!=hv_NumGenParamValues)))
  {
    throw HException("Number of generic parameter names does not match generic parameter values.");
    return;
  }
  //
  {
  HTuple end_val217 = (hv_GenParamName.TupleLength())-1;
  HTuple step_val217 = 1;
  for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val217, step_val217); hv_GenParamIndex += step_val217)
  {
    //
    //Set 'axes_color'.
    if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("axes_color"))))
    {
      hv_AxesColor = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'style'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("style"))))
    {
      hv_Style = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'clip'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("clip"))))
    {
      hv_Clip = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      if (0 != (HTuple(int(hv_Clip!=HTuple("yes"))).TupleAnd(int(hv_Clip!=HTuple("no")))))
      {
        throw HException(("Unsupported clipping option: '"+hv_Clip)+"'");
      }
      //
      //Set 'ticks'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("ticks"))))
    {
      hv_XTicks = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      hv_YTicks = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'ticks_x'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("ticks_x"))))
    {
      hv_XTicks = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'ticks_y'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("ticks_y"))))
    {
      hv_YTicks = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'grid'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("grid"))))
    {
      hv_XGrid = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      hv_YGrid = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      hv_XGridTicks = hv_XTicks;
      //
      //Set 'grid_x'
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("grid_x"))))
    {
      hv_XGrid = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'grid_y'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("grid_y"))))
    {
      hv_YGrid = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'grid_color'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("grid_color"))))
    {
      hv_GridColor = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'start_x'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("start_x"))))
    {
      hv_XAxisStartValue = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'end_x'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("end_x"))))
    {
      hv_XAxisEndValue = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'start_y'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("start_y"))))
    {
      hv_YAxisStartValue = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      if (0 != hv_PlotYLog)
      {
        hv_YAxisStartValue = (HTuple(0.00000001).TupleMax2(hv_YAxisStartValue)).TupleLog10();
      }
      //
      //Set 'end_y'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("end_y"))))
    {
      hv_YAxisEndValue = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      if (0 != hv_PlotYLog)
      {
        hv_YAxisEndValue = (HTuple(0.00000001).TupleMax2(hv_YAxisEndValue)).TupleLog10();
      }
      //
      //Set 'axis_location_y' (old name 'origin_x').
    }
    else if (0 != (HTuple(int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("axis_location_y"))).TupleOr(int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("origin_x")))))
    {
      hv_YAxisPosition = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'axis_location_x' (old name: 'origin_y').
    }
    else if (0 != (HTuple(int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("axis_location_x"))).TupleOr(int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("origin_y")))))
    {
      hv_XAxisPosition = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'margin'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin"))))
    {
      hv_LeftBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      hv_RightBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      hv_UpperBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      hv_LowerBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'margin_left'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin_left"))))
    {
      hv_LeftBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'margin_right'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin_right"))))
    {
      hv_RightBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'margin_top'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin_top"))))
    {
      hv_UpperBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
      //
      //Set 'margin_bottom'.
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin_bottom"))))
    {
      hv_LowerBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("format_x"))))
    {
      hv_FormatX = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("format_y"))))
    {
      hv_FormatY = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("line_width"))))
    {
      hv_LineWidth = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("log_y"))))
    {
      //log_y already checked before because some other values depend on it.
    }
    else
    {
      throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
    }
  }
  }
  //
  //Check consistency of start and end values of the axes.
  if (0 != (int(hv_XAxisStartValue>hv_XAxisEndValue)))
  {
    throw HException("Value for 'start_x' is greater than value for 'end_x'");
  }
  if (0 != (int(hv_YAxisStartValue>hv_YAxisEndValue)))
  {
    throw HException("Value for 'start_y' is greater than value for 'end_y'");
  }
  //
  //Set the position of the y-axis.
  if (0 != (int(hv_YAxisPosition==HTuple("default"))))
  {
    hv_YAxisPosition = hv_XAxisStartValue;
  }
  if (0 != (int((hv_YAxisPosition.TupleIsString())==1)))
  {
    if (0 != (int(hv_YAxisPosition==HTuple("left"))))
    {
      hv_YAxisPosition = hv_XAxisStartValue;
    }
    else if (0 != (int(hv_YAxisPosition==HTuple("right"))))
    {
      hv_YAxisPosition = hv_XAxisEndValue;
    }
    else if (0 != (int(hv_YAxisPosition==HTuple("origin"))))
    {
      hv_YAxisPosition = 0;
    }
    else
    {
      throw HException(("Unsupported axis_location_y: '"+hv_YAxisPosition)+"'");
    }
  }
  //Set the position of the ticks on the y-axis
  //depending of the location of the y-axis.
  if (0 != (int(((hv_XAxisStartValue.TupleConcat(hv_XAxisEndValue)).TupleMean())>hv_YAxisPosition)))
  {
    hv_YTickDirection = "right";
  }
  else
  {
    hv_YTickDirection = "left";
  }
  //
  //Set the position of the x-axis.
  if (0 != (int(hv_XAxisPosition==HTuple("default"))))
  {
    hv_XAxisPosition = hv_YAxisStartValue;
  }
  if (0 != (int((hv_XAxisPosition.TupleIsString())==1)))
  {
    if (0 != (int(hv_XAxisPosition==HTuple("bottom"))))
    {
      hv_XAxisPosition = hv_YAxisStartValue;
    }
    else if (0 != (int(hv_XAxisPosition==HTuple("top"))))
    {
      hv_XAxisPosition = hv_YAxisEndValue;
    }
    else if (0 != (int(hv_XAxisPosition==HTuple("origin"))))
    {
      hv_XAxisPosition = 0;
    }
    else
    {
      throw HException(("Unsupported axis_location_x: '"+hv_XAxisPosition)+"'");
    }
  }
  //Set the position of the ticks on the y-axis
  //depending of the location of the y-axis.
  if (0 != (int(((hv_YAxisStartValue.TupleConcat(hv_YAxisEndValue)).TupleMean())>hv_XAxisPosition)))
  {
    hv_XTickDirection = "up";
  }
  else
  {
    hv_XTickDirection = "down";
  }
  //
  //Calculate basic pixel coordinates and scale factors.
  //
  hv_XAxisWidthPx = (hv_Width-hv_LeftBorder)-hv_RightBorder;
  hv_XAxisWidth = hv_XAxisEndValue-hv_XAxisStartValue;
  if (0 != (int(hv_XAxisWidth==0)))
  {
    hv_XAxisStartValue = hv_XAxisStartValue-0.5;
    hv_XAxisEndValue += 0.5;
    hv_XAxisWidth = 1;
  }
  hv_XScaleFactor = hv_XAxisWidthPx/(hv_XAxisWidth.TupleReal());
  hv_YAxisHeightPx = (hv_Height-hv_LowerBorder)-hv_UpperBorder;
  hv_YAxisHeight = hv_YAxisEndValue-hv_YAxisStartValue;
  if (0 != (int(hv_YAxisHeight==0)))
  {
    hv_YAxisStartValue = hv_YAxisStartValue-0.5;
    hv_YAxisEndValue += 0.5;
    hv_YAxisHeight = 1;
  }
  hv_YScaleFactor = hv_YAxisHeightPx/(hv_YAxisHeight.TupleReal());
  hv_YAxisOffsetPx = (hv_YAxisPosition-hv_XAxisStartValue)*hv_XScaleFactor;
  hv_XAxisOffsetPx = (hv_XAxisPosition-hv_YAxisStartValue)*hv_YScaleFactor;
  //
  //Display grid lines.
  //
  if (0 != (int(hv_GridColor!=HTuple("none"))))
  {
    hv_DotStyle.Clear();
    hv_DotStyle[0] = 5;
    hv_DotStyle[1] = 7;
    SetLineStyle(hv_WindowHandle, hv_DotStyle);
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),hv_GridColor);
    //
    //Display x grid lines.
    if (0 != (int(hv_XGrid!=HTuple("none"))))
    {
      if (0 != (int(hv_XGrid==HTuple("min_max_origin"))))
      {
        //Calculate 'min_max_origin' grid line coordinates.
        if (0 != (int(hv_YAxisPosition==hv_XAxisStartValue)))
        {
          hv_XGridValues.Clear();
          hv_XGridValues.Append(hv_XAxisStartValue);
          hv_XGridValues.Append(hv_XAxisEndValue);
        }
        else
        {
          hv_XGridValues.Clear();
          hv_XGridValues.Append(hv_XAxisStartValue);
          hv_XGridValues.Append(hv_YAxisPosition);
          hv_XGridValues.Append(hv_XAxisEndValue);
        }
      }
      else
      {
        //Calculate equidistant grid line coordinates.
        hv_XGridStart = ((hv_XAxisStartValue/hv_XGrid).TupleCeil())*hv_XGrid;
        hv_XGridValues = HTuple::TupleGenSequence(hv_XGridStart,hv_XAxisEndValue,hv_XGrid);
      }
      hv_XCoord = (hv_XGridValues-hv_XAxisStartValue)*hv_XScaleFactor;
      //Generate and display grid lines.
      {
      HTuple end_val428 = (hv_XGridValues.TupleLength())-1;
      HTuple step_val428 = 1;
      for (hv_IndexGrid=0; hv_IndexGrid.Continue(end_val428, step_val428); hv_IndexGrid += step_val428)
      {
        GenContourPolygonXld(&ho_ContourXGrid, (hv_Height-hv_LowerBorder).TupleConcat(hv_UpperBorder), 
            (hv_LeftBorder+HTuple(hv_XCoord[hv_IndexGrid])).TupleConcat(hv_LeftBorder+HTuple(hv_XCoord[hv_IndexGrid])));
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ContourXGrid, HDevWindowStack::GetActive());
      }
      }
    }
    //
    //Display y grid lines.
    if (0 != (int(hv_YGrid!=HTuple("none"))))
    {
      if (0 != (int(hv_YGrid==HTuple("min_max_origin"))))
      {
        //Calculate 'min_max_origin' grid line coordinates.
        if (0 != (int(hv_XAxisPosition==hv_YAxisStartValue)))
        {
          hv_YGridValues.Clear();
          hv_YGridValues.Append(hv_YAxisStartValue);
          hv_YGridValues.Append(hv_YAxisEndValue);
        }
        else
        {
          hv_YGridValues.Clear();
          hv_YGridValues.Append(hv_YAxisStartValue);
          hv_YGridValues.Append(hv_XAxisPosition);
          hv_YGridValues.Append(hv_YAxisEndValue);
        }
      }
      else
      {
        //Calculate equidistant grid line coordinates.
        hv_YGridStart = ((hv_YAxisStartValue/hv_YGrid).TupleCeil())*hv_YGrid;
        hv_YGridValues = HTuple::TupleGenSequence(hv_YGridStart,hv_YAxisEndValue,hv_YGrid);
      }
      hv_YCoord = (hv_YGridValues-hv_YAxisStartValue)*hv_YScaleFactor;
      //Generate and display grid lines.
      {
      HTuple end_val450 = (hv_YGridValues.TupleLength())-1;
      HTuple step_val450 = 1;
      for (hv_IndexGrid=0; hv_IndexGrid.Continue(end_val450, step_val450); hv_IndexGrid += step_val450)
      {
        GenContourPolygonXld(&ho_ContourYGrid, ((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexGrid])).TupleConcat((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexGrid])), 
            hv_LeftBorder.TupleConcat(hv_Width-hv_RightBorder));
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ContourYGrid, HDevWindowStack::GetActive());
      }
      }
    }
  }
  SetLineStyle(hv_WindowHandle, HTuple());
  //
  //
  //Display the coordinate system axes.
  if (0 != (int(hv_AxesColor!=HTuple("none"))))
  {
    //Display axes.
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),hv_AxesColor);
    gen_arrow_contour_xld(&ho_XArrow, (hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx, 
        hv_LeftBorder, (hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx, hv_Width-hv_RightBorder, 
        0, 0);
    if (HDevWindowStack::IsOpen())
      DispObj(ho_XArrow, HDevWindowStack::GetActive());
    gen_arrow_contour_xld(&ho_YArrow, hv_Height-hv_LowerBorder, hv_LeftBorder+hv_YAxisOffsetPx, 
        hv_UpperBorder, hv_LeftBorder+hv_YAxisOffsetPx, 0, 0);
    if (HDevWindowStack::IsOpen())
      DispObj(ho_YArrow, HDevWindowStack::GetActive());
    //Display labels.
    GetStringExtents(hv_WindowHandle, hv_XLabel, &hv_Ascent, &hv_Descent, &hv_TextWidthXLabel, 
        &hv_TextHeightXLabel);
    GetStringExtents(hv_WindowHandle, hv_YLabel, &hv_Ascent, &hv_Descent, &hv_TextWidthYLabel, 
        &hv_TextHeightYLabel);
    if (0 != (int(hv_YTickDirection==HTuple("right"))))
    {
      if (0 != (int(hv_XTickDirection==HTuple("up"))))
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_XLabel, "image", ((hv_Height-hv_LowerBorder)-hv_TextHeightXLabel)-3, 
              ((hv_Width-hv_RightBorder)-hv_TextWidthXLabel)-3, hv_AxesColor, "box", 
              "false");
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive()," "+hv_YLabel, "image", hv_UpperBorder, 
              (hv_LeftBorder+3)+hv_YAxisOffsetPx, hv_AxesColor, "box", "false");
      }
      else
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_XLabel, "image", ((hv_Height-hv_LowerBorder)+3)-hv_XAxisOffsetPx, 
              ((hv_Width-hv_RightBorder)-hv_TextWidthXLabel)-3, hv_AxesColor, "box", 
              "false");
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive()," "+hv_YLabel, "image", ((hv_Height-hv_LowerBorder)-hv_TextHeightXLabel)-3, 
              (hv_LeftBorder+3)+hv_YAxisOffsetPx, hv_AxesColor, "box", "false");
      }
    }
    else
    {
      if (0 != (int(hv_XTickDirection==HTuple("up"))))
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_XLabel, "image", ((hv_Height-hv_LowerBorder)-(2*hv_TextHeightXLabel))+3, 
              hv_LeftBorder-3, hv_AxesColor, "box", "false");
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive()," "+hv_YLabel, "image", hv_UpperBorder, 
              ((hv_Width-hv_RightBorder)-hv_TextWidthYLabel)-13, hv_AxesColor, "box", 
              "false");
      }
      else
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_XLabel, "image", ((hv_Height-hv_LowerBorder)+3)-hv_XAxisOffsetPx, 
              hv_LeftBorder-3, hv_AxesColor, "box", "false");
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive()," "+hv_YLabel, "image", ((hv_Height-hv_LowerBorder)-hv_TextHeightXLabel)-3, 
              ((hv_Width-hv_RightBorder)-(2*hv_TextWidthYLabel))-3, hv_AxesColor, 
              "box", "false");
      }
    }
  }
  //
  //Display ticks.
  //
  if (0 != (int(hv_AxesColor!=HTuple("none"))))
  {
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),hv_AxesColor);
    if (0 != (int(hv_XTicks!=HTuple("none"))))
    {
      //
      //Display x ticks.
      if (0 != hv_XValuesAreStrings)
      {
        //Display string XValues as categories.
        hv_XTicks = (hv_XValues.TupleLength())/(hv_XTickValues.TupleLength());
        hv_XCoord = (hv_XValues-hv_XAxisStartValue)*hv_XScaleFactor;
      }
      else
      {
        //Display tick values.
        if (0 != (int(hv_XTicks==HTuple("min_max_origin"))))
        {
          //Calculate 'min_max_origin' tick coordinates.
          if (0 != (int(hv_YAxisPosition==hv_XAxisStartValue)))
          {
            hv_XTickValues.Clear();
            hv_XTickValues.Append(hv_XAxisStartValue);
            hv_XTickValues.Append(hv_XAxisEndValue);
          }
          else
          {
            hv_XTickValues.Clear();
            hv_XTickValues.Append(hv_XAxisStartValue);
            hv_XTickValues.Append(hv_YAxisPosition);
            hv_XTickValues.Append(hv_XAxisEndValue);
          }
        }
        else
        {
          //Calculate equidistant tick coordinates.
          hv_XTickStart = ((hv_XAxisStartValue/hv_XTicks).TupleCeil())*hv_XTicks;
          hv_XTickValues = HTuple::TupleGenSequence(hv_XTickStart,hv_XAxisEndValue,hv_XTicks);
        }
        //Remove ticks that are smaller than the x-axis start.
        hv_Indices = (hv_XTickValues.TupleLessElem(hv_XAxisStartValue)).TupleFind(1);
        hv_XCoord = (hv_XTickValues-hv_XAxisStartValue)*hv_XScaleFactor;
        hv_XCoord = hv_XCoord.TupleRemove(hv_Indices);
        hv_XTickValues = hv_XTickValues.TupleRemove(hv_Indices);
        //
        if (0 != (int(hv_FormatX==HTuple("default"))))
        {
          hv_TypeTicks = hv_XTicks.TupleType();
          if (0 != (int(hv_TypeTicks==4)))
          {
            //String ('min_max_origin').
            //Format depends on actual values.
            hv_TypeTicks = hv_XTickValues.TupleType();
          }
          if (0 != (int(hv_TypeTicks==1)))
          {
            //Round to integer.
            hv_XTickValues = hv_XTickValues.TupleInt();
          }
          else
          {
            //Use floating point numbers.
            hv_XTickValues = hv_XTickValues.TupleString(".2f");
          }
        }
        else
        {
          hv_XTickValues = hv_XTickValues.TupleString(hv_FormatX);
        }
      }
      //Generate and display ticks.
      {
      HTuple end_val539 = (hv_XTickValues.TupleLength())-1;
      HTuple step_val539 = 1;
      for (hv_IndexTicks=0; hv_IndexTicks.Continue(end_val539, step_val539); hv_IndexTicks += step_val539)
      {
        GetStringExtents(hv_WindowHandle, HTuple(hv_XTickValues[hv_IndexTicks]), 
            &hv_Ascent1, &hv_Descent1, &hv_TextWidthXTicks, &hv_TextHeightXTicks);
        if (0 != (int(hv_XTickDirection==HTuple("up"))))
        {
          GenContourPolygonXld(&ho_ContourXTick, ((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx).TupleConcat(((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx)-5), 
              (hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks])).TupleConcat(hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks])));
          if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),HTuple(hv_XTickValues[hv_IndexTicks]), 
                "image", ((hv_Height-hv_LowerBorder)+2)-hv_XAxisOffsetPx, (hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks]))-(0.5*hv_TextWidthXTicks), 
                hv_AxesColor, "box", "false");
        }
        else
        {
          GenContourPolygonXld(&ho_ContourXTick, (((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx)+5).TupleConcat((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx), 
              (hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks])).TupleConcat(hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks])));
          if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),HTuple(hv_XTickValues[hv_IndexTicks]), 
                "image", ((hv_Height-hv_LowerBorder)-(2*hv_TextHeightXTicks))-hv_XAxisOffsetPx, 
                (hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks]))-(0.5*hv_TextWidthXTicks), 
                hv_AxesColor, "box", "false");
        }
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ContourXTick, HDevWindowStack::GetActive());
      }
      }
    }
    //
    if (0 != (int(hv_YTicks!=HTuple("none"))))
    {
      //
      //Display y ticks.

      if (0 != (int(hv_YTicks==HTuple("min_max_origin"))))
      {
        //Calculate 'min_max_origin' tick coordinates.
        if (0 != (int(hv_XAxisPosition==hv_YAxisStartValue)))
        {
          hv_YTickValues.Clear();
          hv_YTickValues.Append(hv_YAxisStartValue);
          hv_YTickValues.Append(hv_YAxisEndValue);
        }
        else
        {
          hv_YTickValues.Clear();
          hv_YTickValues.Append(hv_YAxisStartValue);
          hv_YTickValues.Append(hv_XAxisPosition);
          hv_YTickValues.Append(hv_YAxisEndValue);
        }
      }
      else
      {
        //Calculate equidistant tick coordinates.
        hv_YTickStart = ((hv_YAxisStartValue/hv_YTicks).TupleCeil())*hv_YTicks;
        hv_YTickValues = HTuple::TupleGenSequence(hv_YTickStart,hv_YAxisEndValue,hv_YTicks);
      }

      //Remove ticks that are smaller than the y-axis start.
      hv_Indices = (hv_YTickValues.TupleLessElem(hv_YAxisStartValue)).TupleFind(1);
      hv_YCoord = (hv_YTickValues-hv_YAxisStartValue)*hv_YScaleFactor;
      hv_YCoord = hv_YCoord.TupleRemove(hv_Indices);
      hv_YTickValues = hv_YTickValues.TupleRemove(hv_Indices);
      //
      if (0 != hv_PlotYLog)
      {
        hv_YTickValues = HTuple(10).TuplePow(hv_YTickValues);
      }
      if (0 != (int(hv_FormatY==HTuple("default"))))
      {
        hv_TypeTicks = hv_YTicks.TupleType();
        if (0 != (int(hv_TypeTicks==4)))
        {
          //String ('min_max_origin').
          //Format depends on actual values.
          hv_TypeTicks = hv_YTickValues.TupleType();
        }
        if (0 != (int(hv_TypeTicks==1)))
        {
          //Round to integer.
          hv_YTickValues = hv_YTickValues.TupleInt();
        }
        else
        {
          //Use floating point numbers.
          hv_YTickValues = hv_YTickValues.TupleString(".2f");
        }
      }
      else
      {
        hv_YTickValues = hv_YTickValues.TupleString(hv_FormatY);
      }
      //Generate and display ticks.
      {
      HTuple end_val596 = (hv_YTickValues.TupleLength())-1;
      HTuple step_val596 = 1;
      for (hv_IndexTicks=0; hv_IndexTicks.Continue(end_val596, step_val596); hv_IndexTicks += step_val596)
      {
        GetStringExtents(hv_WindowHandle, HTuple(hv_YTickValues[hv_IndexTicks]), 
            &hv_Ascent1, &hv_Descent1, &hv_TextWidthYTicks, &hv_TextHeightYTicks);
        //Since we only deal with numbers, use the Ascent as text height.
        hv_TextHeightYTicks = hv_Ascent;
        if (0 != (int(hv_YTickDirection==HTuple("right"))))
        {
          GenContourPolygonXld(&ho_ContourYTick, ((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexTicks])).TupleConcat((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexTicks])), 
              (hv_LeftBorder+hv_YAxisOffsetPx).TupleConcat((hv_LeftBorder+hv_YAxisOffsetPx)+5));
          if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),HTuple(hv_YTickValues[hv_IndexTicks]), 
                "image", (((hv_Height-hv_LowerBorder)-hv_TextHeightYTicks)+3)-HTuple(hv_YCoord[hv_IndexTicks]), 
                ((hv_LeftBorder-hv_TextWidthYTicks)-4)+hv_YAxisOffsetPx, hv_Color, 
                "box", "false");
        }
        else
        {
          GenContourPolygonXld(&ho_ContourYTick, ((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexTicks])).TupleConcat((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexTicks])), 
              ((hv_LeftBorder+hv_YAxisOffsetPx)-5).TupleConcat(hv_LeftBorder+hv_YAxisOffsetPx));
          if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),HTuple(hv_YTickValues[hv_IndexTicks]), 
                "image", (((hv_Height-hv_LowerBorder)-hv_TextHeightYTicks)+3)-HTuple(hv_YCoord[hv_IndexTicks]), 
                (hv_LeftBorder+4)+hv_YAxisOffsetPx, hv_Color, "box", "false");
        }
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ContourYTick, HDevWindowStack::GetActive());
      }
      }
    }
  }
  //
  //Display function plot.
  //
  if (0 != (int(hv_Color!=HTuple("none"))))
  {
    if (0 != (HTuple(int(hv_XValues!=HTuple())).TupleAnd(int(hv_YValues!=HTuple()))))
    {
      hv_Num = (hv_YValues.TupleLength())/(hv_XValues.TupleLength());
      //
      //Iterate over all functions to be displayed.
      {
      HTuple end_val619 = hv_Num-1;
      HTuple step_val619 = 1;
      for (hv_I=0; hv_I.Continue(end_val619, step_val619); hv_I += step_val619)
      {
        //Select y values for current function.
        hv_YSelected = hv_YValues.TupleSelectRange(hv_I*(hv_XValues.TupleLength()),((hv_I+1)*(hv_XValues.TupleLength()))-1);
        //Set color
        if (0 != (int(hv_Color==HTuple())))
        {
          SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
        }
        else
        {
          if (HDevWindowStack::IsOpen())
            SetColor(HDevWindowStack::GetActive(),HTuple(hv_Color[hv_I%(hv_Color.TupleLength())]));
        }
        //
        //Display in different styles.
        //
        if (0 != (HTuple(HTuple(HTuple(int(hv_Style==HTuple("line"))).TupleOr(int(hv_Style==HTuple()))).TupleOr(hv_Style.TupleIsReal())).TupleOr(hv_Style.TupleIsInt())))
        {
          //Style = Line. For real value, the line is plotted dashed.
          if (0 != ((hv_Style.TupleIsReal()).TupleOr(hv_Style.TupleIsInt())))
          {
            GetLineStyle(hv_WindowHandle, &hv_StyleOriginal);
            SetLineStyle(hv_WindowHandle, hv_Style.TupleConcat(hv_Style/2.0));
          }
          GenContourPolygonXld(&ho_Contour, ((hv_Height-hv_LowerBorder)-(hv_YSelected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor), 
              ((hv_XValues*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor));
          //Clip, if necessary.
          if (0 != (int(hv_Clip==HTuple("yes"))))
          {
            ClipContoursXld(ho_Contour, &ho_Contour, hv_UpperBorder, hv_LeftBorder, 
                hv_Height-hv_LowerBorder, hv_Width-hv_RightBorder);
          }
          GetLineWidth(hv_WindowHandle, &hv_OldLineWidth);
          if (HDevWindowStack::IsOpen())
            SetLineWidth(HDevWindowStack::GetActive(),hv_LineWidth.TupleInt());
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Contour, HDevWindowStack::GetActive());
          if (HDevWindowStack::IsOpen())
            SetLineWidth(HDevWindowStack::GetActive(),hv_OldLineWidth.TupleInt());
          if (0 != ((hv_Style.TupleIsReal()).TupleOr(hv_Style.TupleIsInt())))
          {
            SetLineStyle(hv_WindowHandle, hv_StyleOriginal);
          }
        }
        else if (0 != (int(hv_Style==HTuple("cross"))))
        {
          //Style = Cross.
          GetLineWidth(hv_WindowHandle, &hv_LineWidth);
          GenCrossContourXld(&ho_Cross, ((hv_Height-hv_LowerBorder)-(hv_YSelected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor), 
              ((hv_XValues*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor), 
              6, 0.785398);
          //Clip, if necessary.
          if (0 != (int(hv_Clip==HTuple("yes"))))
          {
            ClipContoursXld(ho_Cross, &ho_Cross, hv_UpperBorder, hv_LeftBorder, hv_Height-hv_LowerBorder, 
                hv_Width-hv_RightBorder);
          }
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Cross, HDevWindowStack::GetActive());
        }
        else if (0 != (int(hv_Style==HTuple("circle"))))
        {
          //Style = Circle.
          GetLineWidth(hv_WindowHandle, &hv_LineWidth);
          TupleGenConst(hv_YSelected.TupleLength(), 3*hv_LineWidth, &hv_Radii);
          GenCircleContourXld(&ho_Circle, ((hv_Height-hv_LowerBorder)-(hv_YSelected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor), 
              ((hv_XValues*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor), 
              hv_Radii, 0, 6.28318, "positive", 1);
          //Clip, if necessary.
          if (0 != (int(hv_Clip==HTuple("yes"))))
          {
            ClipContoursXld(ho_Circle, &ho_Circle, hv_UpperBorder, hv_LeftBorder, 
                hv_Height-hv_LowerBorder, hv_Width-hv_RightBorder);
          }
          GetContourStyle(hv_WindowHandle, &hv_OldContourStyle);
          SetContourStyle(hv_WindowHandle, "stroke_and_fill");
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Circle, HDevWindowStack::GetActive());
          SetContourStyle(hv_WindowHandle, hv_OldContourStyle);
        }
        else if (0 != (int(hv_Style==HTuple("filled"))))
        {
          //Style = Filled.
          hv_Y1Selected.Clear();
          hv_Y1Selected.Append(0+hv_XAxisPosition);
          hv_Y1Selected.Append(hv_YSelected);
          hv_Y1Selected.Append(0+hv_XAxisPosition);
          hv_X1Selected.Clear();
          hv_X1Selected.Append(hv_XValues.TupleMin());
          hv_X1Selected.Append(hv_XValues);
          hv_X1Selected.Append(hv_XValues.TupleMax());
          if (HDevWindowStack::IsOpen())
            SetDraw(HDevWindowStack::GetActive(),"fill");
          GenRegionPolygonFilled(&ho_Filled, ((hv_Height-hv_LowerBorder)-(hv_Y1Selected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor), 
              ((hv_X1Selected*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor));
          //Clip, if necessary.
          if (0 != (int(hv_Clip==HTuple("yes"))))
          {
            ClipRegion(ho_Filled, &ho_Filled, hv_UpperBorder, hv_LeftBorder, hv_Height-hv_LowerBorder, 
                hv_Width-hv_RightBorder);
          }
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Filled, HDevWindowStack::GetActive());
        }
        else if (0 != (int(hv_Style==HTuple("step"))))
        {
          GenEmptyObj(&ho_Stair);
          {
          HTuple end_val684 = (hv_XValues.TupleLength())-2;
          HTuple step_val684 = 1;
          for (hv_Index=0; hv_Index.Continue(end_val684, step_val684); hv_Index += step_val684)
          {
            hv_Row1 = ((hv_Height-hv_LowerBorder)-(HTuple(hv_YSelected[hv_Index])*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor);
            hv_Row2 = ((hv_Height-hv_LowerBorder)-(HTuple(hv_YSelected[hv_Index+1])*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor);
            hv_Col1 = ((HTuple(hv_XValues[hv_Index])*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor);
            hv_Col2 = ((HTuple(hv_XValues[hv_Index+1])*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor);
            GenContourPolygonXld(&ho_StairTmp, (hv_Row1.TupleConcat(hv_Row1)).TupleConcat(hv_Row2), 
                (hv_Col1.TupleConcat(hv_Col2)).TupleConcat(hv_Col2));
            ConcatObj(ho_Stair, ho_StairTmp, &ho_Stair);
          }
          }
          UnionAdjacentContoursXld(ho_Stair, &ho_Stair, 0.1, 0.1, "attr_keep");
          if (0 != (int(hv_Clip==HTuple("yes"))))
          {
            ClipRegion(ho_Stair, &ho_Stair, hv_UpperBorder, hv_LeftBorder, hv_Height-hv_LowerBorder, 
                hv_Width-hv_RightBorder);
          }
          if (HDevWindowStack::IsOpen())
            DispObj(ho_Stair, HDevWindowStack::GetActive());
        }
        else
        {
          throw HException("Unsupported style: "+hv_Style);
        }
      }
      }
    }
  }
  //
  //
  SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),hv_DrawMode);
  SetLineStyle(hv_WindowHandle, hv_OriginStyle);
  SetSystem("clip_region", hv_ClipRegion);
  return;
}

// Chapter: Tuple / Conversion
// Short Description: Print a tuple of values to a string. 
void pretty_print_tuple (HTuple hv_Tuple, HTuple *hv_TupleStr)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_J;

  //
  //This procedure prints a tuple of values to a string.
  //
  if (0 != (int((hv_Tuple.TupleLength())>1)))
  {
    (*hv_TupleStr) = "[";
    {
    HTuple end_val5 = (hv_Tuple.TupleLength())-1;
    HTuple step_val5 = 1;
    for (hv_J=0; hv_J.Continue(end_val5, step_val5); hv_J += step_val5)
    {
      if (0 != (int(hv_J>0)))
      {
        (*hv_TupleStr) += HTuple(HTuple(","));
      }
      (*hv_TupleStr) += HTuple(hv_Tuple[hv_J]);
    }
    }
    (*hv_TupleStr) += HTuple("]");
  }
  else
  {
    (*hv_TupleStr) = hv_Tuple;
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Reduce the evaluation result to a single value. 
void reduce_dl_evaluation_result (HTuple hv_EvaluationResult, HTuple hv_EvaluationComparisonKeys, 
    HTuple *hv_Value, HTuple *hv_ValidEvaluationKeys)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_TopLevelResult, hv_KeysEvalResult;
  HTuple  hv_NumMatches, hv_FirstMaxNumDetections, hv_KeysFirstMaxNumDetections;
  HTuple  hv_DetectionResult, hv_Index, hv_ClassificationResult;
  HTuple  hv_KeysExist, hv_Indices, hv_Values, hv_K, hv_Key;
  HTuple  hv_Tuple;

  //
  //In order to compare a model we need to reduce the evaluation parameter/result
  //to a single float Value which is comparable via >.
  //
  if (0 != (HTuple(int((hv_EvaluationComparisonKeys.TupleLength())>0)).TupleAnd(int((hv_EvaluationResult.TupleLength())>0))))
  {
    hv_TopLevelResult = hv_EvaluationResult;
    //We need to check for a special case: detection results.
    //They have a complex structure.
    GetDictParam(hv_EvaluationResult, "keys", HTuple(), &hv_KeysEvalResult);
    TupleRegexpTest(hv_KeysEvalResult, "max_num_detections_.*", &hv_NumMatches);
    if (0 != (int(hv_NumMatches>0)))
    {
      //We use only the first results of every level.
      GetDictTuple(hv_EvaluationResult, HTuple(hv_KeysEvalResult[0]), &hv_FirstMaxNumDetections);
      GetDictParam(hv_FirstMaxNumDetections, "keys", HTuple(), &hv_KeysFirstMaxNumDetections);
      GetDictTuple(hv_FirstMaxNumDetections, HTuple(hv_KeysFirstMaxNumDetections[0]), 
          &hv_DetectionResult);
      //We use this result here as the top level to retrieve values.
      hv_EvaluationResult = hv_DetectionResult;
    }
    //We need to check for a special case: classification results.
    //They have a complex structure.
    TupleFind(hv_KeysEvalResult.TupleEqualElem("global"), 1, &hv_Index);
    if (0 != (int(hv_Index!=-1)))
    {
      //We use the results for key 'global'.
      GetDictTuple(hv_EvaluationResult, HTuple(hv_KeysEvalResult[hv_Index]), &hv_ClassificationResult);
      hv_EvaluationResult = hv_ClassificationResult;
    }
    TupleFind(hv_KeysEvalResult.TupleEqualElem("ocr_detection"), 1, &hv_Index);
    if (0 != (int(hv_Index!=-1)))
    {
      //We use the results for key 'ocr_detection'.
      GetDictTuple(hv_TopLevelResult, HTuple(hv_KeysEvalResult[hv_Index]), &hv_EvaluationResult);
    }
    //Reduce comparison to keys that exist.
    GetDictParam(hv_EvaluationResult, "key_exists", hv_EvaluationComparisonKeys, 
        &hv_KeysExist);
    //
    TupleFind(hv_KeysExist, 1, &hv_Indices);
    if (0 != (int(hv_Indices==-1)))
    {
      hv_EvaluationComparisonKeys = HTuple();
    }
    else
    {
      hv_EvaluationComparisonKeys = HTuple(hv_EvaluationComparisonKeys[hv_Indices]);
    }
  }
  //
  (*hv_ValidEvaluationKeys) = hv_EvaluationComparisonKeys;
  //
  (*hv_Value) = 0.0;
  hv_Values = HTuple();
  if (0 != (int((hv_EvaluationResult.TupleLength())>0)))
  {
    {
    HTuple end_val47 = (hv_EvaluationComparisonKeys.TupleLength())-1;
    HTuple step_val47 = 1;
    for (hv_K=0; hv_K.Continue(end_val47, step_val47); hv_K += step_val47)
    {
      hv_Key = HTuple(hv_EvaluationComparisonKeys[hv_K]);
      //
      GetDictTuple(hv_EvaluationResult, hv_Key, &hv_Tuple);
      //Use the mean in order to reduce tuples with length > 1.
      hv_Values = hv_Values.TupleConcat(hv_Tuple.TupleMean());
    }
    }
  }
  else
  {
    (*hv_Value) = -1;
  }
  if (0 != (int((hv_Values.TupleLength())>0)))
  {
    (*hv_Value) = hv_Values.TupleMean();
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Restore serialized DL train information to resume the training. 
void restore_dl_train_info_for_resuming (HTuple hv_StartEpoch, HTuple hv_SerializationData, 
    HTuple hv_TrainParam, HTuple hv_DisplayData, HTuple *hv_EvaluationInfos, HTuple *hv_TrainInfos, 
    HTuple *hv_DisplayEvaluationEpochs, HTuple *hv_DisplayValidationEvaluationValues, 
    HTuple *hv_DisplayTrainEvaluationValues, HTuple *hv_DisplayLossEpochs, HTuple *hv_DisplayLoss, 
    HTuple *hv_DisplayLearningRates, HTuple *hv_TrainResultsRestored, HTuple *hv_StartEpochNumber)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_TrainResults, hv_SerializationStrategies;
  HTuple  hv_RawData, hv_FoundEpochs, hv_FoundDicts, hv_Index;
  HTuple  hv_Strategy, hv_Type, hv_Basename, hv_Substrings;
  HTuple  hv_BaseFolder, hv_Files, hv_DictFiles, hv_EpochStrings;
  HTuple  hv_EpochStringsNumbers, hv_DictFileNames, hv_IndexDict;
  HTuple  hv_DictFileName, hv_InfoDicts, hv_Epochs, hv_ReadSuccess;
  HTuple  hv_InfoDict, hv_Epoch, hv_Exception, hv_EvaluationComparisonKeys;
  HTuple  hv_DisplayEnabled, hv_IndexEval, hv_EvaluationResult;
  HTuple  hv_Value, hv_ValidEvaluationKeys, hv_IndexTrain;
  HTuple  hv_EpochsStatus, hv_MeanLoss, hv_ModelParams, hv_DisplayLearningRate;
  HTuple  hv_LossParam, hv_CountSamples, hv_LossValues, hv_NumMeanLossSamples;
  HTuple  hv_SamplesPerEpoch, hv_MeanLossCur, hv_NumSamplesInterval;
  HTuple  hv_LossValueIdxsPrev, hv_MeanLossCurInterval, hv_LossValuesCurInterval;
  HTuple  hv_IndexSample, hv_TrainResult, hv_NumEpochs;

  //
  //This procedure initializes training relevant parameters that are stored
  //during training. If StartEpoch is greater than zero or equal to 'resume',
  //the procedure restores this information. This allows to properly resume a
  //training that had been paused or should be continued for another reason.
  //
  //Initialize the variable to collect all training results during training.
  hv_TrainResults = HTuple();
  //
  //Initialize the variable to collect the evaluation information during training.
  (*hv_EvaluationInfos) = HTuple();
  (*hv_TrainResultsRestored) = HTuple();
  //
  //Initialize the variable to collect the train status information during training.
  (*hv_TrainInfos) = HTuple();
  //
  //Initialize visualization parameters.
  (*hv_DisplayLossEpochs) = HTuple();
  (*hv_DisplayLoss) = HTuple();
  (*hv_DisplayEvaluationEpochs) = HTuple();
  (*hv_DisplayValidationEvaluationValues) = HTuple();
  (*hv_DisplayTrainEvaluationValues) = HTuple();
  (*hv_DisplayLearningRates) = HTuple();
  //
  //Initialize the start epoch number.
  (*hv_StartEpochNumber) = 0;
  //
  //Training parameters are initialized for new training,
  //hence return if StartEpoch is zero.
  if (0 != (int(hv_StartEpoch==0.0)))
  {
    return;
  }
  //
  //This procedure reads the latest training and evaluation information from disk to resume training.
  //
  //Initialize each serialization strategy.
  GetDictTuple(hv_SerializationData, "strategies", &hv_SerializationStrategies);
  GetDictTuple(hv_SerializationData, "raw_data", &hv_RawData);
  //
  //Loop over all serialization strategies. If more than one is available and StartEpoch='resume',
  //choose the most up-to-date training information that can be found.
  hv_FoundEpochs = HTuple();
  hv_FoundDicts = HTuple();
  {
  HTuple end_val43 = (hv_SerializationStrategies.TupleLength())-1;
  HTuple step_val43 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val43, step_val43); hv_Index += step_val43)
  {
    //
    //Get current strategy and data.
    hv_Strategy = HTuple(hv_SerializationStrategies[hv_Index]);
    GetDictTuple(hv_Strategy, "type", &hv_Type);
    GetDictTuple(hv_Strategy, "basename", &hv_Basename);
    //
    if (0 != (HTuple(HTuple(int(hv_Type==HTuple("best"))).TupleOr(int(hv_Type==HTuple("current")))).TupleOr(int(hv_Type==HTuple("epochs")))))
    {
      //
      if (0 != (int(hv_Type==HTuple("epochs"))))
      {
        //Find the last written training information
        TupleRegexpReplace(hv_Basename, (HTuple("\\\\+").Append("replace_all")), 
            "/", &hv_Basename);
        TupleSplit(hv_Basename, "/", &hv_Substrings);
        hv_BaseFolder = ".";
        if (0 != (int((hv_Substrings.TupleLength())>1)))
        {
          hv_BaseFolder = (hv_Substrings.TupleSelectRange(0,(hv_Substrings.TupleLength())-2))+"/";
        }
        ListFiles(hv_BaseFolder, "files", &hv_Files);
        TupleRegexpSelect(hv_Files, "[0-9]\\.[0-9]*_info\\.hdict", &hv_DictFiles);
        TupleRegexpMatch(hv_DictFiles, "[0-9]\\.[0-9]*", &hv_EpochStrings);
        hv_EpochStringsNumbers = hv_EpochStrings.TupleNumber();
        TupleGenConst(hv_EpochStrings.TupleLength(), "", &hv_DictFileNames);
        {
        HTuple end_val65 = (hv_EpochStrings.TupleLength())-1;
        HTuple step_val65 = 1;
        for (hv_IndexDict=0; hv_IndexDict.Continue(end_val65, step_val65); hv_IndexDict += step_val65)
        {
          TupleRegexpSelect(hv_DictFiles, (HTuple(hv_EpochStringsNumbers[hv_IndexDict]).TupleString(".2f"))+"_info.hdict", 
              &hv_DictFileName);
          if (0 != (int((hv_DictFileName.TupleLength())!=0)))
          {
            hv_DictFileNames[hv_IndexDict] = hv_DictFileName;
          }
        }
        }
      }
      else
      {
        hv_DictFileNames = hv_Basename+"_info.hdict";
      }
      //
      //Try to read in the training information dictionaries.
      TupleGenConst(hv_DictFileNames.TupleLength(), -1, &hv_InfoDicts);
      TupleGenConst(hv_DictFileNames.TupleLength(), -1, &hv_Epochs);
      hv_ReadSuccess = 0;
      {
      HTuple end_val79 = (hv_DictFileNames.TupleLength())-1;
      HTuple step_val79 = 1;
      for (hv_IndexDict=0; hv_IndexDict.Continue(end_val79, step_val79); hv_IndexDict += step_val79)
      {
        try
        {
          ReadDict(HTuple(hv_DictFileNames[hv_IndexDict]), HTuple(), HTuple(), &hv_InfoDict);
          GetDictTuple(hv_InfoDict, "epoch", &hv_Epoch);
          hv_InfoDicts[hv_IndexDict] = hv_InfoDict;
          hv_Epochs[hv_IndexDict] = hv_Epoch;
          hv_ReadSuccess = 1;
        }
        // catch (Exception) 
        catch (HException &HDevExpDefaultException)
        {
          HDevExpDefaultException.ToHTuple(&hv_Exception);
        }
      }
      }
      if (0 != (hv_ReadSuccess.TupleNot()))
      {
        //Not even a single file has been found.
        continue;
      }
      //
      hv_FoundEpochs = hv_FoundEpochs.TupleConcat(hv_Epochs);
      hv_FoundDicts = hv_FoundDicts.TupleConcat(hv_InfoDicts);
      //
    }
    else if (0 != (int(hv_Type==HTuple("final"))))
    {
      //Nothing to restore.
      continue;
    }
    else
    {
      throw HException(("Unknown serialization strategy type: '"+hv_Type)+"'");
    }
  }
  }
  //
  //Check if training can or needs to be resumed.
  if (0 != (int(hv_StartEpoch==HTuple("resume"))))
  {
    //Resume at highest epoch available.
    hv_Epoch = hv_FoundEpochs.TupleMax();
    if (0 != (int(hv_Epoch<0.0)))
    {
      throw HException("No training information found. Training cannot be resumed.");
    }
    hv_Index = (hv_FoundEpochs.TupleEqualElem(hv_Epoch)).TupleFindFirst(1);
    hv_InfoDict = HTuple(hv_FoundDicts[hv_Index]);
    hv_StartEpoch = hv_Epoch;
  }
  else
  {
    //Check if requested StartEpoch was found.
    hv_Index = (hv_FoundEpochs.TupleEqualElem(hv_StartEpoch)).TupleFindFirst(1);
    if (0 != (HTuple(int(hv_Index!=HTuple())).TupleAnd(int(hv_Index!=-1))))
    {
      hv_InfoDict = HTuple(hv_FoundDicts[hv_Index]);
    }
    else
    {
      //Try to find the rounded value as it is serialized.
      hv_Index = ((hv_FoundEpochs.TupleString(".2f")).TupleEqualElem(hv_StartEpoch.TupleString(".2f"))).TupleFindFirst(1);
      if (0 != (HTuple(int(hv_Index!=HTuple())).TupleAnd(int(hv_Index!=-1))))
      {
        hv_InfoDict = HTuple(hv_FoundDicts[hv_Index]);
      }
      else
      {
        throw HException("No training information matches requested StartEpoch "+hv_StartEpoch);
      }
    }
  }
  //
  //Get evaluation and training information.
  GetDictTuple(hv_InfoDict, "evaluation_infos", &(*hv_EvaluationInfos));
  GetDictTuple(hv_InfoDict, "train_infos", &(*hv_TrainInfos));
  GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
  //
  //Restore history of display values.
  GetDictTuple(hv_DisplayData, "enabled", &hv_DisplayEnabled);
  if (0 != hv_DisplayEnabled)
  {
    {
    HTuple end_val139 = ((*hv_EvaluationInfos).TupleLength())-1;
    HTuple step_val139 = 1;
    for (hv_IndexEval=0; hv_IndexEval.Continue(end_val139, step_val139); hv_IndexEval += step_val139)
    {
      GetDictTuple(HTuple((*hv_EvaluationInfos)[hv_IndexEval]), "result", &hv_EvaluationResult);
      reduce_dl_evaluation_result(hv_EvaluationResult, hv_EvaluationComparisonKeys, 
          &hv_Value, &hv_ValidEvaluationKeys);
      (*hv_DisplayValidationEvaluationValues) = (*hv_DisplayValidationEvaluationValues).TupleConcat(hv_Value);
      hv_Value = -1;
      try
      {
        GetDictTuple(HTuple((*hv_EvaluationInfos)[hv_IndexEval]), "train_result", 
            &hv_EvaluationResult);
        reduce_dl_evaluation_result(hv_EvaluationResult, hv_EvaluationComparisonKeys, 
            &hv_Value, &hv_ValidEvaluationKeys);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
      }
      (*hv_DisplayTrainEvaluationValues) = (*hv_DisplayTrainEvaluationValues).TupleConcat(hv_Value);
      GetDictTuple(HTuple((*hv_EvaluationInfos)[hv_IndexEval]), "epoch", &hv_Epoch);
      (*hv_DisplayEvaluationEpochs) = (*hv_DisplayEvaluationEpochs).TupleConcat(hv_Epoch);
    }
    }
    {
    HTuple end_val153 = ((*hv_TrainInfos).TupleLength())-1;
    HTuple step_val153 = 1;
    for (hv_IndexTrain=0; hv_IndexTrain.Continue(end_val153, step_val153); hv_IndexTrain += step_val153)
    {
      GetDictTuple(HTuple((*hv_TrainInfos)[hv_IndexTrain]), "epoch", &hv_EpochsStatus);
      (*hv_DisplayLossEpochs) = (*hv_DisplayLossEpochs).TupleConcat(hv_EpochsStatus);
      GetDictTuple(HTuple((*hv_TrainInfos)[hv_IndexTrain]), "mean_loss", &hv_MeanLoss);
      (*hv_DisplayLoss) = (*hv_DisplayLoss).TupleConcat(hv_MeanLoss);
      GetDictTuple(HTuple((*hv_TrainInfos)[hv_IndexTrain]), "model_params", &hv_ModelParams);
      GetDictTuple(hv_ModelParams, "learning_rate", &hv_DisplayLearningRate);
      (*hv_DisplayLearningRates) = (*hv_DisplayLearningRates).TupleConcat(hv_DisplayLearningRate);
    }
    }
  }
  //
  //Restore dictionaries that contain the approximate loss-values for each iteration.
  //We cannot reconstruct the exact loss values, therefore, we use the serialized mean values.
  hv_LossParam = "total_loss";
  hv_CountSamples = 0;
  hv_LossValues = HTuple();
  GetDictTuple(HTuple((*hv_TrainInfos)[0]), "epoch", &hv_Epoch);
  GetDictTuple(HTuple((*hv_TrainInfos)[0]), "mean_loss_samples", &hv_NumMeanLossSamples);
  hv_SamplesPerEpoch = (hv_NumMeanLossSamples.TupleReal())/hv_Epoch;
  //
  {
  HTuple end_val173 = ((*hv_TrainInfos).TupleLength())-1;
  HTuple step_val173 = 1;
  for (hv_IndexTrain=0; hv_IndexTrain.Continue(end_val173, step_val173); hv_IndexTrain += step_val173)
  {
    GetDictTuple(HTuple((*hv_TrainInfos)[hv_IndexTrain]), "mean_loss", &hv_MeanLossCur);
    GetDictTuple(HTuple((*hv_TrainInfos)[hv_IndexTrain]), "mean_loss_samples", &hv_NumMeanLossSamples);
    //The iterations within one interval are not fixed.
    //Calculate the current iteration and the number of iterations within the interval based on the epoch.
    GetDictTuple(HTuple((*hv_TrainInfos)[hv_IndexTrain]), "epoch", &hv_Epoch);
    hv_NumSamplesInterval = ((hv_Epoch*hv_SamplesPerEpoch).TupleRound())-hv_CountSamples;
    //For multiple resuming it can happen that more than one train-info for the same time-point exists.
    if (0 != (int(hv_NumSamplesInterval==0)))
    {
      continue;
    }
    //Calculate the mean loss within the interval between the previous and the current serialization time-point.
    hv_LossValueIdxsPrev = HTuple::TupleGenSequence((hv_LossValues.TupleLength())-(hv_NumMeanLossSamples-hv_NumSamplesInterval),(hv_LossValues.TupleLength())-1,1).TupleInt();
    if (0 != (hv_LossValueIdxsPrev.TupleLength()))
    {
      //The total mean loss (MeanLossCur) consists of the mean loss within this interval (MeanLossCurInterval) and
      //the fraction of previous samples.
      hv_MeanLossCurInterval = ((hv_MeanLossCur*hv_NumMeanLossSamples)-(HTuple(hv_LossValues[hv_LossValueIdxsPrev]).TupleSum()))/hv_NumSamplesInterval;
    }
    else
    {
      //In this case the total mean loss is just the loss of this interval.
      hv_MeanLossCurInterval = hv_MeanLossCur;
    }
    //
    hv_LossValuesCurInterval = HTuple(hv_NumSamplesInterval,hv_MeanLossCurInterval);
    hv_LossValues = hv_LossValues.TupleConcat(hv_LossValuesCurInterval);
    //
    //Pack the loss values into dictionaries.
    (*hv_TrainResultsRestored) = (*hv_TrainResultsRestored).TupleConcat(HTuple(hv_NumSamplesInterval,-1));
    {
    HTuple end_val200 = hv_NumSamplesInterval-1;
    HTuple step_val200 = 1;
    for (hv_IndexSample=0; hv_IndexSample.Continue(end_val200, step_val200); hv_IndexSample += step_val200)
    {
      CreateDict(&hv_TrainResult);
      SetDictTuple(hv_TrainResult, hv_LossParam, HTuple(hv_LossValuesCurInterval[hv_IndexSample]));
      (*hv_TrainResultsRestored)[hv_CountSamples] = hv_TrainResult;
      hv_CountSamples += 1;
    }
    }
  }
  }
  //
  //Plot the current training status.
  if (0 != hv_DisplayEnabled)
  {
    GetDictTuple(hv_TrainParam, "num_epochs", &hv_NumEpochs);
    SetDictTuple(HTuple((*hv_TrainInfos)[((*hv_TrainInfos).TupleLength())-1]), "num_epochs", 
        hv_NumEpochs);
    dev_display_update_train_dl_model(hv_TrainParam, hv_DisplayData, HTuple((*hv_TrainInfos)[((*hv_TrainInfos).TupleLength())-1]), 
        (*hv_DisplayLossEpochs), (*hv_DisplayLoss), (*hv_DisplayLearningRates), (*hv_DisplayEvaluationEpochs), 
        (*hv_DisplayValidationEvaluationValues), (*hv_DisplayTrainEvaluationValues));
  }
  //
  //Return StartEpoch as number.
  (*hv_StartEpochNumber) = hv_StartEpoch;
  //
  return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Scale and shift a DL model layer. 
void scale_and_shift_dl_model_layer (HTuple hv_DLModelHandle, HTuple hv_LayerName, 
    HTuple hv_Scale, HTuple hv_Shift)
{

  // Local iconic variables
  HObject  ho_Weights, ho_Bias, ho_WeightsScaled;
  HObject  ho_ChannelWeights, ho_ChannelWeightsScaled, ho_BiasScaled;

  // Local control variables
  HTuple  hv_BiasTuple, hv_NumOutputChannels, hv_BiasScaledTuple;
  HTuple  hv_OutputChannelIndex, hv_ChannelMult, hv_ChannelAdd;
  HTuple  hv_ChannelBias, hv_ChannelBiasScaled;

  //Get the original weights.
  GetDlModelLayerWeights(&ho_Weights, hv_DLModelHandle, hv_LayerName, "weights");
  GetDlModelLayerWeights(&ho_Bias, hv_DLModelHandle, hv_LayerName, "bias");
  GetGrayval(ho_Bias, 0, 0, &hv_BiasTuple);
  CountObj(ho_Weights, &hv_NumOutputChannels);
  //Create collections for the new weights and biases.
  GenEmptyObj(&ho_WeightsScaled);
  hv_BiasScaledTuple = HTuple(hv_NumOutputChannels,0);
  //Iterate over the output channels.
  {
  HTuple end_val9 = hv_NumOutputChannels-1;
  HTuple step_val9 = 1;
  for (hv_OutputChannelIndex=0; hv_OutputChannelIndex.Continue(end_val9, step_val9); hv_OutputChannelIndex += step_val9)
  {
    hv_ChannelMult = HTuple(hv_Scale[hv_OutputChannelIndex]);
    hv_ChannelAdd = HTuple(hv_Shift[hv_OutputChannelIndex]);
    //Get the weights and bias of this channel.
    SelectObj(ho_Weights, &ho_ChannelWeights, hv_OutputChannelIndex+1);
    hv_ChannelBias = HTuple(hv_BiasTuple[hv_OutputChannelIndex]);
    //Each weight scalar needs to be multiplied with ChannelMult.
    ScaleImage(ho_ChannelWeights, &ho_ChannelWeightsScaled, hv_ChannelMult, 0);
    //The bias needs to be multiplied with ChannelMult and
    //added to ChannelAdd.
    hv_ChannelBiasScaled = (hv_ChannelBias*hv_ChannelMult)+hv_ChannelAdd;
    //Store the scaled weights and bias.
    ConcatObj(ho_WeightsScaled, ho_ChannelWeightsScaled, &ho_WeightsScaled);
    hv_BiasScaledTuple[hv_OutputChannelIndex] = hv_ChannelBiasScaled;
  }
  }
  //Create the new bias image.
  CopyImage(ho_Bias, &ho_BiasScaled);
  SetGrayval(ho_BiasScaled, 0, 0, hv_BiasScaledTuple);
  //Set the weights in the model.
  SetDlModelLayerWeights(ho_WeightsScaled, hv_DLModelHandle, hv_LayerName, "weights");
  SetDlModelLayerWeights(ho_BiasScaled, hv_DLModelHandle, hv_LayerName, "bias");
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Serialize a DLModelHandle with current meta information. 
void serialize_train_dl_model_intermediate (HTuple hv_DLModelHandle, HTuple hv_Epoch, 
    HTuple hv_EvaluationValueReduced, HTuple hv_Strategy, HTuple hv_TrainInfos, HTuple hv_EvaluationInfos, 
    HTuple *hv_FilenameModel, HTuple *hv_FilenameMetaData)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Type, hv_Basename, hv_Exception, hv_Epochs;
  HTuple  hv_Index, hv_MetaData;

  //
  //Serialize the model DLModelHandle with current meta information.
  //
  //We need the type of strategy used.
  GetDictTuple(hv_Strategy, "type", &hv_Type);

  //Get basename/default.
  try
  {
    GetDictTuple(hv_Strategy, "basename", &hv_Basename);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    if (0 != (int(hv_Type==HTuple("epochs"))))
    {
      hv_Basename = "model_at_epoch";
    }
    else
    {
      hv_Basename = hv_Type;
    }
  }
  //
  //If we serialize epochs and only one basename is given,
  //we need to add the current epoch to it.
  //If a basename has been specified for each epoch,
  //appending the current epoch is not necessary.
  if (0 != (int(hv_Type==HTuple("epochs"))))
  {
    GetDictTuple(hv_Strategy, "epochs", &hv_Epochs);
    if (0 != (int((hv_Basename.TupleLength())==(hv_Epochs.TupleLength()))))
    {
      TupleFindLast(hv_Epoch.TupleLessElem(hv_Epochs), 0, &hv_Index);
      hv_Basename = HTuple(hv_Basename[hv_Index]);
    }
    else
    {
      hv_Basename = (hv_Basename+"_")+(hv_Epoch.TupleString(".2f"));
    }
  }
  //
  //Filenames.
  (*hv_FilenameModel) = hv_Basename+".hdl";
  (*hv_FilenameMetaData) = hv_Basename+"_info.hdict";
  //
  //Metadata.
  CreateDict(&hv_MetaData);
  SetDictTuple(hv_MetaData, "train_infos", hv_TrainInfos);
  SetDictTuple(hv_MetaData, "evaluation_infos", hv_EvaluationInfos);
  SetDictTuple(hv_MetaData, "epoch", hv_Epoch);
  if (0 != (int((hv_EvaluationValueReduced.TupleLength())>=1)))
  {
    SetDictTuple(hv_MetaData, "best_value", hv_EvaluationValueReduced);
  }
  //
  //Write files.
  WriteDlModel(hv_DLModelHandle, (*hv_FilenameModel));
  WriteDict(hv_MetaData, (*hv_FilenameMetaData), HTuple(), HTuple());
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Set the model parameters based on preprocessing parameters. 
void set_dl_model_param_based_on_preprocessing (HTuple hv_DLModelHandle, HTuple hv_DLPreprocessParam, 
    HTuple hv_ClassIDs)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ModelType, hv_ImageWidth, hv_ImageHeight;
  HTuple  hv_ImageNumChannels, hv_ImageRangeMin, hv_ImageRangeMax;
  HTuple  hv_ImageRangeMinModel, hv_ImageRangeMaxModel, hv_ClassIDsBackground;
  HTuple  hv_IgnoreClassIDs, hv_RemoveClassIDs, hv_Index;
  HTuple  hv_ClassID, hv_IndexFind;

  //
  //This procedure sets the model parameters based on preprocessing parameters.
  //Thereby, the deep-learning-based model has to be of type segmentation.
  //
  GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
  //
  if (0 != (int(hv_ModelType==HTuple("segmentation"))))
  {
    //Get image dimensions from preprocessing.
    GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
    GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
    GetDictTuple(hv_DLPreprocessParam, "image_num_channels", &hv_ImageNumChannels);
    //
    //Set the image dimensions in the model.
    SetDlModelParam(hv_DLModelHandle, "image_width", hv_ImageWidth);
    SetDlModelParam(hv_DLModelHandle, "image_height", hv_ImageHeight);
    SetDlModelParam(hv_DLModelHandle, "image_num_channels", hv_ImageNumChannels);
    //
    //Check that image range is the same as in the model.
    GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
    GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
    GetDlModelParam(hv_DLModelHandle, "image_range_min", &hv_ImageRangeMinModel);
    GetDlModelParam(hv_DLModelHandle, "image_range_max", &hv_ImageRangeMaxModel);
    if (0 != (HTuple(int(hv_ImageRangeMin!=hv_ImageRangeMinModel)).TupleOr(int(hv_ImageRangeMax!=hv_ImageRangeMaxModel))))
    {
      throw HException("Warning: The preprocessed image range should be equal to the model range.");
    }
    //
    //Remove all background and ignore class IDs.
    GetDictTuple(hv_DLPreprocessParam, "class_ids_background", &hv_ClassIDsBackground);
    GetDictTuple(hv_DLPreprocessParam, "ignore_class_ids", &hv_IgnoreClassIDs);
    hv_RemoveClassIDs.Clear();
    hv_RemoveClassIDs.Append(hv_ClassIDsBackground);
    hv_RemoveClassIDs.Append(hv_IgnoreClassIDs);
    {
    HTuple end_val30 = (hv_RemoveClassIDs.TupleLength())-1;
    HTuple step_val30 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val30, step_val30); hv_Index += step_val30)
    {
      hv_ClassID = HTuple(hv_RemoveClassIDs[hv_Index]);
      TupleFindFirst(hv_ClassIDs, hv_ClassID, &hv_IndexFind);
      if (0 != (HTuple(int((hv_IndexFind.TupleLength())>0)).TupleAnd(int(hv_IndexFind!=-1))))
      {
        TupleRemove(hv_ClassIDs, hv_IndexFind, &hv_ClassIDs);
      }
    }
    }
    //Set class IDs.
    SetDlModelParam(hv_DLModelHandle, "class_ids", hv_ClassIDs);
    //Set ignore class IDs.
    SetDlModelParam(hv_DLModelHandle, "ignore_class_ids", hv_IgnoreClassIDs);
  }
  else
  {
    throw HException("Procedure is only applicable for models of type 'segmentation'.");
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Train a deep-learning-based model on a dataset. 
void train_dl_model (HTuple hv_DLDataset, HTuple hv_DLModelHandle, HTuple hv_TrainParam, 
    HTuple hv_StartEpoch, HTuple *hv_TrainResults, HTuple *hv_TrainInfos, HTuple *hv_EvaluationInfos)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ModelType, hv_DLSamples, hv_TrainSampleIndices;
  HTuple  hv_NumTrainSamples, hv_EvaluationComparisonKeyExist;
  HTuple  hv_EvaluationComparisonKeys, hv_EvaluationOptimizationMethod;
  HTuple  hv_NumEpochs, hv_SeedRand, hv_SampleIndicesTrainRaw;
  HTuple  hv_Index, hv_Shuffled, hv_SampleSeedsTrainRaw, hv_BatchSize;
  HTuple  hv_EvaluateBeforeTraining, hv_ChangeStrategyData;
  HTuple  hv_SerializationData, hv_DisplayData, hv_DisplayEnabled;
  HTuple  hv_DisplayPreviewInitialized, hv_DisplayEvaluationEpochs;
  HTuple  hv_DisplayValidationEvaluationValues, hv_DisplayTrainEvaluationValues;
  HTuple  hv_DisplayLossEpochs, hv_DisplayLoss, hv_DisplayLearningRates;
  HTuple  hv_TrainResultsRestored, hv_StartTime, hv_ThresholdInformation;
  HTuple  hv_FirstIteration, hv_Epoch, hv_Iteration, hv_NumIterationsPerEpoch;
  HTuple  hv_BatchSizeDevice, hv_BatchSizeMultiplier, hv_BatchSizeModel;
  HTuple  hv_NumIterations, hv_SampleIndicesTrain, hv_IterationEvaluateOnly;
  HTuple  hv_BatchStart, hv_BatchEnd, hv_BatchIndices, hv_DLSampleBatch;
  HTuple  hv_AugmentationParam, hv_TrainResult, hv_EvaluationIntervalEpochs;
  HTuple  hv_EvaluationInterval, hv_ValidationEvaluationResult;
  HTuple  hv_TrainEvaluationResult, hv_DisplayParam, hv_SelectPercentageTrainSamples;
  HTuple  hv_EvaluationParam, hv__, hv_TrainEvaluationRatio;
  HTuple  hv_NumTrainEvaluationSampleIndices, hv_TrainEvaluationSampleIndices;
  HTuple  hv_Exception, hv_EvaluationInfo, hv_Valuevalidation;
  HTuple  hv_ValueTrain, hv_TrainInfoUpdateIntervalSeconds;
  HTuple  hv_LastUpdate, hv_Seconds, hv_NumSamplesMeanLoss;
  HTuple  hv_TrainInfo, hv_UpdateTime, hv_EpochsStatus, hv_MeanLoss;
  HTuple  hv_DisplayLearningRate, hv_NumImages, hv_UpdateImagesIntervalEpochs;
  HTuple  hv_UpdateImagesInterval, hv_WindowImages, hv_FirstCall;
  HTuple  hv_GenParamTiled, hv_TrainParamAnomaly, hv_WindowHandleInfo;
  HTuple  hv___Tmp_Ctrl_Dict_Init_0, hv___Tmp_Ctrl_0;

  //
  //This procedure contains all steps for training a model given through DLModelHandle
  //on a dataset DLDataset.
  //The required training parameters are provided through the dictionary TrainParam,
  //which can be created by create_dl_train_param.
  //The training is started at StartEpoch, which allows resuming the training of a model.
  //In case of models of type 'anomaly_detection', training cannot be resumed and hence,
  //StartEpoch is always 0.
  //
  //The procedure returns three dictionaries:
  //- TrainResults: Collected results returned by train_dl_model_batch of every iteration.
  //                For models of type 'anomaly_detection': The final error and the final epoch.
  //- TrainInfo: Collected information of the training progress. This dictionary is empty
  //             for models of type 'anomaly_detection'.
  //- EvaluationInfos: Evaluation results collected during training. This dictionary is empty
  //                   for models of type 'anomaly_detection'.
  //
  //Get the model type.
  GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
  if (0 != (HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(int(hv_ModelType!=HTuple("anomaly_detection"))).TupleAnd(int(hv_ModelType!=HTuple("classification")))).TupleAnd(int(hv_ModelType!=HTuple("detection")))).TupleAnd(int(hv_ModelType!=HTuple("gc_anomaly_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_recognition")))).TupleAnd(int(hv_ModelType!=HTuple("segmentation")))).TupleAnd(int(hv_ModelType!=HTuple("3d_gripping_point_detection")))))
  {
    throw HException(("Current model type is not supported: \""+hv_ModelType)+"\"");
  }
  //
  //Get the samples for training.
  GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
  find_dl_samples(hv_DLSamples, "split", "train", "match", &hv_TrainSampleIndices);
  hv_NumTrainSamples = hv_TrainSampleIndices.TupleLength();
  //
  //Check inconsistent training parameters.
  check_train_dl_model_params(hv_DLDataset, hv_DLModelHandle, hv_NumTrainSamples, 
      hv_StartEpoch, hv_TrainParam);
  //
  //Determine evaluation optimization method.
  GetDictParam(hv_TrainParam, "key_exists", "evaluation_comparison_keys", &hv_EvaluationComparisonKeyExist);
  if (0 != hv_EvaluationComparisonKeyExist)
  {
    GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
    get_dl_evaluation_optimization_method(hv_EvaluationComparisonKeys, &hv_EvaluationOptimizationMethod);
  }
  //
  if (0 != (int(hv_ModelType!=HTuple("anomaly_detection"))))
  {
    //
    //Check if training is required.
    GetDictTuple(hv_TrainParam, "num_epochs", &hv_NumEpochs);
    if (0 != (hv_StartEpoch.TupleIsNumber()))
    {
      if (0 != (int(hv_StartEpoch>=hv_NumEpochs)))
      {
        //Nothing to do.
        return;
      }
    }
    //
    //Set random seed according to parameter value.
    GetDictTuple(hv_TrainParam, "seed_rand", &hv_SeedRand);
    if (0 != (int((hv_SeedRand.TupleLength())>0)))
    {
      //Note, that setting this random seed will not enforce every training to
      //result in the exact same model because the cuDNN library uses approximate
      //algorithms on some architectures.
      //If you want to enforce bit-wise reproducibility, you should also set:
      //   'set_system('cudnn_deterministic', 'true')'
      //However, this can slow down computations on some architectures.
      SetSystem("seed_rand", hv_SeedRand);
    }
    //
    //Generate a random sample index for the whole training independent of batch size.
    hv_SampleIndicesTrainRaw = HTuple();
    {
    HTuple end_val63 = (hv_NumEpochs.TupleCeil())-1;
    HTuple step_val63 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val63, step_val63); hv_Index += step_val63)
    {
      tuple_shuffle(hv_TrainSampleIndices, &hv_Shuffled);
      hv_SampleIndicesTrainRaw = hv_SampleIndicesTrainRaw.TupleConcat(hv_Shuffled);
    }
    }
    //
    //Generate a random seed pool for the whole training independent of batch size.
    hv_SampleSeedsTrainRaw = HTuple(((HTuple(2).TuplePow(31))-1)*HTuple::TupleRand(hv_SampleIndicesTrainRaw.TupleLength())).TupleInt();
    //
    //Initialize the variables for the training.
    //
    //Initialize the batch size with an invalid value so that
    //the while loop will initialize all values directly.
    hv_BatchSize = -1;
    //Initialize iteration overhead parameter to 0 or 1.
    //0: if no evaluation before training is performed
    //1: if evaluation before training is performed
    CreateDict(&hv___Tmp_Ctrl_Dict_Init_0);
    SetDictTuple(hv___Tmp_Ctrl_Dict_Init_0, "comp", "true");
    hv_EvaluateBeforeTraining = (hv_TrainParam.TupleConcat(hv___Tmp_Ctrl_Dict_Init_0)).TupleTestEqualDictItem("evaluate_before_train","comp");
    hv___Tmp_Ctrl_Dict_Init_0 = HTuple::TupleConstant("HNULL");
    //
    //Initialize change strategies.
    init_train_dl_model_change_strategies(hv_TrainParam, &hv_ChangeStrategyData);
    //
    //Initialize serialization strategies.
    init_train_dl_model_serialization_strategies(hv_TrainParam, &hv_SerializationData);
    //
    //Initialize visualizations if enabled.
    dev_display_init_train_dl_model(hv_DLModelHandle, hv_TrainParam, &hv_DisplayData);
    GetDictTuple(hv_DisplayData, "enabled", &hv_DisplayEnabled);
    hv_DisplayPreviewInitialized = 0;
    //
    //Initialize parameters to start new or resume previous training.
    restore_dl_train_info_for_resuming(hv_StartEpoch, hv_SerializationData, hv_TrainParam, 
        hv_DisplayData, &(*hv_EvaluationInfos), &(*hv_TrainInfos), &hv_DisplayEvaluationEpochs, 
        &hv_DisplayValidationEvaluationValues, &hv_DisplayTrainEvaluationValues, 
        &hv_DisplayLossEpochs, &hv_DisplayLoss, &hv_DisplayLearningRates, &hv_TrainResultsRestored, 
        &hv_StartEpoch);
    //
    //Start time for measurement of elapsed training time.
    CountSeconds(&hv_StartTime);
    //
    //In case of a 'gc_anomaly_detection' model it is necessary to normalize
    //the model outputs before training.
    if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
    {
      if (0 != hv_DisplayEnabled)
      {
        hv_ThresholdInformation.Clear();
        hv_ThresholdInformation[0] = "Preparing the model for training";
        hv_ThresholdInformation[1] = "by analyzing image statistics...";
        if (HDevWindowStack::IsOpen())
          ClearWindow(HDevWindowStack::GetActive());
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_ThresholdInformation, "window", 
              "top", "left", "black", "box", "false");
        CountSeconds(&hv___Tmp_Ctrl_0);
        SetDictTuple(hv_DisplayData, "last_update", hv___Tmp_Ctrl_0);
      }
      normalize_dl_gc_anomaly_features(hv_DLDataset, hv_DLModelHandle, HTuple());
    }
    //
    //The while loop needs to know if it is the very first iteration.
    hv_FirstIteration = 1;
    while (true)
    {
      //Do some initializations only for the very first iteration.
      if (0 != hv_FirstIteration)
      {
        //Jump to StartEpoch (Default: 0 but it could be used to resume training at given StartIteration).
        hv_Epoch = hv_StartEpoch;
      }
      else
      {
        hv_Epoch = (hv_Iteration+1)/(hv_NumIterationsPerEpoch.TupleReal());
      }
      //
      //Update any parameters based on strategies.
      update_train_dl_model_change_strategies(hv_DLModelHandle, hv_ChangeStrategyData, 
          hv_Epoch);
      //
      //Check if the current batch size and total model batch size differ.
      GetDlModelParam(hv_DLModelHandle, "batch_size", &hv_BatchSizeDevice);
      GetDlModelParam(hv_DLModelHandle, "batch_size_multiplier", &hv_BatchSizeMultiplier);
      hv_BatchSizeModel = hv_BatchSizeDevice*hv_BatchSizeMultiplier;
      //
      if (0 != (HTuple(int(hv_BatchSize!=hv_BatchSizeModel)).TupleOr(hv_FirstIteration)))
      {
        //Set the current value.
        hv_BatchSize = hv_BatchSizeModel;
        //Now, we compute all values which are related to the batch size of the model.
        //That way, the batch_size can be changed during the training without issues.
        //All inputs/outputs/visualizations are based on epochs.
        //
        //Calculate total number of iterations.
        hv_NumIterationsPerEpoch = ((hv_NumTrainSamples/(hv_BatchSize.TupleReal())).TupleFloor()).TupleInt();
        hv_NumIterations = (hv_NumIterationsPerEpoch*hv_NumEpochs).TupleInt();
        //Select those indices that fit into the batch size.
        hv_SampleIndicesTrain = hv_SampleIndicesTrainRaw.TupleSelectRange(0,(hv_NumIterations*hv_BatchSize)-1);
        //The TrainResults tuple will be updated every iteration.
        //Hence, we initialize it as a constant tuple for speedup.
        //It is based on the iterations and hence cannot be reused if the batch size changes.
        TupleGenConst(hv_NumIterations, -1, &(*hv_TrainResults));
        if (0 != (hv_FirstIteration.TupleNot()))
        {
          hv_Iteration = (((hv_Epoch.TupleReal())*hv_NumIterationsPerEpoch).TupleFloor()).TupleInt();
          hv_Epoch = (hv_Iteration+1)/(hv_NumIterationsPerEpoch.TupleReal());
        }
      }
      //
      //In the first iteration do some initializations.
      if (0 != hv_FirstIteration)
      {
        //Jump to StartEpoch (Default: 0 but it could be used to resume training at given StartIteration).
        hv_Iteration = (((hv_StartEpoch.TupleReal())*hv_NumIterationsPerEpoch).TupleFloor()).TupleInt();
        hv_FirstIteration = 0;
        if (0 != (int(((hv_Iteration*hv_BatchSize)+hv_BatchSize)>(hv_SampleIndicesTrain.TupleLength()))))
        {
          hv_Iteration = hv_NumIterations-1;
          break;
        }
        if (0 != (HTuple(int(hv_StartEpoch>0.0)).TupleAnd(int((hv_TrainResultsRestored.TupleLength())>0))))
        {
          //Overwrite the first train results.
          if (0 != (int((hv_TrainResultsRestored.TupleLength())>hv_Iteration)))
          {
            hv_TrainResultsRestored = hv_TrainResultsRestored.TupleSelectRange((hv_TrainResultsRestored.TupleLength())-hv_Iteration,(hv_TrainResultsRestored.TupleLength())-1);
          }
          (*hv_TrainResults)[HTuple::TupleGenSequence(hv_Iteration-(hv_TrainResultsRestored.TupleLength()),hv_Iteration-1,1)] = hv_TrainResultsRestored;
        }
        //
        //Add an iteration before starting the training for the evaluation if specified.
        hv_IterationEvaluateOnly = hv_Iteration-1;
        hv_Iteration = hv_Iteration-hv_EvaluateBeforeTraining;
      }
      if (0 != (int(hv_Iteration>hv_IterationEvaluateOnly)))
      {
        //
        //Generate the sample batch indices.
        hv_BatchStart = hv_Iteration*hv_BatchSize;
        hv_BatchEnd = (hv_BatchStart+hv_BatchSize)-1;
        hv_BatchIndices = hv_SampleIndicesTrain.TupleSelectRange(hv_BatchStart,hv_BatchEnd);
        //
        //Set a random seed for the sample batch.
        SetSystem("seed_rand", HTuple(hv_SampleSeedsTrainRaw[hv_BatchEnd]));
        //
        //Read preprocessed samples.
        read_dl_samples(hv_DLDataset, hv_BatchIndices, &hv_DLSampleBatch);
        //
        //Augment samples based on train parameter.
        GetDictTuple(hv_TrainParam, "augmentation_param", &hv_AugmentationParam);
        augment_dl_samples(hv_DLSampleBatch, hv_AugmentationParam);
        //
        //Train the model on current batch.
        TrainDlModelBatch(hv_DLModelHandle, hv_DLSampleBatch, &hv_TrainResult);
        //
        //We store each train result.
        (*hv_TrainResults)[hv_Iteration] = hv_TrainResult;
      }
      //
      //Evaluation handling.
      GetDictTuple(hv_TrainParam, "evaluation_interval_epochs", &hv_EvaluationIntervalEpochs);
      hv_EvaluationInterval = ((hv_EvaluationIntervalEpochs*hv_NumIterationsPerEpoch).TupleFloor()).TupleInt();
      hv_ValidationEvaluationResult = HTuple();
      hv_TrainEvaluationResult = HTuple();
      GetDictTuple(hv_DisplayData, "display_param", &hv_DisplayParam);
      //Get percentage of evaluated training samples from display parameters.
      GetDictTuple(hv_DisplayParam, "selected_percentage_train_samples", &hv_SelectPercentageTrainSamples);
      //
      //Evaluate the current model.
      if (0 != (int(hv_EvaluationInterval>0)))
      {
        //Evaluate the model at given intervals.
        if (0 != (HTuple(HTuple(HTuple(int(hv_EvaluationInterval==1)).TupleOr(HTuple(int((hv_Iteration%hv_EvaluationInterval)==0)).TupleAnd(int(hv_Iteration!=0)))).TupleOr(int(hv_Iteration==(hv_NumIterations-1)))).TupleOr(int(hv_Iteration==hv_IterationEvaluateOnly))))
        {
          GetDictTuple(hv_TrainParam, "evaluation_param", &hv_EvaluationParam);
          //Evaluate on validation split.
          evaluate_dl_model(hv_DLDataset, hv_DLModelHandle, "split", "validation", 
              hv_EvaluationParam, &hv_ValidationEvaluationResult, &hv__);
          //Evaluate a subset of the train split.
          hv_TrainEvaluationRatio = hv_SelectPercentageTrainSamples/100.0;
          hv_NumTrainEvaluationSampleIndices = (hv_TrainEvaluationRatio*(hv_TrainSampleIndices.TupleLength())).TupleInt();
          if (0 != (int(hv_NumTrainEvaluationSampleIndices>0)))
          {
            tuple_shuffle(hv_TrainSampleIndices, &hv_TrainEvaluationSampleIndices);
            //It might happen that the subset is too small for evaluation.
            try
            {
              evaluate_dl_model(hv_DLDataset, hv_DLModelHandle, "sample_indices", 
                  hv_TrainEvaluationSampleIndices.TupleSelectRange(0,hv_NumTrainEvaluationSampleIndices-1), 
                  hv_EvaluationParam, &hv_TrainEvaluationResult, &hv__);
            }
            // catch (Exception) 
            catch (HException &HDevExpDefaultException)
            {
              HDevExpDefaultException.ToHTuple(&hv_Exception);
            }
          }
          CreateDict(&hv_EvaluationInfo);
          SetDictTuple(hv_EvaluationInfo, "epoch", hv_Epoch);
          SetDictTuple(hv_EvaluationInfo, "iteration", hv_Iteration+hv_EvaluateBeforeTraining);
          SetDictTuple(hv_EvaluationInfo, "result", hv_ValidationEvaluationResult);
          SetDictTuple(hv_EvaluationInfo, "result_train", hv_TrainEvaluationResult);
          (*hv_EvaluationInfos) = (*hv_EvaluationInfos).TupleConcat(hv_EvaluationInfo);
          if (0 != hv_DisplayEnabled)
          {
            GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
            reduce_dl_evaluation_result(hv_ValidationEvaluationResult, hv_EvaluationComparisonKeys, 
                &hv_Valuevalidation, &hv__);
            reduce_dl_evaluation_result(hv_TrainEvaluationResult, hv_EvaluationComparisonKeys, 
                &hv_ValueTrain, &hv__);
            hv_DisplayValidationEvaluationValues = hv_DisplayValidationEvaluationValues.TupleConcat(hv_Valuevalidation);
            hv_DisplayTrainEvaluationValues = hv_DisplayTrainEvaluationValues.TupleConcat(hv_ValueTrain);
            hv_DisplayEvaluationEpochs = hv_DisplayEvaluationEpochs.TupleConcat(hv_Epoch);
          }
        }
      }
      if (0 != (int(hv_Iteration>hv_IterationEvaluateOnly)))
      {
        //
        //Check if an update is needed.
        GetDictTuple(hv_TrainParam, "update_interval_seconds", &hv_TrainInfoUpdateIntervalSeconds);
        GetDictTuple(hv_DisplayData, "last_update", &hv_LastUpdate);
        CountSeconds(&hv_Seconds);
        //Check for next update (enough time has elapsed or last iteration).
        if (0 != (HTuple(HTuple(int(((hv_LastUpdate-hv_Seconds).TupleAbs())>hv_TrainInfoUpdateIntervalSeconds)).TupleOr(int(hv_Iteration==(hv_NumIterations-1)))).TupleOr(int((hv_ValidationEvaluationResult.TupleLength())>0))))
        {
          SetDictTuple(hv_DisplayData, "last_update", hv_Seconds);
          GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
          GetDictTuple(hv_TrainParam, "num_samples_mean_loss", &hv_NumSamplesMeanLoss);
          collect_train_dl_model_info(hv_DLModelHandle, (*hv_TrainResults), (*hv_EvaluationInfos), 
              hv_EvaluationComparisonKeys, hv_EvaluationOptimizationMethod, hv_Iteration, 
              hv_NumIterations, hv_NumIterationsPerEpoch, hv_NumSamplesMeanLoss, 
              &hv_TrainInfo);

          SetDictTuple(hv_TrainInfo, "start_epoch", hv_StartEpoch);
          SetDictTuple(hv_TrainInfo, "start_time", hv_StartTime);
          CountSeconds(&hv_UpdateTime);
          SetDictTuple(hv_TrainInfo, "time_elapsed", hv_UpdateTime-hv_StartTime);
          (*hv_TrainInfos) = (*hv_TrainInfos).TupleConcat(hv_TrainInfo);
          //
          //Display handling.
          if (0 != hv_DisplayEnabled)
          {
            GetDictTuple(hv_TrainInfo, "epoch", &hv_EpochsStatus);
            hv_DisplayLossEpochs = hv_DisplayLossEpochs.TupleConcat(hv_EpochsStatus);
            GetDictTuple(hv_TrainInfo, "mean_loss", &hv_MeanLoss);
            hv_DisplayLoss = hv_DisplayLoss.TupleConcat(hv_MeanLoss);
            GetDlModelParam(hv_DLModelHandle, "learning_rate", &hv_DisplayLearningRate);
            hv_DisplayLearningRates = hv_DisplayLearningRates.TupleConcat(hv_DisplayLearningRate);
            dev_display_update_train_dl_model(hv_TrainParam, hv_DisplayData, hv_TrainInfo, 
                hv_DisplayLossEpochs, hv_DisplayLoss, hv_DisplayLearningRates, hv_DisplayEvaluationEpochs, 
                hv_DisplayValidationEvaluationValues, hv_DisplayTrainEvaluationValues);
          }
        }
        //
        //Image result preview handling.
        if (0 != hv_DisplayEnabled)
        {
          //Show interim results for test images.
          //For models of type 'gc_anomaly_detection' this is not possible.
          GetDictTuple(hv_DisplayParam, "num_images", &hv_NumImages);
          if (0 != (int(hv_NumImages>0)))
          {
            //Check if the image preview has to be updated.
            GetDictTuple(hv_DisplayParam, "update_images_interval_epochs", &hv_UpdateImagesIntervalEpochs);
            hv_UpdateImagesInterval = (((hv_UpdateImagesIntervalEpochs.TupleReal())*hv_NumIterationsPerEpoch).TupleFloor()).TupleInt();
            if (0 != (int(hv_UpdateImagesInterval==0)))
            {
              hv_UpdateImagesInterval = 1;
            }
            if (0 != (HTuple(int((hv_Iteration%hv_UpdateImagesInterval)==0)).TupleOr(hv_DisplayPreviewInitialized.TupleNot())))
            {
              GetDictTuple(hv_DisplayData, "window_images", &hv_WindowImages);
              hv_FirstCall = int((hv_WindowImages.TupleLength())==0);
              GetDictTuple(hv_DisplayParam, "tiled_param", &hv_GenParamTiled);
              //
              dev_display_dl_data_tiled(hv_DLDataset, hv_DLModelHandle, hv_NumImages, 
                  "validation", hv_GenParamTiled, hv_WindowImages, &hv_WindowImages);
              //
              if (0 != hv_FirstCall)
              {
                SetDictTuple(hv_DisplayData, "window_images", hv_WindowImages);
                set_display_font(hv_WindowImages, 12, "mono", "true", "false");
              }
              dev_display_tiled_legend(hv_WindowImages, hv_GenParamTiled);
              hv_DisplayPreviewInitialized = 1;
            }
          }
        }
        //
        //Serialization handling.
        update_train_dl_model_serialization(hv_TrainParam, hv_SerializationData, 
            hv_Iteration, hv_NumIterations, hv_Epoch, hv_ValidationEvaluationResult, 
            hv_EvaluationOptimizationMethod, hv_DLModelHandle, (*hv_TrainInfos), 
            (*hv_EvaluationInfos));
      }
      //
      //Check for end of training.
      if (0 != (int(hv_Iteration>=(hv_NumIterations-1))))
      {
        break;
      }
      if (0 != (int(hv_Iteration==hv_IterationEvaluateOnly)))
      {
        hv_EvaluateBeforeTraining = 0;
      }
      //
      //Continue with next iteration.
      hv_Iteration += 1;
    }
    //
  }
  else
  {
    //Case for models of type 'anomaly_detection'.
    //
    //Read the training samples.
    read_dl_samples(hv_DLDataset, hv_TrainSampleIndices, &hv_DLSamples);
    //
    //Get training parameters for anomaly detection.
    GetDictTuple(hv_TrainParam, "anomaly_param", &hv_TrainParamAnomaly);
    //
    //Display information about training.
    GetDictTuple(hv_TrainParam, "display_param", &hv_DisplayParam);
    GetDictTuple(hv_DisplayParam, "enabled", &hv_DisplayEnabled);
    if (0 != hv_DisplayEnabled)
    {
      dev_display_train_info_anomaly_detection(hv_TrainParam, &hv_WindowHandleInfo);
    }
    //
    //Train the model.
    TrainDlModelAnomalyDataset(hv_DLModelHandle, hv_DLSamples, hv_TrainParamAnomaly, 
        &(*hv_TrainResults));
    //
    //Initialize TrainInfos and EvaluationInfos
    (*hv_TrainInfos) = HTuple();
    (*hv_EvaluationInfos) = HTuple();
    //
    //Close window with information about the training.
    if (0 != hv_DisplayEnabled)
    {
      HDevWindowStack::SetActive(hv_WindowHandleInfo);
    }
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Update model parameters according to the change strategies. 
void update_train_dl_model_change_strategies (HTuple hv_DLModelHandle, HTuple hv_ChangeStrategyData, 
    HTuple hv_Epoch)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Enabled, hv_ChangeStrategies, hv_SolverType;
  HTuple  hv_Index, hv_ChangeStrategy, hv_ModelParam, hv_Epochs;
  HTuple  hv_Values, hv_Initial, hv_Greater, hv_ValueIndex;
  HTuple  hv_Value, hv_InternalCurrentExists, hv_InternalCurrent;
  HTuple  hv_ScaleThreshold, hv_CurrentLR, hv_LRChangeRatio;
  HTuple  hv_PreviousMomentumExists, hv_CurrentMomentum, hv_AdaptedMomentum;
  HTuple  hv_AdaptedMomentumExists, hv_PreviousMomentum;

  //
  //This procedure updates all parameters according to the change strategies
  //with respect to the current iteration.
  //
  GetDictTuple(hv_ChangeStrategyData, "enabled", &hv_Enabled);
  if (0 != (hv_Enabled.TupleNot()))
  {
    return;
  }
  //
  GetDictTuple(hv_ChangeStrategyData, "strategies", &hv_ChangeStrategies);
  GetDlModelParam(hv_DLModelHandle, "solver_type", &hv_SolverType);
  //
  //Update the parameter of each strategy.
  {
  HTuple end_val13 = (hv_ChangeStrategies.TupleLength())-1;
  HTuple step_val13 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val13, step_val13); hv_Index += step_val13)
  {
    hv_ChangeStrategy = HTuple(hv_ChangeStrategies[hv_Index]);
    GetDictTuple(hv_ChangeStrategy, "model_param", &hv_ModelParam);
    GetDictTuple(hv_ChangeStrategy, "epochs", &hv_Epochs);
    GetDictTuple(hv_ChangeStrategy, "values", &hv_Values);
    GetDictTuple(hv_ChangeStrategy, "initial_value", &hv_Initial);
    //Epochs defines at which epoch the change happens. Its sorting is enforced during initialization.
    hv_Greater = hv_Epoch.TupleGreaterEqualElem(hv_Epochs);
    TupleFindLast(hv_Greater, 1, &hv_ValueIndex);
    if (0 != (int(hv_ValueIndex==-1)))
    {
      hv_Value = hv_Initial;
    }
    else
    {
      hv_Value = HTuple(hv_Values[hv_ValueIndex]);
    }
    //Check current value and only make changes if the value changed.
    GetDictParam(hv_ChangeStrategy, "key_exists", "internal_current_value", &hv_InternalCurrentExists);
    if (0 != hv_InternalCurrentExists)
    {
      GetDictTuple(hv_ChangeStrategy, "internal_current_value", &hv_InternalCurrent);
    }
    else
    {
      GetDlModelParam(hv_DLModelHandle, hv_ModelParam, &hv_InternalCurrent);
    }
    //If the current value differs from the new value we change it.
    if (0 != (int(((hv_InternalCurrent.TupleNotEqualElem(hv_Value)).TupleSum())>0)))
    {
      //If the changed model parameter is the learning rate, we also change the momentum
      //to adapt the scale of the previous update.
      if (0 != (int(hv_ModelParam==HTuple("learning_rate"))))
      {
        //Get the threshold.
        GetDictTuple(hv_ChangeStrategy, "scale_momentum_threshold", &hv_ScaleThreshold);
        if (0 != (HTuple(int((hv_ScaleThreshold.TupleLength())>0)).TupleAnd(int(hv_SolverType==HTuple("sgd")))))
        {
          GetDlModelParam(hv_DLModelHandle, hv_ModelParam, &hv_CurrentLR);
          //Check if the change is larger than the specified threshold.
          hv_LRChangeRatio = ((hv_Value.TupleReal())/(hv_CurrentLR.TupleMax2(1e-10))).TupleMax2((hv_CurrentLR.TupleReal())/(hv_Value.TupleMax2(1e-10)));
          if (0 != (HTuple(int(hv_LRChangeRatio>hv_ScaleThreshold)).TupleAnd(int(hv_CurrentLR>1e-7))))
          {
            GetDictParam(hv_ChangeStrategy, "key_exists", "previous_momentum", &hv_PreviousMomentumExists);
            if (0 != hv_PreviousMomentumExists)
            {
              GetDictTuple(hv_ChangeStrategy, "previous_momentum", &hv_CurrentMomentum);
            }
            else
            {
              GetDlModelParam(hv_DLModelHandle, "momentum", &hv_CurrentMomentum);
            }
            hv_AdaptedMomentum = (hv_Value/(hv_CurrentLR.TupleReal()))*hv_CurrentMomentum;
            SetDlModelParam(hv_DLModelHandle, "momentum", hv_AdaptedMomentum);
            //In the next iteration the momentum has to be set back.
            SetDictTuple(hv_ChangeStrategy, "adapted_momentum", 1);
            SetDictTuple(hv_ChangeStrategy, "previous_momentum", hv_CurrentMomentum);
          }
        }
      }
      SetDlModelParam(hv_DLModelHandle, hv_ModelParam, hv_Value);
    }
    else if (0 != (HTuple(int(hv_ModelParam==HTuple("learning_rate"))).TupleAnd(int(hv_SolverType==HTuple("sgd")))))
    {
      //Get the threshold.
      GetDictTuple(hv_ChangeStrategy, "scale_momentum_threshold", &hv_ScaleThreshold);
      if (0 != (int((hv_ScaleThreshold.TupleLength())>0)))
      {
        //Set the momentum back if it was adapted in the previous iteration.
        GetDictParam(hv_ChangeStrategy, "key_exists", "adapted_momentum", &hv_AdaptedMomentumExists);
        if (0 != hv_AdaptedMomentumExists)
        {
          GetDictTuple(hv_ChangeStrategy, "adapted_momentum", &hv_AdaptedMomentum);
          if (0 != hv_AdaptedMomentum)
          {
            GetDictTuple(hv_ChangeStrategy, "previous_momentum", &hv_PreviousMomentum);
            SetDlModelParam(hv_DLModelHandle, "momentum", hv_PreviousMomentum);
            SetDictTuple(hv_ChangeStrategy, "adapted_momentum", 0);
            RemoveDictKey(hv_ChangeStrategy, "previous_momentum");
          }
        }
      }
    }
    //Store the new internal current value.
    SetDictTuple(hv_ChangeStrategy, "internal_current_value", hv_Value);
  }
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Serialize the model if a strategy applies to the current training status. 
void update_train_dl_model_serialization (HTuple hv_TrainParam, HTuple hv_SerializationData, 
    HTuple hv_Iteration, HTuple hv_NumIterations, HTuple hv_Epoch, HTuple hv_EvaluationResult, 
    HTuple hv_EvaluationOptimizationMethod, HTuple hv_DLModelHandle, HTuple hv_TrainInfos, 
    HTuple hv_EvaluationInfos)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_RawData, hv_Types, hv_Strategies, hv_Index;
  HTuple  hv_Type, hv_Data, hv_Strategy, hv_EvaluationComparisonKeys;
  HTuple  hv_Value, hv_ValidEvaluationKeys, hv_CurrentBest;
  HTuple  hv_IsNewBest, hv_FilenameModel, hv_FilenameMetaData;
  HTuple  hv_Epochs, hv_Indices, hv_LastIndex;

  //
  //Serialize the model if a strategy applies to the current training status.
  //
  GetDictTuple(hv_SerializationData, "raw_data", &hv_RawData);
  GetDictTuple(hv_SerializationData, "types", &hv_Types);
  GetDictTuple(hv_SerializationData, "strategies", &hv_Strategies);
  //
  {
  HTuple end_val7 = (hv_Types.TupleLength())-1;
  HTuple step_val7 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val7, step_val7); hv_Index += step_val7)
  {
    //
    hv_Type = HTuple(hv_Types[hv_Index]);
    hv_Data = HTuple(hv_RawData[hv_Index]);
    hv_Strategy = HTuple(hv_Strategies[hv_Index]);
    //
    if (0 != (int(hv_Type==HTuple("best"))))
    {
      //If there is no new evaluation result, we will not serialize.
      if (0 != (int((hv_EvaluationResult.TupleLength())==0)))
      {
        continue;
      }
      //Get a single value which is combined based on the given evaluation keys.
      GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
      reduce_dl_evaluation_result(hv_EvaluationResult, hv_EvaluationComparisonKeys, 
          &hv_Value, &hv_ValidEvaluationKeys);
      GetDictTuple(hv_Data, "best_value", &hv_CurrentBest);
      if (0 != (int(hv_CurrentBest==-1)))
      {
        hv_IsNewBest = 1;
      }
      else if (0 != (int(hv_EvaluationOptimizationMethod==HTuple("min"))))
      {
        hv_IsNewBest = int(hv_Value<hv_CurrentBest);
      }
      else
      {
        hv_IsNewBest = int(hv_Value>hv_CurrentBest);
      }
      if (0 != hv_IsNewBest)
      {
        SetDictTuple(hv_Data, "best_value", hv_Value);
        serialize_train_dl_model_intermediate(hv_DLModelHandle, hv_Epoch, hv_Value, 
            hv_Strategy, hv_TrainInfos, hv_EvaluationInfos, &hv_FilenameModel, &hv_FilenameMetaData);
      }
    }
    else if (0 != (int(hv_Type==HTuple("final"))))
    {
      if (0 != (int(hv_Iteration==(hv_NumIterations-1))))
      {
        //Serialize final model.
        serialize_train_dl_model_intermediate(hv_DLModelHandle, hv_Epoch, HTuple(), 
            hv_Strategy, hv_TrainInfos, hv_EvaluationInfos, &hv_FilenameModel, &hv_FilenameMetaData);
      }
    }
    else if (0 != (HTuple(int(hv_Type==HTuple("epochs"))).TupleOr(int(hv_Type==HTuple("current")))))
    {
      //Check if the specified epoch is reached.
      GetDictTuple(hv_Data, "epochs", &hv_Epochs);
      TupleFindLast(hv_Epoch.TupleLessElem(hv_Epochs), 0, &hv_Indices);
      //Also check that the last saved epoch is not the same.
      GetDictTuple(hv_Data, "last_epoch_index", &hv_LastIndex);
      if (0 != (HTuple(int(hv_Type==HTuple("current"))).TupleAnd(int((hv_EvaluationResult.TupleLength())>0))))
      {
        //For type current we also write every EvaluationIntervalEpochs epochs.
        serialize_train_dl_model_intermediate(hv_DLModelHandle, hv_Epoch, HTuple(), 
            hv_Strategy, hv_TrainInfos, hv_EvaluationInfos, &hv_FilenameModel, &hv_FilenameMetaData);
      }
      else if (0 != (int((hv_Indices.TupleLength())>0)))
      {
        //
        if (0 != (HTuple(int(HTuple(hv_Indices[0])>-1)).TupleAnd(int(HTuple(hv_Indices[0])!=hv_LastIndex))))
        {
          SetDictTuple(hv_Data, "last_epoch_index", HTuple(hv_Indices[0]));
          //Serialize final model.
          serialize_train_dl_model_intermediate(hv_DLModelHandle, hv_Epoch, HTuple(), 
              hv_Strategy, hv_TrainInfos, hv_EvaluationInfos, &hv_FilenameModel, 
              &hv_FilenameMetaData);
        }
      }
    }
  }
  }
  //
  return;
}


