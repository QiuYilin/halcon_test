///////////////////////////////////////////////////////////////////////////////
// File generated by HDevelop for HALCON/C++ Version 23.05.0.0
// Non-ASCII strings in this file are encoded in local-8-bit encoding (cp936).
// Ensure that the interface encoding is set to locale encoding by calling
// SetHcppInterfaceStringEncodingIsUtf8(false) at the beginning of the program.
// 
// Please note that non-ASCII characters in string constants are exported
// as octal codes in order to guarantee that the strings are correctly
// created on all systems, independent on any compiler settings.
// 
// Source files with different encoding should not be mixed in one project.
///////////////////////////////////////////////////////////////////////////////

#include "HalconCpp.h"
#include "HDevThread.h"



using namespace HalconCpp;

// Procedure declarations 
// Chapter: Graphics / Output
// Short Description: Display an interactive button. 
extern void dev_disp_button (HTuple hv_String, HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_ColorString, HTuple hv_ColorBackground, HTuple hv_ColorBackgroundActive, 
    HTuple hv_WindowHandle, HTuple *hv_SelectedButton);
// Chapter: Graphics / Output
// Short Description: Display an interactive button. 
extern void dev_disp_button (HTuple hv_String, HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_ColorString, HTuple hv_ColorBackground, HTuple hv_ColorBackgroundActive, 
    HTuple hv_WindowHandle, HTuple *hv_SelectedButton);
// Chapter: Develop
// Short Description: Change the size of a graphics window with a given maximum and minimum extent such that it preserves the aspect ratio of the given image 
extern void dev_resize_window_fit_image (HObject ho_Image, HTuple hv_Row, HTuple hv_Column, 
    HTuple hv_WidthLimit, HTuple hv_HeightLimit);
// Chapter: Develop
// Short Description: Resize a graphics window with a given maximum extent such that it preserves the aspect ratio of a given width and height 
extern void dev_resize_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit);
// Chapter: Deep Learning / Classification
// Short Description: Compute a confusion matrix, which an be visualized and/or returned. 
extern void gen_confusion_matrix (HTuple hv_GroundTruthLabels, HTuple hv_PredictedClasses, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle, HTuple *hv_ConfusionMatrix);
// Chapter: File / Misc
// Short Description: Get all image files under the given path 
extern void list_image_files (HTuple hv_ImageDirectory, HTuple hv_Extensions, HTuple hv_Options, 
    HTuple *hv_ImageFiles);
// Chapter: Graphics / Output
// Short Description: Plot tuples representing functions or curves in a coordinate system. 
extern void plot_funct_1d (HTuple hv_WindowHandle, HTuple hv_Function, HTuple hv_XLabel, 
    HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamName, HTuple hv_GenParamValue);
// Chapter: Graphics / Output
// Short Description: Plot tuples representing functions or curves in a coordinate system. 
extern void plot_funct_1d (HTuple hv_WindowHandle, HTuple hv_Function, HTuple hv_XLabel, 
    HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamName, HTuple hv_GenParamValue);
// Chapter: Graphics / Output
// Short Description: Plot tuples representing functions or curves in a coordinate system. 
extern void plot_funct_1d (HTuple hv_WindowHandle, HTuple hv_Function, HTuple hv_XLabel, 
    HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamName, HTuple hv_GenParamValue);
// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
extern void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled);
// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
extern void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled);
// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
extern void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled);
// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
extern void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled);
// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
extern void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled);
// Chapter: Legacy / DL Classification
// Short Description: Return the classification results for the given images. 
void apply_dl_classifier_batchwise (HTuple hv_ImageFiles, HTuple hv_DLClassifierHandle, 
    HTuple *hv_DLClassifierResultIDs, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_PredictedClasses, 
    HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_Confidences);
// Chapter: Legacy / DL Classification
// Short Description: Compute the TopK error. 
void compute_top_k_error (HTuple hv_DLClassifierHandle, HTuple hv_DLClassifierResultID, 
    HTuple hv_GroundTruthLabels, HTuple hv_Indices, HTuple hv_K, HTuple *hv_TopKError);
// Chapter: Legacy / DL Classification
// Short Description: Visualize and return the heatmap of a deep learning classification. 
void dev_display_dl_classifier_heatmap (HObject ho_Image, HTuple hv_DLClassifierHandle, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle);
// Chapter: Legacy / DL Classification
// Short Description: Evaluate the performance of a deep-learning-based classifier. 
void evaluate_dl_classifier (HTuple hv_GroundTruthLabels, HTuple hv_DLClassifierHandle, 
    HTuple hv_DLClassifierResultID, HTuple hv_EvaluationMeasureType, HTuple hv_ClassesToEvaluate, 
    HTuple *hv_EvaluationMeasure);
// Chapter: Legacy / DL Classification
// Short Description: Refer to new procedure. 
void gen_dl_classifier_heatmap (HObject ho_Image, HObject *ho_HeatmapRegions, HTuple hv_DLClassifierHandle, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle);
// Chapter: Legacy / DL Classification
// Short Description: Visualize and return the confusion matrix for the given labels. 
void gen_interactive_confusion_matrix (HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_PredictedClasses, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_WindowHandle, HTuple *hv_ConfusionMatrix);
// Chapter: Legacy / DL Classification
// Short Description: Display and return the classified images. 
void get_dl_classifier_image_results (HObject *ho_Images, HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_PredictedClasses, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_WindowHandle);
// Chapter: Legacy / DL Classification
// Short Description: Plot the training error, validation error and learning rate during deep learning classifier training. 
void plot_dl_classifier_training_progress (HTuple hv_TrainingErrors, HTuple hv_ValidationErrors, 
    HTuple hv_LearningRates, HTuple hv_Epochs, HTuple hv_NumEpochs, HTuple hv_WindowHandle);
// Chapter: Legacy / DL Classification
// Short Description: Preprocess images for deep-learning-based classification training and inference. 
void preprocess_dl_classifier_images (HObject ho_Images, HObject *ho_ImagesPreprocessed, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_DLClassifierHandle);
// Chapter: Legacy / DL Classification
// Short Description: Read the data set containing the images and their respective ground truth labels. 
void read_dl_classifier_data_set (HTuple hv_ImageDirectory, HTuple hv_LabelSource, 
    HTuple *hv_ImageFiles, HTuple *hv_GroundTruthLabels, HTuple *hv_LabelIndices, 
    HTuple *hv_UniqueClasses);
// Chapter: Legacy / DL Classification
// Short Description: Select a percentage of the given data. 
void select_percentage_dl_classifier_data (HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_SelectPercentage, HTuple *hv_ImageFilesOut, HTuple *hv_LabelsOut);
// Chapter: Legacy / DL Classification
// Short Description: Split and shuffle the images and ground truth labels into training, validation and test subsets. 
void split_dl_classifier_data_set (HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_TrainingPercent, HTuple hv_ValidationPercent, HTuple *hv_TrainingImages, 
    HTuple *hv_TrainingLabels, HTuple *hv_ValidationImages, HTuple *hv_ValidationLabels, 
    HTuple *hv_TestImages, HTuple *hv_TestLabels);

// Procedures 
// Chapter: Legacy / DL Classification
// Short Description: Return the classification results for the given images. 
void apply_dl_classifier_batchwise (HTuple hv_ImageFiles, HTuple hv_DLClassifierHandle, 
    HTuple *hv_DLClassifierResultIDs, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_PredictedClasses, 
    HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_Confidences)
{

  // Local iconic variables
  HObject  ho_BatchImages;

  // Local control variables
  HTuple  hv_BatchSize, hv_NumImages, hv_Sequence;
  HTuple  hv_BatchStartIndex, hv_BatchIndices, hv_BatchImageFiles;
  HTuple  hv_DLClassifierResultID, hv_Exception, hv_NumImagesInBatch;
  HTuple  hv_Index, hv_PredictedClass, hv_ClassConfidence;
  HTuple  hv_VectorIndex;

  //This procedure classifies the images given as paths
  //by ImageFiles using the operator apply_dl_classifier.
  //To avoid that the main memory is overloaded, the images
  //are classified batchwise, according to the hyperparameter 'batch_size',
  //which is stored in the DLClassifierHandle.
  //As result, the classification result handles for every batch
  //are returned in DLClassifierResultIDs.
  //Additionally, for every image the descending sorted
  //Confidences and corresponding PredictedClasses
  //are returned as vectors.
  //
  //Get batch size from handle.
  GetDlClassifierParam(hv_DLClassifierHandle, "batch_size", &hv_BatchSize);
  //
  //Check the input parameters.
  if (0 != (int((hv_ImageFiles.TupleLength())<1)))
  {
    throw HException("ImageFiles must not be empty.");
  }
  //
  //Sequence is used for easier indexing of the images.
  hv_NumImages = hv_ImageFiles.TupleLength();
  hv_Sequence = HTuple::TupleGenSequence(0,hv_NumImages-1,1);
  //
  //Loop through all selected images.
  (*hvec_PredictedClasses) = HTupleVector(1);
  (*hvec_Confidences) = HTupleVector(1);
  (*hv_DLClassifierResultIDs) = HTuple();
  {
  HTuple end_val27 = hv_NumImages-1;
  HTuple step_val27 = hv_BatchSize;
  for (hv_BatchStartIndex=0; hv_BatchStartIndex.Continue(end_val27, step_val27); hv_BatchStartIndex += step_val27)
  {
    //Select the data for the current batch.
    hv_BatchIndices = hv_Sequence.TupleSelectRange(hv_BatchStartIndex,((hv_BatchStartIndex+hv_BatchSize)-1).TupleMin2(hv_NumImages-1));
    hv_BatchImageFiles = HTuple(hv_ImageFiles[hv_BatchIndices]);
    //Read the current batch images.
    ReadImage(&ho_BatchImages, hv_BatchImageFiles);
    //Apply the classifier for this batch.
    try
    {
      ApplyDlClassifier(ho_BatchImages, hv_DLClassifierHandle, &hv_DLClassifierResultID);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      if (0 != ((HTuple(hv_Exception[0]).TupleEqualElem(((((HTuple(2106).Append(2107)).Append(3122)).Append(9001)).Append(9003)))).TupleSum()))
      {
        throw HException(HTuple("Images need to fulfill the network requirements, please provide preprocessed images."));
      }
      else
      {
        throw HException(hv_Exception);
      }
    }
    //Get results from result handle.
    hv_NumImagesInBatch = hv_BatchImageFiles.TupleLength();
    {
    HTuple end_val45 = hv_NumImagesInBatch-1;
    HTuple step_val45 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val45, step_val45); hv_Index += step_val45)
    {
      GetDlClassifierResult(hv_DLClassifierResultID, hv_Index, "predicted_classes", 
          &hv_PredictedClass);
      GetDlClassifierResult(hv_DLClassifierResultID, hv_Index, "confidences", &hv_ClassConfidence);
      //Store the classification results.
      hv_VectorIndex = hv_BatchStartIndex+hv_Index;
      (*hvec_PredictedClasses)[hv_VectorIndex] = HTupleVector(hv_PredictedClass);
      (*hvec_Confidences)[hv_VectorIndex] = HTupleVector(hv_ClassConfidence);
    }
    }
    (*hv_DLClassifierResultIDs) = (*hv_DLClassifierResultIDs).TupleConcat(hv_DLClassifierResultID);
  }
  }
  return;
}

// Chapter: Legacy / DL Classification
// Short Description: Compute the TopK error. 
void compute_top_k_error (HTuple hv_DLClassifierHandle, HTuple hv_DLClassifierResultID, 
    HTuple hv_GroundTruthLabels, HTuple hv_Indices, HTuple hv_K, HTuple *hv_TopKError)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumMatches, hv_GroundTruthLabelsSelected;
  HTuple  hv_BatchSize, hv_IndexLabel, hv_CurrentLabel, hv_ResultHandleIndex;
  HTuple  hv_ResultIndex, hv_PredictedClasses;

  //This procedure compares the GroundtruthLabels
  //with the K inferred classes of highest probability,
  //stored in DLClassifierResultID, and returns the TopKError.
  //Indices defines which images (and thus GroundTruthLabels
  //as well as inference results) are considered.
  hv_NumMatches = 0;
  //
  //Select the chosen GroundTruthLabels.
  hv_GroundTruthLabelsSelected = HTuple(hv_GroundTruthLabels[hv_Indices]);
  //
  //Get the batch size from the classifier handle.
  GetDlClassifierParam(hv_DLClassifierHandle, "batch_size", &hv_BatchSize);
  //
  //Loop through all selected ground truth labels.
  {
  HTuple end_val14 = (hv_GroundTruthLabelsSelected.TupleLength())-1;
  HTuple step_val14 = 1;
  for (hv_IndexLabel=0; hv_IndexLabel.Continue(end_val14, step_val14); hv_IndexLabel += step_val14)
  {
    //Get ground truth label.
    hv_CurrentLabel = HTuple(hv_GroundTruthLabelsSelected[hv_IndexLabel]);
    hv_ResultHandleIndex = ((HTuple(hv_Indices[hv_IndexLabel])/hv_BatchSize).TupleFloor()).TupleInt();
    hv_ResultIndex = HTuple(hv_Indices[hv_IndexLabel])%hv_BatchSize;
    GetDlClassifierResult(HTuple(hv_DLClassifierResultID[hv_ResultHandleIndex]), 
        hv_ResultIndex, "predicted_classes", &hv_PredictedClasses);
    //Get the K best results.
    hv_PredictedClasses = hv_PredictedClasses.TupleSelectRange(0,hv_K-1);
    //Count how often the ground truth label
    //and K predicted classes match.
    if (0 != (int((hv_PredictedClasses.TupleFind(hv_CurrentLabel))!=-1)))
    {
      hv_NumMatches += 1;
    }
  }
  }
  (*hv_TopKError) = 1.0-((hv_NumMatches.TupleReal())/(hv_GroundTruthLabelsSelected.TupleLength()));
  return;
}

// Chapter: Legacy / DL Classification
// Short Description: Visualize and return the heatmap of a deep learning classification. 
void dev_display_dl_classifier_heatmap (HObject ho_Image, HTuple hv_DLClassifierHandle, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle)
{

  // Local iconic variables
  HObject  ho_Partition, ho_RegionGrid, ho_OccludedRegions;
  HObject  ho_ImageR, ho_ImageG, ho_ImageB, ho_ImagesOccluded;
  HObject  ho_OccludedRegion, ho_ImageOccluded, ho_HeatmapRegions;
  HObject  ho_PartsSelected, ho_HeatmapRegion, ho_HeatmapRegionsNegative;
  HObject  ho_HeatmapRegionNegative, ho_BinRegion;

  // Local control variables
  HTuple  hv_FeatureSize, hv_SamplingSize, hv_DisplayConfidence;
  HTuple  hv_GenParamIndex, hv_Number, hv_NumInputChannels;
  HTuple  hv_NumImageChannels, hv_DLClassifierResultHandle;
  HTuple  hv_OriginalConfidence, hv_OriginalPredictedClass;
  HTuple  hv_ClipRegionSettingBefore, hv_HeightRegion, hv_WidthRegion;
  HTuple  hv_RatioRegion, hv_SamplingSizeUsed, hv_Width, hv_Height;
  HTuple  hv_CenterRows, hv_CenterColumns, hv_NumRegions;
  HTuple  hv_Confidences, hv_MeanGray, hv_DeviationGray, hv_MeanRed;
  HTuple  hv_DeviationRed, hv_MeanGreen, hv_DeviationGreen;
  HTuple  hv_MeanBlue, hv_DeviationBlue, hv_BatchSize, hv_BatchIndex;
  HTuple  hv_BatchIndices, hv_Index, hv_Mean, hv_NumImagesOccluded;
  HTuple  hv_IndexOccluded, hv_PredictedClass, hv_Confidence;
  HTuple  hv_Area, hv_AveragingCenterRows, hv_AveragingCenterColumns;
  HTuple  hv_PartitionConfidences, hv_PartIndex, hv_ConfidenceIndices;
  HTuple  hv_ConfidenceDeviations, hv_MaxDeviation, hv_NumBins;
  HTuple  hv_Step, hv_End, hv_Factor, hv_Lesser, hv_Greater;
  HTuple  hv_IndicesInBin, hv_WidthImage, hv_HeightImage;
  HTuple  hv_Colors, hv_BinIndex, hv_Text;

  //This procedure generates a heatmap for an Image which is classified
  //with the deep learning classifier DLClassifierHandle and displays
  //it in the WindowHandle. The procedure can be adjusted with generic
  //parameters using GenParamName and GenParamValue.
  //
  //Please note that the heatmap is intended for visual inspection.
  //Therefore, the resulting regions and confidence values are not
  //returned. If you require the heatmap regions or confidence values,
  //e.g. for your own visualization, these are the parameters to return:
  //- HeatmapRegions (Regions in which confidence is decreased when occluded)
  //- HeatmapRegionsNegative (Regions in which confidence is increased
  //  when occluded)
  //- OriginalConfidence (Confidence of original class assignment)
  //- MaxDeviation (Maximum absolute deviation from OriginalConfidence in heatmap)
  //
  //Set default parameters.
  hv_FeatureSize = 30;
  hv_SamplingSize = 7;
  hv_DisplayConfidence = 1;
  //
  //Parse the input parameters.
  {
  HTuple end_val21 = (hv_GenParamName.TupleLength())-1;
  HTuple step_val21 = 1;
  for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val21, step_val21); hv_GenParamIndex += step_val21)
  {
    if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("feature_size"))))
    {
      //Set 'feature_size'.
      hv_FeatureSize = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("sampling_size"))))
    {
      //Set 'sampling_size'.
      hv_SamplingSize = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_confidence"))))
    {
      //Set 'display_confidence'.
      hv_DisplayConfidence = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else
    {
      throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
    }
  }
  }
  //
  //Check the input parameters.
  CountObj(ho_Image, &hv_Number);
  if (0 != (int(hv_Number>1)))
  {
    throw HException("Please use only a single image as input.");
  }
  if (0 != (int(hv_SamplingSize<0)))
  {
    throw HException(("The \"sampling_size\" ("+hv_SamplingSize)+") must be greater than zero.");
  }
  if (0 != (int(hv_FeatureSize<0)))
  {
    throw HException(("The \"feature_size\" ("+hv_FeatureSize)+") must be greater than zero.");
  }
  if (0 != (int(hv_SamplingSize>=hv_FeatureSize)))
  {
    throw HException(((("The \"sampling_size\" ("+hv_SamplingSize)+") must be smaller than the \"feature_size\" (")+hv_FeatureSize)+")");
  }
  GetDlClassifierParam(hv_DLClassifierHandle, "image_num_channels", &hv_NumInputChannels);
  CountChannels(ho_Image, &hv_NumImageChannels);
  if (0 != (int(hv_NumImageChannels!=hv_NumInputChannels)))
  {
    throw HException((((("The number of image channels ("+hv_NumImageChannels)+") does not match ")+"the number of input channels expected by the classifier (")+hv_NumInputChannels)+")");
  }
  //
  //Get the predicted class and its confidence
  //when classifying the original (not occluded) image.
  ApplyDlClassifier(ho_Image, hv_DLClassifierHandle, &hv_DLClassifierResultHandle);
  GetDlClassifierResult(hv_DLClassifierResultHandle, "all", "confidences", &hv_OriginalConfidence);
  GetDlClassifierResult(hv_DLClassifierResultHandle, "all", "predicted_classes", 
      &hv_OriginalPredictedClass);
  ClearDlClassifierResult(hv_DLClassifierResultHandle);
  //
  GetSystem("clip_region", &hv_ClipRegionSettingBefore);
  SetSystem("clip_region", "false");
  //
  //Partition the image into rectangular regions. The height and width of the
  //rectangles are approximately equal to sampling_size.
  PartitionRectangle(ho_Image, &ho_Partition, hv_SamplingSize, hv_SamplingSize);
  HeightWidthRatio(ho_Partition, &hv_HeightRegion, &hv_WidthRegion, &hv_RatioRegion);
  //
  //Generate a set of regions to be occluded based on the center coordinates
  //and the dimensions of these rectangles. Depending on the values of
  //feature_size and sampling_size, these regions may overlap.
  hv_SamplingSizeUsed = (hv_HeightRegion.TupleConcat(hv_WidthRegion)).TupleMedian();
  GetImageSize(ho_Image, &hv_Width, &hv_Height);
  GenGridRegion(&ho_RegionGrid, hv_SamplingSizeUsed, hv_SamplingSizeUsed, "points", 
      hv_Width+1, hv_Height+1);
  GetRegionPoints(ho_RegionGrid, &hv_CenterRows, &hv_CenterColumns);
  hv_NumRegions = hv_CenterRows.TupleLength();
  GenCircle(&ho_OccludedRegions, hv_CenterRows, hv_CenterColumns, HTuple(hv_NumRegions,hv_FeatureSize/2));
  //
  //Generate and classify the occluded images.
  hv_Confidences = HTuple();
  if (0 != (int(hv_NumInputChannels==1)))
  {
    Intensity(ho_OccludedRegions, ho_Image, &hv_MeanGray, &hv_DeviationGray);
  }
  else
  {
    Decompose3(ho_Image, &ho_ImageR, &ho_ImageG, &ho_ImageB);
    Intensity(ho_OccludedRegions, ho_ImageR, &hv_MeanRed, &hv_DeviationRed);
    Intensity(ho_OccludedRegions, ho_ImageG, &hv_MeanGreen, &hv_DeviationGreen);
    Intensity(ho_OccludedRegions, ho_ImageB, &hv_MeanBlue, &hv_DeviationBlue);
  }
  GetDlClassifierParam(hv_DLClassifierHandle, "batch_size", &hv_BatchSize);
  {
  HTuple end_val92 = (hv_NumRegions/hv_BatchSize).TupleInt();
  HTuple step_val92 = 1;
  for (hv_BatchIndex=0; hv_BatchIndex.Continue(end_val92, step_val92); hv_BatchIndex += step_val92)
  {
    GenEmptyObj(&ho_ImagesOccluded);
    TupleGenSequence((hv_BatchIndex*hv_BatchSize)+1, (((hv_BatchIndex+1)*hv_BatchSize).TupleConcat(hv_NumRegions)).TupleMin(), 
        1, &hv_BatchIndices);
    {
    HTuple end_val95 = (hv_BatchIndices.TupleLength())-1;
    HTuple step_val95 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val95, step_val95); hv_Index += step_val95)
    {
      SelectObj(ho_OccludedRegions, &ho_OccludedRegion, HTuple(hv_BatchIndices[hv_Index]));
      if (0 != (int(hv_NumInputChannels==1)))
      {
        hv_Mean = HTuple(hv_MeanGray[HTuple(hv_BatchIndices[hv_Index])-1]);
      }
      else
      {
        hv_Mean.Clear();
        hv_Mean.Append(HTuple(hv_MeanRed[HTuple(hv_BatchIndices[hv_Index])-1]));
        hv_Mean.Append(HTuple(hv_MeanGreen[HTuple(hv_BatchIndices[hv_Index])-1]));
        hv_Mean.Append(HTuple(hv_MeanBlue[HTuple(hv_BatchIndices[hv_Index])-1]));
      }
      PaintRegion(ho_OccludedRegion, ho_Image, &ho_ImageOccluded, hv_Mean, "fill");
      ConcatObj(ho_ImagesOccluded, ho_ImageOccluded, &ho_ImagesOccluded);
    }
    }
    //
    //For each occluded image, get the confidence
    //for the predicted class of the original image.
    CountObj(ho_ImagesOccluded, &hv_NumImagesOccluded);
    if (0 != (int(hv_NumImagesOccluded>0)))
    {
      ApplyDlClassifier(ho_ImagesOccluded, hv_DLClassifierHandle, &hv_DLClassifierResultHandle);
      {
      HTuple end_val111 = hv_NumImagesOccluded-1;
      HTuple step_val111 = 1;
      for (hv_IndexOccluded=0; hv_IndexOccluded.Continue(end_val111, step_val111); hv_IndexOccluded += step_val111)
      {
        GetDlClassifierResult(hv_DLClassifierResultHandle, hv_IndexOccluded, "predicted_classes", 
            &hv_PredictedClass);
        GetDlClassifierResult(hv_DLClassifierResultHandle, hv_IndexOccluded, "confidences", 
            &hv_Confidence);
        hv_Confidences = hv_Confidences.TupleConcat(HTuple(hv_Confidence[hv_PredictedClass.TupleFind(hv_OriginalPredictedClass)]));
      }
      }
      ClearDlClassifierResult(hv_DLClassifierResultHandle);
    }
  }
  }
  //
  //Since it is too expensive to compute the confidence value
  //for each individual pixel, we work with a subsampling of the image.
  //The distance between two sampling points is controlled
  //by the parameter 'sampling_size'. For each sampling point,
  //we average over the confidence values of all images
  //which were occluded with a regions to which this point belongs.
  AreaCenter(ho_Partition, &hv_Area, &hv_AveragingCenterRows, &hv_AveragingCenterColumns);
  TupleGenConst(hv_AveragingCenterRows.TupleLength(), 0, &hv_PartitionConfidences);
  {
  HTuple end_val128 = (hv_AveragingCenterRows.TupleLength())-1;
  HTuple step_val128 = 1;
  for (hv_PartIndex=0; hv_PartIndex.Continue(end_val128, step_val128); hv_PartIndex += step_val128)
  {
    GetRegionIndex(ho_OccludedRegions, HTuple(hv_AveragingCenterRows[hv_PartIndex]).TupleInt(), 
        HTuple(hv_AveragingCenterColumns[hv_PartIndex]).TupleInt(), &hv_ConfidenceIndices);
    hv_PartitionConfidences[hv_PartIndex] = HTuple(hv_Confidences[hv_ConfidenceIndices-1]).TupleMean();
  }
  }
  //
  //Compute the deviation from the original confidence value and its maximum absolute value.
  hv_ConfidenceDeviations = hv_OriginalConfidence-hv_PartitionConfidences;
  hv_MaxDeviation = (hv_ConfidenceDeviations.TupleAbs()).TupleMax();
  //
  //The heatmap is categorized into 'bins'. The regions where the deviation
  //is highest are in the first bin, the regions where the deviation
  //is lowest are in the last bin. This is done separately for deviations with
  //positive and negative sign.
  hv_NumBins = 10;
  hv_Step = 1/(hv_NumBins.TupleReal());
  hv_End = 1-((hv_NumBins-1)*hv_Step);
  GenEmptyObj(&ho_HeatmapRegions);
  {
  HTuple end_val145 = hv_End;
  HTuple step_val145 = -hv_Step;
  for (hv_Factor=1; hv_Factor.Continue(end_val145, step_val145); hv_Factor += step_val145)
  {
    hv_Lesser = hv_ConfidenceDeviations.TupleLessEqualElem(hv_MaxDeviation*hv_Factor);
    hv_Greater = hv_ConfidenceDeviations.TupleGreaterElem(hv_MaxDeviation*(hv_Factor-hv_Step));
    hv_IndicesInBin = (hv_Lesser+hv_Greater).TupleFind(2);
    if (0 != (int(hv_IndicesInBin!=-1)))
    {
      SelectObj(ho_Partition, &ho_PartsSelected, hv_IndicesInBin+1);
      Union1(ho_PartsSelected, &ho_HeatmapRegion);
    }
    else
    {
      GenEmptyRegion(&ho_HeatmapRegion);
    }
    ConcatObj(ho_HeatmapRegions, ho_HeatmapRegion, &ho_HeatmapRegions);
  }
  }
  GenEmptyObj(&ho_HeatmapRegionsNegative);
  {
  HTuple end_val158 = hv_End;
  HTuple step_val158 = -hv_Step;
  for (hv_Factor=1; hv_Factor.Continue(end_val158, step_val158); hv_Factor += step_val158)
  {
    hv_Lesser = hv_ConfidenceDeviations.TupleLessElem((-hv_MaxDeviation)*(hv_Factor-hv_Step));
    hv_Greater = hv_ConfidenceDeviations.TupleGreaterEqualElem((-hv_MaxDeviation)*hv_Factor);
    hv_IndicesInBin = (hv_Lesser+hv_Greater).TupleFind(2);
    if (0 != (int(hv_IndicesInBin!=-1)))
    {
      SelectObj(ho_Partition, &ho_PartsSelected, hv_IndicesInBin+1);
      Union1(ho_PartsSelected, &ho_HeatmapRegionNegative);
    }
    else
    {
      GenEmptyRegion(&ho_HeatmapRegionNegative);
    }
    ConcatObj(ho_HeatmapRegionsNegative, ho_HeatmapRegionNegative, &ho_HeatmapRegionsNegative
        );
  }
  }
  //
  //Visualize the heatmap.
  HDevWindowStack::SetActive(hv_WindowHandle);
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_HeightImage-1, hv_WidthImage-1);
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Image, HDevWindowStack::GetActive());
  //For regions for which the confidence decreased, generate a color palette
  //from red to yellow with 66% transparency
  hv_Colors = ((((HTuple("#ff3300").Append("#ff6600")).Append("#ff9900")).Append("#ffcc00")).Append("#ffff00"))+"66";
  for (hv_BinIndex=1; hv_BinIndex<=5; hv_BinIndex+=1)
  {
    SelectObj(ho_HeatmapRegions, &ho_BinRegion, hv_BinIndex);
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),HTuple(hv_Colors[hv_BinIndex-1]));
    if (HDevWindowStack::IsOpen())
      DispObj(ho_BinRegion, HDevWindowStack::GetActive());
  }
  //For regions for which the confidence increased, generate a color palette
  //from blue to cyan with 66% transparency
  hv_Colors = ((((HTuple("#0033ff").Append("#0066ff")).Append("#0099ff")).Append("#00ccff")).Append("#00ffff"))+"66";
  for (hv_BinIndex=1; hv_BinIndex<=5; hv_BinIndex+=1)
  {
    SelectObj(ho_HeatmapRegionsNegative, &ho_BinRegion, hv_BinIndex);
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),HTuple(hv_Colors[hv_BinIndex-1]));
    if (HDevWindowStack::IsOpen())
      DispObj(ho_BinRegion, HDevWindowStack::GetActive());
  }
  //
  if (0 != hv_DisplayConfidence)
  {
    hv_Text = HTuple();
    hv_Text[hv_Text.TupleLength()] = "Predicted Class: "+hv_OriginalPredictedClass;
    hv_Text[hv_Text.TupleLength()] = "Original Confidence: "+(hv_OriginalConfidence.TupleString(".3f"));
    hv_Text[hv_Text.TupleLength()] = "Maximum Deviation:   "+(hv_MaxDeviation.TupleString(".3f"));
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "right", (HTuple("black").Append("black")), 
          HTuple(), HTuple());
  }
  //
  SetSystem("clip_region", hv_ClipRegionSettingBefore);
  return;
}

// Chapter: Legacy / DL Classification
// Short Description: Evaluate the performance of a deep-learning-based classifier. 
void evaluate_dl_classifier (HTuple hv_GroundTruthLabels, HTuple hv_DLClassifierHandle, 
    HTuple hv_DLClassifierResultID, HTuple hv_EvaluationMeasureType, HTuple hv_ClassesToEvaluate, 
    HTuple *hv_EvaluationMeasure)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Classes, hv_TestClassesToEvaluate;
  HTuple  hv_NumEvalMeasureTypes, hv_NumEvalClasses, hv_ComputePrecision;
  HTuple  hv_ComputeRecall, hv_ComputeFScore, hv_ComputeConfusionMatrix;
  HTuple  hv_PredictedClasses, hv_Index, hv_PredictedClass;
  HTuple  hv_ConfusionMatrix, hv_EvalMeasureTypeIndex, hv_CurrentEvalMeasure;
  HTuple  hv_CurrentEvalClass, hv_RegExpTopKError, hv_ComputeTopKError;
  HTuple  hv_K, hv_Indices, hv_TopKError, hv_NumClasses, hv_IndexClass;
  HTuple  hv_ClassPrecisions, hv_MatrixRowSumID, hv_TruePositive;
  HTuple  hv_SumPredictedClass, hv_ClassPrecision, hv_Precision;
  HTuple  hv_ClassRecalls, hv_MatrixColumnSumID, hv_SumLabel;
  HTuple  hv_ClassRecall, hv_Recall, hv_FScore;

  //This procedure can be used to compute various evaluation measures
  //to check the performance of your trained
  //deep-learning-based classifier DLClassifierHandle.
  //For this, the GroundTruthLabels must be given. Additionally,
  //the results of the classification must be given in DLClassifierResultID,
  //as returned by apply_dl_classifier and apply_dl_classifier_batchwise.
  //With EvaluationMeasureType, you can choose which evaluation measure
  //to return. With ClassesToEvaluate, you can choose whether to return
  //the result for a single class, a result for every class, or
  //for all classes combined. The result is returned in EvaluationMeasure.
  //
  //Check input.
  //Check whether ClassesToEvaluate is a class or 'global'.
  GetDlClassifierParam(hv_DLClassifierHandle, "classes", &hv_Classes);
  //
  //Convert the class indices to class labels if necessary
  if (0 != (int(((hv_GroundTruthLabels.TupleIsIntElem()).TupleFind(0))==-1)))
  {
    if (0 != (HTuple(int((hv_GroundTruthLabels.TupleMin())<0)).TupleOr(int((hv_GroundTruthLabels.TupleMax())>((hv_Classes.TupleLength())-1)))))
    {
      throw HException("The Indices of the GroundTruthLabels exceed the range of classes. \nPlease check your data split.");
    }
    hv_GroundTruthLabels = HTuple(hv_Classes[hv_GroundTruthLabels]);
  }
  if (0 != (int(((hv_GroundTruthLabels.TupleSort()).TupleUniq())!=(hv_Classes.TupleSort()))))
  {
    throw HException("Not all classes are represented in the GroundTruthLabels. \nPlease check your data split.");
  }
  hv_TestClassesToEvaluate.Clear();
  hv_TestClassesToEvaluate[0] = "global";
  hv_TestClassesToEvaluate.Append(hv_Classes);
  if (0 != (int((hv_ClassesToEvaluate.TupleDifference(hv_TestClassesToEvaluate))!=HTuple())))
  {
    throw HException("ClassesToEvaluate invalid.");
  }
  //
  //Count the measure types and modes of ClassesToEvaluate.
  hv_NumEvalMeasureTypes = hv_EvaluationMeasureType.TupleLength();
  hv_NumEvalClasses = hv_ClassesToEvaluate.TupleLength();
  //
  //If the numbers are not equal, extend the shorter one.
  if (0 != (int(hv_NumEvalMeasureTypes>hv_NumEvalClasses)))
  {
    if (0 != (HTuple(int(hv_NumEvalMeasureTypes>1)).TupleAnd(int(hv_NumEvalClasses>1))))
    {
      throw HException("Invalid number of elements in EvaluationMeasureType/ClassesToEvaluate.");
    }
    else
    {
      hv_ClassesToEvaluate = HTuple(hv_NumEvalMeasureTypes,hv_ClassesToEvaluate);
    }
  }
  if (0 != (int(hv_NumEvalMeasureTypes<hv_NumEvalClasses)))
  {
    if (0 != (HTuple(int(hv_NumEvalMeasureTypes>1)).TupleAnd(int(hv_NumEvalClasses>1))))
    {
      throw HException("Invalid number of elements in EvaluationMeasureType/ClassesToEvaluate.");
    }
    else
    {
      hv_EvaluationMeasureType = HTuple(hv_NumEvalClasses,hv_EvaluationMeasureType);
    }
  }
  //
  //Check whether we need to compute a confusion matrix.
  //We want to do this only once to save run time.
  hv_ComputePrecision = hv_EvaluationMeasureType.TupleRegexpTest("precision");
  hv_ComputeRecall = hv_EvaluationMeasureType.TupleRegexpTest("recall");
  hv_ComputeFScore = hv_EvaluationMeasureType.TupleRegexpTest("f_score");
  hv_ComputeConfusionMatrix = (hv_ComputePrecision+hv_ComputeRecall)+hv_ComputeFScore;
  if (0 != (int(hv_ComputeConfusionMatrix>0)))
  {
    //Get the top-1 predicted classes from the result handle(s).
    hv_PredictedClasses = HTuple();
    {
    HTuple end_val59 = (hv_DLClassifierResultID.TupleLength())-1;
    HTuple step_val59 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val59, step_val59); hv_Index += step_val59)
    {
      GetDlClassifierResult(HTuple(hv_DLClassifierResultID[hv_Index]), "all", "predicted_classes", 
          &hv_PredictedClass);
      hv_PredictedClasses = hv_PredictedClasses.TupleConcat(hv_PredictedClass);
    }
    }
    //Compute the confusion matrix.
    gen_confusion_matrix(hv_GroundTruthLabels, hv_PredictedClasses, "display_matrix", 
        "none", HTuple(), &hv_ConfusionMatrix);
  }
  //
  //Loop through all given measure types.
  (*hv_EvaluationMeasure) = HTuple();
  {
  HTuple end_val69 = ((hv_NumEvalMeasureTypes.TupleConcat(hv_NumEvalClasses)).TupleMax())-1;
  HTuple step_val69 = 1;
  for (hv_EvalMeasureTypeIndex=0; hv_EvalMeasureTypeIndex.Continue(end_val69, step_val69); hv_EvalMeasureTypeIndex += step_val69)
  {
    //Select the current combination.
    hv_CurrentEvalMeasure = HTuple(hv_EvaluationMeasureType[hv_EvalMeasureTypeIndex]);
    hv_CurrentEvalClass = HTuple(hv_ClassesToEvaluate[hv_EvalMeasureTypeIndex]);
    //Set the output accordingly.
    //Check whether to compute the top-k error.
    hv_RegExpTopKError = "top([0-9]+)_error";
    hv_ComputeTopKError = hv_CurrentEvalMeasure.TupleRegexpTest(hv_RegExpTopKError);
    //Check whether to compute the precision, recall, F-score.
    hv_ComputePrecision = hv_CurrentEvalMeasure.TupleRegexpTest("precision");
    hv_ComputeRecall = hv_CurrentEvalMeasure.TupleRegexpTest("recall");
    hv_ComputeFScore = hv_CurrentEvalMeasure.TupleRegexpTest("f_score");
    //
    if (0 != hv_ComputeTopKError)
    {
      //Get the K from the input string 'topK_error'.
      hv_K = (hv_CurrentEvalMeasure.TupleRegexpMatch(hv_RegExpTopKError)).TupleNumber();
      //Select all labels or only the labels with the respective class.
      if (0 != (int(hv_CurrentEvalClass==HTuple("global"))))
      {
        hv_Indices = HTuple::TupleGenSequence(0,(hv_GroundTruthLabels.TupleLength())-1,1);
      }
      else
      {
        hv_Indices = hv_GroundTruthLabels.TupleFind(hv_CurrentEvalClass);
      }
      compute_top_k_error(hv_DLClassifierHandle, hv_DLClassifierResultID, hv_GroundTruthLabels, 
          hv_Indices, hv_K, &hv_TopKError);
      (*hv_EvaluationMeasure)[hv_EvalMeasureTypeIndex] = hv_TopKError;
    }
    else if (0 != (HTuple(hv_ComputePrecision.TupleOr(hv_ComputeRecall)).TupleOr(hv_ComputeFScore)))
    {
      if (0 != (int(hv_CurrentEvalClass==HTuple("global"))))
      {
        //Compute the mean of the measures for all classes.
        hv_NumClasses = hv_Classes.TupleLength();
        hv_IndexClass = HTuple::TupleGenSequence(0,hv_NumClasses-1,1);
      }
      else
      {
        //Compute the measures for a certain class.
        hv_NumClasses = 1;
        hv_IndexClass = hv_Classes.TupleFind(hv_CurrentEvalClass);
      }
      if (0 != (hv_ComputePrecision.TupleOr(hv_ComputeFScore)))
      {
        hv_ClassPrecisions = HTuple();
        SumMatrix(hv_ConfusionMatrix, "rows", &hv_MatrixRowSumID);
        {
        HTuple end_val106 = hv_NumClasses-1;
        HTuple step_val106 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val106, step_val106); hv_Index += step_val106)
        {
          //Compute the precision for every selected class.
          GetValueMatrix(hv_ConfusionMatrix, HTuple(hv_IndexClass[hv_Index]), HTuple(hv_IndexClass[hv_Index]), 
              &hv_TruePositive);
          GetValueMatrix(hv_MatrixRowSumID, HTuple(hv_IndexClass[hv_Index]), 0, &hv_SumPredictedClass);
          if (0 != (int(hv_SumPredictedClass==0)))
          {
            hv_ClassPrecision = 0;
          }
          else
          {
            hv_ClassPrecision = hv_TruePositive/hv_SumPredictedClass;
          }
          hv_ClassPrecisions = hv_ClassPrecisions.TupleConcat(hv_ClassPrecision);
        }
        }
        hv_Precision = hv_ClassPrecisions.TupleMean();
        ClearMatrix(hv_MatrixRowSumID);
        if (0 != hv_ComputePrecision)
        {
          (*hv_EvaluationMeasure)[hv_EvalMeasureTypeIndex] = hv_Precision;
        }
      }
      if (0 != (hv_ComputeRecall.TupleOr(hv_ComputeFScore)))
      {
        hv_ClassRecalls = HTuple();
        SumMatrix(hv_ConfusionMatrix, "columns", &hv_MatrixColumnSumID);
        {
        HTuple end_val126 = hv_NumClasses-1;
        HTuple step_val126 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val126, step_val126); hv_Index += step_val126)
        {
          //Compute the recall for every class.
          GetValueMatrix(hv_ConfusionMatrix, HTuple(hv_IndexClass[hv_Index]), HTuple(hv_IndexClass[hv_Index]), 
              &hv_TruePositive);
          GetValueMatrix(hv_MatrixColumnSumID, 0, HTuple(hv_IndexClass[hv_Index]), 
              &hv_SumLabel);
          hv_ClassRecall = hv_TruePositive/hv_SumLabel;
          hv_ClassRecalls = hv_ClassRecalls.TupleConcat(hv_ClassRecall);
        }
        }
        hv_Recall = hv_ClassRecalls.TupleMean();
        ClearMatrix(hv_MatrixColumnSumID);
        if (0 != hv_ComputeRecall)
        {
          (*hv_EvaluationMeasure)[hv_EvalMeasureTypeIndex] = hv_Recall;
        }
      }
      if (0 != hv_ComputeFScore)
      {
        //Compute the F-score for a certain class or globally
        //for the averaged precision and recall.
        //Precision and recall were already computed above.
        if (0 != (int((hv_Precision+hv_Recall)==0)))
        {
          hv_FScore = 0.0;
        }
        else
        {
          hv_FScore = ((2*hv_Precision)*hv_Recall)/(hv_Precision+hv_Recall);
        }
        (*hv_EvaluationMeasure)[hv_EvalMeasureTypeIndex] = hv_FScore;
      }
    }
    else
    {
      throw HException(("Invalid option for EvaluationMeasureType: '"+hv_CurrentEvalMeasure)+"'");
    }
  }
  }
  if (0 != hv_ComputeConfusionMatrix)
  {
    ClearMatrix(hv_ConfusionMatrix);
  }
  return;

}

// Chapter: Legacy / DL Classification
// Short Description: Refer to new procedure. 
void gen_dl_classifier_heatmap (HObject ho_Image, HObject *ho_HeatmapRegions, HTuple hv_DLClassifierHandle, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Text;

  //The procedure gen_dl_classifier_heatmap has been revised and renamed.
  //This procedure now displays a text to guide the user to the correct procedure.
  //
  hv_Text = HTuple();
  hv_Text[hv_Text.TupleLength()] = "ERROR: This procedure (gen_dl_classifier_heatmap) ";
  hv_Text[hv_Text.TupleLength()] = "has been revised and renamed.";
  hv_Text[hv_Text.TupleLength()] = "Its heatmap functionality is now available in other procedures.";
  hv_Text[hv_Text.TupleLength()] = HTuple("If you need to use the legacy classification operators,");
  hv_Text[hv_Text.TupleLength()] = "please use the procedure dev_display_dl_classifier_heatmap.";
  hv_Text[hv_Text.TupleLength()] = "But we recommend to use the current functionality";
  hv_Text[hv_Text.TupleLength()] = "and its procedure gen_dl_model_classification_heatmap.";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "center", "center", 
        (HTuple("red").Append("red")), HTuple(), HTuple());
  return;
}

// Chapter: Legacy / DL Classification
// Short Description: Visualize and return the confusion matrix for the given labels. 
void gen_interactive_confusion_matrix (HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_PredictedClasses, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_WindowHandle, HTuple *hv_ConfusionMatrix)
{

  // Local iconic variables
  HObject  ho_Images;

  // Local control variables
  HTuple  hv_DisplayMatrix, hv_ReturnMatrix, hv_DisplayColor;
  HTuple  hv_DisplayColumnWidth, hv_GenParamIndex, hv_CalculateRelativeMatrix;
  HTuple  hv_Classes, hv_NumClasses, hv_AbsoluteMatrixID;
  HTuple  hv_RelativeMatrixID, hv_ColumnMatrix, hv_Class;
  HTuple  hv_ThisLabel, hv_NumClassGroundTruth, hv_RowMatrix;
  HTuple  hv_PredictedClass, hv_ThisPredictedClass, hv_NumMatches;
  HTuple  hv_RelativeError, hv_DisplayMatrixAgain, hv_StringWidths;
  HTuple  hv_StringIndex, hv_String, hv_Ascent, hv_Descent;
  HTuple  hv_StringWidth, hv_StringHeight, hv_MaxStringWidth;
  HTuple  hv_RowStart, hv_RowDistance, hv_RowEnd, hv_ColumnStart;
  HTuple  hv_ColumnOffset, hv_ColumnEnd, hv_WindowWidth, hv_WindowHeight;
  HTuple  hv_WidthLimit, hv_HeightLimit, hv_TextRow, hv_TextColumn;
  HTuple  hv_Index, hv_Text, hv_Row, hv_Column, hv_AbsoluteTransposedMatrixID;
  HTuple  hv_MatrixText, hv_MatrixMaxID, hv_MaxValue, hv_StringConversion;
  HTuple  hv_RelativeTransposedMatrixID, hv_TextColor, hv_RelativeValues;
  HTuple  hv_Thresholds, hv_Colors, hv_Greater, hv_Indices;
  HTuple  hv_DiagonalIndex, hv_Value, hv_ButtonHeight, hv_ButtonWidth;
  HTuple  hv_I, hv_BoxColor, hv_AbsValues, hv_FoundIndices;
  HTuple  hv_HighlightColor, hv_TextWidth, hv_TextHeight;
  HTuple  hv_SelectedElement, hv_ClickedGroundTruthLabel;
  HTuple  hv_ClickedPredictedClass;

  //This procedure computes a confusion matrix.
  //Therefore, it compares the classes
  //assigned in GroundTruthLabels and PredictedClasses.
  //The resulting confusion matrix can be
  //visualized, returned, or both.
  //In each case, the output can be changed
  //via generic parameters using GenParamName and GenParamValue.
  //For the visualization, the graphics window
  //must be specified with WindowHandle.
  //
  if (0 != (int((hv_GroundTruthLabels.TupleLength())!=(hv_PredictedClasses.TupleLength()))))
  {
    throw HException("Number of ground truth labels and predicted classes must be equal.");
  }
  //
  //Set generic parameter defaults.
  hv_DisplayMatrix = "absolute";
  hv_ReturnMatrix = "absolute";
  hv_DisplayColor = "true";
  hv_DisplayColumnWidth = "minimal";
  //
  //Parse generic parameters.
  {
  HTuple end_val21 = (hv_GenParamName.TupleLength())-1;
  HTuple step_val21 = 1;
  for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val21, step_val21); hv_GenParamIndex += step_val21)
  {
    if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_matrix"))))
    {
      //Set 'display_matrix'.
      hv_DisplayMatrix = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("return_matrix"))))
    {
      //Set 'return_matrix'.
      hv_ReturnMatrix = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_color"))))
    {
      //Set 'display_color'.
      hv_DisplayColor = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_column_width"))))
    {
      //Set 'display_column_width'.
      hv_DisplayColumnWidth = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else
    {
      throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
    }
  }
  }
  //
  if (0 != (HTuple(HTuple(int(hv_DisplayMatrix==HTuple("relative"))).TupleOr(int(hv_ReturnMatrix==HTuple("relative")))).TupleOr(int(hv_DisplayColor==HTuple("true")))))
  {
    hv_CalculateRelativeMatrix = 1;
  }
  else
  {
    hv_CalculateRelativeMatrix = 0;
  }
  //
  //Calculate the confusion matrix with absolute values
  //and the confusion matrix with relative errors.
  //We start with an empty matrix
  //and add the number of matching labels.
  hv_Classes = (hv_GroundTruthLabels.TupleSort()).TupleUniq();
  hv_NumClasses = hv_Classes.TupleLength();
  CreateMatrix(hv_NumClasses, hv_NumClasses, 0, &hv_AbsoluteMatrixID);
  if (0 != hv_CalculateRelativeMatrix)
  {
    CreateMatrix(hv_NumClasses, hv_NumClasses, 0, &hv_RelativeMatrixID);
  }
  {
  HTuple end_val55 = hv_NumClasses-1;
  HTuple step_val55 = 1;
  for (hv_ColumnMatrix=0; hv_ColumnMatrix.Continue(end_val55, step_val55); hv_ColumnMatrix += step_val55)
  {
    hv_Class = HTuple(hv_Classes[hv_ColumnMatrix]);
    hv_ThisLabel = hv_GroundTruthLabels.TupleEqualElem(hv_Class);
    if (0 != hv_CalculateRelativeMatrix)
    {
      //Obtain the number of ground truth labels per class.
      hv_NumClassGroundTruth = hv_ThisLabel.TupleSum();
    }
    {
    HTuple end_val62 = hv_NumClasses-1;
    HTuple step_val62 = 1;
    for (hv_RowMatrix=0; hv_RowMatrix.Continue(end_val62, step_val62); hv_RowMatrix += step_val62)
    {
      //Select classes for this row/column.
      hv_PredictedClass = HTuple(hv_Classes[hv_RowMatrix]);
      //Check whether the input data
      //corresponds to these classes.
      hv_ThisPredictedClass = hv_PredictedClasses.TupleEqualElem(hv_PredictedClass);
      //Count the number of elements where the predicted class
      //matches the ground truth label.
      hv_NumMatches = ((hv_ThisLabel+hv_ThisPredictedClass).TupleEqualElem(2)).TupleSum();
      //Set value in matrix.
      SetValueMatrix(hv_AbsoluteMatrixID, hv_RowMatrix, hv_ColumnMatrix, hv_NumMatches);
      if (0 != hv_CalculateRelativeMatrix)
      {
        if (0 != (int(hv_NumClassGroundTruth>0)))
        {
          hv_RelativeError = (hv_NumMatches.TupleReal())/hv_NumClassGroundTruth;
        }
        else
        {
          hv_RelativeError = 0;
        }
        SetValueMatrix(hv_RelativeMatrixID, hv_RowMatrix, hv_ColumnMatrix, hv_RelativeError);
      }
    }
    }
  }
  }
  //
  //Return the result.
  if (0 != (int(hv_ReturnMatrix==HTuple("absolute"))))
  {
    CopyMatrix(hv_AbsoluteMatrixID, &(*hv_ConfusionMatrix));
  }
  else if (0 != (int(hv_ReturnMatrix==HTuple("relative"))))
  {
    CopyMatrix(hv_RelativeMatrixID, &(*hv_ConfusionMatrix));
  }
  else if (0 != (int(hv_ReturnMatrix==HTuple("none"))))
  {
    //No matrix is returned.
  }
  else
  {
    throw HException("Unsupported mode for 'return_matrix'");
  }
  //
  //Display the matrix.
  if (0 != (int(hv_DisplayMatrix!=HTuple("none"))))
  {
    hv_DisplayMatrixAgain = 1;
    while (0 != hv_DisplayMatrixAgain)
    {
      //
      //Find maximal string width and set display position parameters.
      hv_StringWidths = HTuple();
      //Get the string width of each class.
      {
      HTuple end_val103 = (hv_Classes.TupleLength())-1;
      HTuple step_val103 = 1;
      for (hv_StringIndex=0; hv_StringIndex.Continue(end_val103, step_val103); hv_StringIndex += step_val103)
      {
        hv_String = HTuple(hv_Classes[hv_StringIndex]);
        GetStringExtents(hv_WindowHandle, hv_String, &hv_Ascent, &hv_Descent, &hv_StringWidth, 
            &hv_StringHeight);
        hv_StringWidths = hv_StringWidths.TupleConcat(hv_StringWidth);
      }
      }
      //The columns should have a minimum width for 4 characters.
      GetStringExtents(hv_WindowHandle, "test", &hv_Ascent, &hv_Descent, &hv_StringWidth, 
          &hv_StringHeight);
      hv_MaxStringWidth = (hv_StringWidths.TupleMax()).TupleMax2(hv_StringWidth);
      //Get the maximum string width
      //and resize the window accordingly.
      hv_RowStart = 80;
      hv_RowDistance = hv_StringHeight+10;
      hv_RowEnd = hv_StringHeight*7;
      hv_ColumnStart = 50+hv_MaxStringWidth;
      hv_ColumnOffset = 20;
      hv_ColumnEnd = hv_ColumnOffset;
      //
      //Adapt the window size to fit the confusion matrix.
      if (0 != (int(hv_DisplayColumnWidth==HTuple("minimal"))))
      {
        //Every column of the confusion matrix is as narrow as possible
        //based to the respective string widths.
        hv_WindowWidth = (((hv_StringWidths.TupleSum())+(hv_ColumnOffset*hv_NumClasses))+hv_ColumnStart)+hv_ColumnEnd;
      }
      else if (0 != (int(hv_DisplayColumnWidth==HTuple("equal"))))
      {
        //Every column of the confusion matrix should have the same width.
        //based on the maximum string width.
        hv_WindowWidth = (((hv_MaxStringWidth+hv_ColumnOffset)*hv_NumClasses)+hv_ColumnStart)+hv_ColumnEnd;
      }
      else
      {
        throw HException("");
      }
      hv_WindowHeight = ((hv_RowDistance*hv_NumClasses)+hv_RowStart)+hv_RowEnd;
      HDevWindowStack::SetActive(hv_WindowHandle);
      if (HDevWindowStack::IsOpen())
        ClearWindow(HDevWindowStack::GetActive());
      //
      //Set reasonable limits for graphics window (adapt if necessary).
      hv_WidthLimit.Clear();
      hv_WidthLimit[0] = 450;
      hv_WidthLimit[1] = 1920;
      hv_HeightLimit.Clear();
      hv_HeightLimit[0] = 250;
      hv_HeightLimit[1] = 1080;
      if (0 != (HTuple(int(hv_WindowWidth>HTuple(hv_WidthLimit[1]))).TupleOr(int(hv_WindowHeight>HTuple(hv_HeightLimit[1])))))
      {
        throw HException("Confusion Matrix does not fit into graphics window. Please adapt font and/or size limits.");
      }
      dev_resize_window_fit_size(0, 0, hv_WindowWidth, hv_WindowHeight, hv_WidthLimit, 
          hv_HeightLimit);
      //
      //Get display coordinates.
      //Get row coordinates for display.
      hv_TextRow = HTuple();
      {
      HTuple end_val147 = hv_NumClasses-1;
      HTuple step_val147 = 1;
      for (hv_ColumnMatrix=0; hv_ColumnMatrix.Continue(end_val147, step_val147); hv_ColumnMatrix += step_val147)
      {
        hv_TextRow = hv_TextRow.TupleConcat(HTuple::TupleGenSequence(0,(hv_NumClasses-1)*hv_RowDistance,hv_RowDistance));
      }
      }
      //Get column coordinates for display.
      hv_TextColumn = HTuple();
      {
      HTuple end_val152 = hv_NumClasses-1;
      HTuple step_val152 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val152, step_val152); hv_Index += step_val152)
      {
        hv_TextColumn = hv_TextColumn.TupleConcat(HTuple(hv_NumClasses,hv_ColumnStart));
        if (0 != (int(hv_DisplayColumnWidth==HTuple("minimal"))))
        {
          hv_ColumnStart = (hv_ColumnStart+HTuple(hv_StringWidths[hv_Index]))+hv_ColumnOffset;
        }
        else if (0 != (int(hv_DisplayColumnWidth==HTuple("equal"))))
        {
          hv_ColumnStart = (hv_ColumnStart+hv_MaxStringWidth)+hv_ColumnOffset;
        }
      }
      }
      //Display the confusion matrix with a margin from the top.
      hv_TextRow += hv_RowStart;
      //Display axis titles.
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Ground truth labels", "window", "top", 
            "right", "white", "box", "false");
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Predicted classes", "window", "bottom", 
            "left", "white", "box", "false");
      {
      HTuple end_val165 = (hv_Classes.TupleLength())-1;
      HTuple step_val165 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val165, step_val165); hv_Index += step_val165)
      {
        hv_Text = HTuple(hv_Classes[hv_Index]);
        //Display predicted class names.
        hv_Row = HTuple(hv_TextRow[hv_Index]);
        hv_Column = (HTuple(hv_TextColumn[0])-hv_MaxStringWidth)-hv_ColumnOffset;
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_Row, hv_Column, 
              "light gray", "box", "false");
        //Display ground truth label names.
        hv_Row = HTuple(hv_TextRow[0])-(hv_RowDistance*1.1);
        hv_Column = HTuple(hv_TextColumn[hv_Index*hv_NumClasses]);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_Row, hv_Column, 
              "light gray", "box", "false");
      }
      }
      //
      //Get the confusion matrix values for display.
      if (0 != (int(hv_DisplayMatrix==HTuple("absolute"))))
      {
        //Displayed matrix corresponds to the transposed returned matrix.
        TransposeMatrix(hv_AbsoluteMatrixID, &hv_AbsoluteTransposedMatrixID);
        GetFullMatrix(hv_AbsoluteTransposedMatrixID, &hv_MatrixText);
        //Align the numbers right.
        MaxMatrix(hv_AbsoluteMatrixID, "full", &hv_MatrixMaxID);
        GetFullMatrix(hv_MatrixMaxID, &hv_MaxValue);
        ClearMatrix(hv_MatrixMaxID);
        hv_StringConversion = (((hv_MaxValue.TupleLog10()).TupleCeil()).TupleInt())+".0f";
        hv_MatrixText = hv_MatrixText.TupleString(hv_StringConversion);
      }
      else
      {
        //Displayed matrix corresponds to the transposed returned matrix.
        TransposeMatrix(hv_RelativeMatrixID, &hv_RelativeTransposedMatrixID);
        GetFullMatrix(hv_RelativeTransposedMatrixID, &hv_MatrixText);
        ClearMatrix(hv_RelativeTransposedMatrixID);
        hv_MatrixText = hv_MatrixText.TupleString(".2f");
      }
      //Set color for displayed confusion matrix.
      if (0 != (int(hv_DisplayColor==HTuple("true"))))
      {
        TupleGenConst(hv_MatrixText.TupleLength(), "#666666", &hv_TextColor);
        //Use the relative values to adapt the color of the text.
        TransposeMatrix(hv_RelativeMatrixID, &hv_RelativeTransposedMatrixID);
        GetFullMatrix(hv_RelativeTransposedMatrixID, &hv_RelativeValues);
        ClearMatrix(hv_RelativeTransposedMatrixID);
        //Set the colors and respective thresholds for the off-diagonal values.
        hv_Thresholds.Clear();
        hv_Thresholds[0] = 0.0;
        hv_Thresholds[1] = 0.05;
        hv_Thresholds[2] = 0.1;
        hv_Thresholds[3] = 0.2;
        hv_Colors.Clear();
        hv_Colors[0] = "#8C4D4D";
        hv_Colors[1] = "#B33333";
        hv_Colors[2] = "#D91A1A";
        hv_Colors[3] = "#FF0000";
        {
        HTuple end_val205 = (hv_Thresholds.TupleLength())-1;
        HTuple step_val205 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val205, step_val205); hv_Index += step_val205)
        {
          TupleGreaterElem(hv_RelativeValues, HTuple(hv_Thresholds[hv_Index]), &hv_Greater);
          TupleFind(hv_Greater, 1, &hv_Indices);
          if (0 != (int(hv_Indices!=-1)))
          {
            TupleReplace(hv_TextColor, hv_Indices, HTuple(hv_Colors[hv_Index]), &hv_TextColor);
          }
          else
          {
            break;
          }
        }
        }
        //Set the colors and respective thresholds for the diagonal values.
        hv_Thresholds.Clear();
        hv_Thresholds[0] = -0.01;
        hv_Thresholds[1] = 0.60;
        hv_Thresholds[2] = 0.80;
        hv_Thresholds[3] = 0.90;
        hv_Thresholds[4] = 0.95;
        hv_Thresholds[5] = 0.98;
        hv_Colors.Clear();
        hv_Colors[0] = "#666666";
        hv_Colors[1] = "#508650";
        hv_Colors[2] = "#419C41";
        hv_Colors[3] = "#2BBD2B";
        hv_Colors[4] = "#15DE15";
        hv_Colors[5] = "#00FF00";
        {
        HTuple end_val217 = hv_NumClasses-1;
        HTuple step_val217 = 1;
        for (hv_DiagonalIndex=0; hv_DiagonalIndex.Continue(end_val217, step_val217); hv_DiagonalIndex += step_val217)
        {
          GetValueMatrix(hv_RelativeMatrixID, hv_DiagonalIndex, hv_DiagonalIndex, 
              &hv_Value);
          {
          HTuple end_val219 = (hv_Thresholds.TupleLength())-1;
          HTuple step_val219 = 1;
          for (hv_Index=0; hv_Index.Continue(end_val219, step_val219); hv_Index += step_val219)
          {
            if (0 != (int(hv_Value>HTuple(hv_Thresholds[hv_Index]))))
            {
              hv_TextColor[hv_DiagonalIndex*(hv_NumClasses+1)] = HTuple(hv_Colors[hv_Index]);
            }
            else
            {
              break;
            }
          }
          }
        }
        }
      }
      else
      {
        //Default value for the text color.
        TupleGenConst(hv_MatrixText.TupleLength(), "white", &hv_TextColor);
      }
      //
      //Prepare display of buttons.
      hv_ButtonHeight = HTuple(hv_TextRow.TupleLength(),hv_RowDistance*0.8);
      hv_ButtonWidth = HTuple();
      {
      HTuple end_val235 = hv_NumClasses-1;
      HTuple step_val235 = 1;
      for (hv_I=0; hv_I.Continue(end_val235, step_val235); hv_I += step_val235)
      {
        hv_ButtonWidth[HTuple::TupleGenSequence(hv_I*hv_NumClasses,((hv_I*hv_NumClasses)+hv_NumClasses)-1,1)] = HTuple(hv_StringWidths[hv_I%hv_NumClasses])+hv_ColumnOffset;
      }
      }
      hv_ButtonWidth = HTuple(hv_ButtonWidth.TupleLength(),(hv_ButtonWidth.TupleMin())*0.9);
      hv_BoxColor = HTuple(hv_ButtonWidth.TupleLength(),"#333333");
      //Do not display colored box
      //when no images can be shown.
      TransposeMatrix(hv_AbsoluteMatrixID, &hv_AbsoluteTransposedMatrixID);
      GetFullMatrix(hv_AbsoluteTransposedMatrixID, &hv_AbsValues);
      hv_FoundIndices = (hv_AbsValues.TupleEqualElem(0.0)).TupleFind(1);
      if (0 != (int(hv_FoundIndices!=-1)))
      {
        hv_BoxColor = hv_BoxColor.TupleReplace(hv_FoundIndices,"black");
      }
      hv_HighlightColor = "#fce9d4";
      //Add continue button.
      hv_MatrixText = hv_MatrixText.TupleConcat("Continue");
      GetStringExtents(hv_WindowHandle, "Continue", &hv_Ascent, &hv_Descent, &hv_TextWidth, 
          &hv_TextHeight);
      GetWindowExtents(hv_WindowHandle, &hv_Row, &hv_Column, &hv_WindowWidth, &hv_WindowHeight);
      hv_TextRow = hv_TextRow.TupleConcat((hv_WindowHeight-hv_TextHeight)-20);
      hv_TextColumn = hv_TextColumn.TupleConcat((hv_WindowWidth-hv_TextWidth)-40);
      hv_ButtonHeight = hv_ButtonHeight.TupleConcat(hv_TextHeight*1.5);
      hv_ButtonWidth = hv_ButtonWidth.TupleConcat(hv_TextWidth*1.2);
      hv_TextColor = hv_TextColor.TupleConcat("black");
      hv_BoxColor = hv_BoxColor.TupleConcat("#f28d26");
      //
      //Display confusion matrix.
      dev_disp_button(hv_MatrixText, hv_TextRow, hv_TextColumn, hv_ButtonWidth, hv_ButtonHeight, 
          hv_TextColor, hv_BoxColor, hv_HighlightColor, hv_WindowHandle, &hv_SelectedElement);
      if (HDevWindowStack::IsOpen())
        ClearWindow(HDevWindowStack::GetActive());
      //
      if (0 != (int(hv_SelectedElement!=((hv_Classes.TupleLength())*(hv_Classes.TupleLength())))))
      {
        //
        //Display images as selected with confusion matrix.
        hv_ClickedGroundTruthLabel = HTuple(hv_Classes[hv_SelectedElement/(hv_Classes.TupleLength())]);
        hv_ClickedPredictedClass = HTuple(hv_Classes[hv_SelectedElement%(hv_Classes.TupleLength())]);
        //
        //Check if 0 images are to be displayed.
        GetValueMatrix(hv_AbsoluteMatrixID, hv_SelectedElement%(hv_Classes.TupleLength()), 
            hv_SelectedElement/(hv_Classes.TupleLength()), &hv_Value);
        if (0 != (int(hv_Value!=0.0)))
        {
          hv_GenParamName.Clear();
          hv_GenParamName[0] = "global_selection";
          hv_GenParamName[1] = "label_selection";
          hv_GenParamName[2] = "predicted_class_selection";
          hv_GenParamName[3] = "display_buttons";
          hv_GenParamValue.Clear();
          hv_GenParamValue[0] = "all";
          hv_GenParamValue.Append(hv_ClickedGroundTruthLabel);
          hv_GenParamValue.Append(hv_ClickedPredictedClass);
          hv_GenParamValue.Append("true");
          get_dl_classifier_image_results(&ho_Images, hv_ImageFiles, hv_GroundTruthLabels, 
              hv_PredictedClasses, hv_GenParamName, hv_GenParamValue, hv_WindowHandle);
        }
        else
        {
          if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),"Please select an element where images are available.", 
                "window", "center", "center", "black", HTuple(), HTuple());
          WaitSeconds(3);
        }
      }
      else
      {
        //Exit the display loop.
        hv_DisplayMatrixAgain = 0;
      }
    }
    //
    //Clean up.
    if (0 != hv_CalculateRelativeMatrix)
    {
      ClearMatrix(hv_RelativeMatrixID);
    }
    ClearMatrix(hv_AbsoluteMatrixID);
  }
  return;
}

// Chapter: Legacy / DL Classification
// Short Description: Display and return the classified images. 
void get_dl_classifier_image_results (HObject *ho_Images, HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_PredictedClasses, HTuple hv_GenParamName, HTuple hv_GenParamValue, 
    HTuple hv_WindowHandle)
{

  // Local iconic variables
  HObject  ho_Image;

  // Local control variables
  HTuple  hv_LabelSelection, hv_PredictedClassSelection;
  HTuple  hv_GlobalSelection, hv_DisplayImages, hv_DisplayButtons;
  HTuple  hv_GenParamIndex, hv_Mask, hv_ImageIndex, hv_Label;
  HTuple  hv_PredictedClass, hv_Text, hv_Color, hv_Row, hv_Column;
  HTuple  hv_WindowWidth, hv_WindowHeight, hv_ButtonLabel;
  HTuple  hv_Ascent, hv_Descent, hv_TextWidth, hv_TextHeight;
  HTuple  hv_ButtonRow, hv_ButtonColumn, hv_ColorLabels, hv_HighlightColor;
  HTuple  hv_SelectedButton;

  //This procedure can be used to visualize classified
  //ImageFiles selected according to the specifications
  //given with GenParamName and GenParamValue.
  //
  //Set parameter defaults.
  hv_LabelSelection = "all";
  hv_PredictedClassSelection = "all";
  hv_GlobalSelection = "erroneously_classified";
  hv_DisplayImages = "true";
  hv_DisplayButtons = "false";
  //
  //Check if number of elements in
  //GenParamName and GenParamValue is equal.
  if (0 != (int((hv_GenParamName.TupleLength())!=(hv_GenParamValue.TupleLength()))))
  {
    throw HException("Number of generic parameter names does not match number of generic parameter values.");
  }
  //
  //Parse generic parameters.
  {
  HTuple end_val18 = (hv_GenParamName.TupleLength())-1;
  HTuple step_val18 = 1;
  for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val18, step_val18); hv_GenParamIndex += step_val18)
  {
    if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("label_selection"))))
    {
      //Set 'label_selection'.
      hv_LabelSelection = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("predicted_class_selection"))))
    {
      //Set 'predicted_class_selection'.
      hv_PredictedClassSelection = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("global_selection"))))
    {
      //Set 'global_selection'.
      hv_GlobalSelection = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_images"))))
    {
      //Set 'display_images'.
      hv_DisplayImages = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_buttons"))))
    {
      //Set 'display_buttons'.
      hv_DisplayButtons = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else
    {
      throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
    }
  }
  }
  //
  //Filter data according to LabelSelection.
  if (0 != (int(hv_LabelSelection!=HTuple("all"))))
  {
    hv_Mask = hv_GroundTruthLabels.TupleEqualElem(hv_LabelSelection);
    if (0 != (int((hv_Mask.TupleSum())==0)))
    {
      throw HException(("LabelSelection '"+hv_LabelSelection)+"' not found in GroundTruthLabels.");
    }
    hv_ImageFiles = hv_ImageFiles.TupleSelectMask(hv_Mask);
    hv_GroundTruthLabels = hv_GroundTruthLabels.TupleSelectMask(hv_Mask);
    hv_PredictedClasses = hv_PredictedClasses.TupleSelectMask(hv_Mask);
  }
  //
  //Filter data according to PredictedClassSelection.
  if (0 != (int(hv_PredictedClassSelection!=HTuple("all"))))
  {
    hv_Mask = hv_PredictedClasses.TupleEqualElem(hv_PredictedClassSelection);
    if (0 != (int((hv_Mask.TupleSum())==0)))
    {
      throw HException(("PredictedClassSelection '"+hv_PredictedClassSelection)+"' not found in PredictedClasses.");
    }
    hv_ImageFiles = hv_ImageFiles.TupleSelectMask(hv_Mask);
    hv_GroundTruthLabels = hv_GroundTruthLabels.TupleSelectMask(hv_Mask);
    hv_PredictedClasses = hv_PredictedClasses.TupleSelectMask(hv_Mask);
  }
  //
  //Filter data according to GlobalSelection.
  if (0 != (int(hv_GlobalSelection!=HTuple("all"))))
  {
    hv_Mask = hv_GroundTruthLabels.TupleEqualElem(hv_PredictedClasses);
    if (0 != (int(hv_GlobalSelection==HTuple("erroneously_classified"))))
    {
      //Flip the mask.
      hv_Mask = (hv_Mask-1).TupleAbs();
    }
    hv_ImageFiles = hv_ImageFiles.TupleSelectMask(hv_Mask);
    hv_GroundTruthLabels = hv_GroundTruthLabels.TupleSelectMask(hv_Mask);
    hv_PredictedClasses = hv_PredictedClasses.TupleSelectMask(hv_Mask);
  }
  //
  if (0 != (int(hv_DisplayImages==HTuple("true"))))
  {
    //Loop over the images.
    GenEmptyObj(&(*ho_Images));
    {
    HTuple end_val76 = (hv_ImageFiles.TupleLength())-1;
    HTuple step_val76 = 1;
    for (hv_ImageIndex=0; hv_ImageIndex.Continue(end_val76, step_val76); hv_ImageIndex += step_val76)
    {
      //
      //Concatenate selected images.
      ReadImage(&ho_Image, HTuple(hv_ImageFiles[hv_ImageIndex]));
      ConcatObj((*ho_Images), ho_Image, &(*ho_Images));
      //
      hv_Label = HTuple(hv_GroundTruthLabels[hv_ImageIndex]);
      hv_PredictedClass = HTuple(hv_PredictedClasses[hv_ImageIndex]);
      //
      hv_Text = (("Image "+(hv_ImageIndex+1))+"/")+(hv_ImageFiles.TupleLength());
      hv_Text[1] = "Label: "+hv_Label;
      hv_Text[2] = "Predicted Class: "+hv_PredictedClass;
      if (0 != (int(hv_Label==hv_PredictedClass)))
      {
        hv_Color = "forest green";
      }
      else
      {
        hv_Color = "red";
      }
      //
      //Display the image.
      dev_resize_window_fit_image(ho_Image, 0, 0, -1, -1);
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", (HTuple("black").Append("black")).TupleConcat(hv_Color), 
            "box_color", "#ffffffaa");
      if (0 != (int(hv_DisplayButtons==HTuple("false"))))
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
              "bottom", "right", "black", "box_color", "#ffffffaa");
        // stop(...); only in hdevelop
      }
      else
      {
        GetWindowExtents(hv_WindowHandle, &hv_Row, &hv_Column, &hv_WindowWidth, &hv_WindowHeight);
        hv_ButtonLabel.Clear();
        hv_ButtonLabel[0] = "Next image";
        hv_ButtonLabel[1] = "Continue";
        GetStringExtents(hv_WindowHandle, HTuple(hv_ButtonLabel[0]), &hv_Ascent, 
            &hv_Descent, &hv_TextWidth, &hv_TextHeight);
        hv_ButtonRow.Clear();
        hv_ButtonRow.Append((hv_WindowHeight-hv_TextHeight)-20);
        hv_ButtonRow.Append((hv_WindowHeight-hv_TextHeight)-20);
        hv_ButtonColumn.Clear();
        hv_ButtonColumn[0] = 20;
        hv_ButtonColumn.Append((hv_WindowWidth-hv_TextWidth)-40);
        hv_ColorLabels = "black";
        hv_Color.Clear();
        hv_Color[0] = "#fce9d4";
        hv_Color[1] = "#fce9d4";
        hv_HighlightColor = "#f28d26";
        dev_disp_button(hv_ButtonLabel, hv_ButtonRow, hv_ButtonColumn, hv_TextWidth*1.2, 
            hv_TextHeight*1.2, hv_ColorLabels, hv_Color, hv_HighlightColor, hv_WindowHandle, 
            &hv_SelectedButton);
        if (0 != (int(hv_SelectedButton==0)))
        {
          WaitSeconds(0.1);
        }
        else
        {
          return;
        }
      }
    }
    }
  }
  else
  {
    ReadImage(&(*ho_Images), hv_ImageFiles);
  }
  return;
}

// Chapter: Legacy / DL Classification
// Short Description: Plot the training error, validation error and learning rate during deep learning classifier training. 
void plot_dl_classifier_training_progress (HTuple hv_TrainingErrors, HTuple hv_ValidationErrors, 
    HTuple hv_LearningRates, HTuple hv_Epochs, HTuple hv_NumEpochs, HTuple hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_TrainingErrorPercent, hv_ValidationErrorPercent;
  HTuple  hv_AxesColor, hv_TrainingErrorColor, hv_ValidationErrorColor;
  HTuple  hv_LearningRateColor, hv_TrainingErrorFunction;
  HTuple  hv_ValidationErrorFunction, hv_LearningRateFunction;
  HTuple  hv_GenParamName, hv_GenParamValue, hv_EndYError;
  HTuple  hv_EndYLearningRate, hv_Style, hv_Flush, hv_IndexMinValError;
  HTuple  hv_Text;

  //This procedure plots the tuples training error and
  //validation error with the y-axis on the left side,
  //and the learning rate with the y-axis on the right side,
  //versus the epochs over batches on the x-axis.
  //The maximum number of epochs should be given by NumEpochs,
  //to scale the x-axis appropriately.
  //The plot is displayed in the graphics window given by WindowHandle.
  //
  //The procedure expects the input tuples TrainingErrors, ValidationErrors,
  //LearningRates, and Epochs with their values sorted in chronological order,
  //the current value in each case as last element.
  //
  //Check input parameters.
  if (0 != (int(hv_NumEpochs==HTuple())))
  {
    hv_NumEpochs = hv_Epochs.TupleMax();
  }
  else if (0 != (int((hv_NumEpochs.TupleIsNumber())!=1)))
  {
    throw HException("NumEpochs must be a number or an empty tuple.");
  }
  hv_TrainingErrorPercent = hv_TrainingErrors*100;
  hv_ValidationErrorPercent = hv_ValidationErrors*100;
  //
  //Set the colors of the axes, plots and texts.
  hv_AxesColor = "white";
  hv_TrainingErrorColor = "magenta";
  hv_ValidationErrorColor = "gold";
  hv_LearningRateColor = "dark turquoise";
  //
  //Create functions from the input tuples.
  CreateFunct1dPairs(hv_Epochs, hv_TrainingErrorPercent, &hv_TrainingErrorFunction);
  CreateFunct1dPairs(hv_Epochs, hv_ValidationErrorPercent, &hv_ValidationErrorFunction);
  CreateFunct1dPairs(hv_Epochs, hv_LearningRates, &hv_LearningRateFunction);
  //
  //Assemble generic parameters for the plots.
  hv_GenParamName.Clear();
  hv_GenParamName[0] = "axis_location_x";
  hv_GenParamName[1] = "end_x";
  hv_GenParamName[2] = "ticks_x";
  hv_GenParamName[3] = "start_y";
  hv_GenParamName[4] = "margin_top";
  hv_GenParamName[5] = "margin_right";
  hv_GenParamValue.Clear();
  hv_GenParamValue[0] = "origin";
  hv_GenParamValue.Append(hv_NumEpochs);
  hv_GenParamValue.Append((hv_NumEpochs/5)+1);
  hv_GenParamValue.Append(0);
  hv_GenParamValue.Append(70);
  hv_GenParamValue.Append(100);
  hv_EndYError = ((hv_TrainingErrorPercent.TupleConcat(hv_ValidationErrorPercent)).TupleConcat(0.1)).TupleMax();
  //Round the maximum value of the left Y-axis
  //to an integer or a real value with one decimal.
  if (0 != (int(hv_EndYError>=1.0)))
  {
    hv_EndYError = (hv_EndYError.TupleCeil()).TupleInt();
  }
  else
  {
    hv_EndYError = ((hv_EndYError*10.0).TupleCeil())/10.0;
  }
  hv_EndYLearningRate = hv_LearningRates.TupleMax();
  //Display the first values as crosses
  //for better visibility.
  if (0 != (int((hv_Epochs.TupleLength())==1)))
  {
    hv_Style = "cross";
  }
  else
  {
    hv_Style = "line";
  }
  //
  //Disable flushing the graphics window temporarily
  //to avoid flickering.
  GetWindowParam(hv_WindowHandle, "flush", &hv_Flush);
  SetWindowParam(hv_WindowHandle, "flush", "false");
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  //
  //Display plots.
  plot_funct_1d(hv_WindowHandle, hv_TrainingErrorFunction, HTuple(), "Error [%]", 
      hv_TrainingErrorColor, hv_GenParamName.TupleConcat((((HTuple("axes_color").Append("end_y")).Append("ticks_y")).Append("style"))), 
      (((hv_GenParamValue.TupleConcat(hv_AxesColor)).TupleConcat(hv_EndYError)).TupleConcat(hv_EndYError/5.0)).TupleConcat(hv_Style));
  plot_funct_1d(hv_WindowHandle, hv_ValidationErrorFunction, HTuple(), HTuple(), 
      hv_ValidationErrorColor, hv_GenParamName.TupleConcat(((HTuple("axes_color").Append("end_y")).Append("style"))), 
      ((hv_GenParamValue.TupleConcat("none")).TupleConcat(hv_EndYError)).TupleConcat(hv_Style));
  plot_funct_1d(hv_WindowHandle, hv_LearningRateFunction, HTuple(), "Learning rate", 
      hv_LearningRateColor, hv_GenParamName.TupleConcat((((((HTuple("axes_color").Append("axis_location_y")).Append("end_y")).Append("ticks_y")).Append("format_y")).Append("style"))), 
      ((((hv_GenParamValue.TupleConcat(hv_AxesColor)).TupleConcat("right")).TupleConcat(hv_EndYLearningRate)).TupleConcat(hv_EndYLearningRate/5.0)).TupleConcat((HTuple(".1e").Append("step"))));
  //
  //Display current values in appropriate colors.
  hv_IndexMinValError = hv_ValidationErrorPercent.TupleFindLast(hv_ValidationErrorPercent.TupleMin());
  hv_Text = "Best validation error: "+(HTuple(hv_ValidationErrorPercent[hv_IndexMinValError]).TupleString(".1f"));
  hv_Text[1] = "Associated training error: "+(HTuple(hv_TrainingErrorPercent[hv_IndexMinValError]).TupleString(".1f"));
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text+" %", "window", "top", "left", 
        hv_ValidationErrorColor.TupleConcat(hv_TrainingErrorColor), "box", "false");
  hv_Text = "Learning rate: "+(HTuple(hv_LearningRates[(hv_LearningRates.TupleLength())-1]).TupleString(".1e"));
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "right", hv_LearningRateColor, 
        "box", "false");
  hv_Text = "Epoch: "+(HTuple(hv_Epochs[(hv_Epochs.TupleLength())-1]).TupleString(".1f"));
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "center", 
        "white", "box", "false");
  //
  //Flush the buffer and re-enable flushing.
  FlushBuffer(hv_WindowHandle);
  SetWindowParam(hv_WindowHandle, "flush", hv_Flush);
  return;
}

// Chapter: Legacy / DL Classification
// Short Description: Preprocess images for deep-learning-based classification training and inference. 
void preprocess_dl_classifier_images (HObject ho_Images, HObject *ho_ImagesPreprocessed, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_DLClassifierHandle)
{

  // Local iconic variables
  HObject  ho_ImagesNew, ho_ImageSelected, ho_ObjectSelected;
  HObject  ho_ThreeChannelImage, ho_SingleChannelImage;

  // Local control variables
  HTuple  hv_ContrastNormalization, hv_DomainHandling;
  HTuple  hv_GenParamIndex, hv_ImageWidth, hv_ImageHeight;
  HTuple  hv_ImageRangeMin, hv_ImageRangeMax, hv_ImageNumChannels;
  HTuple  hv_ImageWidthInput, hv_ImageHeightInput, hv_EqualWidth;
  HTuple  hv_EqualHeight, hv_Type, hv_NumMatches, hv_NumImages;
  HTuple  hv_ImageIndex, hv_Min, hv_Max, hv_Range, hv_Scale;
  HTuple  hv_Shift, hv_EqualByte, hv_RescaleRange, hv_NumChannels;

  //This procedure preprocesses the provided images given by Image
  //so that they can be handled by
  //train_dl_classifier_batch and apply_dl_classifier_batch.
  //Note that depending on the images,
  //additional preprocessing steps might be beneficial.
  //
  //Set defaults.
  hv_ContrastNormalization = "false";
  hv_DomainHandling = "full_domain";
  //Set generic parameters.
  {
  HTuple end_val10 = (hv_GenParamName.TupleLength())-1;
  HTuple step_val10 = 1;
  for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val10, step_val10); hv_GenParamIndex += step_val10)
  {
    if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("contrast_normalization"))))
    {
      //Set 'contrast_normalization'
      hv_ContrastNormalization = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("domain_handling"))))
    {
      //Set 'domain_handling'
      hv_DomainHandling = HTuple(hv_GenParamValue[hv_GenParamIndex]);
    }
    else
    {
      throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
    }
  }
  }
  //
  //Get the network's image requirements
  //from the handle of the classifier
  //and use them as preprocessing parameters.
  //
  //Expected input image size:
  GetDlClassifierParam(hv_DLClassifierHandle, "image_width", &hv_ImageWidth);
  GetDlClassifierParam(hv_DLClassifierHandle, "image_height", &hv_ImageHeight);
  //Expected gray value range:
  GetDlClassifierParam(hv_DLClassifierHandle, "image_range_min", &hv_ImageRangeMin);
  GetDlClassifierParam(hv_DLClassifierHandle, "image_range_max", &hv_ImageRangeMax);
  //Expected number of channels:
  GetDlClassifierParam(hv_DLClassifierHandle, "image_num_channels", &hv_ImageNumChannels);
  //
  //Preprocess the images.
  //
  if (0 != (int(hv_DomainHandling==HTuple("full_domain"))))
  {
    FullDomain(ho_Images, &ho_Images);
  }
  else if (0 != (int(hv_DomainHandling==HTuple("crop_domain"))))
  {
    CropDomain(ho_Images, &ho_Images);
  }
  else
  {
    throw HException("Unsupported parameter value for 'domain_handling'");
  }
  //
  //Zoom images only if they have a different size than the specified size
  GetImageSize(ho_Images, &hv_ImageWidthInput, &hv_ImageHeightInput);
  hv_EqualWidth = hv_ImageWidth.TupleEqualElem(hv_ImageWidthInput);
  hv_EqualHeight = hv_ImageHeight.TupleEqualElem(hv_ImageHeightInput);
  if (0 != (HTuple(int((hv_EqualWidth.TupleMin())==0)).TupleOr(int((hv_EqualHeight.TupleMin())==0))))
  {
    ZoomImageSize(ho_Images, &ho_Images, hv_ImageWidth, hv_ImageHeight, "constant");
  }
  if (0 != (int(hv_ContrastNormalization==HTuple("true"))))
  {
    //Check the type of the input images.
    //Contrast normalization works here only for byte, integer and real images.
    GetImageType(ho_Images, &hv_Type);
    TupleRegexpTest(hv_Type, "byte|int|real", &hv_NumMatches);
    CountObj(ho_Images, &hv_NumImages);
    if (0 != (int(hv_NumMatches!=hv_NumImages)))
    {
      throw HException(HTuple("In case of contrast normalization, please provide only images of type 'byte', 'int1', 'int2', 'uint2', 'int4', 'int8', or 'real'."));
    }
    //
    //Perform contrast normalization
    if (0 != (int(hv_Type==HTuple("byte"))))
    {
      //Scale the gray values to [0-255].
      ScaleImageMax(ho_Images, &ho_Images);
    }
    else
    {
      //Scale the gray values to [ImageRangeMin-ImageRangeMax].
      //Scaling is performed separately for each image.
      GenEmptyObj(&ho_ImagesNew);
      {
      HTuple end_val70 = hv_NumImages;
      HTuple step_val70 = 1;
      for (hv_ImageIndex=1; hv_ImageIndex.Continue(end_val70, step_val70); hv_ImageIndex += step_val70)
      {
        SelectObj(ho_Images, &ho_ImageSelected, hv_ImageIndex);
        MinMaxGray(ho_ImageSelected, ho_ImageSelected, 0, &hv_Min, &hv_Max, &hv_Range);
        hv_Scale = (hv_ImageRangeMax-hv_ImageRangeMin)/(hv_Max-hv_Min);
        hv_Shift = ((-hv_Scale)*hv_Min)+hv_ImageRangeMin;
        ScaleImage(ho_ImageSelected, &ho_ImageSelected, hv_Scale, hv_Shift);
        ConcatObj(ho_ImagesNew, ho_ImageSelected, &ho_ImagesNew);
      }
      }
      ho_Images = ho_ImagesNew;
      //Integer image convert to real image
      if (0 != (int(hv_Type!=HTuple("real"))))
      {
        ConvertImageType(ho_Images, &ho_Images, "real");
      }
    }
  }
  else if (0 != (int(hv_ContrastNormalization!=HTuple("false"))))
  {
    throw HException("Unsupported parameter value for 'contrast_normalization'");
  }
  //Check the type of the input images.
  //If the type is not 'byte',
  //the gray value scaling does not work correctly.
  GetImageType(ho_Images, &hv_Type);
  TupleRegexpTest(hv_Type, "byte|real", &hv_NumMatches);
  CountObj(ho_Images, &hv_NumImages);
  if (0 != (int(hv_NumMatches!=hv_NumImages)))
  {
    throw HException("Please provide only images of type 'byte' or 'real'.");
  }
  hv_EqualByte = hv_Type.TupleEqualElem("byte");
  if (0 != (int((hv_EqualByte.TupleMax())==1)))
  {
    if (0 != (int((hv_EqualByte.TupleMin())==0)))
    {
      throw HException("Passing mixed type images is not supported.");
    }
    //Convert the image type from byte to real,
    //because the classifier expects 'real' images.
    ConvertImageType(ho_Images, &ho_Images, "real");
    //Scale/Shift the gray values from [0-255] to the expected range.
    hv_RescaleRange = (hv_ImageRangeMax-hv_ImageRangeMin)/255.0;
    ScaleImage(ho_Images, &ho_Images, hv_RescaleRange, hv_ImageRangeMin);
  }
  else
  {
    //For real images it is assumed that the range is already correct
  }

  //Check the number of channels.
  CountObj(ho_Images, &hv_NumImages);
  {
  HTuple end_val113 = hv_NumImages;
  HTuple step_val113 = 1;
  for (hv_ImageIndex=1; hv_ImageIndex.Continue(end_val113, step_val113); hv_ImageIndex += step_val113)
  {
    SelectObj(ho_Images, &ho_ObjectSelected, hv_ImageIndex);
    CountChannels(ho_ObjectSelected, &hv_NumChannels);
    if (0 != (int(hv_NumChannels!=hv_ImageNumChannels)))
    {
      //
      if (0 != (HTuple(int(hv_NumChannels==1)).TupleAnd(int(hv_ImageNumChannels==3))))
      {
        //If the image is a grayscale image, but the classifier expects a color image:
        //convert it to an image with three channels.
        Compose3(ho_ObjectSelected, ho_ObjectSelected, ho_ObjectSelected, &ho_ThreeChannelImage
            );
        ReplaceObj(ho_Images, ho_ThreeChannelImage, &ho_Images, hv_ImageIndex);
      }
      else if (0 != (HTuple(int(hv_NumChannels==3)).TupleAnd(int(hv_ImageNumChannels==1))))
      {
        //If the image is a color image, but the classifier expects a grayscale image:
        //convert it to an image with only one channel.
        Rgb1ToGray(ho_ObjectSelected, &ho_SingleChannelImage);
        ReplaceObj(ho_Images, ho_SingleChannelImage, &ho_Images, hv_ImageIndex);
      }
      else
      {
        throw HException("Number of channels not supported. Please provide a grayscale or an RGB image.");
      }
      //
    }
  }
  }
  (*ho_ImagesPreprocessed) = ho_Images;
  return;
}

// Chapter: Legacy / DL Classification
// Short Description: Read the data set containing the images and their respective ground truth labels. 
void read_dl_classifier_data_set (HTuple hv_ImageDirectory, HTuple hv_LabelSource, 
    HTuple *hv_ImageFiles, HTuple *hv_GroundTruthLabels, HTuple *hv_LabelIndices, 
    HTuple *hv_UniqueClasses)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_LabelsTmp, hv_ClassIndex;

  //This procedures lists all ImageFiles
  //located in ImageDirectory and its subdirectories,
  //and returns the label of each image in GroundTruthLabels.
  //LabelSource determines how the ground truth labels are extracted.
  //Additionally, indices are assigned to the labels,
  //which can be used for the training instead
  //of the string labels, which is more time efficient.
  //The order of indices corresponds with the returned
  //unique Classes.
  //
  //Check the parameter ImageDirectory.
  if (0 != ((hv_ImageDirectory.TupleIsString()).TupleNot()))
  {
    throw HException(("ImageDirectory "+hv_ImageDirectory)+"is not a string.");
  }
  //
  //List all images in the provided directory
  //and its subdirectories ('recursive').
  list_image_files(hv_ImageDirectory, ((((((((((((((HTuple("hobj").Append("ima")).Append("bmp")).Append("jpg")).Append("png")).Append("tiff")).Append("tif")).Append("gif")).Append("jpeg")).Append("pcx")).Append("pgm")).Append("ppm")).Append("pbm")).Append("xwd")).Append("pnm")), 
      (HTuple("recursive").Append("follow_links")), &(*hv_ImageFiles));
  if (0 != (int(((*hv_ImageFiles).TupleLength())==0)))
  {
    throw HException(("Error: Could not find any image files in folder: \""+hv_ImageDirectory)+"\"");
  }
  //
  //Get the ground truth labels.
  //Note that when configuring your own LabelSource mode,
  //you might find the procedure parse_filename helpful.
  if (0 != (int(hv_LabelSource==HTuple("last_folder"))))
  {
    //The last folder name containing the image
    //is used as label.
    TupleRegexpMatch((*hv_ImageFiles), ".*/([^/]+)/[^/]*$", &(*hv_GroundTruthLabels));
  }
  else if (0 != (int(hv_LabelSource==HTuple("file_name"))))
  {
    //The file name of each image is used as label.
    TupleRegexpMatch((*hv_ImageFiles), ".*/([^/]+)[.][^/]*$", &(*hv_GroundTruthLabels));
  }
  else if (0 != (int(hv_LabelSource==HTuple("file_name_remove_index"))))
  {
    //The file name of each image is used as label.
    //All consecutive digits and underscores
    //at the end of the file name are removed.
    TupleRegexpMatch((*hv_ImageFiles), ".*/([^/]+)[.][^/]*$", &hv_LabelsTmp);
    TupleRegexpReplace(hv_LabelsTmp, "[0-9_]*$", "", &(*hv_GroundTruthLabels));
  }
  else if (0 != (int(hv_LabelSource==HTuple())))
  {
    (*hv_GroundTruthLabels) = HTuple();
  }
  else
  {
    throw HException("LabelSource not supported.");
  }
  //Get the unique elements of Labels,
  //which represent the classes.
  (*hv_UniqueClasses) = ((*hv_GroundTruthLabels).TupleSort()).TupleUniq();
  //Assign indices to the labels.
  (*hv_LabelIndices) = (*hv_GroundTruthLabels);
  {
  HTuple end_val48 = ((*hv_UniqueClasses).TupleLength())-1;
  HTuple step_val48 = 1;
  for (hv_ClassIndex=0; hv_ClassIndex.Continue(end_val48, step_val48); hv_ClassIndex += step_val48)
  {
    (*hv_LabelIndices)[(*hv_LabelIndices).TupleFind(HTuple((*hv_UniqueClasses)[hv_ClassIndex]))] = hv_ClassIndex;
  }
  }
  return;
}

// Chapter: Legacy / DL Classification
// Short Description: Select a percentage of the given data. 
void select_percentage_dl_classifier_data (HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_SelectPercentage, HTuple *hv_ImageFilesOut, HTuple *hv_LabelsOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_UniqueClasses, hv_Ratio, hv_ClassIndex;
  HTuple  hv_Label, hv_LabelIndices, hv_ImageFilesLabel, hv_IndexEnd;

  //This procedure selects SelectPercentage percentages
  //of the input data set ImageFiles and GroundTruthLabels and returns
  //the result in ImageFilesOut and LabelsOut.
  //The original ratio of class sizes is kept
  //when applying this percentage.
  //
  //Check the input parameters.
  if (0 != (int((hv_ImageFiles.TupleLength())<1)))
  {
    throw HException("ImageFiles must not be empty.");
  }
  if (0 != (int((hv_ImageFiles.TupleLength())!=(hv_GroundTruthLabels.TupleLength()))))
  {
    throw HException("Please provide a label for every image.");
  }
  if (0 != (HTuple(int(hv_SelectPercentage<0)).TupleOr(int(hv_SelectPercentage>100))))
  {
    throw HException("UsedPercentage must be between 0 and 100.");
  }
  hv_UniqueClasses = (hv_GroundTruthLabels.TupleSort()).TupleUniq();
  //
  //Select the user-defined percentage of every class.
  if (0 != (int(hv_SelectPercentage==100)))
  {
    (*hv_ImageFilesOut) = hv_ImageFiles;
    (*hv_LabelsOut) = hv_GroundTruthLabels;
  }
  else
  {
    hv_Ratio = hv_SelectPercentage*0.01;
    (*hv_ImageFilesOut) = HTuple();
    (*hv_LabelsOut) = HTuple();
    {
    HTuple end_val26 = (hv_UniqueClasses.TupleLength())-1;
    HTuple step_val26 = 1;
    for (hv_ClassIndex=0; hv_ClassIndex.Continue(end_val26, step_val26); hv_ClassIndex += step_val26)
    {
      //For each class, find the images with this label.
      hv_Label = HTuple(hv_UniqueClasses[hv_ClassIndex]);
      hv_LabelIndices = hv_GroundTruthLabels.TupleFind(hv_Label);
      hv_ImageFilesLabel = HTuple(hv_ImageFiles[hv_LabelIndices]);
      //Shuffle the images with this label.
      tuple_shuffle(hv_ImageFilesLabel, &hv_ImageFilesLabel);
      //Select images from the class according to the given percentage.
      hv_IndexEnd = HTuple(0).TupleMax2(((((hv_ImageFilesLabel.TupleLength())*hv_Ratio).TupleFloor()).TupleInt())-1);
      (*hv_ImageFilesOut) = (*hv_ImageFilesOut).TupleConcat(hv_ImageFilesLabel.TupleSelectRange(0,hv_IndexEnd));
      (*hv_LabelsOut) = (*hv_LabelsOut).TupleConcat(HTuple(hv_IndexEnd+1,hv_Label));
    }
    }
  }
  return;
}

// Chapter: Legacy / DL Classification
// Short Description: Split and shuffle the images and ground truth labels into training, validation and test subsets. 
void split_dl_classifier_data_set (HTuple hv_ImageFiles, HTuple hv_GroundTruthLabels, 
    HTuple hv_TrainingPercent, HTuple hv_ValidationPercent, HTuple *hv_TrainingImages, 
    HTuple *hv_TrainingLabels, HTuple *hv_ValidationImages, HTuple *hv_ValidationLabels, 
    HTuple *hv_TestImages, HTuple *hv_TestLabels)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_TrainingRatio, hv_ValidationRatio;
  HTuple  hv_UniqueClasses, hv_ClassIndex, hv_Class, hv_ClassIndices;
  HTuple  hv_ImageFilesClass, hv_LabelsClass, hv_IndexTrainingEnd;
  HTuple  hv_IndexValidationEnd, hv_TrainingSequence, hv_ValidationSequence;
  HTuple  hv_TestSequence;

  //This procedure divides the data set (images and ground truth labels)
  //into three disjoint subsets: training, validation, and test.
  //The number of images and labels in each subset is defined
  //by the given percentages TrainingPercent and ValidationPercent.
  //Each subset contains randomly distributed data,
  //whereby the original ratio of class sizes is kept.
  //
  //Check the input parameters.
  if (0 != (int((hv_ImageFiles.TupleLength())!=(hv_GroundTruthLabels.TupleLength()))))
  {
    throw HException("Please provide a label for every image file.");
  }
  if (0 != (int(hv_TrainingPercent<0)))
  {
    throw HException("TrainingPercent must not be smaller than zero.");
  }
  if (0 != (int(hv_ValidationPercent<0)))
  {
    throw HException("ValidationPercent must not be smaller than zero.");
  }
  if (0 != (int((hv_ImageFiles.TupleLength())<1)))
  {
    throw HException("ImageFiles must not be empty.");
  }
  if (0 != (int((hv_TrainingPercent+hv_ValidationPercent)>100)))
  {
    throw HException("The sum of TrainingPercent and ValidationPercent must not be greater than 100.");
  }
  //
  //Set classes and data ratios.
  hv_TrainingRatio = hv_TrainingPercent*0.01;
  hv_ValidationRatio = hv_ValidationPercent*0.01;
  //
  //Prepare output tuples.
  (*hv_TrainingImages) = HTuple();
  (*hv_TrainingLabels) = HTuple();
  (*hv_ValidationImages) = HTuple();
  (*hv_ValidationLabels) = HTuple();
  (*hv_TestImages) = HTuple();
  (*hv_TestLabels) = HTuple();
  //
  //Loop through all unique classes and add data
  //according to the specified percentages.
  hv_UniqueClasses = (hv_GroundTruthLabels.TupleSort()).TupleUniq();
  {
  HTuple end_val39 = (hv_UniqueClasses.TupleLength())-1;
  HTuple step_val39 = 1;
  for (hv_ClassIndex=0; hv_ClassIndex.Continue(end_val39, step_val39); hv_ClassIndex += step_val39)
  {
    //Select all images and ground truth labels with the class.
    hv_Class = HTuple(hv_UniqueClasses[hv_ClassIndex]);
    hv_ClassIndices = hv_GroundTruthLabels.TupleFind(hv_Class);
    hv_ImageFilesClass = HTuple(hv_ImageFiles[hv_ClassIndices]);
    hv_LabelsClass = HTuple(hv_ImageFilesClass.TupleLength(),hv_Class);
    //Shuffle the images in this class.
    tuple_shuffle(hv_ImageFilesClass, &hv_ImageFilesClass);
    //Determine the boundaries of the respective selection.
    hv_IndexTrainingEnd = ((((hv_ImageFilesClass.TupleLength())*hv_TrainingRatio).TupleFloor()).TupleInt())-1;
    hv_IndexValidationEnd = ((((hv_ImageFilesClass.TupleLength())*(hv_ValidationRatio+hv_TrainingRatio)).TupleFloor()).TupleInt())-1;
    //Add the respective images and labels.
    (*hv_TrainingImages) = (*hv_TrainingImages).TupleConcat(hv_ImageFilesClass.TupleSelectRange(0,hv_IndexTrainingEnd));
    (*hv_TrainingLabels) = (*hv_TrainingLabels).TupleConcat(hv_LabelsClass.TupleSelectRange(0,hv_IndexTrainingEnd));
    (*hv_ValidationImages) = (*hv_ValidationImages).TupleConcat(hv_ImageFilesClass.TupleSelectRange(hv_IndexTrainingEnd+1,hv_IndexValidationEnd));
    (*hv_ValidationLabels) = (*hv_ValidationLabels).TupleConcat(hv_LabelsClass.TupleSelectRange(hv_IndexTrainingEnd+1,hv_IndexValidationEnd));
    (*hv_TestImages) = (*hv_TestImages).TupleConcat(hv_ImageFilesClass.TupleSelectRange(hv_IndexValidationEnd+1,(hv_ImageFilesClass.TupleLength())-1));
    (*hv_TestLabels) = (*hv_TestLabels).TupleConcat(hv_LabelsClass.TupleSelectRange(hv_IndexValidationEnd+1,(hv_ImageFilesClass.TupleLength())-1));
  }
  }
  //
  //Shuffle the output.
  tuple_shuffle(HTuple::TupleGenSequence(0,((*hv_TrainingImages).TupleLength())-1,1), 
      &hv_TrainingSequence);
  (*hv_TrainingImages) = HTuple((*hv_TrainingImages)[hv_TrainingSequence]);
  (*hv_TrainingLabels) = HTuple((*hv_TrainingLabels)[hv_TrainingSequence]);
  tuple_shuffle(HTuple::TupleGenSequence(0,((*hv_ValidationImages).TupleLength())-1,1), 
      &hv_ValidationSequence);
  (*hv_ValidationImages) = HTuple((*hv_ValidationImages)[hv_ValidationSequence]);
  (*hv_ValidationLabels) = HTuple((*hv_ValidationLabels)[hv_ValidationSequence]);
  tuple_shuffle(HTuple::TupleGenSequence(0,((*hv_TestImages).TupleLength())-1,1), 
      &hv_TestSequence);
  (*hv_TestImages) = HTuple((*hv_TestImages)[hv_TestSequence]);
  (*hv_TestLabels) = HTuple((*hv_TestLabels)[hv_TestSequence]);
  return;
}


