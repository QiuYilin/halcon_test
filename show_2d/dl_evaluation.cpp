///////////////////////////////////////////////////////////////////////////////
// File generated by HDevelop for HALCON/C++ Version 23.05.0.0
// Non-ASCII strings in this file are encoded in local-8-bit encoding (cp936).
// Ensure that the interface encoding is set to locale encoding by calling
// SetHcppInterfaceStringEncodingIsUtf8(false) at the beginning of the program.
// 
// Please note that non-ASCII characters in string constants are exported
// as octal codes in order to guarantee that the strings are correctly
// created on all systems, independent on any compiler settings.
// 
// Source files with different encoding should not be mixed in one project.
///////////////////////////////////////////////////////////////////////////////

#include "HalconCpp.h"
#include "HDevThread.h"



using namespace HalconCpp;

// Procedure declarations 
// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Initialize and check parameter for the generation of 3D gripping points and poses. 
extern void check_dl_3d_gripping_points_and_poses_params (HTuple hv_DLGrippingPointParams);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Check if scores of a Global Context Anomaly Detection model have been normalized 
extern void check_dl_gc_anomaly_scores_normalization (HTuple hv_DLModelHandle, HTuple hv_GenParam);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Check if scores of a Global Context Anomaly Detection model have been normalized 
extern void check_dl_gc_anomaly_scores_normalization (HTuple hv_DLModelHandle, HTuple hv_GenParam);
// Chapter: OCR / Deep OCR
// Short Description: This procedure converts Deep OCR Detection results to an Object Detection results. 
extern void convert_ocr_detection_result_to_object_detection (HTuple hv_OcrResults, 
    HTuple *hv_DetectionResults);
// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var, and dev_update_window to 'off'. 
extern void dev_update_off ();
// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var, and dev_update_window to 'off'. 
extern void dev_update_off ();
// Chapter: System / Operating System
// Short Description: Estimate the remaining time for a task given the current progress. 
extern void estimate_progress (HTuple hv_SecondsStart, HTuple hv_ProgressMin, HTuple hv_ProgressCurrent, 
    HTuple hv_ProgressMax, HTuple *hv_SecondsElapsed, HTuple *hv_SecondsRemaining, 
    HTuple *hv_ProgressPercent, HTuple *hv_ProgressPerSecond);
// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set. 
extern void find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, 
    HTuple hv_Mode, HTuple *hv_SampleIndices);
// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set. 
extern void find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, 
    HTuple hv_Mode, HTuple *hv_SampleIndices);
// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set. 
extern void find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, 
    HTuple hv_Mode, HTuple *hv_SampleIndices);
// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set. 
extern void find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, 
    HTuple hv_Mode, HTuple *hv_SampleIndices);
// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set. 
extern void find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, 
    HTuple hv_Mode, HTuple *hv_SampleIndices);
// Chapter: Deep Learning / Classification
// Short Description: Compute a confusion matrix, which an be visualized and/or returned. 
extern void gen_confusion_matrix (HTuple hv_GroundTruthLabels, HTuple hv_PredictedClasses, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle, HTuple *hv_ConfusionMatrix);
// Chapter: Deep Learning / Classification
// Short Description: Compute a confusion matrix, which an be visualized and/or returned. 
extern void gen_confusion_matrix (HTuple hv_GroundTruthLabels, HTuple hv_PredictedClasses, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle, HTuple *hv_ConfusionMatrix);
// Chapter: Deep Learning / Classification
// Short Description: Compute a confusion matrix, which an be visualized and/or returned. 
extern void gen_confusion_matrix (HTuple hv_GroundTruthLabels, HTuple hv_PredictedClasses, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle, HTuple *hv_ConfusionMatrix);
// Chapter: Deep Learning / Classification
// Short Description: Compute a confusion matrix, which an be visualized and/or returned. 
extern void gen_confusion_matrix (HTuple hv_GroundTruthLabels, HTuple hv_PredictedClasses, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle, HTuple *hv_ConfusionMatrix);
// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Extract gripping points based on a 3D gripping point detection model output. 
extern void gen_dl_3d_gripping_points_and_poses (HTuple hv_DLSampleBatch, HTuple hv_DLGrippingPointParams, 
    HTuple hv_DLResultBatch);
// Chapter: Deep Learning / Model
// Short Description: Store the given images in a tuple of dictionaries DLSamples. 
extern void gen_dl_samples_from_images (HObject ho_Images, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Model
// Short Description: Read the dictionaries DLSamples from files. 
extern void read_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Model
// Short Description: Read the dictionaries DLSamples from files. 
extern void read_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Model
// Short Description: Read the dictionaries DLSamples from files. 
extern void read_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Model
// Short Description: Read the dictionaries DLSamples from files. 
extern void read_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple *hv_DLSampleBatch);
// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
extern void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, 
    HTuple hv_Bold, HTuple hv_Slant);
// Chapter: System / Operating System
// Short Description: Create a formatted string of a time span. 
extern void timespan_string (HTuple hv_TotalSeconds, HTuple hv_Format, HTuple *hv_TimeString);
// Chapter: System / Operating System
// Short Description: Create a formatted string of a time span. 
extern void timespan_string (HTuple hv_TotalSeconds, HTuple hv_Format, HTuple *hv_TimeString);
// Chapter: Deep Learning / Object Detection and Instance Segmentation
void area_iou (HTuple hv_Sample, HTuple hv_Result, HTuple hv_InstanceType, HTuple hv_ResultSortIndices, 
    HTuple *hv_SampleArea, HTuple *hv_ResultArea, HTuple *hv_IoU);
// Chapter: Deep Learning / Model
// Short Description: Calculate evaluation measures based on the values of RunningMeasures and the settings in EvalParams. 
void calculate_evaluation_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Calculate anomaly measures based on RunningMeasures. 
void calculate_image_anomaly_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult);
// Chapter: Deep Learning / Classification
// Short Description: Calculate image classification measures based on RunningMeasures. 
void calculate_image_classification_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult);
// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Calculate instance measures based on RunningMeasures. 
void calculate_instance_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult);
// Chapter: OCR / Deep OCR
// Short Description: Computes the ocr_detection relevant evaluation measures. 
void calculate_ocr_detection_measures (HTuple hv_DetectionEvaluationResult, HTuple *hv_EvaluationResult);
// Chapter: OCR / Deep OCR
// Short Description: Calculate OCR recognition measures based on RunningMeasures. 
void calculate_ocr_recognition_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult);
// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Calculate pixel measures based on RunningMeasures. 
void calculate_pixel_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, HTuple *hv_EvaluationResult);
// Chapter: Deep Learning / Model
// Short Description: Calculate region measures based on running measure values. 
void calculate_region_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult);
// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Calculate 3D gripping point measures based on RunningMeasures. 
void calculate_running_gripping_point_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Compute thresholds for anomaly detection or Global Context Anomaly Detection. 
void compute_dl_anomaly_thresholds (HTuple hv_DLModelHandle, HTuple hv_DLDataset, 
    HTuple hv_GenParam, HTuple *hv_AnomalySegmentationThreshold, HTuple *hv_AnomalyClassificationThresholds);
// Chapter: Deep Learning / Classification
// Short Description: Calculate top-K error. 
void compute_top_k_error_dl_evaluation (HTuple hv_ImageLabelIDs, HTuple hv_TopKPredictions, 
    HTuple hv_K, HTuple *hv_TopKError);
// Chapter: Deep Learning / Model
// Short Description: Generate a dictionary EvalParams, which contains default values for evaluation parameters. 
void create_evaluation_default_param (HTuple hv_EvaluationType, HTuple hv_ClassIDsModel, 
    HTuple *hv_EvalParams);
// Chapter: Deep Learning / Model
// Short Description: Evaluate the model given by DLModelHandle on the selected samples of DLDataset. 
void evaluate_dl_model (HTuple hv_DLDataset, HTuple hv_DLModelHandle, HTuple hv_SampleSelectMethod, 
    HTuple hv_SampleSelectValues, HTuple hv_GenParam, HTuple *hv_EvaluationResult, 
    HTuple *hv_EvalParams);
// Chapter: Deep Learning / Classification
// Short Description: Return the confidence based heatmap of a deep learning classification in DLResult. 
void gen_dl_model_classification_heatmap (HTuple hv_DLModelHandle, HTuple hv_DLSample, 
    HTuple hv_DLResult, HTuple hv_GenParam);
// Chapter: Deep Learning / Model
// Short Description: Return the intended optimization method based on given evaluation key(s). 
void get_dl_evaluation_optimization_method (HTuple hv_EvaluationKeys, HTuple *hv_OptimizationMethod);
// Chapter: Deep Learning / Model
// Short Description: Return all pixel measures from a specified list of measures. 
void get_requested_pixel_measures (HTuple hv_Measures, HTuple hv_EvaluationType, 
    HTuple *hv_PixelMeasures);
// Chapter: Deep Learning / Model
// Short Description: Returns the list of available pixel evaluation measures for the specified type. 
void get_valid_pixel_measures (HTuple hv_EvaluationType, HTuple *hv_EvaluationMeasures);
// Chapter: Deep Learning / Model
// Short Description: Initialize the dictionary RunningMeasures for the evaluation. 
void init_running_evaluation_measures (HTuple hv_EvalParams, HTuple *hv_RunningMeasures);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Apply the given thresholds on anomaly detection and Global Context Anomaly Detection results for image classification and region segmentation. 
void threshold_dl_anomaly_results (HTuple hv_AnomalySegmentationThreshold, HTuple hv_AnomalyClassificationThreshold, 
    HTuple hv_DLResults);
// Chapter: Deep Learning / Model
// Short Description: Update RunningMeasures by evaluating Samples and corresponding Results. 
void update_running_evaluation_measures (HTuple hv_Samples, HTuple hv_Results, HTuple hv_EvalParams, 
    HTuple hv_RunningMeasures);
// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Update running measures for 3D gripping points. 
void update_running_gripping_point_measures (HTuple hv_Samples, HTuple hv_Results, 
    HTuple hv_EvalParams, HTuple hv_RunningMeasures);
// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Update running measures for an anomaly detection or Global Context Anomaly Detection evaluation. 
void update_running_image_anomaly_measures (HTuple hv_Samples, HTuple hv_Results, 
    HTuple hv_EvalParams, HTuple hv_RunningMeasures);
// Chapter: Deep Learning / Classification
// Short Description: Update running measures for an image classification evaluation. 
void update_running_image_classification_measures (HTuple hv_Samples, HTuple hv_Results, 
    HTuple hv_EvalParams, HTuple hv_RunningMeasures);
// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Update running measures for an instance-based evaluation. 
void update_running_instance_measures (HTuple hv_Samples, HTuple hv_Results, HTuple hv_EvalParams, 
    HTuple hv_RunningMeasures);
// Chapter: OCR / Deep OCR
// Short Description: Update running measures for an OCR recognition evaluation. 
void update_running_ocr_recognition_measures (HTuple hv_Samples, HTuple hv_Results, 
    HTuple hv_EvalParams, HTuple hv_RunningMeasures);
// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Update running measures for a pixel-based evaluation. 
void update_running_pixel_measures (HTuple hv_Samples, HTuple hv_Results, HTuple hv_EvalParams, 
    HTuple hv_RunningMeasures);
// Chapter: Deep Learning / Model
// Short Description: Update running measures for a region-based evaluation. 
void update_running_region_measures (HTuple hv_Samples, HTuple hv_Results, HTuple hv_EvalParams, 
    HTuple hv_RunningMeasures);
// Chapter: Deep Learning / Model
// Short Description: Check that all given entries in EvalParams are valid. 
void validate_evaluation_param (HTuple hv_EvalParams, HTuple *hv_Valid, HTuple *hv_Exception);

// Procedures 
// Chapter: Deep Learning / Object Detection and Instance Segmentation
void area_iou (HTuple hv_Sample, HTuple hv_Result, HTuple hv_InstanceType, HTuple hv_ResultSortIndices, 
    HTuple *hv_SampleArea, HTuple *hv_ResultArea, HTuple *hv_IoU)
{

  // Local iconic variables
  HObject  ho_GtMask, ho_ResMask, ho_CurrentGtMask;
  HObject  ho_ValidResMask, ho_RegionIntersection;

  // Local control variables
  HTuple  hv_GtRow1, hv_GtCol1, hv_GtRow2, hv_GtCol2;
  HTuple  hv_ResRow1, hv_ResCol1, hv_ResRow2, hv_ResCol2;
  HTuple  hv_GtIdx, hv_Height, hv_Width, hv_ValidIdxs, hv_Intersection;
  HTuple  hv_Union, hv_GtRow, hv_GtCol, hv_GtLength1, hv_GtLength2;
  HTuple  hv_GtPhi, hv_ResRow, hv_ResCol, hv_ResLength1, hv_ResLength2;
  HTuple  hv_ResPhi, hv__, hv_NumGt, hv_NumRes;

  //
  //Compute the intersection over union (IoU) between
  //the ground truth and the inferred bounding box or instance
  //segmentation mask of the object instances.
  //The instance type is determined over the InstanceType.
  //
  if (0 != (int(hv_InstanceType==HTuple("rectangle1"))))
  {
    //Get bounding box coordinates.
    GetDictTuple(hv_Sample, "bbox_row1", &hv_GtRow1);
    GetDictTuple(hv_Sample, "bbox_col1", &hv_GtCol1);
    GetDictTuple(hv_Sample, "bbox_row2", &hv_GtRow2);
    GetDictTuple(hv_Sample, "bbox_col2", &hv_GtCol2);
    GetDictTuple(hv_Result, "bbox_row1", &hv_ResRow1);
    GetDictTuple(hv_Result, "bbox_col1", &hv_ResCol1);
    GetDictTuple(hv_Result, "bbox_row2", &hv_ResRow2);
    GetDictTuple(hv_Result, "bbox_col2", &hv_ResCol2);
    //
    //Sort the results.
    hv_ResRow1 = HTuple(hv_ResRow1[hv_ResultSortIndices]);
    hv_ResCol1 = HTuple(hv_ResCol1[hv_ResultSortIndices]);
    hv_ResRow2 = HTuple(hv_ResRow2[hv_ResultSortIndices]);
    hv_ResCol2 = HTuple(hv_ResCol2[hv_ResultSortIndices]);
    //
    //Compute areas.
    (*hv_SampleArea) = (hv_GtRow2-hv_GtRow1)*(hv_GtCol2-hv_GtCol1);
    (*hv_ResultArea) = (hv_ResRow2-hv_ResRow1)*(hv_ResCol2-hv_ResCol1);
    //
    //Compute IoUs.
    (*hv_IoU) = HTuple((hv_GtRow1.TupleLength())*(hv_ResRow1.TupleLength()),0);
    if (0 != (int(((*hv_IoU).TupleLength())>0)))
    {
      {
      HTuple end_val30 = (hv_GtRow1.TupleLength())-1;
      HTuple step_val30 = 1;
      for (hv_GtIdx=0; hv_GtIdx.Continue(end_val30, step_val30); hv_GtIdx += step_val30)
      {
        hv_Height = (HTuple(hv_GtRow2[hv_GtIdx]).TupleMin2(hv_ResRow2))-(HTuple(hv_GtRow1[hv_GtIdx]).TupleMax2(hv_ResRow1));
        hv_Width = (HTuple(hv_GtCol2[hv_GtIdx]).TupleMin2(hv_ResCol2))-(HTuple(hv_GtCol1[hv_GtIdx]).TupleMax2(hv_ResCol1));
        hv_ValidIdxs = HTuple((hv_Height.TupleGreaterElem(0)).TupleAnd(hv_Width.TupleGreaterElem(0))).TupleFind(1);
        if (0 != (int(hv_ValidIdxs>-1)))
        {
          hv_Intersection = HTuple(hv_Height[hv_ValidIdxs])*HTuple(hv_Width[hv_ValidIdxs]);
          hv_Union = (HTuple((*hv_SampleArea)[hv_GtIdx])+HTuple((*hv_ResultArea)[hv_ValidIdxs]))-hv_Intersection;
          (*hv_IoU)[(hv_GtIdx*(hv_ResRow1.TupleLength()))+hv_ValidIdxs] = (hv_Intersection.TupleReal())/hv_Union;
        }
      }
      }
    }
  }
  else if (0 != (int(hv_InstanceType==HTuple("rectangle2"))))
  {
    //Get bounding box coordinates.
    GetDictTuple(hv_Sample, "bbox_row", &hv_GtRow);
    GetDictTuple(hv_Sample, "bbox_col", &hv_GtCol);
    GetDictTuple(hv_Sample, "bbox_length1", &hv_GtLength1);
    GetDictTuple(hv_Sample, "bbox_length2", &hv_GtLength2);
    GetDictTuple(hv_Sample, "bbox_phi", &hv_GtPhi);
    GetDictTuple(hv_Result, "bbox_row", &hv_ResRow);
    GetDictTuple(hv_Result, "bbox_col", &hv_ResCol);
    GetDictTuple(hv_Result, "bbox_length1", &hv_ResLength1);
    GetDictTuple(hv_Result, "bbox_length2", &hv_ResLength2);
    GetDictTuple(hv_Result, "bbox_phi", &hv_ResPhi);
    //
    //Sort results.
    hv_ResRow = HTuple(hv_ResRow[hv_ResultSortIndices]);
    hv_ResCol = HTuple(hv_ResCol[hv_ResultSortIndices]);
    hv_ResLength1 = HTuple(hv_ResLength1[hv_ResultSortIndices]);
    hv_ResLength2 = HTuple(hv_ResLength2[hv_ResultSortIndices]);
    hv_ResPhi = HTuple(hv_ResPhi[hv_ResultSortIndices]);
    //
    //Compute Areas.
    (*hv_SampleArea) = (4.0*hv_GtLength1)*hv_GtLength2;
    (*hv_ResultArea) = (4.0*hv_ResLength1)*hv_ResLength2;
    //
    //Compute IoUs.
    (*hv_IoU) = HTuple((hv_GtRow.TupleLength())*(hv_ResRow.TupleLength()),0);
    if (0 != (int(((*hv_IoU).TupleLength())>0)))
    {
      {
      HTuple end_val68 = (hv_GtRow.TupleLength())-1;
      HTuple step_val68 = 1;
      for (hv_GtIdx=0; hv_GtIdx.Continue(end_val68, step_val68); hv_GtIdx += step_val68)
      {
        hv_ValidIdxs = HTuple((HTuple((*hv_SampleArea)[hv_GtIdx]).TupleGreaterElem(0)).TupleAnd((*hv_ResultArea).TupleGreaterElem(0))).TupleFind(1);
        if (0 != (int(hv_ValidIdxs>-1)))
        {
          AreaIntersectionRectangle2(HTuple(hv_GtRow[hv_GtIdx]), HTuple(hv_GtCol[hv_GtIdx]), 
              HTuple(hv_GtPhi[hv_GtIdx]), HTuple(hv_GtLength1[hv_GtIdx]), HTuple(hv_GtLength2[hv_GtIdx]), 
              HTuple(hv_ResRow[hv_ValidIdxs]), HTuple(hv_ResCol[hv_ValidIdxs]), HTuple(hv_ResPhi[hv_ValidIdxs]), 
              HTuple(hv_ResLength1[hv_ValidIdxs]), HTuple(hv_ResLength2[hv_ValidIdxs]), 
              &hv_Intersection);
          hv_Union = (HTuple((*hv_SampleArea)[hv_GtIdx])+HTuple((*hv_ResultArea)[hv_ValidIdxs]))-hv_Intersection;
          (*hv_IoU)[(hv_GtIdx*(hv_ResRow.TupleLength()))+hv_ValidIdxs] = (hv_Intersection.TupleReal())/hv_Union;
        }
      }
      }
    }
  }
  else if (0 != (int(hv_InstanceType==HTuple("mask"))))
  {
    //Get the ground truth mask.
    GetDictObject(&ho_GtMask, hv_Sample, "mask");
    //
    //Get the result mask.
    GetDictObject(&ho_ResMask, hv_Result, "mask");
    //
    //Sort the results.
    SelectObj(ho_ResMask, &ho_ResMask, hv_ResultSortIndices+1);
    //
    //Compute Areas.
    AreaCenter(ho_GtMask, &(*hv_SampleArea), &hv__, &hv__);
    AreaCenter(ho_ResMask, &(*hv_ResultArea), &hv__, &hv__);
    //
    //Compute IoUs.
    CountObj(ho_GtMask, &hv_NumGt);
    CountObj(ho_ResMask, &hv_NumRes);
    (*hv_IoU) = HTuple(hv_NumGt*hv_NumRes,0);
    if (0 != (int(((*hv_IoU).TupleLength())>0)))
    {
      {
      HTuple end_val96 = hv_NumGt-1;
      HTuple step_val96 = 1;
      for (hv_GtIdx=0; hv_GtIdx.Continue(end_val96, step_val96); hv_GtIdx += step_val96)
      {
        hv_ValidIdxs = HTuple((HTuple((*hv_SampleArea)[hv_GtIdx]).TupleGreaterElem(0)).TupleAnd((*hv_ResultArea).TupleGreaterElem(0))).TupleFind(1);
        if (0 != (int(hv_ValidIdxs>-1)))
        {
          SelectObj(ho_GtMask, &ho_CurrentGtMask, hv_GtIdx+1);
          SelectObj(ho_ResMask, &ho_ValidResMask, hv_ValidIdxs+1);
          Intersection(ho_ValidResMask, ho_CurrentGtMask, &ho_RegionIntersection);
          AreaCenter(ho_RegionIntersection, &hv_Intersection, &hv__, &hv__);
          hv_Union = (HTuple((*hv_SampleArea)[hv_GtIdx])+HTuple((*hv_ResultArea)[hv_ValidIdxs]))-hv_Intersection;
          (*hv_IoU)[(hv_GtIdx*hv_NumRes)+hv_ValidIdxs] = (hv_Intersection.TupleReal())/hv_Union;
        }
      }
      }
    }
  }
  else
  {
    throw HException(("Instance type '"+hv_InstanceType)+"' is not supported");
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Calculate evaluation measures based on the values of RunningMeasures and the settings in EvalParams. 
void calculate_evaluation_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_EvaluationType, hv_EvaluationResultTmp;
  HTuple  hv_PixelMeasures, hv_PixelMeasureValues, hv_ResultKeys;
  HTuple  hv_KeyIndex, hv___Tmp_Ctrl_Type;

  //
  //This procedure calculates the final measures depending on the evaluation type.
  //
  GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
  if (0 != (HTuple(int(hv_EvaluationType==HTuple("anomaly_detection"))).TupleOr(int(hv_EvaluationType==HTuple("gc_anomaly_detection")))))
  {
    calculate_image_anomaly_measures(hv_RunningMeasures, hv_EvalParams, &(*hv_EvaluationResult));
  }
  else if (0 != (int(hv_EvaluationType==HTuple("classification"))))
  {
    calculate_image_classification_measures(hv_RunningMeasures, hv_EvalParams, &(*hv_EvaluationResult));
  }
  else if (0 != (HTuple(int(hv_EvaluationType==HTuple("detection"))).TupleOr(int(hv_EvaluationType==HTuple("ocr_detection")))))
  {
    calculate_instance_measures(hv_RunningMeasures, hv_EvalParams, &(*hv_EvaluationResult));
    if (0 != (int(hv_EvaluationType==HTuple("ocr_detection"))))
    {
      calculate_ocr_detection_measures((*hv_EvaluationResult), &(*hv_EvaluationResult));
    }
  }
  else if (0 != (HTuple(int(hv_EvaluationType==HTuple("segmentation"))).TupleOr(int(hv_EvaluationType==HTuple("3d_gripping_point_detection")))))
  {
    calculate_pixel_measures(hv_RunningMeasures, hv_EvalParams, &(*hv_EvaluationResult));
    if (0 != (int(hv_EvaluationType==HTuple("3d_gripping_point_detection"))))
    {
      calculate_region_measures(hv_RunningMeasures, hv_EvalParams, &hv_EvaluationResultTmp);
      //Only report requested pixel and region measures.
      get_requested_pixel_measures(hv_EvalParams.TupleGetDictTuple("measures"), hv_EvaluationType, 
          &hv_PixelMeasures);
      GetDictTuple((*hv_EvaluationResult), hv_PixelMeasures, &hv_PixelMeasureValues);
      SetDictTuple(hv_EvaluationResultTmp, hv_PixelMeasures, hv_PixelMeasureValues);
      (*hv_EvaluationResult) = hv_EvaluationResultTmp;
      calculate_running_gripping_point_measures(hv_RunningMeasures, hv_EvalParams, 
          &hv_EvaluationResultTmp);
      GetDictParam(hv_EvaluationResultTmp, "keys", HTuple(), &hv_ResultKeys);
      {
      HTuple end_val24 = (hv_ResultKeys.TupleLength())-1;
      HTuple step_val24 = 1;
      for (hv_KeyIndex=0; hv_KeyIndex.Continue(end_val24, step_val24); hv_KeyIndex += step_val24)
      {
        GetDictParam(hv_EvaluationResultTmp, "key_data_type", HTuple(hv_ResultKeys[hv_KeyIndex]), 
            &hv___Tmp_Ctrl_Type);
        if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
        {
          SetDictObject(hv_EvaluationResultTmp.TupleGetDictObject(HTuple(hv_ResultKeys[hv_KeyIndex])), 
              (*hv_EvaluationResult), HTuple(hv_ResultKeys[hv_KeyIndex]));
        }
        else
        {
          SetDictTuple((*hv_EvaluationResult), HTuple(hv_ResultKeys[hv_KeyIndex]), 
              hv_EvaluationResultTmp.TupleGetDictTuple(HTuple(hv_ResultKeys[hv_KeyIndex])));
        }
      }
      }
    }
  }
  else if (0 != (int(hv_EvaluationType==HTuple("ocr_recognition"))))
  {
    calculate_ocr_recognition_measures(hv_RunningMeasures, hv_EvalParams, &(*hv_EvaluationResult));
  }
  //
  return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Calculate anomaly measures based on RunningMeasures. 
void calculate_image_anomaly_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CalcAnomalyHistogram, hv_CalcPrecision;
  HTuple  hv_CalcRecall, hv_CalcAbsoluteConfusionMatrix, hv_CalcRelativeConfusionMatrix;
  HTuple  hv_MeasuresExists, hv_Measures, hv_M, hv_AnomalyClassificationThresholdExists;
  HTuple  hv_AnomalyClassificationThreshold, hv_ImageIDs;
  HTuple  hv_AnomalyLabelIDs, hv_AnomalyScores, hv_OKIndices;
  HTuple  hv_NOKIndices, hv_HistoOKXValues, hv_HistoOKYValues;
  HTuple  hv_NumOKEvalData, hv_ImageLevelScoresOK, hv_HistoNOKXValues;
  HTuple  hv_HistoNOKYValues, hv_NumNOKEvalData, hv_ImageLevelScoresNOK;
  HTuple  hv_ScoreHistogram, hv_NumClasses, hv_ClassIDs, hv_AllPredictions;
  HTuple  hv_IndThreshold, hv_CurrentThresholdValue, hv_CurrentThresholdKey;
  HTuple  hv_Predictions, hv_AbsoluteConfustionMatrices, hv_AbsoluteConfusionMatrix;
  HTuple  hv_Rows, hv_Columns, hv_Value, hv_AbsoluteConfusionMatrixDictionary;
  HTuple  hv_RelativeConfustionMatrices, hv_RelativeConfusionMatrix;
  HTuple  hv_RelativeConfusionMatrixDictionary, hv_GlobalEvaluation;
  HTuple  hv_AllClassPrecisions, hv_AllMeanPrecisions, hv_AbsoluteConfusionMatrices;
  HTuple  hv_ClassPrecisions, hv_MatrixRowSumID, hv_MatrixColumnSumID;
  HTuple  hv_Index, hv_TruePositive, hv_SumPredictedClass;
  HTuple  hv_SumLabel, hv_ClassPrecision, hv_ValidClassPrecisions;
  HTuple  hv_MeanPrecision, hv_AllClassRecalls, hv_AllMeanRecalls;
  HTuple  hv_ClassRecalls, hv_ClassRecall, hv_ValidClassRecalls;
  HTuple  hv_MeanRecall;

  //
  //This procedure calculates the final summarizing image anomaly measures based on the running measures.
  //
  hv_CalcAnomalyHistogram = 1;
  hv_CalcPrecision = 0;
  hv_CalcRecall = 0;
  hv_CalcAbsoluteConfusionMatrix = 0;
  hv_CalcRelativeConfusionMatrix = 0;
  GetDictParam(hv_EvalParams, "key_exists", "measures", &hv_MeasuresExists);
  if (0 != hv_MeasuresExists)
  {
    GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
    {
    HTuple end_val11 = (hv_Measures.TupleLength())-1;
    HTuple step_val11 = 1;
    for (hv_M=0; hv_M.Continue(end_val11, step_val11); hv_M += step_val11)
    {
      if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("anomaly_score_histogram"))))
      {
        //The default, just here for consistency.
        hv_CalcAnomalyHistogram = 1;
      }
      else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("precision"))))
      {
        hv_CalcPrecision = 1;
        hv_CalcAbsoluteConfusionMatrix = 1;
      }
      else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("recall"))))
      {
        hv_CalcRecall = 1;
        hv_CalcAbsoluteConfusionMatrix = 1;
      }
      else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("absolute_confusion_matrix"))))
      {
        hv_CalcAbsoluteConfusionMatrix = 1;
      }
      else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("relative_confusion_matrix"))))
      {
        hv_CalcRelativeConfusionMatrix = 1;
      }
      else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("all"))))
      {
        hv_CalcPrecision = 1;
        hv_CalcRecall = 1;
        hv_CalcAbsoluteConfusionMatrix = 1;
        hv_CalcRelativeConfusionMatrix = 1;
      }
      else
      {
        throw HException(("Unknown Measure: "+HTuple(hv_Measures[hv_M]))+".");
      }
    }
    }
  }
  //
  GetDictParam(hv_EvalParams, "key_exists", "anomaly_classification_thresholds", 
      &hv_AnomalyClassificationThresholdExists);
  if (0 != hv_AnomalyClassificationThresholdExists)
  {
    GetDictTuple(hv_EvalParams, "anomaly_classification_thresholds", &hv_AnomalyClassificationThreshold);
  }
  else if (0 != (hv_CalcRelativeConfusionMatrix.TupleOr(hv_CalcAbsoluteConfusionMatrix)))
  {
    throw HException("A threshold value is needed to calculate a confusion matrix.");
  }
  //
  //Get and check values in RunningMeasures.
  //
  //Get image ids.
  GetDictTuple(hv_RunningMeasures, "image_ids", &hv_ImageIDs);
  //Get anomaly ids.
  GetDictTuple(hv_RunningMeasures, "anomaly_label_ids", &hv_AnomalyLabelIDs);
  //Get image scores.
  GetDictTuple(hv_RunningMeasures, "anomaly_scores", &hv_AnomalyScores);
  //
  //Calculate histograms.
  //
  //Find scores of 'ok' and 'nok' images.
  hv_OKIndices = hv_AnomalyLabelIDs.TupleFind(0);
  hv_NOKIndices = hv_AnomalyLabelIDs.TupleFind(1);
  if (0 != (HTuple(int(hv_OKIndices==-1)).TupleAnd(int(hv_NOKIndices==-1))))
  {
    throw HException("No data available for evaluation");
  }
  //
  //Calculate histogram for 'ok' images.
  hv_HistoOKXValues = HTuple();
  hv_HistoOKYValues = HTuple();
  hv_NumOKEvalData = 0;
  if (0 != (int(hv_OKIndices!=-1)))
  {
    hv_NumOKEvalData = hv_OKIndices.TupleLength();
    hv_ImageLevelScoresOK = HTuple(hv_AnomalyScores[hv_OKIndices]);
    hv_HistoOKXValues = hv_ImageLevelScoresOK.TupleSort();
    hv_HistoOKYValues = (HTuple::TupleGenSequence(hv_ImageLevelScoresOK.TupleLength(),1,-1).TupleReal())/(hv_ImageLevelScoresOK.TupleLength());
  }
  //
  //Calculate histogram for 'nok' images.
  hv_HistoNOKXValues = HTuple();
  hv_HistoNOKYValues = HTuple();
  hv_NumNOKEvalData = 0;
  if (0 != (int(hv_NOKIndices!=-1)))
  {
    hv_NumNOKEvalData = hv_NOKIndices.TupleLength();
    hv_ImageLevelScoresNOK = HTuple(hv_AnomalyScores[hv_NOKIndices]);
    hv_HistoNOKXValues = hv_ImageLevelScoresNOK.TupleSort();
    hv_HistoNOKYValues = (HTuple::TupleGenSequence(1,hv_ImageLevelScoresNOK.TupleLength(),1).TupleReal())/(hv_ImageLevelScoresNOK.TupleLength());
  }
  //
  //Create dictionary for the score histogram.
  CreateDict(&hv_ScoreHistogram);
  SetDictTuple(hv_ScoreHistogram, "ok_x", hv_HistoOKXValues);
  SetDictTuple(hv_ScoreHistogram, "ok_y", hv_HistoOKYValues);
  SetDictTuple(hv_ScoreHistogram, "nok_x", hv_HistoNOKXValues);
  SetDictTuple(hv_ScoreHistogram, "nok_y", hv_HistoNOKYValues);
  //
  //Set the score histogram in the results dictionary.
  CreateDict(&(*hv_EvaluationResult));
  SetDictTuple((*hv_EvaluationResult), "anomaly_score_histogram", hv_ScoreHistogram);
  //
  //Get Predictions according to given Threshold value(s).
  //Remember, precision and recall base on the absolute confusion matrix.
  if (0 != (hv_CalcAbsoluteConfusionMatrix.TupleOr(hv_CalcRelativeConfusionMatrix)))
  {
    GetDictTuple(hv_EvalParams, "num_classes", &hv_NumClasses);
    GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
    CreateDict(&hv_AllPredictions);
    {
    HTuple end_val100 = (hv_AnomalyClassificationThreshold.TupleLength())-1;
    HTuple step_val100 = 1;
    for (hv_IndThreshold=0; hv_IndThreshold.Continue(end_val100, step_val100); hv_IndThreshold += step_val100)
    {
      hv_CurrentThresholdValue = HTuple(hv_AnomalyClassificationThreshold[hv_IndThreshold]);
      hv_CurrentThresholdKey = hv_IndThreshold.TupleString(".3d");
      hv_Predictions = hv_AnomalyScores.TupleGreaterEqualElem(hv_CurrentThresholdValue);
      SetDictTuple(hv_AllPredictions, hv_CurrentThresholdKey, hv_Predictions);
    }
    }
  }
  //
  //Calculate absolute confusion matrix.
  if (0 != hv_CalcAbsoluteConfusionMatrix)
  {
    hv_AbsoluteConfustionMatrices = HTuple();
    {
    HTuple end_val111 = (hv_AnomalyClassificationThreshold.TupleLength())-1;
    HTuple step_val111 = 1;
    for (hv_IndThreshold=0; hv_IndThreshold.Continue(end_val111, step_val111); hv_IndThreshold += step_val111)
    {
      hv_CurrentThresholdValue = HTuple(hv_AnomalyClassificationThreshold[hv_IndThreshold]);
      hv_CurrentThresholdKey = hv_IndThreshold.TupleString(".3d");
      GetDictTuple(hv_AllPredictions, hv_CurrentThresholdKey, &hv_Predictions);
      gen_confusion_matrix(hv_AnomalyLabelIDs, hv_Predictions, (HTuple("display_matrix").Append("return_matrix")), 
          (HTuple("none").Append("absolute")), HTuple(), &hv_AbsoluteConfusionMatrix);
      GetSizeMatrix(hv_AbsoluteConfusionMatrix, &hv_Rows, &hv_Columns);
      if (0 != (HTuple(HTuple(int(hv_NumOKEvalData<=0)).TupleOr(int(hv_NumNOKEvalData<=0))).TupleAnd(HTuple(int(hv_Rows<2)).TupleOr(int(hv_Columns<2)))))
      {
        //Patch matrix to 2x2 in case only 'ok' or only 'nok'
        //data is used for evaluation.
        GetValueMatrix(hv_AbsoluteConfusionMatrix, 0, 0, &hv_Value);
        CreateMatrix(2, 2, 0, &hv_AbsoluteConfusionMatrix);
        if (0 != (int(hv_NumOKEvalData<=0)))
        {
          SetValueMatrix(hv_AbsoluteConfusionMatrix, 0, 1, (hv_Predictions.TupleLength())-hv_Value);
          SetValueMatrix(hv_AbsoluteConfusionMatrix, 1, 1, hv_Value);
        }
        if (0 != (int(hv_NumNOKEvalData<=0)))
        {
          SetValueMatrix(hv_AbsoluteConfusionMatrix, 0, 0, hv_Value);
          SetValueMatrix(hv_AbsoluteConfusionMatrix, 1, 0, (hv_Predictions.TupleLength())-hv_Value);
        }
      }
      CreateDict(&hv_AbsoluteConfusionMatrixDictionary);
      SetDictTuple(hv_AbsoluteConfusionMatrixDictionary, "confusion_matrix", hv_AbsoluteConfusionMatrix);
      SetDictTuple(hv_AbsoluteConfusionMatrixDictionary, "threshold", hv_CurrentThresholdValue);
      hv_AbsoluteConfustionMatrices[hv_IndThreshold] = hv_AbsoluteConfusionMatrixDictionary;
    }
    }
    SetDictTuple((*hv_EvaluationResult), "absolute_confusion_matrix", hv_AbsoluteConfustionMatrices);
  }
  //
  //Calculate relative confusion matrix.
  if (0 != hv_CalcRelativeConfusionMatrix)
  {
    hv_RelativeConfustionMatrices = HTuple();
    {
    HTuple end_val142 = (hv_AnomalyClassificationThreshold.TupleLength())-1;
    HTuple step_val142 = 1;
    for (hv_IndThreshold=0; hv_IndThreshold.Continue(end_val142, step_val142); hv_IndThreshold += step_val142)
    {
      hv_CurrentThresholdValue = HTuple(hv_AnomalyClassificationThreshold[hv_IndThreshold]);
      hv_CurrentThresholdKey = hv_IndThreshold.TupleString(".3d");
      GetDictTuple(hv_AllPredictions, hv_CurrentThresholdKey, &hv_Predictions);
      gen_confusion_matrix(hv_AnomalyLabelIDs, hv_Predictions, (HTuple("display_matrix").Append("return_matrix")), 
          (HTuple("none").Append("relative")), HTuple(), &hv_RelativeConfusionMatrix);
      GetSizeMatrix(hv_RelativeConfusionMatrix, &hv_Rows, &hv_Columns);
      if (0 != (HTuple(HTuple(int(hv_NumOKEvalData<=0)).TupleOr(int(hv_NumNOKEvalData<=0))).TupleAnd(HTuple(int(hv_Rows<2)).TupleOr(int(hv_Columns<2)))))
      {
        //Patch matrix to 2x2 in case only 'ok' or only 'nok'
        //data is used for evaluation.
        GetValueMatrix(hv_RelativeConfusionMatrix, 0, 0, &hv_Value);
        CreateMatrix(2, 2, 0, &hv_RelativeConfusionMatrix);
        if (0 != (int(hv_NumOKEvalData<=0)))
        {
          SetValueMatrix(hv_RelativeConfusionMatrix, 0, 1, 1.0-hv_Value);
          SetValueMatrix(hv_RelativeConfusionMatrix, 1, 1, hv_Value);
        }
        if (0 != (int(hv_NumNOKEvalData<=0)))
        {
          SetValueMatrix(hv_RelativeConfusionMatrix, 0, 0, hv_Value);
          SetValueMatrix(hv_RelativeConfusionMatrix, 1, 0, 1.0-hv_Value);
        }
      }
      CreateDict(&hv_RelativeConfusionMatrixDictionary);
      SetDictTuple(hv_RelativeConfusionMatrixDictionary, "confusion_matrix", hv_RelativeConfusionMatrix);
      SetDictTuple(hv_RelativeConfusionMatrixDictionary, "threshold", hv_CurrentThresholdValue);
      hv_RelativeConfustionMatrices[hv_IndThreshold] = hv_RelativeConfusionMatrixDictionary;
    }
    }
    SetDictTuple((*hv_EvaluationResult), "relative_confusion_matrix", hv_RelativeConfustionMatrices);
  }
  //
  if (0 != (hv_CalcPrecision.TupleOr(hv_CalcRecall)))
  {
    CreateDict(&hv_GlobalEvaluation);
  }
  //Calculate precision.
  if (0 != hv_CalcPrecision)
  {
    hv_AllClassPrecisions = HTuple();
    hv_AllMeanPrecisions = HTuple();
    GetDictTuple((*hv_EvaluationResult), "absolute_confusion_matrix", &hv_AbsoluteConfusionMatrices);
    {
    HTuple end_val178 = (hv_AbsoluteConfusionMatrices.TupleLength())-1;
    HTuple step_val178 = 1;
    for (hv_IndThreshold=0; hv_IndThreshold.Continue(end_val178, step_val178); hv_IndThreshold += step_val178)
    {
      hv_AbsoluteConfusionMatrixDictionary = HTuple(hv_AbsoluteConfusionMatrices[hv_IndThreshold]);
      GetDictTuple(hv_AbsoluteConfusionMatrixDictionary, "confusion_matrix", &hv_AbsoluteConfusionMatrix);
      hv_ClassPrecisions = HTuple();
      SumMatrix(hv_AbsoluteConfusionMatrix, "rows", &hv_MatrixRowSumID);
      SumMatrix(hv_AbsoluteConfusionMatrix, "columns", &hv_MatrixColumnSumID);
      {
      HTuple end_val184 = hv_NumClasses-1;
      HTuple step_val184 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val184, step_val184); hv_Index += step_val184)
      {
        //Compute the precision for every selected class.
        GetValueMatrix(hv_AbsoluteConfusionMatrix, HTuple(hv_ClassIDs[hv_Index]), 
            HTuple(hv_ClassIDs[hv_Index]), &hv_TruePositive);
        GetValueMatrix(hv_MatrixRowSumID, HTuple(hv_ClassIDs[hv_Index]), 0, &hv_SumPredictedClass);
        GetValueMatrix(hv_MatrixColumnSumID, 0, HTuple(hv_ClassIDs[hv_Index]), &hv_SumLabel);
        if (0 != (int(hv_SumLabel<=0)))
        {
          //Invalid per-class precision.
          hv_ClassPrecision = -1.0;
        }
        else if (0 != (int(hv_SumPredictedClass==0)))
        {
          hv_ClassPrecision = 0.0;
        }
        else
        {
          hv_ClassPrecision = hv_TruePositive/hv_SumPredictedClass;
        }
        hv_ClassPrecisions = hv_ClassPrecisions.TupleConcat(hv_ClassPrecision);
      }
      }
      TupleSelectMask(hv_ClassPrecisions, hv_ClassPrecisions.TupleGreaterEqualElem(0.0), 
          &hv_ValidClassPrecisions);
      hv_MeanPrecision = hv_ValidClassPrecisions.TupleMean();
      hv_AllClassPrecisions = hv_AllClassPrecisions.TupleConcat(hv_ClassPrecisions);
      hv_AllMeanPrecisions = hv_AllMeanPrecisions.TupleConcat(hv_MeanPrecision);
      ClearMatrix(hv_MatrixRowSumID);
    }
    }
    SetDictTuple(hv_GlobalEvaluation, "precision_per_class", hv_AllClassPrecisions);
    SetDictTuple(hv_GlobalEvaluation, "mean_precision", hv_AllMeanPrecisions);
  }
  //
  //Calculate recall.
  if (0 != hv_CalcRecall)
  {
    hv_AllClassRecalls = HTuple();
    hv_AllMeanRecalls = HTuple();
    GetDictTuple((*hv_EvaluationResult), "absolute_confusion_matrix", &hv_AbsoluteConfustionMatrices);
    {
    HTuple end_val214 = (hv_AbsoluteConfustionMatrices.TupleLength())-1;
    HTuple step_val214 = 1;
    for (hv_IndThreshold=0; hv_IndThreshold.Continue(end_val214, step_val214); hv_IndThreshold += step_val214)
    {
      hv_AbsoluteConfusionMatrixDictionary = HTuple(hv_AbsoluteConfustionMatrices[hv_IndThreshold]);
      GetDictTuple(hv_AbsoluteConfusionMatrixDictionary, "confusion_matrix", &hv_AbsoluteConfusionMatrix);
      hv_ClassRecalls = HTuple();
      SumMatrix(hv_AbsoluteConfusionMatrix, "columns", &hv_MatrixColumnSumID);
      {
      HTuple end_val219 = hv_NumClasses-1;
      HTuple step_val219 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val219, step_val219); hv_Index += step_val219)
      {
        //Compute the recall for every selected class.
        GetValueMatrix(hv_AbsoluteConfusionMatrix, HTuple(hv_ClassIDs[hv_Index]), 
            HTuple(hv_ClassIDs[hv_Index]), &hv_TruePositive);
        GetValueMatrix(hv_MatrixColumnSumID, 0, HTuple(hv_ClassIDs[hv_Index]), &hv_SumLabel);
        if (0 != (int(hv_SumLabel==0)))
        {
          //Invalid per-class recall.
          hv_ClassRecall = -1.0;
        }
        else
        {
          hv_ClassRecall = hv_TruePositive/hv_SumLabel;
        }
        hv_ClassRecalls = hv_ClassRecalls.TupleConcat(hv_ClassRecall);
      }
      }
      TupleSelectMask(hv_ClassRecalls, hv_ClassRecalls.TupleGreaterEqualElem(0.0), 
          &hv_ValidClassRecalls);
      hv_MeanRecall = hv_ValidClassRecalls.TupleMean();
      hv_AllClassRecalls = hv_AllClassRecalls.TupleConcat(hv_ClassRecalls);
      hv_AllMeanRecalls = hv_AllMeanRecalls.TupleConcat(hv_MeanRecall);
      ClearMatrix(hv_MatrixColumnSumID);
      //
    }
    }
    SetDictTuple(hv_GlobalEvaluation, "recall_per_class", hv_AllClassRecalls);
    SetDictTuple(hv_GlobalEvaluation, "mean_recall", hv_AllMeanRecalls);
  }
  //
  if (0 != (hv_CalcPrecision.TupleOr(hv_CalcRecall)))
  {
    SetDictTuple((*hv_EvaluationResult), "global_evaluation", hv_GlobalEvaluation);
  }
  //
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Calculate image classification measures based on RunningMeasures. 
void calculate_image_classification_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_TopKErrorKs, hv_CalcPrecision, hv_CalcRecall;
  HTuple  hv_CalcFScore, hv_CalcAbsoluteConfusionMatrix, hv_CalcRelativeConfusionMatrix;
  HTuple  hv_Measures, hv_RegExpTopKError, hv_M, hv_ComputeTopKError;
  HTuple  hv_K, hv_ClassIDs, hv_KeyExists, hv_ClassesToEvaluate;
  HTuple  hv_ClassIDsToEvaluate, hv_ClassNames, hv_Index;
  HTuple  hv_Position, hv_ImageIDs, hv_ImageLabelIDs, hv_Predictions;
  HTuple  hv_TopKPredictions, hv_EvalIndex, hv_CurrentEvalClass;
  HTuple  hv_IndexClass, hv_EvaluatedSamples, hv_ConfusionMatrix;
  HTuple  hv_RelativeConfusionMatrix, hv_EvalClassID, hv_KIndex;
  HTuple  hv_Indices, hv_TopKError, hv_NumClasses, hv_ClassPrecisions;
  HTuple  hv_MatrixRowSumID, hv_TruePositive, hv_SumPredictedClass;
  HTuple  hv_ClassPrecision, hv_Precision, hv_ClassRecalls;
  HTuple  hv_MatrixColumnSumID, hv_SumLabel, hv_ClassRecall;
  HTuple  hv_Recall, hv_ClassFScores, hv_SumPrecisionRecall;
  HTuple  hv_PositiveIndices, hv_FScore, hv_KeyName;

  //
  //This procedure calculates the final summarizing image classification measures based on the running measures.
  //
  //Set default values.
  hv_TopKErrorKs = HTuple();
  hv_CalcPrecision = 0;
  hv_CalcRecall = 0;
  hv_CalcFScore = 0;
  hv_CalcAbsoluteConfusionMatrix = 0;
  hv_CalcRelativeConfusionMatrix = 0;
  //
  //Check which measures are to be calculated.
  GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
  hv_RegExpTopKError = "top([0-9]+)_error";
  {
  HTuple end_val14 = (hv_Measures.TupleLength())-1;
  HTuple step_val14 = 1;
  for (hv_M=0; hv_M.Continue(end_val14, step_val14); hv_M += step_val14)
  {
    hv_ComputeTopKError = HTuple(hv_Measures[hv_M]).TupleRegexpTest("top([0-9]+)_error");
    if (0 != hv_ComputeTopKError)
    {
      hv_K = (HTuple(hv_Measures[hv_M]).TupleRegexpMatch(hv_RegExpTopKError)).TupleNumber();
      hv_TopKErrorKs = (hv_TopKErrorKs.TupleConcat(hv_K)).TupleSort();
    }
    else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("precision"))))
    {
      hv_CalcPrecision = 1;
    }
    else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("recall"))))
    {
      hv_CalcRecall = 1;
    }
    else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("f_score"))))
    {
      hv_CalcFScore = 1;
    }
    else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("absolute_confusion_matrix"))))
    {
      hv_CalcAbsoluteConfusionMatrix = 1;
    }
    else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("relative_confusion_matrix"))))
    {
      hv_CalcRelativeConfusionMatrix = 1;
    }
    else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("all"))))
    {
      hv_TopKErrorKs = (hv_TopKErrorKs.TupleConcat(1)).TupleSort();
      hv_CalcPrecision = 1;
      hv_CalcRecall = 1;
      hv_CalcFScore = 1;
      hv_CalcAbsoluteConfusionMatrix = 1;
      hv_CalcRelativeConfusionMatrix = 1;
    }
    else
    {
      throw HException("Unknown image classification measure: "+HTuple(hv_Measures[hv_M]));
    }
  }
  }
  //
  //Initialize output dictionary and get necessary evaluation parameters.
  CreateDict(&(*hv_EvaluationResult));
  GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
  GetDictParam(hv_EvalParams, "key_exists", "class_names_to_evaluate", &hv_KeyExists);
  if (0 != hv_KeyExists)
  {
    GetDictTuple(hv_EvalParams, "class_names_to_evaluate", &hv_ClassesToEvaluate);
    hv_ClassIDsToEvaluate = HTuple();
    GetDictTuple(hv_EvalParams, "class_names", &hv_ClassNames);
    {
    HTuple end_val49 = (hv_ClassesToEvaluate.TupleLength())-1;
    HTuple step_val49 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val49, step_val49); hv_Index += step_val49)
    {
      hv_Position = ((HTuple("global").TupleConcat(hv_ClassNames)).TupleEqualElem(HTuple(hv_ClassesToEvaluate[hv_Index]))).TupleFind(1);
      if (0 != (HTuple(int(hv_Position==-1)).TupleOr(int(hv_Position==HTuple()))))
      {
        throw HException("Invalid entry in  'class_names_to_evaluate': "+HTuple((HTuple("global").TupleConcat(hv_ClassesToEvaluate))[hv_Index]));
      }
      hv_ClassIDsToEvaluate = hv_ClassIDsToEvaluate.TupleConcat(HTuple((HTuple("global").TupleConcat(hv_ClassIDs))[hv_Position]));
    }
    }
    SetDictTuple(hv_EvalParams, "class_ids_to_evaluate", hv_ClassIDsToEvaluate);
  }
  GetDictTuple(hv_EvalParams, "class_ids_to_evaluate", &hv_ClassIDsToEvaluate);
  //
  //Get and check values in RunningMeasures.
  GetDictTuple(hv_RunningMeasures, "image_ids", &hv_ImageIDs);
  GetDictTuple(hv_RunningMeasures, "image_label_ids", &hv_ImageLabelIDs);
  GetDictTuple(hv_RunningMeasures, "top1_predictions", &hv_Predictions);
  GetDictTuple(hv_RunningMeasures, "topk_predictions", &hv_TopKPredictions);
  //
  //Check if needed classes appear in image label IDs.
  //For the confusion matrices, all classes need to be represented.
  hv_CalcAbsoluteConfusionMatrix = HTuple(HTuple(hv_CalcPrecision.TupleOr(hv_CalcRecall)).TupleOr(hv_CalcFScore)).TupleOr(hv_CalcAbsoluteConfusionMatrix);
  hv_CalcRelativeConfusionMatrix = HTuple(HTuple(hv_CalcPrecision.TupleOr(hv_CalcRecall)).TupleOr(hv_CalcFScore)).TupleOr(hv_CalcRelativeConfusionMatrix);
  if (0 != (hv_CalcAbsoluteConfusionMatrix.TupleOr(hv_CalcRelativeConfusionMatrix)))
  {
    if (0 != (int(((hv_ImageLabelIDs.TupleSort()).TupleUniq())!=(hv_ClassIDs.TupleSort()))))
    {
      throw HException("Not all classes are represented in the ground truth labels. \nPlease check your data split.");
    }
  }
  //For top-K errors, the evaluated classes need to be represented.
  if (0 != (int(hv_TopKErrorKs!=HTuple())))
  {
    {
    HTuple end_val77 = (hv_ClassIDsToEvaluate.TupleLength())-1;
    HTuple step_val77 = 1;
    for (hv_EvalIndex=0; hv_EvalIndex.Continue(end_val77, step_val77); hv_EvalIndex += step_val77)
    {
      hv_CurrentEvalClass = HTuple(hv_ClassIDsToEvaluate[hv_EvalIndex]);
      if (0 != (int(hv_CurrentEvalClass!=HTuple("global"))))
      {
        hv_IndexClass = hv_ImageLabelIDs.TupleFind(hv_CurrentEvalClass);
        if (0 != (HTuple(int(hv_IndexClass==-1)).TupleOr(int(hv_IndexClass==HTuple()))))
        {
          throw HException(("The evaluated class ID "+hv_CurrentEvalClass)+" is not represented in the ground truth labels.");
        }
      }
    }
    }
  }
  //
  //Set image IDs, image label IDs, and top1-predictions to of evaluated samples EvaluationResult.
  CreateDict(&hv_EvaluatedSamples);
  SetDictTuple(hv_EvaluatedSamples, "image_ids", hv_ImageIDs);
  SetDictTuple(hv_EvaluatedSamples, "image_label_ids", hv_ImageLabelIDs);
  SetDictTuple(hv_EvaluatedSamples, "top1_predictions", hv_Predictions);
  SetDictTuple((*hv_EvaluationResult), "evaluated_samples", hv_EvaluatedSamples);
  //
  //Calculate absolute confusion matrix if needed and set it to EvaluationResult.
  if (0 != hv_CalcAbsoluteConfusionMatrix)
  {
    gen_confusion_matrix(hv_ImageLabelIDs, hv_Predictions, "display_matrix", "none", 
        HTuple(), &hv_ConfusionMatrix);
    SetDictTuple((*hv_EvaluationResult), "absolute_confusion_matrix", hv_ConfusionMatrix);
  }
  //
  //Calculate relative confusion matrix.
  if (0 != hv_CalcRelativeConfusionMatrix)
  {
    gen_confusion_matrix(hv_ImageLabelIDs, hv_Predictions, (HTuple("display_matrix").Append("return_matrix")), 
        (HTuple("none").Append("relative")), HTuple(), &hv_RelativeConfusionMatrix);
    SetDictTuple((*hv_EvaluationResult), "relative_confusion_matrix", hv_RelativeConfusionMatrix);
  }
  //
  // Calculate measures for every class to be evaluated.
  {
  HTuple end_val108 = (hv_ClassIDsToEvaluate.TupleLength())-1;
  HTuple step_val108 = 1;
  for (hv_EvalIndex=0; hv_EvalIndex.Continue(end_val108, step_val108); hv_EvalIndex += step_val108)
  {
    hv_CurrentEvalClass = HTuple(hv_ClassIDsToEvaluate[hv_EvalIndex]);
    CreateDict(&hv_EvalClassID);
    //
    //Calculate top-K errors.
    {
    HTuple end_val113 = (hv_TopKErrorKs.TupleLength())-1;
    HTuple step_val113 = 1;
    for (hv_KIndex=0; hv_KIndex.Continue(end_val113, step_val113); hv_KIndex += step_val113)
    {
      hv_K = HTuple(hv_TopKErrorKs[hv_KIndex]);
      if (0 != (int(hv_CurrentEvalClass==HTuple("global"))))
      {
        hv_Indices = HTuple::TupleGenSequence(0,(hv_ImageLabelIDs.TupleLength())-1,1);
      }
      else
      {
        hv_Indices = hv_ImageLabelIDs.TupleFind(hv_CurrentEvalClass);
      }
      compute_top_k_error_dl_evaluation(HTuple(hv_ImageLabelIDs[hv_Indices]), HTuple(hv_TopKPredictions[hv_Indices]), 
          hv_K, &hv_TopKError);
      SetDictTuple(hv_EvalClassID, ("top"+hv_K)+"_error", hv_TopKError);
    }
    }
    //
    if (0 != (int(hv_CurrentEvalClass==HTuple("global"))))
    {
      //Compute the mean of the measures for all classes.
      hv_NumClasses = hv_ClassIDs.TupleLength();
      hv_IndexClass = hv_ClassIDs;
    }
    else
    {
      //Compute the measures for a certain class.
      hv_NumClasses = 1;
      hv_IndexClass = hv_ClassIDs.TupleFind(hv_CurrentEvalClass);
    }
    //
    //Calculate prediction.
    if (0 != (hv_CalcPrecision.TupleOr(hv_CalcFScore)))
    {
      hv_ClassPrecisions = HTuple();
      SumMatrix(hv_ConfusionMatrix, "rows", &hv_MatrixRowSumID);
      {
      HTuple end_val138 = hv_NumClasses-1;
      HTuple step_val138 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val138, step_val138); hv_Index += step_val138)
      {
        //Compute the precision for every selected class.
        GetValueMatrix(hv_ConfusionMatrix, HTuple(hv_IndexClass[hv_Index]), HTuple(hv_IndexClass[hv_Index]), 
            &hv_TruePositive);
        GetValueMatrix(hv_MatrixRowSumID, HTuple(hv_IndexClass[hv_Index]), 0, &hv_SumPredictedClass);
        if (0 != (int(hv_SumPredictedClass==0)))
        {
          hv_ClassPrecision = 0;
        }
        else
        {
          hv_ClassPrecision = hv_TruePositive/hv_SumPredictedClass;
        }
        hv_ClassPrecisions = hv_ClassPrecisions.TupleConcat(hv_ClassPrecision);
      }
      }
      hv_Precision = hv_ClassPrecisions.TupleMean();
      ClearMatrix(hv_MatrixRowSumID);
      if (0 != (int(hv_NumClasses==1)))
      {
        SetDictTuple(hv_EvalClassID, "precision", hv_Precision);
      }
      else
      {
        SetDictTuple(hv_EvalClassID, "mean_precision", hv_Precision);
        SetDictTuple(hv_EvalClassID, "precision_per_class", hv_ClassPrecisions);
      }
    }
    //
    //Calculate recall.
    if (0 != (hv_CalcRecall.TupleOr(hv_CalcFScore)))
    {
      hv_ClassRecalls = HTuple();
      SumMatrix(hv_ConfusionMatrix, "columns", &hv_MatrixColumnSumID);
      {
      HTuple end_val163 = hv_NumClasses-1;
      HTuple step_val163 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val163, step_val163); hv_Index += step_val163)
      {
        //Compute the recall for every class.
        GetValueMatrix(hv_ConfusionMatrix, HTuple(hv_IndexClass[hv_Index]), HTuple(hv_IndexClass[hv_Index]), 
            &hv_TruePositive);
        GetValueMatrix(hv_MatrixColumnSumID, 0, HTuple(hv_IndexClass[hv_Index]), 
            &hv_SumLabel);
        hv_ClassRecall = hv_TruePositive/hv_SumLabel;
        hv_ClassRecalls = hv_ClassRecalls.TupleConcat(hv_ClassRecall);
      }
      }
      hv_Recall = hv_ClassRecalls.TupleMean();
      ClearMatrix(hv_MatrixColumnSumID);
      if (0 != (int(hv_NumClasses==1)))
      {
        SetDictTuple(hv_EvalClassID, "recall", hv_Recall);
      }
      else
      {
        SetDictTuple(hv_EvalClassID, "mean_recall", hv_Recall);
        SetDictTuple(hv_EvalClassID, "recall_per_class", hv_ClassRecalls);
      }
    }
    //
    //Calculate F-score.
    if (0 != hv_CalcFScore)
    {
      TupleGenConst(hv_ClassPrecisions.TupleLength(), 0.0, &hv_ClassFScores);
      hv_SumPrecisionRecall = hv_ClassPrecisions+hv_ClassRecalls;
      hv_PositiveIndices = (hv_SumPrecisionRecall.TupleNotEqualElem(0.0)).TupleFind(1);
      if (0 != (HTuple(int(hv_PositiveIndices!=-1)).TupleAnd(int(hv_PositiveIndices!=HTuple()))))
      {
        hv_ClassFScores[hv_PositiveIndices] = ((2*HTuple(hv_ClassPrecisions[hv_PositiveIndices]))*HTuple(hv_ClassRecalls[hv_PositiveIndices]))/HTuple(hv_SumPrecisionRecall[hv_PositiveIndices]);
      }
      hv_FScore = hv_ClassFScores.TupleMean();
      if (0 != (int(hv_NumClasses==1)))
      {
        SetDictTuple(hv_EvalClassID, "f_score", hv_FScore);
      }
      else
      {
        SetDictTuple(hv_EvalClassID, "mean_f_score", hv_FScore);
        SetDictTuple(hv_EvalClassID, "f_score_per_class", hv_ClassFScores);
      }
    }
    //
    //Set evaluation results for current class ID.
    hv_KeyName = HTuple(hv_ClassIDsToEvaluate[hv_EvalIndex]);
    if (0 != (int(HTuple(hv_ClassIDsToEvaluate[hv_EvalIndex])!=HTuple("global"))))
    {
      hv_KeyName = "class_id_"+hv_KeyName;
    }
    SetDictTuple((*hv_EvaluationResult), hv_KeyName, hv_EvalClassID);
  }
  }
  //
  return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Calculate instance measures based on RunningMeasures. 
void calculate_instance_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CalcClassAP, hv_CalcMeanAP, hv_CalcSoAP;
  HTuple  hv_EvalType, hv_InstanceType, hv_Measures, hv_M;
  HTuple  hv_ClassIDs, hv_NumClasses, hv_MaxNumDetections;
  HTuple  hv_AreaRanges, hv_IoUThresholds, hv_DetailedEvaluation;
  HTuple  hv_InterpolatePRCurves, hv_KeyExists, hv_AreaNames;
  HTuple  hv_MinAreas, hv_MaxAreas, hv_RecThreshs, hv_MDIdx;
  HTuple  hv_MaxNum, hv_MaxNumStr, hv_CurrentRunningMeasures;
  HTuple  hv_PerMaxNumEvaluationResult, hv_AreaIdx, hv_MinArea;
  HTuple  hv_MaxArea, hv_AreaName, hv_AreaRunningMeasures;
  HTuple  hv_PerClassNumGt, hv_PerClassNumPred, hv_PerClassConfidence;
  HTuple  hv_PerClassNumGtIgnore, hv_CurrentEvaluationResult;
  HTuple  hv_ITIdx, hv_PerIoUAP, hv_PerIoUSoAP, hv_PerIoUDetailedEvaluation;
  HTuple  hv_ClsIdx, hv_PerClassDetailedEvaluation, hv_DetectionConfusionMatrix;
  HTuple  hv_PerIoUMeasure, hv_NumImgIDsWithFN, hv_NumImgIDsWithFP;
  HTuple  hv_ImgIDsWithFN, hv_ImgIDsWithFP, hv_ClassMAPDict;
  HTuple  hv_ClassMSoAPDict, hv_ClassesWithGt, hv_PerClassMAP;
  HTuple  hv_PerIoUMAP, hv_PerClassMSoAP, hv_PerIoUMSoAP;
  HTuple  hv_PerIoUNumClassesWithTP, hv_PerIoUTP, hv_PerIoUFN;
  HTuple  hv_PerIoUFP, hv_PerIoUFPClass, hv_PerIoUFPBackground;
  HTuple  hv_PerIoUFPLocalization, hv_PerIoUFPDuplicate, hv_PerIoUFPMultiple;
  HTuple  hv_PerIoUSoAPClass, hv_PerIoUSoAPLocalization, hv_PerIoUSoAPDuplicate;
  HTuple  hv_PerIoUSoAPMultiple, hv_PerIoUNumClassesWithFPClass;
  HTuple  hv_PerIoUNumClassesWithFPLocalization, hv_PerIoUNumClassesWithFPDuplicate;
  HTuple  hv_PerIoUNumClassesWithFPMultiple, hv_ClassAPPerIoU;
  HTuple  hv_ClassSoAPPerIoU, hv_NumGt, hv_NumGtIgnore, hv_NumPred;
  HTuple  hv_Confidences, hv_SortIdxs, hv_CurrentClassMeasures;
  HTuple  hv_IsTP, hv_Ignore, hv_NoIgnoreIdxs, hv_IsFP, hv_AccumulatedIsTP;
  HTuple  hv_AccumulatedIsFP, hv_Recall, hv_Precision, hv_InterpolatedPrecision;
  HTuple  hv_PIdx, hv_PrecisionAtRecThreshs, hv_RTIdx, hv_RecQuantile;
  HTuple  hv_AOD, hv_IdxsTP, hv_IsFPClass, hv_IsFPBackground;
  HTuple  hv_IsFPLocalization, hv_IsFPDuplicate, hv_IsFPMultiple;
  HTuple  hv_NumTP, hv_NumFP, hv_NumFN, hv_NumFPClass, hv_NumFPBackground;
  HTuple  hv_NumFPLocalization, hv_NumFPDuplicate, hv_NumFPMultiple;
  HTuple  hv_IndicesWithClassConfusion, hv_IsFPClassIdxs;
  HTuple  hv_ClassIdxsConfused, hv_Idx, hv_NumConfusedThisIdx;
  HTuple  hv_AODClass, hv_IdxsClass, hv_ResSoAPClass, hv_AODLocalization;
  HTuple  hv_IdxsLocalization, hv_ResSoAPLocalization, hv_AODDuplicate;
  HTuple  hv_IdxsDuplicate, hv_ResSoAPDuplicate, hv_AODMultiple;
  HTuple  hv_IdxsMultiple, hv_ResSoAPMultiple, hv_SoAPIoUIdxsPositive;
  HTuple  hv_MeanClassAP, hv_MeanClassSoAP, hv_MAP, hv_MSoAP;
  HTuple  hv_IoUsWithTP, hv_MSoAPAll, hv_NumSoAPAll, hv_IoUsWithFPClass;
  HTuple  hv_IoUsWithFPLocalization, hv_IoUsWithFPDuplicate;
  HTuple  hv_IoUsWithFPMultiple;

  //
  //This procedure calculates the final summarizing instance measures based on the running measures.
  //
  //Set default values.
  hv_CalcClassAP = 0;
  hv_CalcMeanAP = 0;
  hv_CalcSoAP = 0;
  //Check which measures are to be calculated.
  GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvalType);
  GetDictTuple(hv_EvalParams, "instance_type", &hv_InstanceType);
  GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
  {
  HTuple end_val11 = (hv_Measures.TupleLength())-1;
  HTuple step_val11 = 1;
  for (hv_M=0; hv_M.Continue(end_val11, step_val11); hv_M += step_val11)
  {
    if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("mean_ap"))))
    {
      hv_CalcMeanAP = 1;
      //As we need to calculate the class APs anyway, we also write them out.
      hv_CalcClassAP = 1;
    }
    else if (0 != (HTuple(int(HTuple(hv_Measures[hv_M])==HTuple("soap"))).TupleAnd(int(hv_InstanceType==HTuple("rectangle2")))))
    {
      hv_CalcSoAP = 1;
    }
    else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("all"))))
    {
      hv_CalcClassAP = 1;
      hv_CalcMeanAP = 1;
      if (0 != (int(hv_InstanceType==HTuple("rectangle2"))))
      {
        hv_CalcSoAP = 1;
      }
    }
    else
    {
      if (0 != (HTuple(int(hv_EvalType==HTuple("ocr_detection"))).TupleAnd(HTuple(HTuple(int(HTuple(hv_Measures[hv_M])==HTuple("recall"))).TupleOr(int(HTuple(hv_Measures[hv_M])==HTuple("precision")))).TupleOr(int(HTuple(hv_Measures[hv_M])==HTuple("f_score"))))))
      {
        hv_CalcMeanAP = 1;
        hv_CalcClassAP = 1;
        continue;
      }
      else
      {
        throw HException("Unknown Instance Measure: "+HTuple(hv_Measures[hv_M]));
      }
    }
  }
  }
  //*
  //Dependencies of measures:
  //
  //Recall (per-class)       *                   --> AP per class --> mAP
  //Precision (per-class)  /
  //
  //*
  //Initialize output dictionary and get necessary evaluation parameters.
  CreateDict(&(*hv_EvaluationResult));
  GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
  GetDictTuple(hv_EvalParams, "num_classes", &hv_NumClasses);
  GetDictTuple(hv_EvalParams, "max_num_detections", &hv_MaxNumDetections);
  GetDictTuple(hv_EvalParams, "area_ranges", &hv_AreaRanges);
  GetDictTuple(hv_EvalParams, "iou_threshold", &hv_IoUThresholds);
  //Check if a detailed evaluation should be done and if PR-curves should be interpolated.
  hv_DetailedEvaluation = 0;
  hv_InterpolatePRCurves = 0;
  GetDictParam(hv_EvalParams, "key_exists", (HTuple("detailed_evaluation").Append("interpolate_pr_curves")), 
      &hv_KeyExists);
  if (0 != (HTuple(hv_KeyExists[0])))
  {
    GetDictTuple(hv_EvalParams, "detailed_evaluation", &hv_DetailedEvaluation);
  }
  if (0 != (HTuple(hv_KeyExists[1])))
  {
    GetDictTuple(hv_EvalParams, "interpolate_pr_curves", &hv_InterpolatePRCurves);
  }
  //
  //Get information about area ranges.
  GetDictTuple(hv_AreaRanges, "name", &hv_AreaNames);
  GetDictTuple(hv_AreaRanges, "min", &hv_MinAreas);
  GetDictTuple(hv_AreaRanges, "max", &hv_MaxAreas);
  //
  //Equidistant thresholds used to approximate the area under the Precision-Recall curve.
  hv_RecThreshs = HTuple::TupleGenSequence(0.0,1.0,0.01);
  //Start with calculation.
  if (0 != (HTuple(hv_CalcClassAP.TupleOr(hv_CalcMeanAP)).TupleOr(hv_CalcSoAP)))
  {
    //Loop over maximal number of detections.
    {
    HTuple end_val69 = (hv_MaxNumDetections.TupleLength())-1;
    HTuple step_val69 = 1;
    for (hv_MDIdx=0; hv_MDIdx.Continue(end_val69, step_val69); hv_MDIdx += step_val69)
    {
      //
      //Get corresponding running measures.
      hv_MaxNum = HTuple(hv_MaxNumDetections[hv_MDIdx]);
      hv_MaxNumStr = ""+hv_MaxNum;
      if (0 != (int(hv_MaxNum==-1)))
      {
        hv_MaxNumStr = "all";
      }
      GetDictTuple(hv_RunningMeasures, "max_num_detections_"+hv_MaxNumStr, &hv_CurrentRunningMeasures);
      //
      //Initialize output dictionary.
      CreateDict(&hv_PerMaxNumEvaluationResult);
      //
      //Loop over area ranges.
      {
      HTuple end_val83 = (hv_AreaNames.TupleLength())-1;
      HTuple step_val83 = 1;
      for (hv_AreaIdx=0; hv_AreaIdx.Continue(end_val83, step_val83); hv_AreaIdx += step_val83)
      {
        //Get area thresholds.
        hv_MinArea = HTuple(hv_MinAreas[hv_AreaIdx]);
        hv_MaxArea = HTuple(hv_MaxAreas[hv_AreaIdx]);
        hv_AreaName = HTuple(hv_AreaNames[hv_AreaIdx]);
        //
        GetDictTuple(hv_CurrentRunningMeasures, "area_"+hv_AreaName, &hv_AreaRunningMeasures);
        //
        GetDictTuple(hv_AreaRunningMeasures, "num_gt", &hv_PerClassNumGt);
        GetDictTuple(hv_AreaRunningMeasures, "num_pred", &hv_PerClassNumPred);
        GetDictTuple(hv_AreaRunningMeasures, "confidence", &hv_PerClassConfidence);
        GetDictTuple(hv_AreaRunningMeasures, "num_gt_ignore", &hv_PerClassNumGtIgnore);
        //
        //Initialize output dictionary.
        CreateDict(&hv_CurrentEvaluationResult);
        {
        HTuple end_val98 = (hv_IoUThresholds.TupleLength())-1;
        HTuple step_val98 = 1;
        for (hv_ITIdx=0; hv_ITIdx.Continue(end_val98, step_val98); hv_ITIdx += step_val98)
        {
          CreateDict(&hv_PerIoUAP);
          SetDictTuple(hv_CurrentEvaluationResult, "ap_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")), 
              hv_PerIoUAP);
          if (0 != hv_CalcSoAP)
          {
            CreateDict(&hv_PerIoUSoAP);
            SetDictTuple(hv_CurrentEvaluationResult, "soap_tp_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")), 
                hv_PerIoUSoAP);
          }
          if (0 != hv_DetailedEvaluation)
          {
            //Initialize detailed measures.
            CreateDict(&hv_PerIoUDetailedEvaluation);
            {
            HTuple end_val108 = hv_NumClasses-1;
            HTuple step_val108 = 1;
            for (hv_ClsIdx=0; hv_ClsIdx.Continue(end_val108, step_val108); hv_ClsIdx += step_val108)
            {
              CreateDict(&hv_PerClassDetailedEvaluation);
              //Initialize with zeros in case there is no ground truth for this class.
              SetDictTuple(hv_PerClassDetailedEvaluation, "num_tp", 0);
              SetDictTuple(hv_PerClassDetailedEvaluation, "num_fn", 0);
              SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp", 0);
              SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_class", 0);
              SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_background", 0);
              SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_duplicate", 0);
              SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_localization", 
                  0);
              SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_multiple", 0);
              if (0 != hv_CalcSoAP)
              {
                SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_class", -1);
                SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_duplicate", 
                    -1);
                SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_localization", 
                    -1);
                SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_multiple", -1);
              }
              SetDictTuple(hv_PerIoUDetailedEvaluation, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), 
                  hv_PerClassDetailedEvaluation);
            }
            }
            CreateMatrix(hv_NumClasses+1, hv_NumClasses+4, 0, &hv_DetectionConfusionMatrix);
            SetDictTuple(hv_PerIoUDetailedEvaluation, "detection_confusion_matrix", 
                hv_DetectionConfusionMatrix);
            //
            //Get and set image IDs with false negatives and false positives.
            GetDictTuple(hv_AreaRunningMeasures, "iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")), 
                &hv_PerIoUMeasure);
            //Get image IDs with false negatives and false positives, respectively.
            GetDictTuple(hv_PerIoUMeasure, "num_image_ids_with_false_negatives", 
                &hv_NumImgIDsWithFN);
            GetDictTuple(hv_PerIoUMeasure, "num_image_ids_with_false_positives", 
                &hv_NumImgIDsWithFP);
            GetDictTuple(hv_PerIoUMeasure, "image_ids_with_false_negatives", &hv_ImgIDsWithFN);
            GetDictTuple(hv_PerIoUMeasure, "image_ids_with_false_positives", &hv_ImgIDsWithFP);
            //Set in current output.
            SetDictTuple(hv_PerIoUDetailedEvaluation, "image_ids_with_false_negatives", 
                hv_ImgIDsWithFN.TupleSelectRange(0,hv_NumImgIDsWithFN-1));
            SetDictTuple(hv_PerIoUDetailedEvaluation, "image_ids_with_false_positives", 
                hv_ImgIDsWithFP.TupleSelectRange(0,hv_NumImgIDsWithFP-1));
            //
            //Set output for this IoU.
            SetDictTuple(hv_CurrentEvaluationResult, "detailed_evaluation_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")), 
                hv_PerIoUDetailedEvaluation);
          }
        }
        }
        CreateDict(&hv_ClassMAPDict);
        SetDictTuple(hv_CurrentEvaluationResult, "mean_iou_ap", hv_ClassMAPDict);
        if (0 != hv_CalcSoAP)
        {
          CreateDict(&hv_ClassMSoAPDict);
          SetDictTuple(hv_CurrentEvaluationResult, "mean_iou_soap_tp", hv_ClassMSoAPDict);
        }
        //
        //Check which classes have ground truth annotations.
        hv_ClassesWithGt = ((hv_PerClassNumGt-hv_PerClassNumGtIgnore).TupleGreaterElem(0)).TupleFind(1);
        if (0 != (int(hv_ClassesWithGt==-1)))
        {
          hv_ClassesWithGt = HTuple();
        }
        //
        //Initialize PerClassMAP, i.e. mean average precision over IoU-thresholds per class.
        hv_PerClassMAP = HTuple(hv_NumClasses,-1.0);
        //
        //Initialize PerIoUMAP, i.e. mean average precision over classes per IoU-threshold.
        hv_PerIoUMAP = HTuple(hv_IoUThresholds.TupleLength(),0.0);
        //
        if (0 != hv_CalcSoAP)
        {
          //Initialize PerClassMSoAP, i.e. mean SoAP over IoU-thresholds per class.
          hv_PerClassMSoAP = HTuple(hv_NumClasses,-1.0);
          //Initialize PerIoUMSoAP, i.e. mean SoAP over classes per IoU-threshold.
          hv_PerIoUMSoAP = HTuple(hv_IoUThresholds.TupleLength(),0.0);
          //Initialize PerIoUNumClassesWithTP to store the class-indices where true positives occurred.
          hv_PerIoUNumClassesWithTP = HTuple(hv_IoUThresholds.TupleLength(),0);
        }
        //
        if (0 != hv_DetailedEvaluation)
        {
          //Initialize overall num_fn, num_tp, ...
          hv_PerIoUTP = HTuple(hv_IoUThresholds.TupleLength(),0);
          hv_PerIoUFN = HTuple(hv_IoUThresholds.TupleLength(),0);
          hv_PerIoUFP = HTuple(hv_IoUThresholds.TupleLength(),0);
          hv_PerIoUFPClass = HTuple(hv_IoUThresholds.TupleLength(),0);
          hv_PerIoUFPBackground = HTuple(hv_IoUThresholds.TupleLength(),0);
          hv_PerIoUFPLocalization = HTuple(hv_IoUThresholds.TupleLength(),0);
          hv_PerIoUFPDuplicate = HTuple(hv_IoUThresholds.TupleLength(),0);
          hv_PerIoUFPMultiple = HTuple(hv_IoUThresholds.TupleLength(),0);
          if (0 != hv_CalcSoAP)
          {
            hv_PerIoUSoAPClass = HTuple(hv_IoUThresholds.TupleLength(),-1);
            hv_PerIoUSoAPLocalization = HTuple(hv_IoUThresholds.TupleLength(),-1);
            hv_PerIoUSoAPDuplicate = HTuple(hv_IoUThresholds.TupleLength(),-1);
            hv_PerIoUSoAPMultiple = HTuple(hv_IoUThresholds.TupleLength(),-1);
            hv_PerIoUNumClassesWithFPClass = HTuple(hv_IoUThresholds.TupleLength(),0);
            hv_PerIoUNumClassesWithFPLocalization = HTuple(hv_IoUThresholds.TupleLength(),0);
            hv_PerIoUNumClassesWithFPDuplicate = HTuple(hv_IoUThresholds.TupleLength(),0);
            hv_PerIoUNumClassesWithFPMultiple = HTuple(hv_IoUThresholds.TupleLength(),0);
          }
        }
        //Loop over all classes.
        {
        HTuple end_val195 = hv_NumClasses-1;
        HTuple step_val195 = 1;
        for (hv_ClsIdx=0; hv_ClsIdx.Continue(end_val195, step_val195); hv_ClsIdx += step_val195)
        {
          //
          //Initialize per-class AP per IoU-threshold (only for one class).
          hv_ClassAPPerIoU = HTuple(hv_IoUThresholds.TupleLength(),-1.0);
          //
          if (0 != hv_CalcSoAP)
          {
            hv_ClassSoAPPerIoU = HTuple(hv_IoUThresholds.TupleLength(),-1.0);
          }
          //Get results for this class.
          hv_NumGt = HTuple(hv_PerClassNumGt[hv_ClsIdx]);
          hv_NumGtIgnore = HTuple(hv_PerClassNumGtIgnore[hv_ClsIdx]);
          if (0 != (int((hv_NumGt-hv_NumGtIgnore)>0)))
          {
            hv_NumPred = HTuple(hv_PerClassNumPred[hv_ClsIdx]);
            GetDictTuple(hv_PerClassConfidence, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), 
                &hv_Confidences);
            //
            //Sort the confidences in descending order and
            //only take the first NumPred ones due to block allocation.
            hv_SortIdxs = (-(hv_Confidences.TupleSelectRange(0,hv_NumPred-1))).TupleSortIndex();
            hv_Confidences = HTuple(hv_Confidences[hv_SortIdxs]);
          }
          //
          //Loop over IoU thresholds.
          {
          HTuple end_val217 = (hv_IoUThresholds.TupleLength())-1;
          HTuple step_val217 = 1;
          for (hv_ITIdx=0; hv_ITIdx.Continue(end_val217, step_val217); hv_ITIdx += step_val217)
          {
            //
            //Check if there are ground truth labels for this class.
            if (0 != (int((hv_NumGt-hv_NumGtIgnore)>0)))
            {
              //
              //Get results for this class and IoU-threshold.
              GetDictTuple(hv_AreaRunningMeasures, "iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")), 
                  &hv_PerIoUMeasure);
              GetDictTuple(hv_PerIoUMeasure, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), 
                  &hv_CurrentClassMeasures);
              GetDictTuple(hv_CurrentClassMeasures, "is_tp", &hv_IsTP);
              GetDictTuple(hv_CurrentClassMeasures, "ignore", &hv_Ignore);
              //
              //Sort the arrays IsTP and Ignore according to the confidence values.
              hv_IsTP = HTuple(hv_IsTP[hv_SortIdxs]);
              hv_Ignore = HTuple(hv_Ignore[hv_SortIdxs]);
              //
              //Sort out the ignored results.
              if (0 != (int((hv_IsTP.TupleLength())>0)))
              {
                hv_NoIgnoreIdxs = hv_Ignore.TupleFind(0);
                if (0 != (int(hv_NoIgnoreIdxs!=-1)))
                {
                  hv_IsTP = HTuple(hv_IsTP[hv_NoIgnoreIdxs]);
                  hv_IsFP = hv_IsTP.TupleNot();
                }
                else
                {
                  hv_IsTP = HTuple();
                  hv_IsFP = HTuple();
                }
              }
              else
              {
                hv_IsFP = HTuple();
              }
              //
              //Accumulate IsTP and IsFP.
              hv_AccumulatedIsTP = hv_IsTP.TupleCumul();
              hv_AccumulatedIsFP = hv_IsFP.TupleCumul();
              //
              //Compute recall.
              //The recall is computed with respect to all ground truth instances,
              //independent of MaxNum.
              hv_Recall = (hv_AccumulatedIsTP.TupleReal())/(hv_NumGt-hv_NumGtIgnore);
              //
              //Compute precision.
              hv_Precision = (hv_AccumulatedIsTP.TupleReal())/(hv_AccumulatedIsTP+hv_AccumulatedIsFP);
              //
              //(Optionally) smooth precision-recall curve.
              hv_InterpolatedPrecision = hv_Precision;
              if (0 != hv_InterpolatePRCurves)
              {
                for (hv_PIdx=hv_NumPred-2; hv_PIdx>=0; hv_PIdx+=-1)
                {
                  hv_InterpolatedPrecision[hv_PIdx] = HTuple(hv_InterpolatedPrecision[hv_PIdx]).TupleMax2(HTuple(hv_InterpolatedPrecision[hv_PIdx+1]));
                }
              }
              //Compute approximated area under the Precision-Recall curve using Recall-Thresholds.
              hv_PrecisionAtRecThreshs = HTuple(hv_RecThreshs.TupleLength(),0.);
              {
              HTuple end_val267 = (hv_RecThreshs.TupleLength())-1;
              HTuple step_val267 = 1;
              for (hv_RTIdx=0; hv_RTIdx.Continue(end_val267, step_val267); hv_RTIdx += step_val267)
              {
                hv_RecQuantile = (hv_Recall.TupleGreaterEqualElem(HTuple(hv_RecThreshs[hv_RTIdx]))).TupleFindFirst(1);
                if (0 != (int(hv_RecQuantile>-1)))
                {
                  hv_PrecisionAtRecThreshs[hv_RTIdx] = HTuple(hv_InterpolatedPrecision[hv_RecQuantile]);
                }
              }
              }
              //
              //Calculate AP as mean of precision at equidistant recall values.
              hv_ClassAPPerIoU[hv_ITIdx] = hv_PrecisionAtRecThreshs.TupleMean();
              //
              //Accumulate AP over classes.
              hv_PerIoUMAP[hv_ITIdx] = HTuple(hv_PerIoUMAP[hv_ITIdx])+HTuple(hv_ClassAPPerIoU[hv_ITIdx]);
              //
              if (0 != hv_CalcSoAP)
              {
                //Calculate SoAP out of the mean over absolute orientation differences.
                GetDictTuple(hv_CurrentClassMeasures, "abs_orientation_diff", &hv_AOD);
                hv_IdxsTP = hv_IsTP.TupleFind(1);
                if (0 != (HTuple(int((hv_IdxsTP.TupleLength())>0)).TupleAnd(int(hv_IdxsTP!=-1))))
                {
                  hv_ClassSoAPPerIoU[hv_ITIdx] = 1.0-((HTuple(hv_AOD[HTuple(hv_SortIdxs[HTuple(hv_NoIgnoreIdxs[hv_IdxsTP])])]).TupleMean())/(HTuple(180).TupleRad()));
                  //Accumulate SoAP over classes.
                  hv_PerIoUMSoAP[hv_ITIdx] = HTuple(hv_PerIoUMSoAP[hv_ITIdx])+HTuple(hv_ClassSoAPPerIoU[hv_ITIdx]);
                }
                //Update PerIoUNumClassesWithTP.
                if (0 != (int((hv_AccumulatedIsTP.TupleLength())>0)))
                {
                  hv_PerIoUNumClassesWithTP[hv_ITIdx] = HTuple(hv_PerIoUNumClassesWithTP[hv_ITIdx])+(HTuple(hv_AccumulatedIsTP[(hv_AccumulatedIsTP.TupleLength())-1]).TupleGreaterElem(0));
                }
              }
              //
              if (0 != hv_DetailedEvaluation)
              {
                //Summarize detailed evaluation running measures, set matrix-values and update overall detailed measures.
                //
                //Get the necessary running measures.
                GetDictTuple(hv_CurrentClassMeasures, "is_fp_class", &hv_IsFPClass);
                GetDictTuple(hv_CurrentClassMeasures, "is_fp_background", &hv_IsFPBackground);
                GetDictTuple(hv_CurrentClassMeasures, "is_fp_localization", &hv_IsFPLocalization);
                GetDictTuple(hv_CurrentClassMeasures, "is_fp_duplicate", &hv_IsFPDuplicate);
                GetDictTuple(hv_CurrentClassMeasures, "is_fp_multiple", &hv_IsFPMultiple);
                //
                //We use the values with maximal recall,
                //in case a higher precision is desired, increase 'min_confidence'.
                if (0 != (int((hv_AccumulatedIsTP.TupleLength())>0)))
                {
                  hv_NumTP = ((const HTuple&)hv_AccumulatedIsTP)[(hv_AccumulatedIsTP.TupleLength())-1];
                }
                else
                {
                  hv_NumTP = 0;
                }
                if (0 != (int((hv_AccumulatedIsFP.TupleLength())>0)))
                {
                  hv_NumFP = ((const HTuple&)hv_AccumulatedIsFP)[(hv_AccumulatedIsFP.TupleLength())-1];
                }
                else
                {
                  hv_NumFP = 0;
                }
                hv_NumFN = (hv_NumGt-hv_NumGtIgnore)-hv_NumTP;
                hv_NumFPClass = (HTuple(hv_IsFPClass[hv_SortIdxs]).TupleGreaterElem(-1)).TupleSum();
                hv_NumFPBackground = (HTuple(hv_IsFPBackground[hv_SortIdxs]).TupleGreaterElem(0)).TupleSum();
                hv_NumFPLocalization = (HTuple(hv_IsFPLocalization[hv_SortIdxs]).TupleGreaterElem(0)).TupleSum();
                hv_NumFPDuplicate = (HTuple(hv_IsFPDuplicate[hv_SortIdxs]).TupleGreaterElem(0)).TupleSum();
                hv_NumFPMultiple = (HTuple(hv_IsFPMultiple[hv_SortIdxs]).TupleGreaterElem(0)).TupleSum();
                if (0 != (int((hv_SortIdxs.TupleLength())==0)))
                {
                  hv_NumFPClass = 0;
                  hv_NumFPBackground = 0;
                  hv_NumFPLocalization = 0;
                  hv_NumFPDuplicate = 0;
                  hv_NumFPMultiple = 0;
                }
                //Consistency checks.
                if (0 != (int(((((((((hv_NumTP.TupleConcat(hv_NumFN)).TupleConcat(hv_NumFP)).TupleConcat(hv_NumFPClass)).TupleConcat(hv_NumFPBackground)).TupleConcat(hv_NumFPLocalization)).TupleConcat(hv_NumFPDuplicate)).TupleConcat(hv_NumFPMultiple)).TupleMin())<0)))
                {
                  throw HException("Fatal error while calculating instance measures.");
                }
                if (0 != (int(hv_NumFP!=((((hv_NumFPClass+hv_NumFPBackground)+hv_NumFPLocalization)+hv_NumFPDuplicate)+hv_NumFPMultiple))))
                {
                  throw HException("Fatal error while calculating instance measures.");
                }
                //
                //Set per-class measures.
                GetDictTuple(hv_CurrentEvaluationResult, "detailed_evaluation_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")), 
                    &hv_PerIoUDetailedEvaluation);
                GetDictTuple(hv_PerIoUDetailedEvaluation, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), 
                    &hv_PerClassDetailedEvaluation);
                SetDictTuple(hv_PerClassDetailedEvaluation, "num_tp", hv_NumTP);
                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fn", hv_NumFN);
                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp", hv_NumFP);
                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_class", hv_NumFPClass);
                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_background", 
                    hv_NumFPBackground);
                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_duplicate", hv_NumFPDuplicate);
                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_localization", 
                    hv_NumFPLocalization);
                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_multiple", hv_NumFPMultiple);
                //
                //Set detection confusion matrix values.
                GetDictTuple(hv_PerIoUDetailedEvaluation, "detection_confusion_matrix", 
                    &hv_DetectionConfusionMatrix);
                SetValueMatrix(hv_DetectionConfusionMatrix, hv_ClsIdx, hv_ClsIdx, 
                    hv_NumTP);
                SetValueMatrix(hv_DetectionConfusionMatrix, hv_NumClasses, hv_ClsIdx, 
                    hv_NumFN);
                SetValueMatrix(hv_DetectionConfusionMatrix, hv_ClsIdx, hv_NumClasses, 
                    hv_NumFPBackground);
                SetValueMatrix(hv_DetectionConfusionMatrix, hv_ClsIdx, hv_NumClasses+1, 
                    hv_NumFPLocalization);
                SetValueMatrix(hv_DetectionConfusionMatrix, hv_ClsIdx, hv_NumClasses+2, 
                    hv_NumFPDuplicate);
                SetValueMatrix(hv_DetectionConfusionMatrix, hv_ClsIdx, hv_NumClasses+3, 
                    hv_NumFPMultiple);
                //
                //Go over IsFPClass and set confusions in matrix.
                hv_IndicesWithClassConfusion = (HTuple(hv_IsFPClass[hv_SortIdxs]).TupleGreaterElem(-1)).TupleFind(1);
                hv_IsFPClassIdxs = HTuple();
                if (0 != (int(hv_IndicesWithClassConfusion>-1)))
                {
                  hv_IsFPClassIdxs = HTuple(hv_IsFPClass[HTuple(hv_SortIdxs[hv_IndicesWithClassConfusion])]);
                }
                hv_ClassIdxsConfused = (hv_IsFPClassIdxs.TupleSort()).TupleUniq();
                {
                HTuple end_val366 = (hv_ClassIdxsConfused.TupleLength())-1;
                HTuple step_val366 = 1;
                for (hv_Idx=0; hv_Idx.Continue(end_val366, step_val366); hv_Idx += step_val366)
                {
                  hv_NumConfusedThisIdx = ((hv_IsFPClassIdxs.TupleFind(HTuple(hv_ClassIdxsConfused[hv_Idx]))).TupleGreaterElem(-1)).TupleSum();
                  SetValueMatrix(hv_DetectionConfusionMatrix, hv_ClsIdx, HTuple(hv_ClassIdxsConfused[hv_Idx]), 
                      hv_NumConfusedThisIdx);
                }
                }
                //
                //Update overall measures.
                hv_PerIoUFN[hv_ITIdx] = HTuple(hv_PerIoUFN[hv_ITIdx])+hv_NumFN;
                hv_PerIoUTP[hv_ITIdx] = HTuple(hv_PerIoUTP[hv_ITIdx])+hv_NumTP;
                hv_PerIoUFP[hv_ITIdx] = HTuple(hv_PerIoUFP[hv_ITIdx])+hv_NumFP;
                hv_PerIoUFPClass[hv_ITIdx] = HTuple(hv_PerIoUFPClass[hv_ITIdx])+hv_NumFPClass;
                hv_PerIoUFPBackground[hv_ITIdx] = HTuple(hv_PerIoUFPBackground[hv_ITIdx])+hv_NumFPBackground;
                hv_PerIoUFPLocalization[hv_ITIdx] = HTuple(hv_PerIoUFPLocalization[hv_ITIdx])+hv_NumFPLocalization;
                hv_PerIoUFPDuplicate[hv_ITIdx] = HTuple(hv_PerIoUFPDuplicate[hv_ITIdx])+hv_NumFPDuplicate;
                hv_PerIoUFPMultiple[hv_ITIdx] = HTuple(hv_PerIoUFPMultiple[hv_ITIdx])+hv_NumFPMultiple;
                if (0 != hv_CalcSoAP)
                {
                  //Calculate and update absolute difference of orientation for class false positives.
                  GetDictTuple(hv_CurrentClassMeasures, "abs_orientation_diff_class", 
                      &hv_AODClass);
                  hv_IdxsClass = (hv_AODClass.TupleGreaterElem(-1)).TupleFind(1);
                  if (0 != (int(hv_IdxsClass!=-1)))
                  {
                    hv_ResSoAPClass = 1.0-((HTuple(hv_AODClass[hv_IdxsClass]).TupleMean())/(HTuple(180).TupleRad()));
                    SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_class", 
                        hv_ResSoAPClass);
                    //Update mean over classes.
                    hv_PerIoUNumClassesWithFPClass[hv_ITIdx] = HTuple(hv_PerIoUNumClassesWithFPClass[hv_ITIdx])+1;
                    if (0 != (int(HTuple(hv_PerIoUSoAPClass[hv_ITIdx])==-1)))
                    {
                      hv_PerIoUSoAPClass[hv_ITIdx] = hv_ResSoAPClass;
                    }
                    else
                    {
                      hv_PerIoUSoAPClass[hv_ITIdx] = HTuple(hv_PerIoUSoAPClass[hv_ITIdx])+hv_ResSoAPClass;
                    }
                  }
                  //Calculate and update absolute difference of orientation for localization false positives.
                  GetDictTuple(hv_CurrentClassMeasures, "abs_orientation_diff_localization", 
                      &hv_AODLocalization);
                  hv_IdxsLocalization = (hv_AODLocalization.TupleGreaterElem(-1)).TupleFind(1);
                  if (0 != (int(hv_IdxsLocalization!=-1)))
                  {
                    hv_ResSoAPLocalization = 1.0-((HTuple(hv_AODLocalization[hv_IdxsLocalization]).TupleMean())/(HTuple(180).TupleRad()));
                    SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_localization", 
                        hv_ResSoAPLocalization);
                    //Update mean over classes.
                    hv_PerIoUNumClassesWithFPLocalization[hv_ITIdx] = HTuple(hv_PerIoUNumClassesWithFPLocalization[hv_ITIdx])+1;
                    if (0 != (int(HTuple(hv_PerIoUSoAPLocalization[hv_ITIdx])==-1)))
                    {
                      hv_PerIoUSoAPLocalization[hv_ITIdx] = hv_ResSoAPLocalization;
                    }
                    else
                    {
                      hv_PerIoUSoAPLocalization[hv_ITIdx] = HTuple(hv_PerIoUSoAPLocalization[hv_ITIdx])+hv_ResSoAPLocalization;
                    }
                  }
                  //Calculate and update absolute difference of orientation for class false positives.
                  GetDictTuple(hv_CurrentClassMeasures, "abs_orientation_diff_duplicate", 
                      &hv_AODDuplicate);
                  hv_IdxsDuplicate = (hv_AODDuplicate.TupleGreaterElem(-1)).TupleFind(1);
                  if (0 != (int(hv_IdxsDuplicate!=-1)))
                  {
                    hv_ResSoAPDuplicate = 1.0-((HTuple(hv_AODDuplicate[hv_IdxsDuplicate]).TupleMean())/(HTuple(180).TupleRad()));
                    SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_duplicate", 
                        hv_ResSoAPDuplicate);
                    //Update mean over classes.
                    hv_PerIoUNumClassesWithFPDuplicate[hv_ITIdx] = HTuple(hv_PerIoUNumClassesWithFPDuplicate[hv_ITIdx])+1;
                    if (0 != (int(HTuple(hv_PerIoUSoAPDuplicate[hv_ITIdx])==-1)))
                    {
                      hv_PerIoUSoAPDuplicate[hv_ITIdx] = hv_ResSoAPDuplicate;
                    }
                    else
                    {
                      hv_PerIoUSoAPDuplicate[hv_ITIdx] = HTuple(hv_PerIoUSoAPDuplicate[hv_ITIdx])+hv_ResSoAPDuplicate;
                    }
                  }
                  //Calculate and update absolute difference of orientation for multiple false positives.
                  GetDictTuple(hv_CurrentClassMeasures, "abs_orientation_diff_multiple", 
                      &hv_AODMultiple);
                  hv_IdxsMultiple = (hv_AODMultiple.TupleGreaterElem(-1)).TupleFind(1);
                  if (0 != (int(hv_IdxsMultiple!=-1)))
                  {
                    hv_ResSoAPMultiple = 1.0-((HTuple(hv_AODMultiple[hv_IdxsMultiple]).TupleMean())/(HTuple(180).TupleRad()));
                    SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_multiple", 
                        hv_ResSoAPMultiple);
                    //Update mean over classes.
                    hv_PerIoUNumClassesWithFPMultiple[hv_ITIdx] = HTuple(hv_PerIoUNumClassesWithFPMultiple[hv_ITIdx])+1;
                    if (0 != (int(HTuple(hv_PerIoUSoAPMultiple[hv_ITIdx])==-1)))
                    {
                      hv_PerIoUSoAPMultiple[hv_ITIdx] = hv_ResSoAPMultiple;
                    }
                    else
                    {
                      hv_PerIoUSoAPMultiple[hv_ITIdx] = HTuple(hv_PerIoUSoAPMultiple[hv_ITIdx])+hv_ResSoAPMultiple;
                    }
                  }
                }
              }
            }
            //
            //Write to output.
            GetDictTuple(hv_CurrentEvaluationResult, "ap_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")), 
                &hv_PerIoUAP);
            SetDictTuple(hv_PerIoUAP, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), HTuple(hv_ClassAPPerIoU[hv_ITIdx]));
            if (0 != hv_CalcSoAP)
            {
              GetDictTuple(hv_CurrentEvaluationResult, "soap_tp_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")), 
                  &hv_PerIoUSoAP);
              SetDictTuple(hv_PerIoUSoAP, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), 
                  HTuple(hv_ClassSoAPPerIoU[hv_ITIdx]));
            }
          }
          }
          //
          //Class mAP is the mean over IoU-thresholds.
          hv_PerClassMAP[hv_ClsIdx] = hv_ClassAPPerIoU.TupleMean();
          GetDictTuple(hv_CurrentEvaluationResult, "mean_iou_ap", &hv_ClassMAPDict);
          SetDictTuple(hv_ClassMAPDict, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), 
              HTuple(hv_PerClassMAP[hv_ClsIdx]));
          if (0 != hv_CalcSoAP)
          {
            //ClassMSoAP is the mean over IoU-thresholds.
            hv_SoAPIoUIdxsPositive = (hv_ClassSoAPPerIoU.TupleGreaterEqualElem(0.0)).TupleFind(1);
            if (0 != (int(hv_SoAPIoUIdxsPositive!=-1)))
            {
              hv_PerClassMSoAP[hv_ClsIdx] = HTuple(hv_ClassSoAPPerIoU[hv_SoAPIoUIdxsPositive]).TupleMean();
            }
            else
            {
              hv_PerClassMSoAP[hv_ClsIdx] = -1.0;
            }
            GetDictTuple(hv_CurrentEvaluationResult, "mean_iou_soap_tp", &hv_ClassMSoAPDict);
            SetDictTuple(hv_ClassMSoAPDict, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), 
                HTuple(hv_PerClassMSoAP[hv_ClsIdx]));
          }
        }
        }
        //
        //Calculate the mean AP and optionally mean SoAP (over classes) per IoU-threshold.
        {
        HTuple end_val468 = (hv_IoUThresholds.TupleLength())-1;
        HTuple step_val468 = 1;
        for (hv_ITIdx=0; hv_ITIdx.Continue(end_val468, step_val468); hv_ITIdx += step_val468)
        {
          GetDictTuple(hv_CurrentEvaluationResult, "ap_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")), 
              &hv_PerIoUAP);
          //
          //Consider only present classes.
          hv_MeanClassAP = -1.0;
          if (0 != (int((hv_ClassesWithGt.TupleLength())>0)))
          {
            hv_MeanClassAP = HTuple(hv_PerIoUMAP[hv_ITIdx])/(hv_ClassesWithGt.TupleLength());
          }
          SetDictTuple(hv_PerIoUAP, "mean_class_ap", hv_MeanClassAP);
          if (0 != hv_CalcSoAP)
          {
            GetDictTuple(hv_CurrentEvaluationResult, "soap_tp_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")), 
                &hv_PerIoUSoAP);
            //
            //Consider only present classes.
            hv_MeanClassSoAP = -1.0;
            if (0 != (int(HTuple(hv_PerIoUNumClassesWithTP[hv_ITIdx])>0)))
            {
              hv_MeanClassSoAP = HTuple(hv_PerIoUMSoAP[hv_ITIdx])/HTuple(hv_PerIoUNumClassesWithTP[hv_ITIdx]);
            }
            SetDictTuple(hv_PerIoUSoAP, "mean_class_soap_tp", hv_MeanClassSoAP);
          }
          //
          if (0 != hv_DetailedEvaluation)
          {
            //Add overall measures for TP, FN, FP, ...
            GetDictTuple(hv_CurrentEvaluationResult, "detailed_evaluation_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")), 
                &hv_PerIoUDetailedEvaluation);
            SetDictTuple(hv_PerIoUDetailedEvaluation, "num_tp", HTuple(hv_PerIoUTP[hv_ITIdx]));
            SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fn", HTuple(hv_PerIoUFN[hv_ITIdx]));
            SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fp", HTuple(hv_PerIoUFP[hv_ITIdx]));
            SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fp_class", HTuple(hv_PerIoUFPClass[hv_ITIdx]));
            SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fp_background", HTuple(hv_PerIoUFPBackground[hv_ITIdx]));
            SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fp_duplicate", HTuple(hv_PerIoUFPDuplicate[hv_ITIdx]));
            SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fp_localization", HTuple(hv_PerIoUFPLocalization[hv_ITIdx]));
            SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fp_multiple", HTuple(hv_PerIoUFPMultiple[hv_ITIdx]));
            if (0 != hv_CalcSoAP)
            {
              if (0 != (int(HTuple(hv_PerIoUNumClassesWithFPClass[hv_ITIdx])>0)))
              {
                hv_PerIoUSoAPClass[hv_ITIdx] = HTuple(hv_PerIoUSoAPClass[hv_ITIdx])/HTuple(hv_PerIoUNumClassesWithFPClass[hv_ITIdx]);
              }
              if (0 != (int(HTuple(hv_PerIoUNumClassesWithFPLocalization[hv_ITIdx])>0)))
              {
                hv_PerIoUSoAPLocalization[hv_ITIdx] = HTuple(hv_PerIoUSoAPLocalization[hv_ITIdx])/HTuple(hv_PerIoUNumClassesWithFPLocalization[hv_ITIdx]);
              }
              if (0 != (int(HTuple(hv_PerIoUNumClassesWithFPDuplicate[hv_ITIdx])>0)))
              {
                hv_PerIoUSoAPDuplicate[hv_ITIdx] = HTuple(hv_PerIoUSoAPDuplicate[hv_ITIdx])/HTuple(hv_PerIoUNumClassesWithFPDuplicate[hv_ITIdx]);
              }
              if (0 != (int(HTuple(hv_PerIoUNumClassesWithFPMultiple[hv_ITIdx])>0)))
              {
                hv_PerIoUSoAPMultiple[hv_ITIdx] = HTuple(hv_PerIoUSoAPMultiple[hv_ITIdx])/HTuple(hv_PerIoUNumClassesWithFPMultiple[hv_ITIdx]);
              }
              SetDictTuple(hv_PerIoUDetailedEvaluation, "soap_fp_class", HTuple(hv_PerIoUSoAPClass[hv_ITIdx]));
              SetDictTuple(hv_PerIoUDetailedEvaluation, "soap_fp_localization", HTuple(hv_PerIoUSoAPLocalization[hv_ITIdx]));
              SetDictTuple(hv_PerIoUDetailedEvaluation, "soap_fp_duplicate", HTuple(hv_PerIoUSoAPDuplicate[hv_ITIdx]));
              SetDictTuple(hv_PerIoUDetailedEvaluation, "soap_fp_multiple", HTuple(hv_PerIoUSoAPMultiple[hv_ITIdx]));
            }
          }
        }
        }
        //
        //Calculate overall mean AP (over classes and IoU-thresholds).
        //Also here only classes with ground truth annotations are taken into account.
        hv_MAP = -1.0;
        if (0 != (int((hv_ClassesWithGt.TupleLength())>0)))
        {
          hv_MAP = (HTuple(hv_PerClassMAP[hv_ClassesWithGt]).TupleSum())/(hv_ClassesWithGt.TupleLength());
        }
        SetDictTuple(hv_CurrentEvaluationResult, "mean_ap", hv_MAP);
        if (0 != hv_CalcSoAP)
        {
          hv_MSoAP = -1.0;
          if (0 != (int((hv_PerIoUNumClassesWithTP.TupleSum())>0)))
          {
            hv_IoUsWithTP = (hv_PerIoUNumClassesWithTP.TupleGreaterElem(0)).TupleFind(1);
            hv_MSoAP = ((HTuple(hv_PerIoUMSoAP[hv_IoUsWithTP])/HTuple(hv_PerIoUNumClassesWithTP[hv_IoUsWithTP])).TupleSum())/(hv_IoUsWithTP.TupleLength());
          }
          SetDictTuple(hv_CurrentEvaluationResult, "mean_soap_tp", hv_MSoAP);
          if (0 != hv_DetailedEvaluation)
          {
            hv_MSoAPAll = 0.0;
            hv_NumSoAPAll = 0;
            if (0 != (int((hv_PerIoUNumClassesWithTP.TupleSum())>0)))
            {
              hv_IoUsWithTP = (hv_PerIoUNumClassesWithTP.TupleGreaterElem(0)).TupleFind(1);
              hv_MSoAPAll = hv_MSoAP*(HTuple(hv_PerIoUNumClassesWithTP[hv_IoUsWithTP]).TupleSum());
              hv_NumSoAPAll += HTuple(hv_PerIoUNumClassesWithTP[hv_IoUsWithTP]).TupleSum();
            }
            if (0 != (int((hv_PerIoUNumClassesWithFPClass.TupleSum())>0)))
            {
              hv_IoUsWithFPClass = (hv_PerIoUNumClassesWithFPClass.TupleGreaterElem(0)).TupleFind(1);
              hv_MSoAPAll += ((HTuple(hv_PerIoUSoAPClass[hv_IoUsWithFPClass]).TupleSum())/(hv_IoUsWithFPClass.TupleLength()))*(HTuple(hv_PerIoUNumClassesWithFPClass[hv_IoUsWithFPClass]).TupleSum());
              hv_NumSoAPAll += HTuple(hv_PerIoUNumClassesWithFPClass[hv_IoUsWithFPClass]).TupleSum();
            }
            if (0 != (int((hv_PerIoUNumClassesWithFPLocalization.TupleSum())>0)))
            {
              hv_IoUsWithFPLocalization = (hv_PerIoUNumClassesWithFPLocalization.TupleGreaterElem(0)).TupleFind(1);
              hv_MSoAPAll += ((HTuple(hv_PerIoUSoAPLocalization[hv_IoUsWithFPLocalization]).TupleSum())/(hv_IoUsWithFPLocalization.TupleLength()))*(HTuple(hv_PerIoUNumClassesWithFPLocalization[hv_IoUsWithFPLocalization]).TupleSum());
              hv_NumSoAPAll += HTuple(hv_PerIoUNumClassesWithFPLocalization[hv_IoUsWithFPLocalization]).TupleSum();
            }
            if (0 != (int((hv_PerIoUNumClassesWithFPDuplicate.TupleSum())>0)))
            {
              hv_IoUsWithFPDuplicate = (hv_PerIoUNumClassesWithFPDuplicate.TupleGreaterElem(0)).TupleFind(1);
              hv_MSoAPAll += ((HTuple(hv_PerIoUSoAPDuplicate[hv_IoUsWithFPDuplicate]).TupleSum())/(hv_IoUsWithFPDuplicate.TupleLength()))*(HTuple(hv_PerIoUNumClassesWithFPDuplicate[hv_IoUsWithFPDuplicate]).TupleSum());
              hv_NumSoAPAll += HTuple(hv_PerIoUNumClassesWithFPDuplicate[hv_IoUsWithFPDuplicate]).TupleSum();
            }
            if (0 != (int((hv_PerIoUNumClassesWithFPMultiple.TupleSum())>0)))
            {
              hv_IoUsWithFPMultiple = (hv_PerIoUNumClassesWithFPMultiple.TupleGreaterElem(0)).TupleFind(1);
              hv_MSoAPAll += ((HTuple(hv_PerIoUSoAPMultiple[hv_IoUsWithFPMultiple]).TupleSum())/(hv_IoUsWithFPMultiple.TupleLength()))*(HTuple(hv_PerIoUNumClassesWithFPMultiple[hv_IoUsWithFPMultiple]).TupleSum());
              hv_NumSoAPAll += HTuple(hv_PerIoUNumClassesWithFPMultiple[hv_IoUsWithFPMultiple]).TupleSum();
            }
            if (0 != (int(hv_NumSoAPAll>0)))
            {
              SetDictTuple(hv_CurrentEvaluationResult, "mean_soap_all", (hv_MSoAPAll.TupleReal())/hv_NumSoAPAll);
            }
            else
            {
              SetDictTuple(hv_CurrentEvaluationResult, "mean_soap_all", -1);
            }
            //
          }
        }
        //
        //Add CurrentEvaluationResult to output.
        SetDictTuple(hv_PerMaxNumEvaluationResult, "area_"+hv_AreaName, hv_CurrentEvaluationResult);
      }
      }
      //Add PerMaxNumEvaluationResult to output.
      SetDictTuple((*hv_EvaluationResult), "max_num_detections_"+hv_MaxNumStr, hv_PerMaxNumEvaluationResult);
    }
    }
  }
  //
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Computes the ocr_detection relevant evaluation measures. 
void calculate_ocr_detection_measures (HTuple hv_DetectionEvaluationResult, HTuple *hv_EvaluationResult)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Keys, hv_Matches, hv_Key, hv_WordEval;
  HTuple  hv_NumAll, hv_NumTPFP, hv_Divisor, hv___Tmp_Ctrl_Type;

  GetDictParam((hv_DetectionEvaluationResult.TupleGetDictTuple("max_num_detections_all")).TupleGetDictTuple("area_all"), 
      "keys", HTuple(), &hv_Keys);
  //Use the first matching key in order to compute the measures.
  TupleRegexpSelect(hv_Keys, "detailed_evaluation_iou_.*", &hv_Matches);
  hv_Key = ((const HTuple&)hv_Matches)[0];
  hv_WordEval = (((hv_DetectionEvaluationResult.TupleGetDictTuple("max_num_detections_all")).TupleGetDictTuple("area_all")).TupleGetDictTuple(hv_Key)).TupleGetDictTuple("class_0");
  CreateDict(&(*hv_EvaluationResult));
  //Recall
  hv_NumAll = (hv_WordEval.TupleGetDictTuple("num_tp"))+(hv_WordEval.TupleGetDictTuple("num_fn"));
  if (0 != (int(hv_NumAll>0)))
  {
    SetDictTuple((*hv_EvaluationResult), "recall", (hv_WordEval.TupleGetDictTuple("num_tp"))/(hv_NumAll.TupleReal()));
  }
  else
  {
    SetDictTuple((*hv_EvaluationResult), "recall", 0.0);
  }
  //Precision
  hv_NumTPFP = (hv_WordEval.TupleGetDictTuple("num_tp"))+(hv_WordEval.TupleGetDictTuple("num_fp"));
  if (0 != (int(hv_NumTPFP>0)))
  {
    SetDictTuple((*hv_EvaluationResult), "precision", (hv_WordEval.TupleGetDictTuple("num_tp"))/(hv_NumTPFP.TupleReal()));
  }
  else
  {
    SetDictTuple((*hv_EvaluationResult), "precision", 0.0);
  }
  //F-Score
  hv_Divisor = ((*hv_EvaluationResult).TupleGetDictTuple("precision"))+((*hv_EvaluationResult).TupleGetDictTuple("recall"));
  if (0 != (int(hv_Divisor!=0)))
  {
    SetDictTuple((*hv_EvaluationResult), "f_score", ((2*((*hv_EvaluationResult).TupleGetDictTuple("precision")))*((*hv_EvaluationResult).TupleGetDictTuple("recall")))/hv_Divisor);
  }
  else
  {
    SetDictTuple((*hv_EvaluationResult), "f_score", 0.0);
  }
  //SoAP
  TupleRegexpSelect(hv_Keys, "soap_tp_iou_.*", &hv_Matches);
  if (0 != (int((hv_Matches.TupleLength())>0)))
  {
    hv_Key = ((const HTuple&)hv_Matches)[0];
    GetDictParam(((hv_DetectionEvaluationResult.TupleGetDictTuple("max_num_detections_all")).TupleGetDictTuple("area_all")).TupleGetDictTuple(hv_Key), 
        "key_data_type", "class_0", &hv___Tmp_Ctrl_Type);
    if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
    {
      SetDictObject((((hv_DetectionEvaluationResult.TupleGetDictTuple("max_num_detections_all")).TupleGetDictTuple("area_all")).TupleGetDictTuple(hv_Key)).TupleGetDictObject("class_0"), 
          (*hv_EvaluationResult), "soap");
    }
    else
    {
      SetDictTuple((*hv_EvaluationResult), "soap", (((hv_DetectionEvaluationResult.TupleGetDictTuple("max_num_detections_all")).TupleGetDictTuple("area_all")).TupleGetDictTuple(hv_Key)).TupleGetDictTuple("class_0"));
    }
  }
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Calculate OCR recognition measures based on RunningMeasures. 
void calculate_ocr_recognition_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Equal;

  //
  //This procedure calculates the final summarizing OCR recognition measures based on the running measures.
  //
  //
  //Initialize output dictionary and get necessary evaluation parameters.
  CreateDict(&(*hv_EvaluationResult));
  //
  //Compute Accuracy
  hv_Equal = (hv_RunningMeasures.TupleGetDictTuple("words_ground_truth")).TupleEqualElem(hv_RunningMeasures.TupleGetDictTuple("words_prediction"));
  if (0 != (int((hv_Equal.TupleLength())>0)))
  {
    SetDictTuple((*hv_EvaluationResult), "accuracy", ((hv_Equal.TupleSum())/(HTuple(hv_Equal.TupleLength()).TupleReal()))*100);
  }
  else
  {
    SetDictTuple((*hv_EvaluationResult), "accuracy", 0);
  }
  return;
}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Calculate pixel measures based on RunningMeasures. 
void calculate_pixel_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, HTuple *hv_EvaluationResult)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CalcClassPixelAccuracy, hv_CalcPixelAccuracy;
  HTuple  hv_CalcPixelConfusionMatrix, hv_CalcMeanAccuracy;
  HTuple  hv_CalcMeanPrecision, hv_CalcMeanIou, hv_CalcClassIou;
  HTuple  hv_CalcFWIou, hv_Measures, hv_EvaluationType, hv_PixelMeasures;
  HTuple  hv_M, hv_ConfMatrix, hv_TPMat, hv_TP, hv_SumRowMat;
  HTuple  hv_RowSum, hv_FP, hv_SumColMat, hv_ColSum, hv_FN;
  HTuple  hv_IgnoreClassIDs, hv_Rows, hv_Columns, hv_FPIgnore;
  HTuple  hv_GT, hv_ClsIdxValid, hv_ClassPixelAccuracy, hv_MeanAccuracy;
  HTuple  hv_PixelAccuracy, hv_PD, hv_PDIdxValid, hv_ClassPixelPrecision;
  HTuple  hv_MeanPrecision, hv_ClassIoU, hv_MeanIoU, hv_FWIoU;
  HTuple  hv_FwWeights;

  //
  //This procedure calculates the pixel-wise measures based on the values in running measures.
  //
  //Set default values.
  hv_CalcClassPixelAccuracy = 0;
  hv_CalcPixelAccuracy = 0;
  hv_CalcPixelConfusionMatrix = 0;
  hv_CalcMeanAccuracy = 0;
  hv_CalcMeanPrecision = 0;
  hv_CalcMeanIou = 0;
  hv_CalcClassIou = 0;
  hv_CalcFWIou = 0;
  CreateDict(&(*hv_EvaluationResult));
  //
  //Check which measures are to be calculated.
  GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
  GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
  get_requested_pixel_measures(hv_Measures, hv_EvaluationType, &hv_PixelMeasures);
  if (0 != (int((hv_PixelMeasures.TupleLength())==0)))
  {
    return;
  }
  //
  {
  HTuple end_val22 = (hv_PixelMeasures.TupleLength())-1;
  HTuple step_val22 = 1;
  for (hv_M=0; hv_M.Continue(end_val22, step_val22); hv_M += step_val22)
  {
    if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("pixel_accuracy"))))
    {
      hv_CalcPixelAccuracy = 1;
    }
    else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("class_pixel_accuracy"))))
    {
      hv_CalcClassPixelAccuracy = 1;
    }
    else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("pixel_confusion_matrix"))))
    {
      hv_CalcPixelConfusionMatrix = 1;
    }
    else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("mean_accuracy"))))
    {
      hv_CalcMeanAccuracy = 1;
    }
    else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("mean_precision"))))
    {
      hv_CalcMeanPrecision = 1;
    }
    else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("mean_iou"))))
    {
      hv_CalcMeanIou = 1;
    }
    else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("class_iou"))))
    {
      hv_CalcClassIou = 1;
    }
    else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("frequency_weighted_iou"))))
    {
      hv_CalcFWIou = 1;
    }
    else
    {
      throw HException("Unknown pixel measure: "+HTuple(hv_PixelMeasures[hv_M]));
    }
  }
  }
  //
  //Depending on the running measure values (ConfusionMatrix or TP/FP/FN),
  //we first calculate TP/FP/FN from the ConfusionMatrix.
  if (0 != hv_CalcPixelConfusionMatrix)
  {
    //Get the running measures.
    GetDictTuple(hv_RunningMeasures, "pixel_confusion_matrix", &hv_ConfMatrix);
    //Get the per-class true positives as the diagonal of the matrix.
    GetDiagonalMatrix(hv_ConfMatrix, 0, &hv_TPMat);
    GetFullMatrix(hv_TPMat, &hv_TP);
    //For the confusion matrix, the row determines the predicted class-IDs,
    //the column determines the ground truth class-IDs.
    //Get the per-class false positives (FP) as the sum over the rows minus the diagonal (TP).
    SumMatrix(hv_ConfMatrix, "rows", &hv_SumRowMat);
    GetFullMatrix(hv_SumRowMat, &hv_RowSum);
    hv_FP = hv_RowSum-hv_TP;
    //Get the per-class false negatives (FN) as the sum over the columns minus the diagonal (TP).
    SumMatrix(hv_ConfMatrix, "columns", &hv_SumColMat);
    GetFullMatrix(hv_SumColMat, &hv_ColSum);
    hv_FN = hv_ColSum-hv_TP;
    //We do not want to count the false positives (FP) in the ignore region.
    //The false negatives (FN) are not affected, since the model does not predict the ignore class.
    GetDictTuple(hv_EvalParams, "ignore_class_ids", &hv_IgnoreClassIDs);
    if (0 != (int((hv_IgnoreClassIDs.TupleLength())>0)))
    {
      //The ignore class corresponds to the last row/column in the confusion matrix.
      GetSizeMatrix(hv_ConfMatrix, &hv_Rows, &hv_Columns);
      GetValueMatrix(hv_ConfMatrix, HTuple::TupleGenSequence(0,hv_Rows-1,1), HTuple(hv_Rows,hv_Columns-1), 
          &hv_FPIgnore);
      hv_FP = hv_FP-hv_FPIgnore;
      //Remove last entries of TP, FP, FN (those related to the ignore class).
      hv_TP = hv_TP.TupleSelectRange(0,(hv_TP.TupleLength())-2);
      hv_FP = hv_FP.TupleSelectRange(0,(hv_FP.TupleLength())-2);
      hv_FN = hv_FN.TupleSelectRange(0,(hv_FN.TupleLength())-2);
      //Remove last row/column from confusion matrix.
      GetSubMatrix(hv_ConfMatrix, 0, 0, hv_Rows-1, hv_Columns-1, &hv_ConfMatrix);
    }
    //Paste the confusion matrix to the output.
    SetDictTuple((*hv_EvaluationResult), "pixel_confusion_matrix", hv_ConfMatrix);
  }
  else
  {
    //Get the running measure values.
    GetDictTuple(hv_RunningMeasures, "tp", &hv_TP);
    GetDictTuple(hv_RunningMeasures, "fp", &hv_FP);
    GetDictTuple(hv_RunningMeasures, "fn", &hv_FN);
  }
  //
  //It might be the case, that some of the classes are not present in the set of validation images.
  //--> Exclude these classes (they are indirectly present as they reduce the number of TP for other classes).
  hv_GT = hv_TP+hv_FN;
  hv_ClsIdxValid = (hv_GT.TupleGreaterElem(0)).TupleFind(1);
  //
  //Mean Accuracy, Class Pixel Accuracy.
  //-> If one of 'mean_accuracy', 'class_pixel_accuracy' is specified, we give back both of them
  //   as they have to be calculated anyway (to the most part).
  if (0 != (hv_CalcClassPixelAccuracy.TupleOr(hv_CalcMeanAccuracy)))
  {
    //Compute pixel accuracy per class (although we might only use it for the overall pixel accuracy).
    hv_ClassPixelAccuracy = HTuple(hv_GT.TupleLength(),-1);
    hv_MeanAccuracy = -1;
    if (0 != (int(HTuple(hv_ClsIdxValid[0])>-1)))
    {
      hv_ClassPixelAccuracy[hv_ClsIdxValid] = (HTuple(hv_TP[hv_ClsIdxValid]).TupleReal())/HTuple(hv_GT[hv_ClsIdxValid]);
      hv_MeanAccuracy = HTuple(hv_ClassPixelAccuracy[hv_ClsIdxValid]).TupleMean();
    }
    SetDictTuple((*hv_EvaluationResult), "class_pixel_accuracy", hv_ClassPixelAccuracy);
    SetDictTuple((*hv_EvaluationResult), "mean_accuracy", hv_MeanAccuracy);
  }
  //Pixel Accuracy.
  if (0 != hv_CalcPixelAccuracy)
  {
    //Compute pixel accuracy as the total ratio of pixels that have been correctly predicted.
    hv_PixelAccuracy = -1;
    if (0 != (int(HTuple(hv_ClsIdxValid[0])>-1)))
    {
      hv_PixelAccuracy = ((HTuple(hv_TP[hv_ClsIdxValid]).TupleSum()).TupleReal())/(HTuple(hv_GT[hv_ClsIdxValid]).TupleSum());
    }
    SetDictTuple((*hv_EvaluationResult), "pixel_accuracy", hv_PixelAccuracy);
  }
  //Mean Precision.
  //-> Also includes precisions for each of the classes which are
  //   used to calculate the mean precision.
  if (0 != hv_CalcMeanPrecision)
  {
    //Compute pixel-level precision averaged over all classes.
    hv_PD = hv_TP+hv_FP;
    hv_PDIdxValid = (hv_PD.TupleGreaterElem(0.0)).TupleFind(1);
    hv_ClassPixelPrecision = HTuple(hv_PD.TupleLength(),-1);
    hv_MeanPrecision = -1;
    if (0 != (int(HTuple(hv_PDIdxValid[0])>-1)))
    {
      hv_ClassPixelPrecision[hv_PDIdxValid] = (HTuple(hv_TP[hv_PDIdxValid]).TupleReal())/HTuple(hv_PD[hv_PDIdxValid]);
      hv_MeanPrecision = HTuple(hv_ClassPixelPrecision[hv_PDIdxValid]).TupleMean();
    }
    SetDictTuple((*hv_EvaluationResult), "mean_precision", hv_MeanPrecision);
  }
  //Mean IoU, class IoU, frequency weighted IoU:
  //-> If the measures 'class_iou', 'mean_iou' or 'frequency_weighted_iou' is specified,
  //   we return all three of them as they have to be calculated anyway (to the most part).
  if (0 != (HTuple(hv_CalcMeanIou.TupleOr(hv_CalcClassIou)).TupleOr(hv_CalcFWIou)))
  {
    hv_ClassIoU = HTuple(hv_GT.TupleLength(),-1);
    hv_MeanIoU = -1;
    hv_FWIoU = -1;
    if (0 != (int(HTuple(hv_ClsIdxValid[0])>-1)))
    {
      hv_ClassIoU[hv_ClsIdxValid] = (HTuple(hv_TP[hv_ClsIdxValid]).TupleReal())/(HTuple(hv_GT[hv_ClsIdxValid])+HTuple(hv_FP[hv_ClsIdxValid]));
      hv_MeanIoU = HTuple(hv_ClassIoU[hv_ClsIdxValid]).TupleMean();
      hv_FwWeights = (hv_GT.TupleReal())/(hv_GT.TupleSum());
      hv_FWIoU = (HTuple(hv_FwWeights[hv_ClsIdxValid])*HTuple(hv_ClassIoU[hv_ClsIdxValid])).TupleSum();
    }
    SetDictTuple((*hv_EvaluationResult), "class_iou", hv_ClassIoU);
    SetDictTuple((*hv_EvaluationResult), "mean_iou", hv_MeanIoU);
    SetDictTuple((*hv_EvaluationResult), "frequency_weighted_iou", hv_FWIoU);
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Calculate region measures based on running measure values. 
void calculate_region_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CalcMeanPRO, hv_Measures, hv_M, hv_ClsIdxValid;
  HTuple  hv_ClassPRO, hv_MeanPRO;

  //
  //This procedure calculates the region measures based on the
  //values in running measures.
  //
  //Set default values.
  hv_CalcMeanPRO = 0;
  CreateDict(&(*hv_EvaluationResult));
  //
  //Check which measures are to be calculated.
  GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
  {
  HTuple end_val10 = (hv_Measures.TupleLength())-1;
  HTuple step_val10 = 1;
  for (hv_M=0; hv_M.Continue(end_val10, step_val10); hv_M += step_val10)
  {
    if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("mean_pro"))))
    {
      hv_CalcMeanPRO = 1;
    }
    else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("all"))))
    {
      hv_CalcMeanPRO = 1;
    }
  }
  }
  //
  if (0 != hv_CalcMeanPRO)
  {
    //It might be the case, that some of the classes are not present
    //in the set of evaluation images and are excluded.
    hv_ClsIdxValid = ((hv_RunningMeasures.TupleGetDictTuple("num_gt_regions")).TupleGreaterElem(0)).TupleFind(1);
    //
    //Compute per-region-overlap averaged over the valid classes.
    hv_ClassPRO = HTuple((hv_RunningMeasures.TupleGetDictTuple("num_gt_regions")).TupleLength(),-1);
    hv_MeanPRO = -1;
    if (0 != (int(HTuple(hv_ClsIdxValid[0])>-1)))
    {
      hv_ClassPRO[hv_ClsIdxValid] = HTuple((hv_RunningMeasures.TupleGetDictTuple("gt_overlap"))[hv_ClsIdxValid])/(HTuple((hv_RunningMeasures.TupleGetDictTuple("num_gt_regions"))[hv_ClsIdxValid]).TupleReal());
      hv_MeanPRO = HTuple(hv_ClassPRO[hv_ClsIdxValid]).TupleMean();
    }
    SetDictTuple((*hv_EvaluationResult), "mean_pro", hv_MeanPRO);
  }
  //
  return;
}

// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Calculate 3D gripping point measures based on RunningMeasures. 
void calculate_running_gripping_point_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, 
    HTuple *hv_EvaluationResult)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Positives, hv_GT, hv_Precision, hv_Recall;
  HTuple  hv_SumPrecisionRecall, hv_FScore;

  CreateDict(&(*hv_EvaluationResult));
  if (0 != (int((HTuple((hv_EvalParams.TupleGetDictTuple("measures")).TupleRegexpSelect("gripping_point_.*|all")).TupleLength())>0)))
  {
    hv_Positives = (hv_RunningMeasures.TupleGetDictTuple("gp_tp"))+(hv_RunningMeasures.TupleGetDictTuple("gp_fp"));
    hv_GT = (hv_RunningMeasures.TupleGetDictTuple("gp_tp"))+(hv_RunningMeasures.TupleGetDictTuple("gp_fn"));
    if (0 != (int(hv_Positives>0.0)))
    {
      hv_Precision = (hv_RunningMeasures.TupleGetDictTuple("gp_tp"))/hv_Positives;
    }
    else
    {
      hv_Precision = 0.0;
    }
    if (0 != (int(hv_GT>0.0)))
    {
      hv_Recall = (hv_RunningMeasures.TupleGetDictTuple("gp_tp"))/hv_GT;
    }
    else
    {
      hv_Recall = 0.0;
    }
    hv_SumPrecisionRecall = hv_Precision+hv_Recall;
    if (0 != (int(hv_SumPrecisionRecall>0.0)))
    {
      hv_FScore = ((2*hv_Precision)*hv_Recall)/hv_SumPrecisionRecall;
    }
    else
    {
      hv_FScore = 0.0;
    }
    if (0 != (int((HTuple((hv_EvalParams.TupleGetDictTuple("measures")).TupleRegexpSelect("gripping_point_precision|all")).TupleLength())>0)))
    {
      SetDictTuple((*hv_EvaluationResult), "gripping_point_precision", hv_Precision);
    }
    if (0 != (int((HTuple((hv_EvalParams.TupleGetDictTuple("measures")).TupleRegexpSelect("gripping_point_recall|all")).TupleLength())>0)))
    {
      SetDictTuple((*hv_EvaluationResult), "gripping_point_recall", hv_Recall);
    }
    if (0 != (int((HTuple((hv_EvalParams.TupleGetDictTuple("measures")).TupleRegexpSelect("gripping_point_f_score|all")).TupleLength())>0)))
    {
      SetDictTuple((*hv_EvaluationResult), "gripping_point_f_score", hv_FScore);
    }
  }
  return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Compute thresholds for anomaly detection or Global Context Anomaly Detection. 
void compute_dl_anomaly_thresholds (HTuple hv_DLModelHandle, HTuple hv_DLDataset, 
    HTuple hv_GenParam, HTuple *hv_AnomalySegmentationThreshold, HTuple *hv_AnomalyClassificationThresholds)
{

  // Local iconic variables
  HObject  ho_AnomalyImage, ho_Domain;

  // Local control variables
  HTuple  hv_ModelType, hv_DLSamples, hv_SplitExists;
  HTuple  hv_SupportedKeys, hv_UseOkSamplesOnly, hv_EnableDisplay;
  HTuple  hv_SupportedSegmentationCriteria, hv_SegmentationCriterion;
  HTuple  hv_SegmentationTolerance, hv_Keys, hv_UnsupportedKeys;
  HTuple  hv_UnsupportedKeysString, hv_UseOkSamplesOnlyExists;
  HTuple  hv_EnableDisplayExists, hv_SegmentationCriterionKeyExists;
  HTuple  hv_ToleranceKeyExists, hv_ValidationIndices, hv_WindowWidth;
  HTuple  hv_WindowHeight, hv_WindowBGColor, hv_WindowHandleInfo;
  HTuple  hv_ValidationSamples, hv_ThresholdInformation, hv_ValidationResults;
  HTuple  hv_Values, hv_NumValues, hv_Index, hv_Width, hv_Height;
  HTuple  hv_Rows, hv_Columns, hv_Grayval, hv_TestIndices;
  HTuple  hv_TestIndicesNOK, hv_TestIndicesOK, hv_TestSamplesOK;
  HTuple  hv_TestResultsOK, hv_AnomalyScoresOK, hv_AnomalyScore;
  HTuple  hv_Eps, hv_TestSamplesNOK, hv_TestResultsNOK, hv_AnomalyScoresNOK;
  HTuple  hv_MaxScoreOK, hv_MinScoreNOK, hv_IntermediateThreshold;
  HTuple  hv_AnomalyScores, hv_AnomalyScoresSortIndices, hv_AnomalyScoresSorted;
  HTuple  hv_TmpOK, hv_TrueNegativesPerScore, hv_FPRate, hv_TmpNOK;
  HTuple  hv_FalseNegativesPerScore, hv_FNRate, hv_FprFnrSum;
  HTuple  hv_MinFprFnRSum, hv_ThresholdIndex, hv___Tmp_Ctrl_Dict_Init_0;
  HTuple  hv___Tmp_Ctrl_Dict_Init_1, hv___Tmp_Ctrl_Dict_Init_2;
  HTuple  hv___Tmp_Ctrl_Dict_Init_3;

  //This procedure estimates two different thresholds used in deep-learning-based
  //anomaly detection and Global Context Anomaly Detection
  //(For models of type 'anomaly_detection' and 'gc_anomaly_detection').
  //These thresholds are used for:
  //1) Region segmentation: AnomalySegmentationThreshold can be used as threshold
  //   whether a pixel within the anomaly image belongs to a region of an anomaly.
  //   The threshold is estimated based on the samples in the validation split of DLDataset.
  //2) Image classification: AnomalyClassificationThresholds can be used as threshold
  //   whether the image is counted as containing an anomaly.
  //   It consists of a tuple with the following values:
  // - the maximal anomaly score obtained for the ok test samples
  // - the minimal anomaly score obtained for the nok test samples
  // - an intermediate threshold for the anomaly scores that minimizes
  //   the sum of the false negative rate and the false positive rate.
  //   Note, the latter two values are only calculated if nok test samples are available.
  //
  //Check model type.
  GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
  if (0 != (HTuple(int(hv_ModelType!=HTuple("anomaly_detection"))).TupleAnd(int(hv_ModelType!=HTuple("gc_anomaly_detection")))))
  {
    throw HException("This procedure can only be used for models of type 'anomaly_detection' and 'gc_anomaly_detection'.");
  }
  //
  //Get sample entries in DLDataset.
  hv_DLSamples = hv_DLDataset.TupleGetDictTuple("samples");
  //
  //Check whether the dataset is split.
  GetDictParam(HTuple(hv_DLSamples[0]), "key_exists", "split", &hv_SplitExists);
  if (0 != (hv_SplitExists.TupleNot()))
  {
    throw HException("This procedure can only be used if DLDataset has already been split.");
  }
  //
  //For Global Context Anomaly Detection, check if model has been normalized.
  if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
  {
    check_dl_gc_anomaly_scores_normalization(hv_DLModelHandle, HTuple());
  }
  //
  //Read in generic parameters.
  hv_SupportedKeys.Clear();
  hv_SupportedKeys[0] = "enable_display";
  hv_SupportedKeys[1] = "use_ok_samples_only";
  hv_SupportedKeys[2] = "segmentation_criterion";
  hv_SupportedKeys[3] = "segmentation_tolerance";
  hv_UseOkSamplesOnly = 0;
  hv_EnableDisplay = 0;
  hv_SupportedSegmentationCriteria.Clear();
  hv_SupportedSegmentationCriteria[0] = "deviation";
  hv_SupportedSegmentationCriteria[1] = "tolerance";
  hv_SegmentationCriterion = ((const HTuple&)hv_SupportedSegmentationCriteria)[0];
  hv_SegmentationTolerance = 0.0;
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_Keys);
    hv_UnsupportedKeys = hv_Keys.TupleDifference(hv_SupportedKeys);
    if (0 != (int(hv_UnsupportedKeys!=HTuple())))
    {
      hv_UnsupportedKeysString = (hv_UnsupportedKeys+HTuple(", ")).TupleSum();
      hv_UnsupportedKeysString = hv_UnsupportedKeysString.TupleStrFirstN((hv_UnsupportedKeysString.TupleStrlen())-3);
      throw HException("Unsupported keys: "+hv_UnsupportedKeysString);
    }
    GetDictParam(hv_GenParam, "key_exists", "use_ok_samples_only", &hv_UseOkSamplesOnlyExists);
    if (0 != hv_UseOkSamplesOnlyExists)
    {
      CreateDict(&hv___Tmp_Ctrl_Dict_Init_0);
      SetDictTuple(hv___Tmp_Ctrl_Dict_Init_0, "comp", 1);
      CreateDict(&hv___Tmp_Ctrl_Dict_Init_1);
      SetDictTuple(hv___Tmp_Ctrl_Dict_Init_1, "comp", "true");
      hv_UseOkSamplesOnly = ((hv_GenParam.TupleConcat(hv___Tmp_Ctrl_Dict_Init_1)).TupleTestEqualDictItem("use_ok_samples_only","comp")).TupleOr((hv_GenParam.TupleConcat(hv___Tmp_Ctrl_Dict_Init_0)).TupleTestEqualDictItem("use_ok_samples_only","comp"));
      hv___Tmp_Ctrl_Dict_Init_1 = HTuple::TupleConstant("HNULL");
      hv___Tmp_Ctrl_Dict_Init_0 = HTuple::TupleConstant("HNULL");
    }
    GetDictParam(hv_GenParam, "key_exists", "enable_display", &hv_EnableDisplayExists);
    if (0 != hv_EnableDisplayExists)
    {
      CreateDict(&hv___Tmp_Ctrl_Dict_Init_2);
      SetDictTuple(hv___Tmp_Ctrl_Dict_Init_2, "comp", 1);
      CreateDict(&hv___Tmp_Ctrl_Dict_Init_3);
      SetDictTuple(hv___Tmp_Ctrl_Dict_Init_3, "comp", "true");
      hv_EnableDisplay = ((hv_GenParam.TupleConcat(hv___Tmp_Ctrl_Dict_Init_3)).TupleTestEqualDictItem("enable_display","comp")).TupleOr((hv_GenParam.TupleConcat(hv___Tmp_Ctrl_Dict_Init_2)).TupleTestEqualDictItem("enable_display","comp"));
      hv___Tmp_Ctrl_Dict_Init_3 = HTuple::TupleConstant("HNULL");
      hv___Tmp_Ctrl_Dict_Init_2 = HTuple::TupleConstant("HNULL");
    }
    GetDictParam(hv_GenParam, "key_exists", "segmentation_criterion", &hv_SegmentationCriterionKeyExists);
    if (0 != hv_SegmentationCriterionKeyExists)
    {
      hv_SegmentationCriterion = hv_GenParam.TupleGetDictTuple("segmentation_criterion");
      if (0 != (int((hv_SupportedSegmentationCriteria.TupleFindFirst(hv_SegmentationCriterion))==-1)))
      {
        throw HException("Unsupported segmentation criterion "+hv_SegmentationCriterion);
      }
    }
    GetDictParam(hv_GenParam, "key_exists", "segmentation_tolerance", &hv_ToleranceKeyExists);
    if (0 != hv_ToleranceKeyExists)
    {
      hv_SegmentationTolerance = hv_GenParam.TupleGetDictTuple("segmentation_tolerance");
      if (0 != ((hv_SegmentationTolerance.TupleIsNumber()).TupleNot()))
      {
        throw HException(HTuple("Value for 'segmentation_tolerance' must be a number, but is ")+hv_SegmentationTolerance);
      }
      if (0 != (HTuple(int(hv_SegmentationTolerance<0.0)).TupleOr(int(hv_SegmentationTolerance>=1.0))))
      {
        throw HException(HTuple("Value for 'segmentation_tolerance' must be larger than or equal to 0 and smaller than 1, but is ")+hv_SegmentationTolerance);
      }
    }
  }
  //
  //Determine the threshold for region segmentation: AnomalySegmentationThreshold.
  //
  //Get the samples in the validation split.
  find_dl_samples(hv_DLSamples, "split", "validation", "or", &hv_ValidationIndices);
  //If the validation split is empty, the segmentation threshold cannot be estimated.
  if (0 != (int((hv_ValidationIndices.TupleLength())==0)))
  {
    throw HException("This procedure can only be used with at least one validation image.");
  }
  //
  //Display progress message.
  if (0 != hv_EnableDisplay)
  {
    hv_WindowWidth = 500;
    hv_WindowHeight = 200;
    hv_WindowBGColor = "light gray";
    //
    //Open and setup text window.
    SetWindowAttr("background_color",hv_WindowBGColor);
    OpenWindow(0,0,hv_WindowWidth,hv_WindowHeight,0,"visible","",&hv_WindowHandleInfo);
    HDevWindowStack::Push(hv_WindowHandleInfo);
    set_display_font(hv_WindowHandleInfo, 16, "mono", "true", "false");
  }
  //
  read_dl_samples(hv_DLDataset, hv_ValidationIndices, &hv_ValidationSamples);
  //
  //Get the gray values of the anomaly images for the validation split.
  if (0 != hv_EnableDisplay)
  {
    hv_ThresholdInformation.Clear();
    hv_ThresholdInformation[0] = "Computing thresholds.";
    hv_ThresholdInformation[1] = "";
    hv_ThresholdInformation[2] = "This may take some time...";
    hv_ThresholdInformation[3] = "";
    hv_ThresholdInformation[4] = "Get gray values of anomaly images";
    hv_ThresholdInformation[5] = "for the validation split (1/3)";
    if (HDevWindowStack::IsOpen())
      ClearWindow(HDevWindowStack::GetActive());
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),hv_ThresholdInformation, "window", "top", 
          "left", "black", "box", "false");
  }
  ApplyDlModel(hv_DLModelHandle, hv_ValidationSamples, HTuple(), &hv_ValidationResults);
  //
  hv_Values = HTuple();
  hv_NumValues = 0;
  {
  HTuple end_val122 = (hv_ValidationResults.TupleLength())-1;
  HTuple step_val122 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val122, step_val122); hv_Index += step_val122)
  {
    GetDictObject(&ho_AnomalyImage, HTuple(hv_ValidationResults[hv_Index]), "anomaly_image");
    if (0 != (int(hv_Values==HTuple())))
    {
      //Allocate buffer for pixel values
      GetImageSize(ho_AnomalyImage, &hv_Width, &hv_Height);
      TupleGenConst((hv_Width*hv_Height)*(hv_ValidationResults.TupleLength()), -1, 
          &hv_Values);
    }
    GetDomain(ho_AnomalyImage, &ho_Domain);
    GetRegionPoints(ho_Domain, &hv_Rows, &hv_Columns);
    GetGrayval(ho_AnomalyImage, hv_Rows, hv_Columns, &hv_Grayval);
    hv_Values[HTuple::TupleGenSequence(hv_NumValues,(hv_NumValues+(hv_Grayval.TupleLength()))-1,1)] = hv_Grayval;
    hv_NumValues += hv_Grayval.TupleLength();
  }
  }
  hv_Values = hv_Values.TupleSelectRange(0,hv_NumValues-1);
  //
  //Compute the estimated threshold.
  if (0 != (int(hv_SegmentationCriterion==HTuple("deviation"))))
  {
    //We take the mean of the anomaly images plus four times their standard deviation.
    //This ensures that almost all gray values in the anomaly images
    //of the validation samples are below threshold, while the estimate
    //is still robust against unexpected outliers.
    (*hv_AnomalySegmentationThreshold) = (hv_Values.TupleMean())+(4.0*(hv_Values.TupleDeviation()));
    if (0 != (int(hv_ModelType==HTuple("anomaly_detection"))))
    {
      (*hv_AnomalySegmentationThreshold) = (*hv_AnomalySegmentationThreshold).TupleMin2(1.0);
    }
  }
  else if (0 != (int(hv_SegmentationCriterion==HTuple("tolerance"))))
  {
    //We tolerate a fraction of anomaly scores to be anomalous. This fraction is
    //given by the value of SegmentationTolerance.
    if (0 != (int(hv_SegmentationTolerance==0.0)))
    {
      (*hv_AnomalySegmentationThreshold) = hv_Values.TupleMax();
    }
    else
    {
      hv_Values = hv_Values.TupleSort();
      (*hv_AnomalySegmentationThreshold) = HTuple(hv_Values[((1-hv_SegmentationTolerance)*((hv_Values.TupleLength())-1)).TupleRound()]);
    }
  }
  //
  //Determine the thresholds for anomaly image classification: AnomalyClassificationThresholds.
  //
  //Get the indices of the ok and nok test samples.
  find_dl_samples(hv_DLSamples, "split", "test", "or", &hv_TestIndices);
  find_dl_samples(hv_DLSamples, "anomaly_label", "nok", "or", &hv_TestIndicesNOK);
  hv_TestIndicesOK = hv_TestIndices.TupleDifference(hv_TestIndicesNOK);
  //
  if (0 != (int((hv_TestIndicesOK.TupleLength())==0)))
  {
    //No thresholds are computed.
    throw HException("This procedure requires at least one test image labeled as 'ok'.");
  }
  //
  //Compute the anomaly scores of the ok test samples.
  if (0 != hv_EnableDisplay)
  {
    hv_ThresholdInformation.Clear();
    hv_ThresholdInformation[0] = "Computing thresholds.";
    hv_ThresholdInformation[1] = "";
    hv_ThresholdInformation[2] = "This may take some time...";
    hv_ThresholdInformation[3] = "";
    hv_ThresholdInformation[4] = "Compute the anomaly scores";
    hv_ThresholdInformation[5] = "of the ok test samples (2/3)";
    if (HDevWindowStack::IsOpen())
      ClearWindow(HDevWindowStack::GetActive());
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),hv_ThresholdInformation, "window", "top", 
          "left", "black", "box", "false");
  }
  read_dl_samples(hv_DLDataset, hv_TestIndicesOK, &hv_TestSamplesOK);
  ApplyDlModel(hv_DLModelHandle, hv_TestSamplesOK, HTuple(), &hv_TestResultsOK);
  hv_AnomalyScoresOK = HTuple(hv_TestResultsOK.TupleLength(),0.0);
  {
  HTuple end_val179 = (hv_TestResultsOK.TupleLength())-1;
  HTuple step_val179 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val179, step_val179); hv_Index += step_val179)
  {
    GetDictTuple(HTuple(hv_TestResultsOK[hv_Index]), "anomaly_score", &hv_AnomalyScore);
    hv_AnomalyScoresOK[hv_Index] = hv_AnomalyScore;
  }
  }
  //
  //Set a small value which is used to slightly increase the calculated thresholds
  //to ensure correct classification of OK scores.
  hv_Eps = 1e-15;
  //
  //In case only test samples labeled as ok are used,
  //only one anomaly image classification threshold is returned.
  if (0 != (HTuple(int((hv_TestIndicesNOK.TupleLength())==0)).TupleOr(hv_UseOkSamplesOnly)))
  {
    (*hv_AnomalyClassificationThresholds) = (hv_AnomalyScoresOK.TupleMax())*(1+hv_Eps);
  }
  else
  {
    if (0 != hv_EnableDisplay)
    {
      hv_ThresholdInformation.Clear();
      hv_ThresholdInformation[0] = "Computing thresholds.";
      hv_ThresholdInformation[1] = "";
      hv_ThresholdInformation[2] = "This may take some time...";
      hv_ThresholdInformation[3] = "";
      hv_ThresholdInformation[4] = "Compute the anomaly scores";
      hv_ThresholdInformation[5] = "of the nok test samples (3/3)";
      if (HDevWindowStack::IsOpen())
        ClearWindow(HDevWindowStack::GetActive());
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_ThresholdInformation, "window", 
            "top", "left", "black", "box", "false");
    }
    //Compute the anomaly scores of the nok test samples.
    read_dl_samples(hv_DLDataset, hv_TestIndicesNOK, &hv_TestSamplesNOK);
    ApplyDlModel(hv_DLModelHandle, hv_TestSamplesNOK, HTuple(), &hv_TestResultsNOK);
    hv_AnomalyScoresNOK = HTuple(hv_TestResultsNOK.TupleLength(),0.0);
    {
    HTuple end_val202 = (hv_TestResultsNOK.TupleLength())-1;
    HTuple step_val202 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val202, step_val202); hv_Index += step_val202)
    {
      GetDictTuple(HTuple(hv_TestResultsNOK[hv_Index]), "anomaly_score", &hv_AnomalyScore);
      hv_AnomalyScoresNOK[hv_Index] = hv_AnomalyScore;
    }
    }
    //Get minimum and maximum values of the anomaly scores.
    hv_MaxScoreOK = hv_AnomalyScoresOK.TupleMax();
    hv_MinScoreNOK = hv_AnomalyScoresNOK.TupleMin();
    if (0 != (int(hv_MaxScoreOK<=hv_MinScoreNOK)))
    {
      //In this case the ok and nok samples can be perfectly separated
      //by a threshold.
      hv_IntermediateThreshold = (hv_MaxScoreOK+hv_MinScoreNOK)/2;
    }
    else
    {
      //In this case there will be false positives or false negatives
      //for any threshold.
      //
      //Compute the histograms of the ok and nok scores.
      //
      //Sort the anomaly scores.
      hv_AnomalyScores.Clear();
      hv_AnomalyScores.Append(hv_AnomalyScoresOK);
      hv_AnomalyScores.Append(hv_AnomalyScoresNOK);
      hv_AnomalyScoresSortIndices = hv_AnomalyScores.TupleSortIndex();
      hv_AnomalyScoresSorted = HTuple(hv_AnomalyScores[hv_AnomalyScoresSortIndices]);
      //
      //Compute the false positive rates.
      hv_TmpOK.Clear();
      hv_TmpOK.Append(HTuple(hv_AnomalyScoresOK.TupleLength(),1.0));
      hv_TmpOK.Append(HTuple(hv_AnomalyScoresNOK.TupleLength(),0.0));
      hv_TrueNegativesPerScore = HTuple(hv_TmpOK[hv_AnomalyScoresSortIndices]).TupleCumul();
      hv_FPRate = 1.0-(hv_TrueNegativesPerScore/(hv_AnomalyScoresOK.TupleLength()));
      //
      //Compute the false negative rates.
      hv_TmpNOK.Clear();
      hv_TmpNOK.Append(HTuple(hv_AnomalyScoresOK.TupleLength(),0.0));
      hv_TmpNOK.Append(HTuple(hv_AnomalyScoresNOK.TupleLength(),1.0));
      hv_FalseNegativesPerScore = HTuple(hv_TmpNOK[hv_AnomalyScoresSortIndices]).TupleCumul();
      hv_FNRate = hv_FalseNegativesPerScore/(hv_AnomalyScoresNOK.TupleLength());
      //
      //Get the threshold for which the sum of the false positive
      //and false negative rates is the lowest.
      hv_FprFnrSum = hv_FPRate+hv_FNRate;
      hv_MinFprFnRSum = hv_FprFnrSum.TupleMin();
      hv_ThresholdIndex = hv_FprFnrSum.TupleFindFirst(hv_MinFprFnRSum);
      hv_IntermediateThreshold = HTuple(hv_AnomalyScoresSorted[hv_ThresholdIndex]);
      //
      //In some cases IntermediateThreshold may be smaller than MinScoreNOK.
      //We set it to at least that value.
      hv_IntermediateThreshold = hv_IntermediateThreshold.TupleMax2(hv_MinScoreNOK);
      //
    }
    //Set the tuple of anomaly classification thresholds.
    (*hv_AnomalyClassificationThresholds).Clear();
    (*hv_AnomalyClassificationThresholds).Append(hv_MaxScoreOK*(1+hv_Eps));
    (*hv_AnomalyClassificationThresholds).Append(hv_MinScoreNOK);
    (*hv_AnomalyClassificationThresholds).Append(hv_IntermediateThreshold);
  }
  //
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Calculate top-K error. 
void compute_top_k_error_dl_evaluation (HTuple hv_ImageLabelIDs, HTuple hv_TopKPredictions, 
    HTuple hv_K, HTuple *hv_TopKError)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumMatches, hv_Index, hv_Predictions;
  HTuple  hv_PredictedClasses;

  //
  //This procedure calculates the top-K error out of the given predictions and labels.
  //
  hv_NumMatches = 0;
  //
  //Loop through all selected ground truth labels.
  {
  HTuple end_val6 = (hv_ImageLabelIDs.TupleLength())-1;
  HTuple step_val6 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val6, step_val6); hv_Index += step_val6)
  {
    //Get the K best results.
    GetDictTuple(HTuple(hv_TopKPredictions[hv_Index]), "predictions", &hv_Predictions);
    hv_PredictedClasses = hv_Predictions.TupleSelectRange(0,hv_K-1);
    //Count how often the ground truth label
    //and K predicted classes match.
    if (0 != (int((hv_PredictedClasses.TupleFind(HTuple(hv_ImageLabelIDs[hv_Index])))!=-1)))
    {
      hv_NumMatches += 1;
    }
  }
  }
  (*hv_TopKError) = 1.0-((hv_NumMatches.TupleReal())/(hv_ImageLabelIDs.TupleLength()));
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Generate a dictionary EvalParams, which contains default values for evaluation parameters. 
void create_evaluation_default_param (HTuple hv_EvaluationType, HTuple hv_ClassIDsModel, 
    HTuple *hv_EvalParams)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_AvailableEvaluationTypes, hv_EvaluationTypesStr;
  HTuple  hv_Indices, hv_EvaluateInstances, hv_Measures, hv_GrippingPointParams;
  HTuple  hv_AreaRanges, hv_AllocationBlockLength;

  //
  //This procedure generates a dictionary EvalParams,
  //which contains default values for evaluation parameters.
  //Depending on the evaluation type, the corresponding default parameters and values are set.
  //The class IDs that the model can predict must be given via ClassIDsModel.
  //
  //Check inputs.
  hv_AvailableEvaluationTypes.Clear();
  hv_AvailableEvaluationTypes[0] = "3d_gripping_point_detection";
  hv_AvailableEvaluationTypes[1] = "anomaly_detection";
  hv_AvailableEvaluationTypes[2] = "classification";
  hv_AvailableEvaluationTypes[3] = "detection";
  hv_AvailableEvaluationTypes[4] = "gc_anomaly_detection";
  hv_AvailableEvaluationTypes[5] = "ocr_detection";
  hv_AvailableEvaluationTypes[6] = "ocr_recognition";
  hv_AvailableEvaluationTypes[7] = "segmentation";
  TupleGenConst((2*(hv_AvailableEvaluationTypes.TupleLength()))-1, HTuple("','"), 
      &hv_EvaluationTypesStr);
  hv_EvaluationTypesStr[HTuple::TupleGenSequence(0,hv_EvaluationTypesStr.TupleLength(),2)] = hv_AvailableEvaluationTypes;
  hv_EvaluationTypesStr = hv_EvaluationTypesStr.TupleSum();
  TupleFind(hv_AvailableEvaluationTypes, hv_EvaluationType, &hv_Indices);
  if (0 != (HTuple(int(hv_Indices==-1)).TupleOr(int(hv_Indices==HTuple()))))
  {
    throw HException(((("Unknown evaluation_type: "+hv_EvaluationType)+". Choose one of ['")+hv_EvaluationTypesStr)+"']");
  }
  //
  if (0 != (int((hv_ClassIDsModel.TupleLength())<1)))
  {
    if (0 != (int(hv_EvaluationType==HTuple("ocr_detection"))))
    {
      hv_ClassIDsModel = 0;
    }
    else
    {
      throw HException("ClassIDsModel should have at least one entry");
    }
  }
  //
  //Initialize EvalParams.
  CreateDict(&(*hv_EvalParams));
  SetDictTuple((*hv_EvalParams), "evaluation_type", hv_EvaluationType);
  //
  //Set the class IDs.
  SetDictTuple((*hv_EvalParams), "class_ids", hv_ClassIDsModel);
  SetDictTuple((*hv_EvalParams), "num_classes", hv_ClassIDsModel.TupleLength());
  //
  //Set specific parameters depending on the evaluation type.
  hv_EvaluateInstances = 0;
  if (0 != (int(hv_EvaluationType==HTuple("3d_gripping_point_detection"))))
  {
    //
    //Set default 3D Gripping Point Detection measures.
    hv_Measures.Clear();
    hv_Measures[0] = "mean_pro";
    hv_Measures[1] = "mean_precision";
    hv_Measures[2] = "mean_iou";
    //
    //There are no ignored classes for this model type.
    SetDictTuple((*hv_EvalParams), "ignore_class_ids", HTuple());
    //
    //Set default 3D gripping point generation parameters.
    CreateDict(&hv_GrippingPointParams);
    check_dl_3d_gripping_points_and_poses_params(hv_GrippingPointParams);
    SetDictTuple((*hv_EvalParams), "gripping_point_params", hv_GrippingPointParams);
  }
  else if (0 != (HTuple(int(hv_EvaluationType==HTuple("anomaly_detection"))).TupleOr(int(hv_EvaluationType==HTuple("gc_anomaly_detection")))))
  {
    //
    //Set default image level measures.
    hv_Measures = "anomaly_score_histogram";
  }
  else if (0 != (int(hv_EvaluationType==HTuple("classification"))))
  {
    //
    //Set default classification measures.
    hv_Measures = "top1_error";
    //
    //Per default all classes are used for evaluation.
    SetDictTuple((*hv_EvalParams), "class_ids_to_evaluate", "global");
  }
  else if (0 != (int(hv_EvaluationType==HTuple("detection"))))
  {
    //
    //Set default detection measures.
    hv_Measures = "mean_ap";
    //
    //Set detection-specific default values.
    hv_EvaluateInstances = 1;
    SetDictTuple((*hv_EvalParams), "instance_type", "rectangle1");
    //Generate ten IoU-thresholds from 0.5 to 0.95 in steps of 0.05.
    SetDictTuple((*hv_EvalParams), "iou_threshold", HTuple::TupleGenSequence(0.5,0.96,0.05));
    //Set maximal number of detections to -1, i.e. all results per image will be evaluated.
    SetDictTuple((*hv_EvalParams), "max_num_detections", -1);
    //Set default area range named 'all', thus areas from 0 to a value larger than all likely occurring values.
    CreateDict(&hv_AreaRanges);
    SetDictTuple(hv_AreaRanges, "name", "all");
    SetDictTuple(hv_AreaRanges, "min", 0);
    SetDictTuple(hv_AreaRanges, "max", 2e8);
    SetDictTuple((*hv_EvalParams), "area_ranges", hv_AreaRanges);
    //Some tuples are changing their length during the evaluation. As this slows down the
    //evaluation process they are allocated in blocks of AllocationBlockLength.
    hv_AllocationBlockLength = 200;
    SetDictTuple((*hv_EvalParams), "allocation_block_length", hv_AllocationBlockLength);
    //Detailed evaluation is not switched on per default, as it slows down the evaluation-process.
    SetDictTuple((*hv_EvalParams), "detailed_evaluation", 0);
    //Interpolate the precision-recall curves per default.
    SetDictTuple((*hv_EvalParams), "interpolate_pr_curves", 1);
  }
  else if (0 != (int(hv_EvaluationType==HTuple("segmentation"))))
  {
    //
    //Set default pixel measures.
    hv_Measures.Clear();
    hv_Measures[0] = "pixel_accuracy";
    hv_Measures[1] = "mean_accuracy";
    hv_Measures[2] = "mean_iou";
    //
    //Per default there are no ignored classes.
    SetDictTuple((*hv_EvalParams), "ignore_class_ids", HTuple());
  }
  else if (0 != (int(hv_EvaluationType==HTuple("ocr_recognition"))))
  {
    //
    //Set default OCR recognition measures
    hv_Measures = "accuracy";
  }
  else if (0 != (int(hv_EvaluationType==HTuple("ocr_detection"))))
  {
    //
    //Set default ocr_detection measures.
    hv_Measures = "f_score";
    SetDictTuple((*hv_EvalParams), "detailed_evaluation", 1);
    SetDictTuple((*hv_EvalParams), "iou_threshold", 0.5);
    SetDictTuple((*hv_EvalParams), "max_num_detections", -1);
    SetDictTuple((*hv_EvalParams), "instance_type", "rectangle2");
    SetDictTuple((*hv_EvalParams), "allocation_block_length", 100);
    //
    //Configure area constraints.
    CreateDict(&hv_AreaRanges);
    SetDictTuple(hv_AreaRanges, "name", "all");
    SetDictTuple(hv_AreaRanges, "min", 0);
    SetDictTuple(hv_AreaRanges, "max", HTuple::TupleConstant("H_INT_MAX"));
    SetDictTuple((*hv_EvalParams), "area_ranges", hv_AreaRanges);
  }
  //
  SetDictTuple((*hv_EvalParams), "evaluate_instances", hv_EvaluateInstances);
  SetDictTuple((*hv_EvalParams), "measures", hv_Measures);
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Evaluate the model given by DLModelHandle on the selected samples of DLDataset. 
void evaluate_dl_model (HTuple hv_DLDataset, HTuple hv_DLModelHandle, HTuple hv_SampleSelectMethod, 
    HTuple hv_SampleSelectValues, HTuple hv_GenParam, HTuple *hv_EvaluationResult, 
    HTuple *hv_EvalParams)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ModelType, hv_ClassIDs, hv_ClassNames;
  HTuple  hv_Alphabet, hv_BatchSize, hv_InstanceTypeModel;
  HTuple  hv_Exception, hv_IsInstanceSegmentation, hv_InstanceType;
  HTuple  hv_ModelIgnoreClassIDs, hv_ShowProgress, hv_GenParamKeys;
  HTuple  hv_OptionalKeyNames, hv_GenParamIndex, hv_IoUThreshold;
  HTuple  hv_MaxNumDetections, hv_AreaRanges, hv_DetailedEvaluation;
  HTuple  hv_AllocationBlockLength, hv_IgnoreClassIDs, hv_AllIgnoreClassIDs;
  HTuple  hv_EvaluateClassIDs, hv_ClassesToEvaluate, hv_KeyExists;
  HTuple  hv_ClassIDsToEvaluate, hv_AnomalyClassificationThresholds;
  HTuple  hv_EvaluateMask, hv_Value, hv_Measures, hv_IgnoreDirection;
  HTuple  hv_ClassInfoExists, hv_DatasetClassIDs, hv_ClassIDsToClassNames;
  HTuple  hv_EvaluateClassNames, hv_DLSamples, hv_SampleIndices;
  HTuple  hv_NumSamples, hv_NumBatches, hv_RunningMeasures;
  HTuple  hv_Outputs, hv_EvalGCAnomalyNetworks, hv_ModelGCAnomalyNetworks;
  HTuple  hv_DefaultRequested, hv_EvalAnomalyNetworkIndex;
  HTuple  hv_EvalGCAnomalyNetwork, hv_FindIndex, hv_Progress;
  HTuple  hv_TaskInfo, hv_SecondsStart, hv_BatchIndex, hv_BatchStart;
  HTuple  hv_BatchEnd, hv_SamplesIndicesBatch, hv_DLSamplesBatch;
  HTuple  hv_DLResultsBatch, hv_SecondsElapsed, hv_SecondsRemaining;
  HTuple  hv_ProgressPercent, hv_ProgressPerSecond, hv_TimeElapsedString;
  HTuple  hv_TimeRemainingString;

  //This procedure applies the model given by DLModelHandle on the selected samples
  //of DLDataset and evaluates the results against the ground truth annotations
  //to calculate evaluation measures.
  //
  //Input:
  // - DLDataset.
  // - DLModelHandle.
  // - SampleSelectMethod: Method by which the samples are selected.
  // - SampleSelectValues: Identifier used to retrieve the samples from the DLDataset
  //                       for the corresponding selection method.
  // - GenParam: Parameters of the evaluation that should be changed from the default.
  //
  //Output:
  // - EvaluationResult: Dictionary containing the output measures.
  // - EvalParams: Dictionary with the used evaluation parameters.
  //
  //** Initialization: ***
  //
  GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
  if (0 != (HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(int(hv_ModelType!=HTuple("3d_gripping_point_detection"))).TupleAnd(int(hv_ModelType!=HTuple("anomaly_detection")))).TupleAnd(int(hv_ModelType!=HTuple("classification")))).TupleAnd(int(hv_ModelType!=HTuple("detection")))).TupleAnd(int(hv_ModelType!=HTuple("gc_anomaly_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_recognition")))).TupleAnd(int(hv_ModelType!=HTuple("segmentation")))))
  {
    throw HException(("Current model type is not supported: \""+hv_ModelType)+"\"");
  }
  //
  //Check if model has been normalized, if required by model type.
  if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
  {
    check_dl_gc_anomaly_scores_normalization(hv_DLModelHandle, HTuple());
  }
  //
  //Get the class IDs as set in the model.
  if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
  {
    //Only the gripping_map class is evaluated.
    GetDlModelParam(hv_DLModelHandle, "class_ids", &hv_ClassIDs);
    GetDlModelParam(hv_DLModelHandle, "class_names", &hv_ClassNames);
    hv_ClassIDs = HTuple(hv_ClassIDs[hv_ClassNames.TupleFind("gripping_map")]);
  }
  else if (0 != (HTuple(int(hv_ModelType==HTuple("anomaly_detection"))).TupleOr(int(hv_ModelType==HTuple("gc_anomaly_detection")))))
  {
    //Default for anomaly detection and Global Context Anomaly Detection is 0,1.
    hv_ClassIDs.Clear();
    hv_ClassIDs[0] = 0;
    hv_ClassIDs[1] = 1;
  }
  else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
  {
    //No Class IDs in case of ocr_recognition models
    GetDlModelParam(hv_DLModelHandle, "alphabet", &hv_Alphabet);
    TupleGenSequence(0, hv_Alphabet.TupleLength(), 1, &hv_ClassIDs);
  }
  else if (0 != (int(hv_ModelType==HTuple("ocr_detection"))))
  {
    //Default for ocr_detection. Only evaluate word.
    //0: word, 1: char, 2: ignore
    hv_ClassIDs = 0;
  }
  else
  {
    GetDlModelParam(hv_DLModelHandle, "class_ids", &hv_ClassIDs);
  }
  //
  //Get the batch size as set in the model.
  GetDlModelParam(hv_DLModelHandle, "batch_size", &hv_BatchSize);
  //
  //Generate default parameters.
  create_evaluation_default_param(hv_ModelType, hv_ClassIDs, &(*hv_EvalParams));
  //
  //Get model specific information.
  if (0 != (int(hv_ModelType==HTuple("detection"))))
  {
    try
    {
      GetDlModelParam(hv_DLModelHandle, "instance_type", &hv_InstanceTypeModel);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      hv_InstanceTypeModel = "rectangle1";
    }
    GetDlModelParam(hv_DLModelHandle, "instance_segmentation", &hv_IsInstanceSegmentation);
    if (0 != (int(hv_IsInstanceSegmentation==HTuple("true"))))
    {
      hv_InstanceType = "mask";
    }
    else
    {
      hv_InstanceType = hv_InstanceTypeModel;
    }
    //Note, these are the defaults. If the user specifies
    //'evaluate_mask' as false, the evaluation will use
    //the instance type of the model (InstanceTypeModel).
  }
  else if (0 != (int(hv_ModelType==HTuple("segmentation"))))
  {
    GetDlModelParam(hv_DLModelHandle, "ignore_class_ids", &hv_ModelIgnoreClassIDs);
  }
  //
  //By default we do not show the progress of evaluation.
  hv_ShowProgress = 0;
  //
  //Set user specified parameters.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenParamKeys);
    hv_OptionalKeyNames.Clear();
    hv_OptionalKeyNames[0] = "measures";
    hv_OptionalKeyNames[1] = "evaluation_type";
    hv_OptionalKeyNames[2] = "class_ids";
    hv_OptionalKeyNames[3] = "num_classes";
    hv_OptionalKeyNames[4] = "evaluate_instances";
    hv_OptionalKeyNames[5] = "gc_anomaly_networks";
    hv_OptionalKeyNames[6] = "gripping_point_params";
    {
    HTuple end_val82 = (hv_GenParamKeys.TupleLength())-1;
    HTuple step_val82 = 1;
    for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val82, step_val82); hv_GenParamIndex += step_val82)
    {
      if (0 != (int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("show_progress"))))
      {
        //Show the progress of the evaluation.
        GetDictTuple(hv_GenParam, "show_progress", &hv_ShowProgress);
        hv_ShowProgress = HTuple(int(hv_ShowProgress==HTuple("true"))).TupleOr(int(hv_ShowProgress==1));
      }
      else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("iou_threshold"))).TupleAnd(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_detection"))))))
      {
        //Set IoU threshold.
        GetDictTuple(hv_GenParam, "iou_threshold", &hv_IoUThreshold);
        SetDictTuple((*hv_EvalParams), "iou_threshold", hv_IoUThreshold);
      }
      else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("max_num_detections"))).TupleAnd(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_detection"))))))
      {
        //Set maximal number detections.
        GetDictTuple(hv_GenParam, "max_num_detections", &hv_MaxNumDetections);
        SetDictTuple((*hv_EvalParams), "max_num_detections", hv_MaxNumDetections);
      }
      else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("area_ranges"))).TupleAnd(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_detection"))))))
      {
        //Set area ranges.
        GetDictTuple(hv_GenParam, "area_ranges", &hv_AreaRanges);
        SetDictTuple((*hv_EvalParams), "area_ranges", hv_AreaRanges);
      }
      else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("detailed_evaluation"))).TupleAnd(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_detection"))))))
      {
        //Set detailed evaluation.
        GetDictTuple(hv_GenParam, "detailed_evaluation", &hv_DetailedEvaluation);
        SetDictTuple((*hv_EvalParams), "detailed_evaluation", hv_DetailedEvaluation);
      }
      else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("allocation_block_length"))).TupleAnd(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_detection"))))))
      {
        //Set length of blocks that are allocated during evaluation.
        GetDictTuple(hv_GenParam, "allocation_block_length", &hv_AllocationBlockLength);
        SetDictTuple((*hv_EvalParams), "allocation_block_length", hv_AllocationBlockLength);
      }
      else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("interpolate_pr_curves"))).TupleAnd(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_detection"))))))
      {
        //Set interpolation of precision-recall curves.
        GetDictTuple(hv_GenParam, "interpolate_pr_curves", &hv_DetailedEvaluation);
        SetDictTuple((*hv_EvalParams), "interpolate_pr_curves", hv_DetailedEvaluation);
      }
      else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("ignore_class_ids"))).TupleAnd(int(hv_ModelType==HTuple("segmentation")))))
      {
        //Set ignore class IDs.
        GetDictTuple(hv_GenParam, "ignore_class_ids", &hv_IgnoreClassIDs);
        //Merge the specified ignore class IDs with the model ignore class IDs.
        hv_AllIgnoreClassIDs = ((hv_ModelIgnoreClassIDs.TupleConcat(hv_IgnoreClassIDs)).TupleSort()).TupleUniq();
        SetDictTuple((*hv_EvalParams), "ignore_class_ids", hv_AllIgnoreClassIDs);
        //Remove the ignore class IDs from the model class IDs.
        TupleDifference(hv_ClassIDs, hv_IgnoreClassIDs, &hv_EvaluateClassIDs);
        SetDictTuple((*hv_EvalParams), "class_ids", hv_EvaluateClassIDs);
        SetDictTuple((*hv_EvalParams), "num_classes", hv_EvaluateClassIDs.TupleLength());
      }
      else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("class_names_to_evaluate"))).TupleAnd(int(hv_ModelType==HTuple("classification")))))
      {
        //Class names to be used in evaluation.
        //To transform the names to IDs later, one has to remember the class names.
        GetDictTuple(hv_GenParam, "class_names_to_evaluate", &hv_ClassesToEvaluate);
        GetDlModelParam(hv_DLModelHandle, "class_names", &hv_ClassNames);
        SetDictTuple((*hv_EvalParams), "class_names_to_evaluate", hv_ClassesToEvaluate);
        SetDictTuple((*hv_EvalParams), "class_names", hv_ClassNames);
        GetDictParam((*hv_EvalParams), "key_exists", "class_ids_to_evaluate", &hv_KeyExists);
        if (0 != hv_KeyExists)
        {
          //To avoid inconsistent class names/IDs, remove the older ones.
          RemoveDictKey((*hv_EvalParams), "class_ids_to_evaluate");
        }
      }
      else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("class_ids_to_evaluate"))).TupleAnd(int(hv_ModelType==HTuple("classification")))))
      {
        //Class IDs to be used in evaluation.
        GetDictTuple(hv_GenParam, "class_ids_to_evaluate", &hv_ClassIDsToEvaluate);
        SetDictTuple((*hv_EvalParams), "class_ids_to_evaluate", hv_ClassIDsToEvaluate);
        GetDictParam((*hv_EvalParams), "key_exists", "class_names_to_evaluate", &hv_KeyExists);
        if (0 != hv_KeyExists)
        {
          //To avoid inconsistent class names/IDs, remove the older ones.
          RemoveDictKey((*hv_EvalParams), "class_names_to_evaluate");
        }
      }
      else if (0 != (int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("anomaly_classification_thresholds"))))
      {
        //Set anomaly classification threshold for confusion matrices.
        GetDictTuple(hv_GenParam, "anomaly_classification_thresholds", &hv_AnomalyClassificationThresholds);
        SetDictTuple((*hv_EvalParams), "anomaly_classification_thresholds", hv_AnomalyClassificationThresholds);
      }
      else if (0 != (int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("evaluate_mask"))))
      {
        GetDictTuple(hv_GenParam, "evaluate_mask", &hv_EvaluateMask);
        if (0 != (hv_EvaluateMask.TupleNot()))
        {
          hv_InstanceType = hv_InstanceTypeModel;
        }
      }
      else if (0 != (int((hv_OptionalKeyNames.TupleFind(HTuple(hv_GenParamKeys[hv_GenParamIndex])))!=-1)))
      {
        GetDictTuple(hv_GenParam, HTuple(hv_GenParamKeys[hv_GenParamIndex]), &hv_Value);
        SetDictTuple((*hv_EvalParams), HTuple(hv_GenParamKeys[hv_GenParamIndex]), 
            hv_Value);
      }
      else
      {
        throw HException(("Unknown parameter : '"+HTuple(hv_GenParamKeys[hv_GenParamIndex]))+"'");
      }
    }
    }
  }
  //
  //Finally specify the detection evaluation based on all given parameters and defaults.
  if (0 != (int(hv_ModelType==HTuple("detection"))))
  {
    if (0 != (int(hv_InstanceType==HTuple("mask"))))
    {
      SetDictTuple((*hv_EvalParams), "evaluate_mask", 1);
      GetDictTuple((*hv_EvalParams), "measures", &hv_Measures);
      SetDictTuple((*hv_EvalParams), "measures", hv_Measures.TupleDifference("soap"));
    }
    else
    {
      SetDictTuple((*hv_EvalParams), "evaluate_mask", 0);
    }
    //Overwrite instance_type
    SetDictTuple((*hv_EvalParams), "instance_type", hv_InstanceType);
    //For rectangle2 detection with ignore_direction set to false, we also evaluate the
    //precision of the predicted angle using the Score of Angle Precision (SoAP).
    if (0 != (int(hv_InstanceType==HTuple("rectangle2"))))
    {
      GetDlModelParam(hv_DLModelHandle, "ignore_direction", &hv_IgnoreDirection);
      if (0 != (int(hv_IgnoreDirection==HTuple("false"))))
      {
        GetDictTuple((*hv_EvalParams), "measures", &hv_Measures);
        SetDictTuple((*hv_EvalParams), "measures", hv_Measures.TupleConcat("soap"));
      }
    }
  }
  //
  //Set class names.
  if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
  {
    SetDictTuple((*hv_EvalParams), "class_names", "gripping_map");
  }
  else
  {
    //Get the class names from the dataset if present.
    GetDictParam(hv_DLDataset, "key_exists", (HTuple("class_names").Append("class_ids")), 
        &hv_ClassInfoExists);
    if (0 != (int((hv_ClassInfoExists.TupleSum())==(hv_ClassInfoExists.TupleLength()))))
    {
      GetDictTuple(hv_DLDataset, "class_names", &hv_ClassNames);
      GetDictTuple(hv_DLDataset, "class_ids", &hv_DatasetClassIDs);
      //Set the class names only for the class IDs that are evaluated.
      GetDictTuple((*hv_EvalParams), "class_ids", &hv_EvaluateClassIDs);
      hv_ClassIDsToClassNames = HTuple((hv_DatasetClassIDs.TupleMax())+1,"");
      hv_ClassIDsToClassNames[hv_DatasetClassIDs] = hv_ClassNames;
      if (0 != (int((hv_EvaluateClassIDs.TupleLength())==(hv_ClassNames.TupleLength()))))
      {
        hv_EvaluateClassNames = HTuple(hv_ClassIDsToClassNames[hv_EvaluateClassIDs]);
        //Set the class names to EvalParams.
        SetDictTuple((*hv_EvalParams), "class_names", hv_EvaluateClassNames);
      }
    }
  }
  //
  //Get indices of samples to read from the dataset.
  GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
  //
  //Check if there are samples present in the dataset.
  if (0 != (int((hv_DLSamples.TupleLength())==0)))
  {
    throw HException("The provided set of samples in the dataset must be non-empty.");
  }
  //
  //Check for empty SampleSelectValues.
  if (0 != (int((hv_SampleSelectValues.TupleLength())==0)))
  {
    if (0 != (int(hv_SampleSelectMethod==HTuple("image_ids"))))
    {
      throw HException("The provided set of samples of the 'image_ids' selection must be non-empty.");
    }
    else if (0 != (int(hv_SampleSelectMethod==HTuple("sample_indices"))))
    {
      throw HException("The provided set of samples of the 'sample_indices' selection must be non-empty.");
    }
    else
    {
      throw HException("Provide a name for 'split' selection.");
    }
  }
  //
  //
  //Get the sample indices according to the sample selection method.
  hv_SampleIndices = HTuple();
  if (0 != (int(hv_SampleSelectMethod==HTuple("split"))))
  {
    //Get the samples of the split specified.
    find_dl_samples(hv_DLSamples, "split", hv_SampleSelectValues, "or", &hv_SampleIndices);
  }
  else if (0 != (int(hv_SampleSelectMethod==HTuple("image_ids"))))
  {
    //Get the samples specified by 'image_ids'.
    if (0 != (int((hv_SampleSelectValues.TupleLength())>(hv_DLSamples.TupleLength()))))
    {
      throw HException("The number of the image ids provided through 'image_id' is invalid.");
    }
    find_dl_samples(hv_DLSamples, "image_id", hv_SampleSelectValues, "or", &hv_SampleIndices);
  }
  else if (0 != (int(hv_SampleSelectMethod==HTuple("sample_indices"))))
  {
    //Get the samples specified by 'sample_indices'.
    if (0 != (HTuple(int((hv_SampleSelectValues.TupleMin())<0)).TupleOr(int((hv_SampleSelectValues.TupleMax())>((hv_DLSamples.TupleLength())-1)))))
    {
      throw HException("The range of the indices provided through 'sample_indices' is invalid.");
    }
    hv_SampleIndices = hv_SampleSelectValues;
  }
  else
  {
    throw HException(("Unknown sample selection method : '"+hv_SampleSelectMethod)+"'");
  }
  //
  //Get the number of batches.
  hv_NumSamples = hv_SampleIndices.TupleLength();
  hv_NumBatches = ((hv_NumSamples/(hv_BatchSize.TupleReal())).TupleCeil()).TupleInt();
  //
  //Check for empty samples selected by the selection method.
  if (0 != (int(hv_NumSamples==0)))
  {
    throw HException(("No samples present in the dataset that are part of the '"+hv_SampleSelectMethod)+"' selection.");
  }
  //
  //
  //** Running measures are initialized according to evaluation method.
  //
  init_running_evaluation_measures((*hv_EvalParams), &hv_RunningMeasures);
  //
  //
  //** Apply model to each image and gather evaluation information: ***
  //
  //Use alternative outputs if requested.
  hv_Outputs = HTuple();
  //
  if (0 != (HTuple(int(hv_ModelType==HTuple("gc_anomaly_detection"))).TupleAnd(int(hv_GenParam!=HTuple()))))
  {
    //
    GetDictParam(hv_GenParam, "key_exists", "gc_anomaly_networks", &hv_KeyExists);
    if (0 != hv_KeyExists)
    {
      GetDictTuple(hv_GenParam, "gc_anomaly_networks", &hv_EvalGCAnomalyNetworks);
      hv_EvalGCAnomalyNetworks = hv_EvalGCAnomalyNetworks.TupleSort();
      GetDlModelParam(hv_DLModelHandle, "gc_anomaly_networks", &hv_ModelGCAnomalyNetworks);
      hv_ModelGCAnomalyNetworks = hv_ModelGCAnomalyNetworks.TupleSort();
      //
      hv_DefaultRequested = HTuple(int((hv_EvalGCAnomalyNetworks.TupleLength())==0)).TupleOr(int(hv_EvalGCAnomalyNetworks==hv_ModelGCAnomalyNetworks));
      {
      HTuple end_val274 = (hv_EvalGCAnomalyNetworks.TupleLength())-1;
      HTuple step_val274 = 1;
      for (hv_EvalAnomalyNetworkIndex=0; hv_EvalAnomalyNetworkIndex.Continue(end_val274, step_val274); hv_EvalAnomalyNetworkIndex += step_val274)
      {
        hv_EvalGCAnomalyNetwork = HTuple(hv_EvalGCAnomalyNetworks[hv_EvalAnomalyNetworkIndex]);
        hv_FindIndex = hv_ModelGCAnomalyNetworks.TupleFind(hv_EvalGCAnomalyNetwork);
        if (0 != (HTuple(int(hv_FindIndex==HTuple())).TupleOr(int(hv_FindIndex==-1))))
        {
          throw HException(("Invalid 'gc_anomaly_networks' requested. Model does not contain a "+hv_EvalGCAnomalyNetwork)+" network.");
        }
        if (0 != (hv_DefaultRequested.TupleNot()))
        {
          hv_Outputs = hv_Outputs.TupleConcat("anomaly_image_"+hv_EvalGCAnomalyNetwork);
        }
      }
      }
    }
  }
  //
  //Initialize progress variables.
  if (0 != hv_ShowProgress)
  {
    hv_Progress.Clear();
    hv_Progress[0] = "Procedure: evaluate_dl_model";
    hv_Progress[1] = "";
    hv_Progress[2] = "";
    hv_Progress[3] = "";
    if (0 != (int(hv_ModelType==HTuple("detection"))))
    {
      hv_TaskInfo = "Task: 1/2: Applying the model and collecting running evaluation measures";
      hv_Progress = hv_Progress.TupleConcat(hv_TaskInfo);
    }
    CountSeconds(&hv_SecondsStart);
    // dev_inspect_ctrl(...); only in hdevelop
  }
  //
  //Loop batchwise over the samples to be evaluated.
  {
  HTuple end_val299 = hv_NumBatches-1;
  HTuple step_val299 = 1;
  for (hv_BatchIndex=0; hv_BatchIndex.Continue(end_val299, step_val299); hv_BatchIndex += step_val299)
  {
    hv_BatchStart = hv_BatchIndex*hv_BatchSize;
    hv_BatchEnd = ((hv_BatchStart+hv_BatchSize)-1).TupleMin2(hv_NumSamples-1);
    hv_SamplesIndicesBatch = hv_SampleIndices.TupleSelectRange(hv_BatchStart,hv_BatchEnd);
    //
    //Read samples
    read_dl_samples(hv_DLDataset, hv_SamplesIndicesBatch, &hv_DLSamplesBatch);
    //
    //Apply the model.
    ApplyDlModel(hv_DLModelHandle, hv_DLSamplesBatch, hv_Outputs, &hv_DLResultsBatch);
    //
    //Update the running measures.
    update_running_evaluation_measures(hv_DLSamplesBatch, hv_DLResultsBatch, (*hv_EvalParams), 
        hv_RunningMeasures);
    //
    //Provide progress information.
    if (0 != hv_ShowProgress)
    {
      if (0 != (HTuple(int((hv_BatchIndex%10)==1)).TupleOr(int(hv_BatchIndex==(hv_NumBatches-1)))))
      {
        estimate_progress(hv_SecondsStart, 0, hv_BatchIndex, hv_NumBatches-1, &hv_SecondsElapsed, 
            &hv_SecondsRemaining, &hv_ProgressPercent, &hv_ProgressPerSecond);
        timespan_string(hv_SecondsElapsed, "auto", &hv_TimeElapsedString);
        timespan_string(hv_SecondsRemaining, "top2", &hv_TimeRemainingString);
        hv_Progress[1] = ("Progress: "+(hv_ProgressPercent.TupleRound()))+" %";
        hv_Progress[2] = "Time elapsed: "+hv_TimeElapsedString;
        hv_Progress[3] = "Time left: "+hv_TimeRemainingString;
      }
    }
  }
  }
  //
  //Provide progress information.
  if (0 != (hv_ShowProgress.TupleAnd(int(hv_ModelType==HTuple("detection")))))
  {
    hv_Progress.Clear();
    hv_Progress[0] = "Procedure: evaluate_dl_model";
    hv_Progress[1] = "";
    hv_Progress[2] = "";
    hv_Progress[1] = "Please wait...";
    hv_Progress[2] = "Task: 2/2: Calculating final evaluation measures";
  }
  //
  //
  //** Do the actual calculation of measures: ***
  //
  calculate_evaluation_measures(hv_RunningMeasures, (*hv_EvalParams), &(*hv_EvaluationResult));
  //
  //Close progress inspect.
  if (0 != hv_ShowProgress)
  {
    hv_Progress = "Done.";
    // dev_close_inspect_ctrl(...); only in hdevelop
  }
  //
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Return the confidence based heatmap of a deep learning classification in DLResult. 
void gen_dl_model_classification_heatmap (HTuple hv_DLModelHandle, HTuple hv_DLSample, 
    HTuple hv_DLResult, HTuple hv_GenParam)
{

  // Local iconic variables
  HObject  ho_Image, ho_KeyValueObject, ho_Partition;
  HObject  ho_RegionGrid, ho_OccludedRegions, ho_ImageR, ho_ImageG;
  HObject  ho_ImageB, ho_ImagesOccluded, ho_OccludedRegion;
  HObject  ho_ImageOccluded, ho_HeatmapRegions, ho_PartsSelected;
  HObject  ho_HeatmapRegion, ho_HeatmapRegionsNegative, ho_HeatmapRegionNegative;
  HObject  ho_BinRegion, ho_Heatmap;

  // Local control variables
  HTuple  hv_FeatureSize, hv_SamplingSize, hv_TargetClassID;
  HTuple  hv_GenParamKeys, hv_Keys, hv_KeyIndex, hv_IsInteger;
  HTuple  hv_NumInputChannels, hv_NumImageChannels, hv_ConfidenceValuesExist;
  HTuple  hv_DLResultTmp, hv_DLResultKeys, hv_KeyValueTuple;
  HTuple  hv_Exception, hv_SampleClassIds, hv_TargetClassIDIndex;
  HTuple  hv_SampleClassNames, hv_TargetClassName, hv_SampleConfidences;
  HTuple  hv_TargetConfidence, hv_ClipRegionSettingBefore;
  HTuple  hv_HeightRegion, hv_WidthRegion, hv_RatioRegion;
  HTuple  hv_SamplingSizeUsed, hv_Width, hv_Height, hv_CenterRows;
  HTuple  hv_CenterColumns, hv_NumRegions, hv_Confidences;
  HTuple  hv_MeanGray, hv_DeviationGray, hv_MeanRed, hv_DeviationRed;
  HTuple  hv_MeanGreen, hv_DeviationGreen, hv_MeanBlue, hv_DeviationBlue;
  HTuple  hv_BatchSize, hv_BatchIndex, hv_BatchIndices, hv_Index;
  HTuple  hv_Mean, hv_NumImagesOccluded, hv_DLSampleImagesOccluded;
  HTuple  hv_DLResultImagesOccluded, hv_IndexOccluded, hv_OccSampleClassIDs;
  HTuple  hv_OccSampleConfidences, hv_Area, hv_AveragingCenterRows;
  HTuple  hv_AveragingCenterColumns, hv_PartitionConfidences;
  HTuple  hv_PartIndex, hv_ConfidenceIndices, hv_ConfidenceDeviations;
  HTuple  hv_MaxDeviation, hv_NumBins, hv_Step, hv_End, hv_Factor;
  HTuple  hv_Lesser, hv_Greater, hv_IndicesInBin, hv_WidthImage;
  HTuple  hv_HeightImage, hv_WindowHandleTmp, hv_Colors, hv_BinIndex;
  HTuple  hv_ActualColor, hv_HeatmapParameters, hv_HeatmapResult;
  HTuple  hv_HeatmapImageName;

  //
  //This procedure generates a heatmap for an image which is classified
  //with the deep learning model DLModelHandle. The generated heatmap is
  //returned in DLResult and can be displayed in the procedure
  //dev_display_dl_data afterwards.
  //The procedure can be adjusted with generic parameters using
  //the dict GenParam.
  //The calculation of this heatmap bases on the confidence value differences.
  //
  //Please note that the heatmap is intended for visual inspection.
  //Therefore, the resulting regions and confidence values are not
  //returned.
  //
  //Set default parameters.
  hv_FeatureSize = 30;
  hv_SamplingSize = 7;
  hv_TargetClassID = HTuple();
  //
  //Set user specific parameters.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    hv_GenParamKeys.Clear();
    hv_GenParamKeys[0] = "feature_size";
    hv_GenParamKeys[1] = "sampling_size";
    hv_GenParamKeys[2] = "target_class_id";
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_Keys);
    {
    HTuple end_val22 = (hv_Keys.TupleLength())-1;
    HTuple step_val22 = 1;
    for (hv_KeyIndex=0; hv_KeyIndex.Continue(end_val22, step_val22); hv_KeyIndex += step_val22)
    {
      //Check the key is allowed.
      if (0 != (int((hv_GenParamKeys.TupleFind(HTuple(hv_Keys[hv_KeyIndex])))==-1)))
      {
        throw HException(("Invalid GenParam key '"+HTuple(hv_Keys[hv_KeyIndex]))+"'");
        //Retrieve the set value.
      }
      else if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("feature_size"))))
      {
        //Set feature size.
        GetDictTuple(hv_GenParam, "feature_size", &hv_FeatureSize);
      }
      else if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("sampling_size"))))
      {
        //Set sampling size.
        GetDictTuple(hv_GenParam, "sampling_size", &hv_SamplingSize);
      }
      else if (0 != (int(HTuple(hv_Keys[hv_KeyIndex])==HTuple("target_class_id"))))
      {
        //Set target class ID.
        GetDictTuple(hv_GenParam, "target_class_id", &hv_TargetClassID);
        if (0 != (int(hv_TargetClassID!=HTuple())))
        {
          //Check if target class ID is an integer.
          TupleIsInt(hv_TargetClassID, &hv_IsInteger);
          if (0 != (hv_IsInteger.TupleNot()))
          {
            throw HException("The \"target_class_id\" must be an integer.");
          }
        }
      }
    }
    }
  }
  //
  //Check the input parameters.
  if (0 != (int((hv_DLSample.TupleLength())!=1)))
  {
    throw HException("Please use only a single sample dictionary as input.");
  }
  if (0 != (int(hv_SamplingSize<1)))
  {
    throw HException(("The \"sampling_size\" ("+hv_SamplingSize)+") must be greater than zero.");
  }
  if (0 != (int(hv_FeatureSize<1)))
  {
    throw HException(("The \"feature_size\" ("+hv_FeatureSize)+") must be greater than zero.");
  }
  if (0 != (int(hv_SamplingSize>=hv_FeatureSize)))
  {
    throw HException(((("The \"sampling_size\" ("+hv_SamplingSize)+") must be smaller than the \"feature_size\" (")+hv_FeatureSize)+")");
  }
  GetDlModelParam(hv_DLModelHandle, "image_num_channels", &hv_NumInputChannels);
  GetDictObject(&ho_Image, hv_DLSample, "image");
  CountChannels(ho_Image, &hv_NumImageChannels);
  if (0 != (int(hv_NumImageChannels!=hv_NumInputChannels)))
  {
    throw HException((((("The number of image channels ("+hv_NumImageChannels)+") does not match ")+"the number of input channels expected by the classifier (")+hv_NumInputChannels)+")");
  }
  dev_update_off();
  //
  //Check if the result dictionary contains confidence values.
  //In case it does not, an additional inference step is needed.
  //Else we can skip this step and directly read out the values.
  GetDictParam(hv_DLResult, "key_exists", "confidences", &hv_ConfidenceValuesExist);
  if (0 != (hv_ConfidenceValuesExist.TupleNot()))
  {
    ApplyDlModel(hv_DLModelHandle, hv_DLSample, HTuple(), &hv_DLResultTmp);
    GetDictParam(hv_DLResultTmp, "keys", HTuple(), &hv_DLResultKeys);
    //The operator apply_dl_model creates a new result dictionary.
    //The results need to be copied in order to have them in the procedure parameter dictionary.
    {
    HTuple end_val77 = (hv_DLResultKeys.TupleLength())-1;
    HTuple step_val77 = 1;
    for (hv_KeyIndex=0; hv_KeyIndex.Continue(end_val77, step_val77); hv_KeyIndex += step_val77)
    {
      try
      {
        GetDictTuple(hv_DLResultTmp, HTuple(hv_DLResultKeys[hv_KeyIndex]), &hv_KeyValueTuple);
        SetDictTuple(hv_DLResult, HTuple(hv_DLResultKeys[hv_KeyIndex]), hv_KeyValueTuple);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        GetDictObject(&ho_KeyValueObject, hv_DLResultTmp, HTuple(hv_DLResultKeys[hv_KeyIndex]));
        SetDictObject(ho_KeyValueObject, hv_DLResult, HTuple(hv_DLResultKeys[hv_KeyIndex]));
      }
    }
    }
  }
  //Get the predicted class and its confidence value
  //for the original (not occluded) image.
  GetDictTuple(hv_DLResult, "classification_class_ids", &hv_SampleClassIds);
  if (0 != (int(hv_TargetClassID==HTuple())))
  {
    hv_TargetClassIDIndex = 0;
    hv_TargetClassID = ((const HTuple&)hv_SampleClassIds)[0];
  }
  else
  {
    hv_TargetClassIDIndex = hv_SampleClassIds.TupleFind(hv_TargetClassID);
    if (0 != (int(hv_TargetClassIDIndex==-1)))
    {
      throw HException(("Selected \"target_class_id\" "+hv_TargetClassID)+" must be in the range of the classification_class_ids of DLResult.");
    }
  }
  hv_TargetClassID = HTuple(hv_SampleClassIds[hv_TargetClassIDIndex]);
  GetDictTuple(hv_DLResult, "classification_class_names", &hv_SampleClassNames);
  hv_TargetClassName = HTuple(hv_SampleClassNames[hv_TargetClassIDIndex]);
  GetDictTuple(hv_DLResult, "classification_confidences", &hv_SampleConfidences);
  hv_TargetConfidence = HTuple(hv_SampleConfidences[hv_TargetClassIDIndex]);
  GetSystem("clip_region", &hv_ClipRegionSettingBefore);
  SetSystem("clip_region", "false");
  //
  //Partition the image into rectangular regions. The height and width of the
  //rectangles are approximately equal to sampling_size.
  PartitionRectangle(ho_Image, &ho_Partition, hv_SamplingSize, hv_SamplingSize);
  HeightWidthRatio(ho_Partition, &hv_HeightRegion, &hv_WidthRegion, &hv_RatioRegion);
  //
  //Generate a set of regions to be occluded based on the center coordinates
  //and the dimensions of these rectangles. Depending on the values of
  //feature_size and sampling_size, these regions may overlap.
  hv_SamplingSizeUsed = (hv_HeightRegion.TupleConcat(hv_WidthRegion)).TupleMedian();
  GetImageSize(ho_Image, &hv_Width, &hv_Height);
  GenGridRegion(&ho_RegionGrid, hv_SamplingSizeUsed, hv_SamplingSizeUsed, "points", 
      hv_Width+1, hv_Height+1);
  GetRegionPoints(ho_RegionGrid, &hv_CenterRows, &hv_CenterColumns);
  hv_NumRegions = hv_CenterRows.TupleLength();
  GenCircle(&ho_OccludedRegions, hv_CenterRows, hv_CenterColumns, HTuple(hv_NumRegions,hv_FeatureSize/2));
  //
  //Generate and classify the occluded images.
  hv_Confidences = HTuple();
  if (0 != (int(hv_NumInputChannels==1)))
  {
    Intensity(ho_OccludedRegions, ho_Image, &hv_MeanGray, &hv_DeviationGray);
  }
  else
  {
    Decompose3(ho_Image, &ho_ImageR, &ho_ImageG, &ho_ImageB);
    Intensity(ho_OccludedRegions, ho_ImageR, &hv_MeanRed, &hv_DeviationRed);
    Intensity(ho_OccludedRegions, ho_ImageG, &hv_MeanGreen, &hv_DeviationGreen);
    Intensity(ho_OccludedRegions, ho_ImageB, &hv_MeanBlue, &hv_DeviationBlue);
  }
  GetDlModelParam(hv_DLModelHandle, "batch_size", &hv_BatchSize);
  {
  HTuple end_val133 = (hv_NumRegions/hv_BatchSize).TupleInt();
  HTuple step_val133 = 1;
  for (hv_BatchIndex=0; hv_BatchIndex.Continue(end_val133, step_val133); hv_BatchIndex += step_val133)
  {
    GenEmptyObj(&ho_ImagesOccluded);
    TupleGenSequence((hv_BatchIndex*hv_BatchSize)+1, (((hv_BatchIndex+1)*hv_BatchSize).TupleConcat(hv_NumRegions)).TupleMin(), 
        1, &hv_BatchIndices);
    {
    HTuple end_val136 = (hv_BatchIndices.TupleLength())-1;
    HTuple step_val136 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val136, step_val136); hv_Index += step_val136)
    {
      SelectObj(ho_OccludedRegions, &ho_OccludedRegion, HTuple(hv_BatchIndices[hv_Index]));
      if (0 != (int(hv_NumInputChannels==1)))
      {
        hv_Mean = HTuple(hv_MeanGray[HTuple(hv_BatchIndices[hv_Index])-1]);
      }
      else
      {
        hv_Mean.Clear();
        hv_Mean.Append(HTuple(hv_MeanRed[HTuple(hv_BatchIndices[hv_Index])-1]));
        hv_Mean.Append(HTuple(hv_MeanGreen[HTuple(hv_BatchIndices[hv_Index])-1]));
        hv_Mean.Append(HTuple(hv_MeanBlue[HTuple(hv_BatchIndices[hv_Index])-1]));
      }
      PaintRegion(ho_OccludedRegion, ho_Image, &ho_ImageOccluded, hv_Mean, "fill");
      ConcatObj(ho_ImagesOccluded, ho_ImageOccluded, &ho_ImagesOccluded);
    }
    }
    //
    //For each occluded image, get the confidence
    //for the predicted class of the original image.
    CountObj(ho_ImagesOccluded, &hv_NumImagesOccluded);
    if (0 != (int(hv_NumImagesOccluded>0)))
    {
      gen_dl_samples_from_images(ho_ImagesOccluded, &hv_DLSampleImagesOccluded);
      ApplyDlModel(hv_DLModelHandle, hv_DLSampleImagesOccluded, HTuple(), &hv_DLResultImagesOccluded);
      {
      HTuple end_val153 = hv_NumImagesOccluded-1;
      HTuple step_val153 = 1;
      for (hv_IndexOccluded=0; hv_IndexOccluded.Continue(end_val153, step_val153); hv_IndexOccluded += step_val153)
      {
        GetDictTuple(HTuple(hv_DLResultImagesOccluded[hv_IndexOccluded]), "classification_class_ids", 
            &hv_OccSampleClassIDs);
        GetDictTuple(HTuple(hv_DLResultImagesOccluded[hv_IndexOccluded]), "classification_confidences", 
            &hv_OccSampleConfidences);
        hv_Confidences = hv_Confidences.TupleConcat(HTuple(hv_OccSampleConfidences[hv_OccSampleClassIDs.TupleFind(hv_TargetClassID)]));
      }
      }
    }
  }
  }
  //
  //Since it is too expensive to compute the confidence value
  //for each individual pixel, we work with a subsampling of the image.
  //The distance between two sampling points is controlled
  //by the parameter 'sampling_size'. For each sampling point,
  //we average over the confidence values of all images
  //which were occluded with a regions to which this point belongs.
  AreaCenter(ho_Partition, &hv_Area, &hv_AveragingCenterRows, &hv_AveragingCenterColumns);
  TupleGenConst(hv_AveragingCenterRows.TupleLength(), 0, &hv_PartitionConfidences);
  {
  HTuple end_val169 = (hv_AveragingCenterRows.TupleLength())-1;
  HTuple step_val169 = 1;
  for (hv_PartIndex=0; hv_PartIndex.Continue(end_val169, step_val169); hv_PartIndex += step_val169)
  {
    GetRegionIndex(ho_OccludedRegions, HTuple(hv_AveragingCenterRows[hv_PartIndex]).TupleInt(), 
        HTuple(hv_AveragingCenterColumns[hv_PartIndex]).TupleInt(), &hv_ConfidenceIndices);
    hv_PartitionConfidences[hv_PartIndex] = HTuple(hv_Confidences[hv_ConfidenceIndices-1]).TupleMean();
  }
  }
  //
  //Compute the deviation from the original confidence value and its maximum absolute value.
  hv_ConfidenceDeviations = hv_TargetConfidence-hv_PartitionConfidences;
  hv_MaxDeviation = (hv_ConfidenceDeviations.TupleAbs()).TupleMax();
  //
  //The heatmap is categorized into 'bins'. The regions where the deviation
  //is highest are in the first bin, the regions where the deviation
  //is lowest are in the last bin. This is done separately for deviations with
  //positive and negative sign.
  hv_NumBins = 10;
  hv_Step = 1/(hv_NumBins.TupleReal());
  hv_End = 1-((hv_NumBins-1)*hv_Step);
  GenEmptyObj(&ho_HeatmapRegions);
  {
  HTuple end_val186 = hv_End;
  HTuple step_val186 = -hv_Step;
  for (hv_Factor=1; hv_Factor.Continue(end_val186, step_val186); hv_Factor += step_val186)
  {
    hv_Lesser = hv_ConfidenceDeviations.TupleLessEqualElem(hv_MaxDeviation*hv_Factor);
    hv_Greater = hv_ConfidenceDeviations.TupleGreaterElem(hv_MaxDeviation*(hv_Factor-hv_Step));
    hv_IndicesInBin = (hv_Lesser+hv_Greater).TupleFind(2);
    if (0 != (int(hv_IndicesInBin!=-1)))
    {
      SelectObj(ho_Partition, &ho_PartsSelected, hv_IndicesInBin+1);
      Union1(ho_PartsSelected, &ho_HeatmapRegion);
    }
    else
    {
      GenEmptyRegion(&ho_HeatmapRegion);
    }
    ConcatObj(ho_HeatmapRegions, ho_HeatmapRegion, &ho_HeatmapRegions);
  }
  }
  GenEmptyObj(&ho_HeatmapRegionsNegative);
  {
  HTuple end_val199 = hv_End;
  HTuple step_val199 = -hv_Step;
  for (hv_Factor=1; hv_Factor.Continue(end_val199, step_val199); hv_Factor += step_val199)
  {
    hv_Lesser = hv_ConfidenceDeviations.TupleLessElem((-hv_MaxDeviation)*(hv_Factor-hv_Step));
    hv_Greater = hv_ConfidenceDeviations.TupleGreaterEqualElem((-hv_MaxDeviation)*hv_Factor);
    hv_IndicesInBin = (hv_Lesser+hv_Greater).TupleFind(2);
    if (0 != (int(hv_IndicesInBin!=-1)))
    {
      SelectObj(ho_Partition, &ho_PartsSelected, hv_IndicesInBin+1);
      Union1(ho_PartsSelected, &ho_HeatmapRegionNegative);
    }
    else
    {
      GenEmptyRegion(&ho_HeatmapRegionNegative);
    }
    ConcatObj(ho_HeatmapRegionsNegative, ho_HeatmapRegionNegative, &ho_HeatmapRegionsNegative
        );
  }
  }
  //
  //Visualize the heatmap.
  GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
  OpenWindow(0, 0, hv_WidthImage, hv_HeightImage, 0, "buffer", "", &hv_WindowHandleTmp);
  SetPart(hv_WindowHandleTmp, 0, 0, hv_HeightImage-1, hv_WidthImage-1);
  DispObj(ho_Image, hv_WindowHandleTmp);
  //
  //For regions for which the confidence decreased, generate a color palette
  //from red to yellow with 66% transparency
  hv_Colors = ((((HTuple("#ff3300").Append("#ff6600")).Append("#ff9900")).Append("#ffcc00")).Append("#ffff00"))+"66";
  for (hv_BinIndex=1; hv_BinIndex<=5; hv_BinIndex+=1)
  {
    SelectObj(ho_HeatmapRegions, &ho_BinRegion, hv_BinIndex);
    hv_ActualColor = HTuple(hv_Colors[hv_BinIndex-1]);
    SetColor(hv_WindowHandleTmp, hv_ActualColor);
    DispRegion(ho_BinRegion, hv_WindowHandleTmp);
  }
  //For regions for which the confidence increased, generate a color palette
  //from blue to cyan with 66% transparency
  hv_Colors = ((((HTuple("#0033ff").Append("#0066ff")).Append("#0099ff")).Append("#00ccff")).Append("#00ffff"))+"66";
  for (hv_BinIndex=1; hv_BinIndex<=5; hv_BinIndex+=1)
  {
    SelectObj(ho_HeatmapRegionsNegative, &ho_BinRegion, hv_BinIndex);
    hv_ActualColor = HTuple(hv_Colors[hv_BinIndex-1]);
    SetColor(hv_WindowHandleTmp, hv_ActualColor);
    DispRegion(ho_BinRegion, hv_WindowHandleTmp);
  }
  //
  //Get the actual window content.
  DumpWindowImage(&ho_Heatmap, hv_WindowHandleTmp);
  CloseWindow(hv_WindowHandleTmp);
  SetSystem("clip_region", hv_ClipRegionSettingBefore);
  //Set the heatmap and its parameters in the result dictionary.
  CreateDict(&hv_HeatmapParameters);
  SetDictTuple(hv_HeatmapParameters, "feature_size", hv_FeatureSize);
  SetDictTuple(hv_HeatmapParameters, "sampling_size", hv_SamplingSize);
  CreateDict(&hv_HeatmapResult);
  hv_HeatmapImageName = "heatmap_image_class_"+hv_TargetClassID;
  SetDictObject(ho_Heatmap, hv_HeatmapResult, hv_HeatmapImageName);
  SetDictTuple(hv_HeatmapResult, "classification_heatmap_maxdeviation", hv_MaxDeviation);
  SetDictTuple(hv_HeatmapResult, "heatmap_parameters", hv_HeatmapParameters);
  SetDictTuple(hv_DLResult, "heatmap_confidence_based", hv_HeatmapResult);
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Return the intended optimization method based on given evaluation key(s). 
void get_dl_evaluation_optimization_method (HTuple hv_EvaluationKeys, HTuple *hv_OptimizationMethod)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Matches, hv_Length, hv_ErrorKeys, hv_Sum;

  //Only evaluation keys which contain the name 'error' are minimization problems.
  TupleRegexpMatch(hv_EvaluationKeys, "error", &hv_Matches);
  TupleStrlen(hv_Matches, &hv_Length);
  TupleGreaterElem(hv_Length, 0, &hv_ErrorKeys);
  TupleSum(hv_ErrorKeys, &hv_Sum);
  if (0 != (int(hv_Sum==(hv_ErrorKeys.TupleLength()))))
  {
    (*hv_OptimizationMethod) = "min";
  }
  else if (0 != (int(hv_Sum==0)))
  {
    (*hv_OptimizationMethod) = "max";
  }
  else
  {
    (*hv_OptimizationMethod) = "mixed";
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Return all pixel measures from a specified list of measures. 
void get_requested_pixel_measures (HTuple hv_Measures, HTuple hv_EvaluationType, 
    HTuple *hv_PixelMeasures)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ValidMeasures, hv_M;

  //
  //This helper procedure returns for a given list of
  //requested measures all pixel measures for the specified
  //evaluation type.
  //
  (*hv_PixelMeasures) = HTuple();
  get_valid_pixel_measures(hv_EvaluationType, &hv_ValidMeasures);
  //
  {
  HTuple end_val8 = (hv_Measures.TupleLength())-1;
  HTuple step_val8 = 1;
  for (hv_M=0; hv_M.Continue(end_val8, step_val8); hv_M += step_val8)
  {
    if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("all"))))
    {
      (*hv_PixelMeasures) = (*hv_PixelMeasures).TupleConcat(hv_ValidMeasures);
    }
    else if (0 != (int((hv_ValidMeasures.TupleFind(HTuple(hv_Measures[hv_M])))!=-1)))
    {
      (*hv_PixelMeasures) = (*hv_PixelMeasures).TupleConcat(HTuple(hv_Measures[hv_M]));
    }
  }
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Returns the list of available pixel evaluation measures for the specified type. 
void get_valid_pixel_measures (HTuple hv_EvaluationType, HTuple *hv_EvaluationMeasures)
{

  // Local iconic variables

  //
  //This helper procedure returns for the given evaluation type
  //all pixel measures available for this type.
  //
  (*hv_EvaluationMeasures) = HTuple();
  if (0 != (int(hv_EvaluationType==HTuple("segmentation"))))
  {
    (*hv_EvaluationMeasures).Clear();
    (*hv_EvaluationMeasures)[0] = "pixel_accuracy";
    (*hv_EvaluationMeasures)[1] = "mean_accuracy";
    (*hv_EvaluationMeasures)[2] = "mean_iou";
    (*hv_EvaluationMeasures)[3] = "class_iou";
    (*hv_EvaluationMeasures)[4] = "class_pixel_accuracy";
    (*hv_EvaluationMeasures)[5] = "pixel_confusion_matrix";
    (*hv_EvaluationMeasures)[6] = "frequency_weighted_iou";
  }
  else if (0 != (int(hv_EvaluationType==HTuple("3d_gripping_point_detection"))))
  {
    (*hv_EvaluationMeasures).Clear();
    (*hv_EvaluationMeasures)[0] = "mean_precision";
    (*hv_EvaluationMeasures)[1] = "mean_iou";
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Initialize the dictionary RunningMeasures for the evaluation. 
void init_running_evaluation_measures (HTuple hv_EvalParams, HTuple *hv_RunningMeasures)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Valid, hv_Exception, hv_NumClasses;
  HTuple  hv_EvaluationType, hv_Measures, hv_ClassIDs, hv_PixelMeasures;
  HTuple  hv_CalcRegionMeasures, hv_CalcGrippingPointMeasures;
  HTuple  hv_InstanceType, hv_EvalOrientation, hv_AllocationBlockLength;
  HTuple  hv_IoUThreshs, hv_MaxNumDetections, hv_AreaRanges;
  HTuple  hv_AreaNames, hv_MinAreas, hv_MaxAreas, hv_DetailedEvaluation;
  HTuple  hv_MaxNumIdx, hv_MaxNum, hv_CurrentRunningMeasure;
  HTuple  hv_AreaIdx, hv_AreaRunningMeasure, hv_I, hv_IoURunningMeasure;
  HTuple  hv_ClsIdx, hv_ClassRunningMeasures, hv_Confidence;
  HTuple  hv_IgnoreClassIDs, hv_CalcConfMatrix, hv_MatrixSize;
  HTuple  hv_PixelConfusionMatrix, hv_MaxId, hv_ClsIDToClsIdx;
  HTuple  hv_TP, hv_FP, hv_FN;

  //
  //This procedure initializes the dictionary RunningMeasures for evaluation.
  //It uses the evaluation parameters to initialize the running measures accordingly.
  //
  //The structure of RunningMeasures depends on the entry 'evaluate_instances' in the dictionary EvalParams.
  //
  //The dictionary RunningMeasures can be updated based on the per-batch/per-image evaluation results.
  //
  CreateDict(&(*hv_RunningMeasures));
  //Check that the necessary evaluation parameters exist.
  validate_evaluation_param(hv_EvalParams, &hv_Valid, &hv_Exception);
  if (0 != (hv_Valid.TupleNot()))
  {
    throw HException(HTuple("Invalid EvalParams, ")+hv_Exception);
  }
  //
  //Get general evaluation parameters.
  GetDictTuple(hv_EvalParams, "num_classes", &hv_NumClasses);
  GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
  GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
  GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
  //
  if (0 != (int(hv_EvaluationType==HTuple("3d_gripping_point_detection"))))
  {
    //RunningMeasures contains:
    //if pixel measures:
    //- tp/fp/fn (pixel numbers for the gripping_map class)
    //if region measures:
    //- gt_overlap (accumulated overlap of groundtruth regions with the prediction)
    //- num_gt_regions (overall number of groundtruth regions)
    //if gripping point measures:
    //- gp_tp/gp_fp/gp_fn (gripping point true positives, false positives, and
    //  false negatives w.r.t. ground truth gripping point region).
    get_requested_pixel_measures(hv_Measures, hv_EvaluationType, &hv_PixelMeasures);
    if (0 != (int((hv_PixelMeasures.TupleLength())>0)))
    {
      SetDictTuple((*hv_RunningMeasures), "tp", 0);
      SetDictTuple((*hv_RunningMeasures), "fp", 0);
      SetDictTuple((*hv_RunningMeasures), "fn", 0);
    }
    hv_CalcRegionMeasures = HTuple(int((hv_Measures.TupleFind("mean_pro"))>-1)).TupleOr(int((hv_Measures.TupleFind("all"))>-1));
    if (0 != hv_CalcRegionMeasures)
    {
      SetDictTuple((*hv_RunningMeasures), "gt_overlap", 0);
      SetDictTuple((*hv_RunningMeasures), "num_gt_regions", 0);
    }
    hv_CalcGrippingPointMeasures = int((HTuple(hv_Measures.TupleRegexpSelect("gripping_point_.*|all")).TupleLength())>0);
    if (0 != hv_CalcGrippingPointMeasures)
    {
      SetDictTuple((*hv_RunningMeasures), "gp_tp", 0);
      SetDictTuple((*hv_RunningMeasures), "gp_fp", 0);
      SetDictTuple((*hv_RunningMeasures), "gp_fn", 0);
    }
  }
  else if (0 != (HTuple(int(hv_EvaluationType==HTuple("anomaly_detection"))).TupleOr(int(hv_EvaluationType==HTuple("gc_anomaly_detection")))))
  {
    //RunningMeasures contains:
    //- image_ids:          IDs of the images.
    //- anomaly_label_ids:  Class IDs of ground truth labels.
    //- anomaly_scores:     Predicted image level anomaly scores.
    SetDictTuple((*hv_RunningMeasures), "image_ids", HTuple());
    SetDictTuple((*hv_RunningMeasures), "anomaly_label_ids", HTuple());
    SetDictTuple((*hv_RunningMeasures), "anomaly_scores", HTuple());
  }
  else if (0 != (int(hv_EvaluationType==HTuple("classification"))))
  {
    //RunningMeasures contains:
    //- image_ids:          IDs of the images.
    //- image_label_ids:    Class IDs of ground truth labels.
    //- top1_predictions:   Class IDs of the top predicted class.
    //- topk_predictions:   Class IDs of top-K predicted classes.
    SetDictTuple((*hv_RunningMeasures), "image_ids", HTuple());
    SetDictTuple((*hv_RunningMeasures), "image_label_ids", HTuple());
    SetDictTuple((*hv_RunningMeasures), "top1_predictions", HTuple());
    SetDictTuple((*hv_RunningMeasures), "topk_predictions", HTuple());
  }
  else if (0 != (HTuple(int(hv_EvaluationType==HTuple("detection"))).TupleOr(int(hv_EvaluationType==HTuple("ocr_detection")))))
  {
    //RunningMeasures contains:
    //For each maximal number of regions (MaxNumDetections):
    // - For each area range (AreaRanges):
    //   -- confidence:     Confidence (score) of each result.
    //   -- num_gt:         Total number of ground truth instances per class.
    //   -- num_pred:       Total number of predictions per class.
    //   -- num_gt_ignore:  Number of ignored ground truth instances per class.
    //   -- for each IoU-threshold:
    //      --- For each class:
    //          ---- is_tp:                  TP/FP assignment of result.
    //          ---- ignore:                 Ignore/Not-Ignore assignment of result.
    //          ---- abs_orientation_diff (for instance_type 'rectangle2' with measure SoAP):
    //                                       Absolute orientation difference of the result.
    //
    //Check if the orientation difference is to be evaluated.
    GetDictTuple(hv_EvalParams, "instance_type", &hv_InstanceType);
    hv_EvalOrientation = 0;
    if (0 != (HTuple(int(hv_InstanceType==HTuple("rectangle2"))).TupleAnd(HTuple(int((hv_Measures.TupleFind("soap"))!=-1)).TupleOr(int((hv_Measures.TupleFind("all"))!=-1)))))
    {
      hv_EvalOrientation = 1;
    }
    //
    //Calculating the measures confidence, is_tp, ignore, and abs_orientation_diff,
    //arrays are allocated with -1 in blocks of AllocationBlockLength
    //(thus, if a block is filled, the next block is allocated).
    //Otherwise the arrays have to be concatenated which is rather slow.
    //The actual length of the array is garnered in num_pred.
    GetDictTuple(hv_EvalParams, "allocation_block_length", &hv_AllocationBlockLength);
    GetDictTuple(hv_EvalParams, "iou_threshold", &hv_IoUThreshs);
    GetDictTuple(hv_EvalParams, "max_num_detections", &hv_MaxNumDetections);
    GetDictTuple(hv_EvalParams, "area_ranges", &hv_AreaRanges);
    //AreaRanges is a dictionary containing 'name', 'min_area', 'max_area'.
    GetDictTuple(hv_AreaRanges, "name", &hv_AreaNames);
    GetDictTuple(hv_AreaRanges, "min", &hv_MinAreas);
    GetDictTuple(hv_AreaRanges, "max", &hv_MaxAreas);
    //Check if a detailed evaluation will be performed.
    GetDictTuple(hv_EvalParams, "detailed_evaluation", &hv_DetailedEvaluation);
    //Set a result dictionary for each maximal number of detections and IoU-threshold.
    {
    HTuple end_val104 = (hv_MaxNumDetections.TupleLength())-1;
    HTuple step_val104 = 1;
    for (hv_MaxNumIdx=0; hv_MaxNumIdx.Continue(end_val104, step_val104); hv_MaxNumIdx += step_val104)
    {
      hv_MaxNum = HTuple(hv_MaxNumDetections[hv_MaxNumIdx]);
      CreateDict(&hv_CurrentRunningMeasure);
      {
      HTuple end_val107 = (hv_AreaNames.TupleLength())-1;
      HTuple step_val107 = 1;
      for (hv_AreaIdx=0; hv_AreaIdx.Continue(end_val107, step_val107); hv_AreaIdx += step_val107)
      {
        CreateDict(&hv_AreaRunningMeasure);
        {
        HTuple end_val109 = (hv_IoUThreshs.TupleLength())-1;
        HTuple step_val109 = 1;
        for (hv_I=0; hv_I.Continue(end_val109, step_val109); hv_I += step_val109)
        {
          CreateDict(&hv_IoURunningMeasure);
          {
          HTuple end_val111 = hv_NumClasses-1;
          HTuple step_val111 = 1;
          for (hv_ClsIdx=0; hv_ClsIdx.Continue(end_val111, step_val111); hv_ClsIdx += step_val111)
          {
            CreateDict(&hv_ClassRunningMeasures);
            SetDictTuple(hv_ClassRunningMeasures, "is_tp", HTuple(hv_AllocationBlockLength,-1));
            SetDictTuple(hv_ClassRunningMeasures, "ignore", HTuple(hv_AllocationBlockLength,-1));
            if (0 != hv_EvalOrientation)
            {
              SetDictTuple(hv_ClassRunningMeasures, "abs_orientation_diff", HTuple(hv_AllocationBlockLength,-1));
            }
            if (0 != hv_DetailedEvaluation)
            {
              SetDictTuple(hv_ClassRunningMeasures, "is_fp_class", HTuple(hv_AllocationBlockLength,-1));
              SetDictTuple(hv_ClassRunningMeasures, "is_fp_background", HTuple(hv_AllocationBlockLength,-1));
              SetDictTuple(hv_ClassRunningMeasures, "is_fp_localization", HTuple(hv_AllocationBlockLength,-1));
              SetDictTuple(hv_ClassRunningMeasures, "is_fp_duplicate", HTuple(hv_AllocationBlockLength,-1));
              SetDictTuple(hv_ClassRunningMeasures, "is_fp_multiple", HTuple(hv_AllocationBlockLength,-1));
              if (0 != hv_EvalOrientation)
              {
                SetDictTuple(hv_ClassRunningMeasures, "abs_orientation_diff_class", 
                    HTuple(hv_AllocationBlockLength,-1));
                SetDictTuple(hv_ClassRunningMeasures, "abs_orientation_diff_localization", 
                    HTuple(hv_AllocationBlockLength,-1));
                SetDictTuple(hv_ClassRunningMeasures, "abs_orientation_diff_duplicate", 
                    HTuple(hv_AllocationBlockLength,-1));
                SetDictTuple(hv_ClassRunningMeasures, "abs_orientation_diff_multiple", 
                    HTuple(hv_AllocationBlockLength,-1));
              }
              SetDictTuple(hv_IoURunningMeasure, "image_ids_with_false_negatives", 
                  HTuple(hv_AllocationBlockLength,-1));
              SetDictTuple(hv_IoURunningMeasure, "image_ids_with_false_positives", 
                  HTuple(hv_AllocationBlockLength,-1));
              SetDictTuple(hv_IoURunningMeasure, "num_image_ids_with_false_negatives", 
                  0);
              SetDictTuple(hv_IoURunningMeasure, "num_image_ids_with_false_positives", 
                  0);
            }
            SetDictTuple(hv_IoURunningMeasure, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), 
                hv_ClassRunningMeasures);
          }
          }
          SetDictTuple(hv_AreaRunningMeasure, "iou_"+((""+HTuple(hv_IoUThreshs[hv_I])).TupleRegexpReplace("\\.","")), 
              hv_IoURunningMeasure);
        }
        }
        CreateDict(&hv_Confidence);
        {
        HTuple end_val140 = hv_NumClasses-1;
        HTuple step_val140 = 1;
        for (hv_ClsIdx=0; hv_ClsIdx.Continue(end_val140, step_val140); hv_ClsIdx += step_val140)
        {
          SetDictTuple(hv_Confidence, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), HTuple(hv_AllocationBlockLength,-1.0));
        }
        }
        SetDictTuple(hv_AreaRunningMeasure, "confidence", hv_Confidence);
        SetDictTuple(hv_AreaRunningMeasure, "num_gt", HTuple(hv_NumClasses,0));
        SetDictTuple(hv_AreaRunningMeasure, "num_pred", HTuple(hv_NumClasses,0));
        SetDictTuple(hv_AreaRunningMeasure, "num_gt_ignore", HTuple(hv_NumClasses,0));
        SetDictTuple(hv_CurrentRunningMeasure, "area_"+HTuple(hv_AreaNames[hv_AreaIdx]), 
            hv_AreaRunningMeasure);
      }
      }
      if (0 != (int(hv_MaxNum==-1)))
      {
        hv_MaxNum = "all";
      }
      SetDictTuple((*hv_RunningMeasures), "max_num_detections_"+hv_MaxNum, hv_CurrentRunningMeasure);
    }
    }
  }
  else if (0 != (int(hv_EvaluationType==HTuple("segmentation"))))
  {
    //RunningMeasures contains:
    //if confusion matrix in Measures (slower but more information).
    // - confusion matrix per pixel.
    //else:
    // - TP/FP/FN (pixel numbers per class).
    //
    //Incorporate ignore class IDs.
    GetDictTuple(hv_EvalParams, "ignore_class_ids", &hv_IgnoreClassIDs);
    //
    //Check if we need to compute/update the confusion matrix.
    hv_CalcConfMatrix = HTuple(int((hv_Measures.TupleFind("pixel_confusion_matrix"))>-1)).TupleOr(int((hv_Measures.TupleFind("all"))>-1));
    if (0 != hv_CalcConfMatrix)
    {
      //Define the size of the confusion matrix.
      hv_MatrixSize = hv_NumClasses+(int((hv_IgnoreClassIDs.TupleLength())>0));
      CreateMatrix(hv_MatrixSize, hv_MatrixSize, 0, &hv_PixelConfusionMatrix);
      SetDictTuple((*hv_RunningMeasures), "pixel_confusion_matrix", hv_PixelConfusionMatrix);
      //
      //If the class IDs are not running indices from 0 to NumClasses we
      //define a mapping from class IDs to class indices.
      if (0 != (HTuple(int(hv_ClassIDs!=HTuple::TupleGenSequence(0,(hv_ClassIDs.TupleLength())-1,1))).TupleOr(int((hv_IgnoreClassIDs.TupleLength())>0))))
      {
        //Get the max ID that can occur.
        hv_MaxId = (hv_ClassIDs.TupleMax())+(int((hv_IgnoreClassIDs.TupleLength())>0));
        //Define the basic mapping.
        TupleGenConst(hv_MaxId+1, -1, &hv_ClsIDToClsIdx);
        hv_ClsIDToClsIdx[hv_ClassIDs] = HTuple::TupleGenSequence(0,(hv_ClassIDs.TupleLength())-1,1);
        //Map ignore IDs to the next higher one.
        hv_ClsIDToClsIdx[hv_IgnoreClassIDs] = (hv_ClsIDToClsIdx.TupleMax())+1;
        //Set the mapping to the evaluation parameters.
        SetDictTuple(hv_EvalParams, "class_id_mapping", hv_ClsIDToClsIdx);
      }
    }
    else
    {
      hv_TP = HTuple(hv_NumClasses,0);
      hv_FP = HTuple(hv_NumClasses,0);
      hv_FN = HTuple(hv_NumClasses,0);
      SetDictTuple((*hv_RunningMeasures), "tp", hv_TP);
      SetDictTuple((*hv_RunningMeasures), "fp", hv_FP);
      SetDictTuple((*hv_RunningMeasures), "fn", hv_FN);
    }
  }
  else if (0 != (int(hv_EvaluationType==HTuple("ocr_recognition"))))
  {
    //RunningMeasures for OCR recognition models.
    SetDictTuple((*hv_RunningMeasures), "image_ids", HTuple());
    SetDictTuple((*hv_RunningMeasures), "words_ground_truth", HTuple());
    SetDictTuple((*hv_RunningMeasures), "words_prediction", HTuple());
  }
  //
  return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Apply the given thresholds on anomaly detection and Global Context Anomaly Detection results for image classification and region segmentation. 
void threshold_dl_anomaly_results (HTuple hv_AnomalySegmentationThreshold, HTuple hv_AnomalyClassificationThreshold, 
    HTuple hv_DLResults)
{

  // Local iconic variables
  HObject  ho_AnomalyImage, ho_AnomalyRegion;

  // Local control variables
  HTuple  hv_DLResultIndex, hv_DLResult, hv_DLResultKeys;
  HTuple  hv_ImageKeys, hv_ScoreKeys, hv_Index, hv_AnomalyImageRegionType;
  HTuple  hv_AnomalyRegionName, hv_AnomalyScoreType, hv_AnomalyScoreName;
  HTuple  hv_AnomalyScore, hv_AnomalyClassName, hv_AnomalyClassIDName;

  //This procedure applies given thresholds on anomaly detection (AD)
  //or Global Context Anomaly Detection (GC-AD) results.
  //The thresholds are used for:
  //
  //1. Region segmentation: AnomalySegmentationThreshold is used as threshold
  //whether a pixel within the anomaly image belongs to a region of an anomaly.
  //The region is returned in DLResult under one of the following keys, depending on
  //the anomaly image key stored in the DLResult:
  //- 'anomaly_region' (AD, GC_AD)
  //- 'anomaly_region_local' (GC-AD)
  //- 'anomaly_region_global' (GC-AD)
  //2. Image classification: AnomalyClassificationThreshold is used as threshold
  //whether the image is classified as containing an anomaly ('nok' / class_id: 1) or not ('ok' / class_id: 0).
  //The class is returned in DLResult under one of the following keys:
  //- 'anomaly_class' (AD, GC_AD): The classification result as a string ('ok' or 'nok').
  //- 'anomaly_class_local' (GC-AD): The classification result as a string ('ok' or 'nok').
  //- 'anomaly_class_global' (GC-AD): The classification result as a string ('ok' or 'nok').
  //- 'anomaly_class_id' (AD, GC_AD): The classification result as an integer (0 or 1).
  //- 'anomaly_class_id_local' (GC-AD): The classification result as an integer (0 or 1).
  //- 'anomaly_class_id_global' (GC-AD): The classification result as an integer (0 or 1).
  //
  //The applied thresholds are also stored in DLResult.
  //
  //Check for invalid AnomalySegmentationThreshold.
  if (0 != (int((hv_AnomalySegmentationThreshold.TupleLength())!=1)))
  {
    throw HException("AnomalySegmentationThreshold must be specified by exactly one value.");
  }
  //
  //Check for invalid AnomalyClassificationThreshold.
  if (0 != (int((hv_AnomalyClassificationThreshold.TupleLength())!=1)))
  {
    throw HException("AnomalyClassificationThreshold must be specified by exactly one value.");
  }
  //
  //Evaluate each DLResult.
  {
  HTuple end_val34 = (hv_DLResults.TupleLength())-1;
  HTuple step_val34 = 1;
  for (hv_DLResultIndex=0; hv_DLResultIndex.Continue(end_val34, step_val34); hv_DLResultIndex += step_val34)
  {
    //
    //Read anomaly image and anomaly score from DLResult.
    hv_DLResult = HTuple(hv_DLResults[hv_DLResultIndex]);
    GetDictParam(hv_DLResult, "keys", HTuple(), &hv_DLResultKeys);
    TupleRegexpSelect(hv_DLResultKeys, ".*_image.*", &hv_ImageKeys);
    TupleRegexpSelect(hv_DLResultKeys, ".*_score.*", &hv_ScoreKeys);
    TupleSort(hv_ImageKeys, &hv_ImageKeys);
    TupleSort(hv_ScoreKeys, &hv_ScoreKeys);
    if (0 != (HTuple(int(hv_ImageKeys==HTuple())).TupleOr(int(hv_ScoreKeys==HTuple()))))
    {
      throw HException(HTuple("DLResult must contain keys 'anomaly_image' (local, global) and 'anomaly_score' (local, global)."));
    }
    {
    HTuple end_val46 = (hv_ImageKeys.TupleLength())-1;
    HTuple step_val46 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val46, step_val46); hv_Index += step_val46)
    {
      //Apply AnomalyThreshold to the anomaly image.
      GetDictObject(&ho_AnomalyImage, hv_DLResult, HTuple(hv_ImageKeys[hv_Index]));
      Threshold(ho_AnomalyImage, &ho_AnomalyRegion, hv_AnomalySegmentationThreshold, 
          "max");
      //
      //Write AnomalyRegion to DLResult.
      TupleRegexpMatch(HTuple(hv_ImageKeys[hv_Index]), "anomaly_image(.*)", &hv_AnomalyImageRegionType);
      hv_AnomalyRegionName = "anomaly_region"+hv_AnomalyImageRegionType;
      SetDictObject(ho_AnomalyRegion, hv_DLResult, hv_AnomalyRegionName);
      //
      //Classify sample as 'ok' or 'nok'.
      TupleRegexpMatch(HTuple(hv_ScoreKeys[hv_Index]), "anomaly_score(.*)", &hv_AnomalyScoreType);
      hv_AnomalyScoreName = HTuple(hv_ScoreKeys[hv_Index]);
      GetDictTuple(hv_DLResult, hv_AnomalyScoreName, &hv_AnomalyScore);
      hv_AnomalyClassName = "anomaly_class"+hv_AnomalyScoreType;
      hv_AnomalyClassIDName = "anomaly_class_id"+hv_AnomalyScoreType;
      if (0 != (int(hv_AnomalyScore<hv_AnomalyClassificationThreshold)))
      {
        SetDictTuple(hv_DLResult, hv_AnomalyClassName, "ok");
        SetDictTuple(hv_DLResult, hv_AnomalyClassIDName, 0);
      }
      else
      {
        SetDictTuple(hv_DLResult, hv_AnomalyClassName, "nok");
        SetDictTuple(hv_DLResult, hv_AnomalyClassIDName, 1);
      }
    }
    }
    //
    //Write anomaly thresholds to DLResult.
    SetDictTuple(hv_DLResult, "anomaly_classification_threshold", hv_AnomalyClassificationThreshold);
    SetDictTuple(hv_DLResult, "anomaly_segmentation_threshold", hv_AnomalySegmentationThreshold);
  }
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Update RunningMeasures by evaluating Samples and corresponding Results. 
void update_running_evaluation_measures (HTuple hv_Samples, HTuple hv_Results, HTuple hv_EvalParams, 
    HTuple hv_RunningMeasures)
{

  // Local control variables
  HTuple  hv_EvaluationType;

  //
  //This procedure updates the running measures depending on the evaluation type.
  GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
  if (0 != (HTuple(int(hv_EvaluationType==HTuple("anomaly_detection"))).TupleOr(int(hv_EvaluationType==HTuple("gc_anomaly_detection")))))
  {
    update_running_image_anomaly_measures(hv_Samples, hv_Results, hv_EvalParams, 
        hv_RunningMeasures);
  }
  else if (0 != (int(hv_EvaluationType==HTuple("classification"))))
  {
    update_running_image_classification_measures(hv_Samples, hv_Results, hv_EvalParams, 
        hv_RunningMeasures);
  }
  else if (0 != (HTuple(int(hv_EvaluationType==HTuple("detection"))).TupleOr(int(hv_EvaluationType==HTuple("ocr_detection")))))
  {
    update_running_instance_measures(hv_Samples, hv_Results, hv_EvalParams, hv_RunningMeasures);
  }
  else if (0 != (HTuple(int(hv_EvaluationType==HTuple("segmentation"))).TupleOr(int(hv_EvaluationType==HTuple("3d_gripping_point_detection")))))
  {
    update_running_pixel_measures(hv_Samples, hv_Results, hv_EvalParams, hv_RunningMeasures);
    if (0 != (int(hv_EvaluationType==HTuple("3d_gripping_point_detection"))))
    {
      update_running_region_measures(hv_Samples, hv_Results, hv_EvalParams, hv_RunningMeasures);
      update_running_gripping_point_measures(hv_Samples, hv_Results, hv_EvalParams, 
          hv_RunningMeasures);
    }
  }
  else if (0 != (int(hv_EvaluationType==HTuple("ocr_recognition"))))
  {
    update_running_ocr_recognition_measures(hv_Samples, hv_Results, hv_EvalParams, 
        hv_RunningMeasures);
  }
  //
  return;
}

// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Update running measures for 3D gripping points. 
void update_running_gripping_point_measures (HTuple hv_Samples, HTuple hv_Results, 
    HTuple hv_EvalParams, HTuple hv_RunningMeasures)
{

  // Local iconic variables
  HObject  ho_AnnotationRegion, ho_GTRegions, ho_GTRegion;

  // Local control variables
  HTuple  hv_Index, hv_Sample, hv_Result, hv_NumGTRegions;
  HTuple  hv_GrippingPointFound, hv_IndexGTRegions, hv_TP;
  HTuple  hv_FP, hv_IndexGrippingPoint, hv_GrippingPoint;
  HTuple  hv_GPFound, hv_NumGrippingPointFound;

  if (0 != (int((HTuple((hv_EvalParams.TupleGetDictTuple("measures")).TupleRegexpSelect("gripping_point_.*|all")).TupleLength())>0)))
  {
    {
    HTuple end_val1 = (hv_Samples.TupleLength())-1;
    HTuple step_val1 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val1, step_val1); hv_Index += step_val1)
    {
      hv_Sample = HTuple(hv_Samples[hv_Index]);
      hv_Result = HTuple(hv_Results[hv_Index]);
      gen_dl_3d_gripping_points_and_poses(hv_Sample, hv_EvalParams.TupleGetDictTuple("gripping_point_params"), 
          hv_Result);
      Threshold(hv_Sample.TupleGetDictObject("segmentation_image"), &ho_AnnotationRegion, 
          HTuple((hv_EvalParams.TupleGetDictTuple("class_ids"))[0]), HTuple((hv_EvalParams.TupleGetDictTuple("class_ids"))[0]));
      Connection(ho_AnnotationRegion, &ho_GTRegions);
      CountObj(ho_GTRegions, &hv_NumGTRegions);
      //True positives: Only one gripping point
      //within a ground truth region is counted
      //as true positive. All additional points
      //witin the same ground truth region are
      //considered a false positive.
      //False negative: All ground truth regions
      //that do not contain at least one
      //gripping point are a false negative.
      hv_GrippingPointFound = HTuple((hv_Result.TupleGetDictTuple("gripping_points")).TupleLength(),0);
      {
      HTuple end_val17 = hv_NumGTRegions;
      HTuple step_val17 = 1;
      for (hv_IndexGTRegions=1; hv_IndexGTRegions.Continue(end_val17, step_val17); hv_IndexGTRegions += step_val17)
      {
        SelectObj(ho_GTRegions, &ho_GTRegion, hv_IndexGTRegions);
        hv_TP = 0.0;
        hv_FP = 0.0;
        {
        HTuple end_val21 = ((hv_Result.TupleGetDictTuple("gripping_points")).TupleLength())-1;
        HTuple step_val21 = 1;
        for (hv_IndexGrippingPoint=0; hv_IndexGrippingPoint.Continue(end_val21, step_val21); hv_IndexGrippingPoint += step_val21)
        {
          hv_GrippingPoint = HTuple((hv_Result.TupleGetDictTuple("gripping_points"))[hv_IndexGrippingPoint]);
          TestRegionPoint(ho_GTRegion, hv_GrippingPoint.TupleGetDictTuple("row"), 
              hv_GrippingPoint.TupleGetDictTuple("column"), &hv_GPFound);
          if (0 != hv_GPFound)
          {
            if (0 != (int(hv_TP==0.0)))
            {
              hv_TP += 1.0;
            }
            else
            {
              hv_FP += 1.0;
            }
            hv_GrippingPointFound[hv_IndexGrippingPoint] = 1;
          }
        }
        }
        SetDictTuple(hv_RunningMeasures, "gp_tp", (hv_RunningMeasures.TupleGetDictTuple("gp_tp"))+hv_TP);
        SetDictTuple(hv_RunningMeasures, "gp_fp", (hv_RunningMeasures.TupleGetDictTuple("gp_fp"))+hv_FP);
        if (0 != (int(hv_TP==0.0)))
        {
          SetDictTuple(hv_RunningMeasures, "gp_fn", (hv_RunningMeasures.TupleGetDictTuple("gp_fn"))+1.0);
        }
      }
      }
      //All gripping points that have not been
      //found to lie within the ground truth
      //region are additional false positives.
      if (0 != (int((hv_GrippingPointFound.TupleLength())>0)))
      {
        hv_NumGrippingPointFound = hv_GrippingPointFound.TupleSum();
      }
      else
      {
        hv_NumGrippingPointFound = 0;
      }
      SetDictTuple(hv_RunningMeasures, "gp_fp", (hv_RunningMeasures.TupleGetDictTuple("gp_fp"))+((hv_GrippingPointFound.TupleLength())-hv_NumGrippingPointFound));
    }
    }
  }
  return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Update running measures for an anomaly detection or Global Context Anomaly Detection evaluation. 
void update_running_image_anomaly_measures (HTuple hv_Samples, HTuple hv_Results, 
    HTuple hv_EvalParams, HTuple hv_RunningMeasures)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ImageIDs, hv_AnomalyLabelIDs, hv_AnomalyScores;
  HTuple  hv_SampleIndex, hv_Sample, hv_ImageID, hv_AnomalyLabelID;
  HTuple  hv_Result, hv_Keys, hv_AnomalyScoreKey, hv_AnomalyScore;

  //
  //This procedure updates the RunningMeasures for an evaluation for anomaly detection.
  //
  //These measures are stored in the dictionary RunningMeasures and
  //updated by incorporating the Results the model obtained for the Samples.
  //
  //
  //Get image ids.
  GetDictTuple(hv_RunningMeasures, "image_ids", &hv_ImageIDs);
  //Get anomaly label ids.
  GetDictTuple(hv_RunningMeasures, "anomaly_label_ids", &hv_AnomalyLabelIDs);
  //Get anomaly scores.
  GetDictTuple(hv_RunningMeasures, "anomaly_scores", &hv_AnomalyScores);
  //Loop over all samples and update running measures accordingly.
  {
  HTuple end_val14 = (hv_Samples.TupleLength())-1;
  HTuple step_val14 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val14, step_val14); hv_SampleIndex += step_val14)
  {
    hv_Sample = HTuple(hv_Samples[hv_SampleIndex]);
    GetDictTuple(hv_Sample, "image_id", &hv_ImageID);
    GetDictTuple(hv_Sample, "anomaly_label_id", &hv_AnomalyLabelID);
    hv_Result = HTuple(hv_Results[hv_SampleIndex]);
    GetDictParam(hv_Result, "keys", HTuple(), &hv_Keys);
    TupleRegexpSelect(hv_Keys, "anomaly_score.*", &hv_AnomalyScoreKey);
    //It is not expected that AnomalyScoreKey contains more than one item.
    //In case it unexpectedly does, we index it with [0].
    GetDictTuple(hv_Result, HTuple(hv_AnomalyScoreKey[0]), &hv_AnomalyScore);
    //
    hv_ImageIDs = hv_ImageIDs.TupleConcat(hv_ImageID);
    hv_AnomalyLabelIDs = hv_AnomalyLabelIDs.TupleConcat(hv_AnomalyLabelID);
    hv_AnomalyScores = hv_AnomalyScores.TupleConcat(hv_AnomalyScore);
  }
  }
  //
  //Set image ids in running measures.
  SetDictTuple(hv_RunningMeasures, "image_ids", hv_ImageIDs);
  //Set anomaly label ids in running measures.
  SetDictTuple(hv_RunningMeasures, "anomaly_label_ids", hv_AnomalyLabelIDs);
  //Set anomaly scores in running measures.
  SetDictTuple(hv_RunningMeasures, "anomaly_scores", hv_AnomalyScores);
  //
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Update running measures for an image classification evaluation. 
void update_running_image_classification_measures (HTuple hv_Samples, HTuple hv_Results, 
    HTuple hv_EvalParams, HTuple hv_RunningMeasures)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_RegExpTopKError, hv_Measures, hv_K;
  HTuple  hv_M, hv_ComputeTopKError, hv_ImageIDs, hv_ImageLabelIDs;
  HTuple  hv_Top1Prediction, hv_TopKPredictionDicts, hv_Index;
  HTuple  hv_Sample, hv_ImageID, hv_ImageLabelID, hv_Result;
  HTuple  hv_PredictedClassIDs, hv_TopKPrediction, hv_TopKPredictionDict;

  //
  //This procedure updates the RunningMeasures for an evaluation for classification.
  //
  //To avoid memory, only save first K predictions per sample.
  hv_RegExpTopKError = "top([0-9]+)_error";
  GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
  hv_K = 1;
  {
  HTuple end_val7 = (hv_Measures.TupleLength())-1;
  HTuple step_val7 = 1;
  for (hv_M=0; hv_M.Continue(end_val7, step_val7); hv_M += step_val7)
  {
    hv_ComputeTopKError = HTuple(hv_Measures[hv_M]).TupleRegexpTest(hv_RegExpTopKError);
    if (0 != hv_ComputeTopKError)
    {
      hv_K = hv_K.TupleMax2((HTuple(hv_Measures[hv_M]).TupleRegexpMatch(hv_RegExpTopKError)).TupleNumber());
    }
  }
  }
  //
  //Extend tuples in RunningMeasures with new results.
  GetDictTuple(hv_RunningMeasures, "image_ids", &hv_ImageIDs);
  GetDictTuple(hv_RunningMeasures, "image_label_ids", &hv_ImageLabelIDs);
  GetDictTuple(hv_RunningMeasures, "top1_predictions", &hv_Top1Prediction);
  GetDictTuple(hv_RunningMeasures, "topk_predictions", &hv_TopKPredictionDicts);
  {
  HTuple end_val19 = (hv_Samples.TupleLength())-1;
  HTuple step_val19 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val19, step_val19); hv_Index += step_val19)
  {
    hv_Sample = HTuple(hv_Samples[hv_Index]);
    GetDictTuple(hv_Sample, "image_id", &hv_ImageID);
    GetDictTuple(hv_Sample, "image_label_id", &hv_ImageLabelID);
    hv_Result = HTuple(hv_Results[hv_Index]);
    GetDictTuple(hv_Result, "classification_class_ids", &hv_PredictedClassIDs);
    hv_TopKPrediction = hv_PredictedClassIDs.TupleSelectRange(0,hv_K-1);
    CreateDict(&hv_TopKPredictionDict);
    SetDictTuple(hv_TopKPredictionDict, "predictions", hv_TopKPrediction);
    //
    hv_ImageIDs = hv_ImageIDs.TupleConcat(hv_ImageID);
    hv_ImageLabelIDs = hv_ImageLabelIDs.TupleConcat(hv_ImageLabelID);
    hv_Top1Prediction = hv_Top1Prediction.TupleConcat(HTuple(hv_TopKPrediction[0]));
    hv_TopKPredictionDicts = hv_TopKPredictionDicts.TupleConcat(hv_TopKPredictionDict);
  }
  }
  //
  SetDictTuple(hv_RunningMeasures, "image_ids", hv_ImageIDs);
  SetDictTuple(hv_RunningMeasures, "image_label_ids", hv_ImageLabelIDs);
  SetDictTuple(hv_RunningMeasures, "top1_predictions", hv_Top1Prediction);
  SetDictTuple(hv_RunningMeasures, "topk_predictions", hv_TopKPredictionDicts);
  //
  return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Update running measures for an instance-based evaluation. 
void update_running_instance_measures (HTuple hv_Samples, HTuple hv_Results, HTuple hv_EvalParams, 
    HTuple hv_RunningMeasures)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MaxNumDetections, hv_AreaRanges, hv_IoUThresholds;
  HTuple  hv_InstanceType, hv_ClassIDs, hv_NumClasses, hv_Measures;
  HTuple  hv_AreaNames, hv_MinAreas, hv_MaxAreas, hv_NumAreaRanges;
  HTuple  hv_AllocationBlockLength, hv_DetailedEvaluation;
  HTuple  hv_KeyExists, hv_ClassIDToClassIdx, hv_EvaluateOrientation;
  HTuple  hv_SIdx, hv_CurrentSample, hv_CurrentResult, hv_GtClassIDs;
  HTuple  hv_ResClassIDs, hv_NumGT, hv_NumRes, hv_Confidences;
  HTuple  hv_ResSortIndices, hv_GtAreas, hv_ResAreas, hv_IoUs;
  HTuple  hv_GtPhis, hv_ResPhis, hv_MDIdx, hv_MaxNum, hv_MaxNumStr;
  HTuple  hv_CurrentRunningMeasures, hv_AreaIdx, hv_MinArea;
  HTuple  hv_MaxArea, hv_AreaName, hv_AreaRunningMeasures;
  HTuple  hv_GtIgnore, hv_GtIgnoreInds, hv_PerClassNumGt;
  HTuple  hv_PerClassNumPred, hv_PerClassConfidences, hv_PerClassNumGtIgnore;
  HTuple  hv_SampleHasFP, hv_SampleHasFN, hv_ClsIdx, hv_CurrentClassID;
  HTuple  hv_CurrentGtIdxs, hv_CurrentNumGt, hv_CurrentGtIgnore;
  HTuple  hv_CurrentNumGtIgnore, hv_CurrentNumGtNoIgnore;
  HTuple  hv_CurrentResIdxs, hv_CurrentNumRes, hv_CurrentResAreas;
  HTuple  hv_OldNumPred, hv_CurrentClassConfidences, hv_GtSortIdx;
  HTuple  hv_CurrentResPhis, hv_CurrentGtPhis, hv_ITIdx, hv_GtMatched;
  HTuple  hv_ResMatched, hv_ResAbsOrientationDiff, hv_ResIgnore;
  HTuple  hv_ResIdx, hv_CurrentIoU, hv_MatchIdx, hv_GtIdx;
  HTuple  hv_AreaIgnore, hv_PerIoUMeasure, hv_PerClassMeasures;
  HTuple  hv_CurrentIsTP, hv_CurrentIgnore, hv_CurrentAbsOrientationDiff;
  HTuple  hv_GtMatchedNoIgnore, hv_ResIsFPClass, hv_ResIsFPBackground;
  HTuple  hv_ResIsFPLocalization, hv_ResIsFPDuplicate, hv_ResIsFPMultiple;
  HTuple  hv_ResAbsOrientationDiffClass, hv_ResAbsOrientationDiffLocalization;
  HTuple  hv_ResAbsOrientationDiffDuplicate, hv_ResAbsOrientationDiffMultiple;
  HTuple  hv_FPResIdxsThisClass, hv_FPResIdxsAllResults, hv_GTIdxsNotToIgnore;
  HTuple  hv_MaxIoU, hv_IoUsWithGT, hv_MaxIdx, hv_GTClassIDMaxIoU;
  HTuple  hv_AbsOrientationDiff, hv_IsFPClass, hv_IsFPBackground;
  HTuple  hv_IsFPLocalization, hv_IsFPDuplicate, hv_IsFPMultiple;
  HTuple  hv_AbsOrientationDiffMultiple, hv_AbsOrientationDiffDuplicate;
  HTuple  hv_AbsOrientationDiffLocalization, hv_AbsOrientationDiffClass;
  HTuple  hv_CurrentImageID, hv_ImageIDsWithFN, hv_NumImageIDsWithFN;
  HTuple  hv_ImageIDsWithFP, hv_NumImageIDsWithFP, hv___Tmp_Ctrl_Dict_Init_0;
  HTuple  hv___Tmp_Ctrl_Dict_Init_1;

  //
  //This procedure updates the RunningMeasures
  //for an instance-based evaluation for detection.
  //These measures are stored in the dictionary RunningMeasures and
  //updated by incorporating the Results the model obtained for the Samples.
  //
  dev_update_off();
  //Get the necessary evaluation parameters.
  GetDictTuple(hv_EvalParams, "max_num_detections", &hv_MaxNumDetections);
  GetDictTuple(hv_EvalParams, "area_ranges", &hv_AreaRanges);
  GetDictTuple(hv_EvalParams, "iou_threshold", &hv_IoUThresholds);
  GetDictTuple(hv_EvalParams, "instance_type", &hv_InstanceType);
  GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
  GetDictTuple(hv_EvalParams, "num_classes", &hv_NumClasses);
  GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
  //
  //Get the area parameters: name, min, and max.
  GetDictTuple(hv_AreaRanges, "name", &hv_AreaNames);
  GetDictTuple(hv_AreaRanges, "min", &hv_MinAreas);
  GetDictTuple(hv_AreaRanges, "max", &hv_MaxAreas);
  hv_NumAreaRanges = (hv_AreaNames.TupleLength())-1;
  //
  //Get the allocation length for extending tuples.
  GetDictTuple(hv_EvalParams, "allocation_block_length", &hv_AllocationBlockLength);
  //
  //Check if a detailed evaluation should be done.
  hv_DetailedEvaluation = 0;
  GetDictParam(hv_EvalParams, "key_exists", "detailed_evaluation", &hv_KeyExists);
  if (0 != (HTuple(hv_KeyExists[0])))
  {
    GetDictTuple(hv_EvalParams, "detailed_evaluation", &hv_DetailedEvaluation);
  }
  if (0 != hv_DetailedEvaluation)
  {
    //We need a mapping from class IDs to class indices
    hv_ClassIDToClassIdx = HTuple((hv_ClassIDs.TupleMax())+1,-1);
    hv_ClassIDToClassIdx[hv_ClassIDs] = HTuple::TupleGenSequence(0,hv_NumClasses-1,1);
  }
  //
  //Check if the orientation is to be evaluated.
  hv_EvaluateOrientation = 0;
  if (0 != (HTuple(int(hv_InstanceType==HTuple("rectangle2"))).TupleAnd(HTuple(int((hv_Measures.TupleFind("soap"))!=-1)).TupleOr(int((hv_Measures.TupleFind("all"))!=-1)))))
  {
    hv_EvaluateOrientation = 1;
  }
  //
  //Go through samples.
  {
  HTuple end_val44 = (hv_Samples.TupleLength())-1;
  HTuple step_val44 = 1;
  for (hv_SIdx=0; hv_SIdx.Continue(end_val44, step_val44); hv_SIdx += step_val44)
  {
    //
    hv_CurrentSample = HTuple(hv_Samples[hv_SIdx]);
    hv_CurrentResult = HTuple(hv_Results[hv_SIdx]);
    //
    //Get classes.
    GetDictTuple(hv_CurrentSample, "bbox_label_id", &hv_GtClassIDs);
    //Convert results from Deep OCR format to rectangle2 Object Detection format.
    CreateDict(&hv___Tmp_Ctrl_Dict_Init_0);
    SetDictTuple(hv___Tmp_Ctrl_Dict_Init_0, "comp", "ocr_detection");
    if (0 != ((hv_EvalParams.TupleConcat(hv___Tmp_Ctrl_Dict_Init_0)).TupleTestEqualDictItem("evaluation_type","comp")))
    {
      convert_ocr_detection_result_to_object_detection(hv_CurrentResult, &hv_CurrentResult);
    }
    hv___Tmp_Ctrl_Dict_Init_0 = HTuple::TupleConstant("HNULL");
    GetDictTuple(hv_CurrentResult, "bbox_class_id", &hv_ResClassIDs);
    hv_NumGT = hv_GtClassIDs.TupleLength();
    hv_NumRes = hv_ResClassIDs.TupleLength();
    //
    //Get result confidences and sort them in descending order.
    GetDictTuple(hv_CurrentResult, "bbox_confidence", &hv_Confidences);
    hv_ResSortIndices = (-hv_Confidences).TupleSortIndex();
    hv_Confidences = HTuple(hv_Confidences[hv_ResSortIndices]);
    //Sort the result class IDs.
    hv_ResClassIDs = HTuple(hv_ResClassIDs[hv_ResSortIndices]);
    //
    //Compute the IoUs of the instances.
    area_iou(hv_CurrentSample, hv_CurrentResult, hv_InstanceType, hv_ResSortIndices, 
        &hv_GtAreas, &hv_ResAreas, &hv_IoUs);
    //
    if (0 != hv_EvaluateOrientation)
    {
      GetDictTuple(hv_CurrentSample, "bbox_phi", &hv_GtPhis);
      GetDictTuple(hv_CurrentResult, "bbox_phi", &hv_ResPhis);
      hv_ResPhis = HTuple(hv_ResPhis[hv_ResSortIndices]);
    }
    //Loop over the maximal number of detections.
    {
    HTuple end_val78 = (hv_MaxNumDetections.TupleLength())-1;
    HTuple step_val78 = 1;
    for (hv_MDIdx=0; hv_MDIdx.Continue(end_val78, step_val78); hv_MDIdx += step_val78)
    {
      hv_MaxNum = HTuple(hv_MaxNumDetections[hv_MDIdx]);
      hv_MaxNumStr = ""+hv_MaxNum;
      if (0 != (int(hv_MaxNum==-1)))
      {
        hv_MaxNumStr = "all";
      }
      GetDictTuple(hv_RunningMeasures, "max_num_detections_"+hv_MaxNumStr, &hv_CurrentRunningMeasures);
      //
      //Loop over the area ranges.
      {
      HTuple end_val87 = (hv_AreaNames.TupleLength())-1;
      HTuple step_val87 = 1;
      for (hv_AreaIdx=0; hv_AreaIdx.Continue(end_val87, step_val87); hv_AreaIdx += step_val87)
      {
        //
        //Get information about the current area range.
        hv_MinArea = HTuple(hv_MinAreas[hv_AreaIdx]);
        hv_MaxArea = HTuple(hv_MaxAreas[hv_AreaIdx]);
        hv_AreaName = HTuple(hv_AreaNames[hv_AreaIdx]);
        //
        GetDictTuple(hv_CurrentRunningMeasures, "area_"+hv_AreaName, &hv_AreaRunningMeasures);
        //
        //Set ignore-flag for ground truth instances.
        //For Deep OCR detection, ignore classes other than 'word'
        CreateDict(&hv___Tmp_Ctrl_Dict_Init_1);
        SetDictTuple(hv___Tmp_Ctrl_Dict_Init_1, "comp", "ocr_detection");
        if (0 != ((hv_EvalParams.TupleConcat(hv___Tmp_Ctrl_Dict_Init_1)).TupleTestEqualDictItem("evaluation_type","comp")))
        {
          hv_GtIgnore = hv_GtClassIDs.TupleNotEqualElem(0);
        }
        else
        {
          hv_GtIgnore = HTuple(hv_NumGT,0);
        }
        hv___Tmp_Ctrl_Dict_Init_1 = HTuple::TupleConstant("HNULL");
        //
        //Ignore ground truth instances with area outside the area range.
        if (0 != (int(hv_NumGT>0)))
        {
          TupleFind((hv_GtAreas.TupleLessElem(hv_MinArea)).TupleOr(hv_GtAreas.TupleGreaterElem(hv_MaxArea)), 
              1, &hv_GtIgnoreInds);
          if (0 != (int(hv_GtIgnoreInds>-1)))
          {
            hv_GtIgnore[hv_GtIgnoreInds] = 1;
          }
        }
        //
        GetDictTuple(hv_AreaRunningMeasures, "num_gt", &hv_PerClassNumGt);
        GetDictTuple(hv_AreaRunningMeasures, "num_pred", &hv_PerClassNumPred);
        GetDictTuple(hv_AreaRunningMeasures, "confidence", &hv_PerClassConfidences);
        GetDictTuple(hv_AreaRunningMeasures, "num_gt_ignore", &hv_PerClassNumGtIgnore);
        //
        if (0 != hv_DetailedEvaluation)
        {
          //Store if a sample has at least one false positive or false negative (for each IoU threshold).
          hv_SampleHasFP = HTuple(hv_IoUThresholds.TupleLength(),0);
          hv_SampleHasFN = HTuple(hv_IoUThresholds.TupleLength(),0);
        }
        //
        //Loop over the classes.
        {
        HTuple end_val127 = hv_NumClasses-1;
        HTuple step_val127 = 1;
        for (hv_ClsIdx=0; hv_ClsIdx.Continue(end_val127, step_val127); hv_ClsIdx += step_val127)
        {
          hv_CurrentClassID = HTuple(hv_ClassIDs[hv_ClsIdx]);
          //
          //Get the ground truth for this class.
          hv_CurrentGtIdxs = hv_GtClassIDs.TupleFind(hv_CurrentClassID);
          if (0 != (int(hv_CurrentGtIdxs==-1)))
          {
            hv_CurrentGtIdxs = HTuple();
          }
          hv_CurrentNumGt = hv_CurrentGtIdxs.TupleLength();
          //
          //Get ground truth ignore for this class.
          hv_CurrentGtIgnore = HTuple(hv_GtIgnore[hv_CurrentGtIdxs]);
          if (0 != (int((hv_CurrentGtIgnore.TupleLength())==0)))
          {
            hv_CurrentNumGtIgnore = 0;
          }
          else
          {
            hv_CurrentNumGtIgnore = hv_CurrentGtIgnore.TupleSum();
          }
          //
          //Number of gt for this class and without ignore.
          hv_CurrentNumGtNoIgnore = hv_CurrentNumGt-hv_CurrentNumGtIgnore;
          //
          //Get results for this class.
          hv_CurrentResIdxs = hv_ResClassIDs.TupleFind(hv_CurrentClassID);
          if (0 != (int(hv_CurrentResIdxs==-1)))
          {
            hv_CurrentResIdxs = HTuple();
          }
          hv_CurrentNumRes = hv_MaxNum.TupleMin2(hv_CurrentResIdxs.TupleLength());
          //MaxNum -1 corresponds to taking all results.
          if (0 != (int(hv_MaxNum==-1)))
          {
            hv_CurrentNumRes = hv_CurrentResIdxs.TupleLength();
          }
          hv_CurrentResIdxs = hv_CurrentResIdxs.TupleSelectRange(0,hv_CurrentNumRes-1);
          //
          //Get areas of the current results.
          hv_CurrentResAreas = HTuple(hv_ResAreas[hv_CurrentResIdxs]);
          //
          //Update the confidences, num_gt and num_pred for this class.
          hv_OldNumPred = HTuple(hv_PerClassNumPred[hv_ClsIdx]);
          hv_PerClassNumGt[hv_ClsIdx] = HTuple(hv_PerClassNumGt[hv_ClsIdx])+hv_CurrentNumGt;
          hv_PerClassNumGtIgnore[hv_ClsIdx] = HTuple(hv_PerClassNumGtIgnore[hv_ClsIdx])+hv_CurrentNumGtIgnore;
          hv_PerClassNumPred[hv_ClsIdx] = HTuple(hv_PerClassNumPred[hv_ClsIdx])+hv_CurrentNumRes;
          GetDictTuple(hv_PerClassConfidences, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), 
              &hv_CurrentClassConfidences);
          //Confidences are allocated in blocks of AllocationBlockLength. Therefore, we have to check
          //if the allocated block is long enough, otherwise allocate a new block.
          if (0 != (int(HTuple(hv_PerClassNumPred[hv_ClsIdx])>(hv_CurrentClassConfidences.TupleLength()))))
          {
            hv_CurrentClassConfidences = hv_CurrentClassConfidences.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
          }
          hv_CurrentClassConfidences[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = HTuple(hv_Confidences[hv_CurrentResIdxs]);
          SetDictTuple(hv_PerClassConfidences, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), 
              hv_CurrentClassConfidences);
          //
          //Sort the ground truth: Non-ignored instances first.
          hv_GtSortIdx = hv_CurrentGtIgnore.TupleSortIndex();
          hv_CurrentGtIgnore = HTuple(hv_CurrentGtIgnore[hv_GtSortIdx]);
          hv_CurrentGtIdxs = HTuple(hv_CurrentGtIdxs[hv_GtSortIdx]);
          //
          //Get orientations of result and ground truth instances.
          if (0 != hv_EvaluateOrientation)
          {
            hv_CurrentResPhis = HTuple(hv_ResPhis[hv_CurrentResIdxs]);
            hv_CurrentGtPhis = HTuple(hv_GtPhis[hv_CurrentGtIdxs]);
          }
          //
          if (0 != (int(hv_CurrentNumRes>0)))
          {
            //Loop over IoU thresholds.
            {
            HTuple end_val190 = (hv_IoUThresholds.TupleLength())-1;
            HTuple step_val190 = 1;
            for (hv_ITIdx=0; hv_ITIdx.Continue(end_val190, step_val190); hv_ITIdx += step_val190)
            {
              //We check which ground truth and
              //result instance can be matched.
              hv_GtMatched = HTuple(hv_CurrentNumGt,0);
              hv_ResMatched = HTuple(hv_CurrentNumRes,0);
              //
              if (0 != hv_EvaluateOrientation)
              {
                //Initialize the absolute orientation difference to -1.
                hv_ResAbsOrientationDiff = HTuple(hv_CurrentNumRes,-1);
              }
              //Store which detections should be ignored.
              hv_ResIgnore = HTuple(hv_CurrentNumRes,0);
              {
              HTuple end_val202 = hv_CurrentNumRes-1;
              HTuple step_val202 = 1;
              for (hv_ResIdx=0; hv_ResIdx.Continue(end_val202, step_val202); hv_ResIdx += step_val202)
              {
                //Set the currently best achieved IoU to the IoU threshold and
                //initialize the matching index.
                hv_CurrentIoU = HTuple(hv_IoUThresholds[hv_ITIdx]).TupleMin2(1-1.0e-10);
                hv_MatchIdx = -1;
                //Loop over ground truth.
                {
                HTuple end_val208 = hv_CurrentNumGt-1;
                HTuple step_val208 = 1;
                for (hv_GtIdx=0; hv_GtIdx.Continue(end_val208, step_val208); hv_GtIdx += step_val208)
                {
                  //Continue if this ground truth has already been matched.
                  if (0 != (HTuple(hv_GtMatched[hv_GtIdx])))
                  {
                    continue;
                  }
                  //Stop if matched with non-ignored ground truth and current ground truth is on ignore.
                  if (0 != (int(hv_MatchIdx>-1)))
                  {
                    if (0 != (HTuple(int(HTuple(hv_CurrentGtIgnore[hv_MatchIdx])==0)).TupleAnd(int(HTuple(hv_CurrentGtIgnore[hv_GtIdx])==1))))
                    {
                      break;
                    }
                  }
                  //Continue if IoU is not better than a previous match.
                  if (0 != (int(HTuple(hv_IoUs[(HTuple(hv_CurrentGtIdxs[hv_GtIdx])*hv_NumRes)+HTuple(hv_CurrentResIdxs[hv_ResIdx])])<hv_CurrentIoU)))
                  {
                    continue;
                  }
                  //We got a new best match, store it.
                  hv_CurrentIoU = HTuple(hv_IoUs[(HTuple(hv_CurrentGtIdxs[hv_GtIdx])*hv_NumRes)+HTuple(hv_CurrentResIdxs[hv_ResIdx])]);
                  hv_MatchIdx = hv_GtIdx;
                }
                }
                //If a match has been made we store it for both ground truth and result.
                if (0 != (int(hv_MatchIdx!=-1)))
                {
                  //In COCO they use the IDs of GT and Res, we just use 1
                  //to indicate the matching, but don't store which one has been matched.
                  hv_ResMatched[hv_ResIdx] = 1;
                  hv_GtMatched[hv_MatchIdx] = 1;
                  hv_ResIgnore[hv_ResIdx] = HTuple(hv_CurrentGtIgnore[hv_MatchIdx]);
                  //
                  if (0 != hv_EvaluateOrientation)
                  {
                    //Set the absolute orientation difference.
                    hv_ResAbsOrientationDiff[hv_ResIdx] = (HTuple(hv_CurrentResPhis[hv_ResIdx])-HTuple(hv_CurrentGtPhis[hv_MatchIdx])).TupleAbs();
                    if (0 != (int(HTuple(hv_ResAbsOrientationDiff[hv_ResIdx])>(HTuple(180).TupleRad()))))
                    {
                      hv_ResAbsOrientationDiff[hv_ResIdx] = (HTuple(360).TupleRad())-HTuple(hv_ResAbsOrientationDiff[hv_ResIdx]);
                    }
                  }
                }
              }
              }
              //Ignore the unmatched results that are outside of the current area range.
              hv_AreaIgnore = (hv_CurrentResAreas.TupleLessElem(hv_MinArea)).TupleOr(hv_CurrentResAreas.TupleGreaterElem(hv_MaxArea));
              hv_ResIgnore = HTuple((hv_ResMatched.TupleEqualElem(-1)).TupleAnd(hv_AreaIgnore.TupleEqualElem(1))).TupleOr(hv_ResIgnore);
              //True positives are the matched results.
              GetDictTuple(hv_AreaRunningMeasures, "iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")), 
                  &hv_PerIoUMeasure);
              GetDictTuple(hv_PerIoUMeasure, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), 
                  &hv_PerClassMeasures);
              GetDictTuple(hv_PerClassMeasures, "is_tp", &hv_CurrentIsTP);
              //As for confidences, check if we have to allocate a new block.
              if (0 != (int(HTuple(hv_PerClassNumPred[hv_ClsIdx])>(hv_CurrentIsTP.TupleLength()))))
              {
                hv_CurrentIsTP = hv_CurrentIsTP.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
              }
              hv_CurrentIsTP[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResMatched;
              SetDictTuple(hv_PerClassMeasures, "is_tp", hv_CurrentIsTP);
              //Set the ignored results.
              GetDictTuple(hv_PerClassMeasures, "ignore", &hv_CurrentIgnore);
              if (0 != (int(HTuple(hv_PerClassNumPred[hv_ClsIdx])>(hv_CurrentIgnore.TupleLength()))))
              {
                hv_CurrentIgnore = hv_CurrentIgnore.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
              }
              hv_CurrentIgnore[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResIgnore;
              SetDictTuple(hv_PerClassMeasures, "ignore", hv_CurrentIgnore);
              //Set the absolute orientation difference.
              if (0 != hv_EvaluateOrientation)
              {
                GetDictTuple(hv_PerClassMeasures, "abs_orientation_diff", &hv_CurrentAbsOrientationDiff);
                if (0 != (int(HTuple(hv_PerClassNumPred[hv_ClsIdx])>(hv_CurrentAbsOrientationDiff.TupleLength()))))
                {
                  hv_CurrentAbsOrientationDiff = hv_CurrentAbsOrientationDiff.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                }
                hv_CurrentAbsOrientationDiff[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResAbsOrientationDiff;
                SetDictTuple(hv_PerClassMeasures, "abs_orientation_diff", hv_CurrentAbsOrientationDiff);
              }
              //
              //Beginning of detailed evaluation processing (optional).
              //
              if (0 != hv_DetailedEvaluation)
              {
                //Check if there have been false negatives.
                if (0 != (int(hv_CurrentNumGtNoIgnore>0)))
                {
                  hv_GtMatchedNoIgnore = hv_GtMatched.TupleAnd(hv_CurrentGtIgnore.TupleNot());
                  if (0 != (int((hv_GtMatchedNoIgnore.TupleSum())<hv_CurrentNumGtNoIgnore)))
                  {
                    hv_SampleHasFN[hv_ITIdx] = 1;
                  }
                }
                //
                //Initialize the detailed running measures.
                hv_ResIsFPClass = HTuple(hv_CurrentNumRes,-1);
                hv_ResIsFPBackground = HTuple(hv_CurrentNumRes,0);
                hv_ResIsFPLocalization = HTuple(hv_CurrentNumRes,0);
                hv_ResIsFPDuplicate = HTuple(hv_CurrentNumRes,0);
                hv_ResIsFPMultiple = HTuple(hv_CurrentNumRes,0);
                //
                //Initialize detailed running measures for orientation difference.
                if (0 != hv_EvaluateOrientation)
                {
                  hv_ResAbsOrientationDiffClass = HTuple(hv_CurrentNumRes,-1);
                  hv_ResAbsOrientationDiffLocalization = HTuple(hv_CurrentNumRes,-1);
                  hv_ResAbsOrientationDiffDuplicate = HTuple(hv_CurrentNumRes,-1);
                  hv_ResAbsOrientationDiffMultiple = HTuple(hv_CurrentNumRes,-1);
                }
                //Check if there have been false positives.
                if (0 != (int((hv_ResMatched.TupleSum())<hv_CurrentNumRes)))
                {
                  hv_SampleHasFP[hv_ITIdx] = 1;
                  //
                  //For each false positive, find out what was the reason for being false positive:
                  hv_FPResIdxsThisClass = hv_ResMatched.TupleFind(0);
                  hv_FPResIdxsAllResults = HTuple(hv_CurrentResIdxs[hv_FPResIdxsThisClass]);
                  hv_GTIdxsNotToIgnore = hv_GtIgnore.TupleFind(0);
                  {
                  HTuple end_val307 = (hv_FPResIdxsThisClass.TupleLength())-1;
                  HTuple step_val307 = 1;
                  for (hv_ResIdx=0; hv_ResIdx.Continue(end_val307, step_val307); hv_ResIdx += step_val307)
                  {
                    if (0 != (HTuple(hv_ResIgnore[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])]).TupleNot()))
                    {
                      if (0 != (HTuple(int((hv_GTIdxsNotToIgnore.TupleLength())==0)).TupleOr(int(hv_GTIdxsNotToIgnore==-1))))
                      {
                        //No GT instances or all GT instances are ignored.
                        //Thus, any detection is a background detection
                        hv_MaxIoU = 0.0;
                      }
                      else
                      {
                        //We have GT instances to consider.
                        hv_IoUsWithGT = HTuple(hv_IoUs[(hv_GTIdxsNotToIgnore*hv_NumRes)+HTuple(hv_FPResIdxsAllResults[hv_ResIdx])]);
                        hv_MaxIoU = hv_IoUsWithGT.TupleMax();
                        //It is enough to look for the first occurrence because the IoUs to ground truth should be different.
                        hv_MaxIdx = hv_IoUsWithGT.TupleFindFirst(hv_MaxIoU);
                        hv_GTClassIDMaxIoU = HTuple(hv_GtClassIDs[HTuple(hv_GTIdxsNotToIgnore[hv_MaxIdx])]);
                      }
                      if (0 != (hv_EvaluateOrientation.TupleAnd(int(hv_MaxIoU>0.0))))
                      {
                        //Calculate the absolute orientation difference to the GT instance with maximal IoU.
                        hv_AbsOrientationDiff = (HTuple(hv_ResPhis[HTuple(hv_FPResIdxsAllResults[hv_ResIdx])])-HTuple(hv_GtPhis[HTuple(hv_GTIdxsNotToIgnore[hv_MaxIdx])])).TupleAbs();
                        if (0 != (int(hv_AbsOrientationDiff>(HTuple(180).TupleRad()))))
                        {
                          hv_AbsOrientationDiff = (HTuple(360).TupleRad())-hv_AbsOrientationDiff;
                        }
                      }
                      //Determine false positive type.
                      if (0 != (int(hv_MaxIoU==0.0)))
                      {
                        //Background detection. This detection does not overlap to any ground truth (that is not ignored).
                        hv_ResIsFPBackground[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = 1;
                      }
                      else if (0 != (HTuple(int(hv_MaxIoU>=HTuple(hv_IoUThresholds[hv_ITIdx]))).TupleAnd(int(hv_CurrentClassID!=hv_GTClassIDMaxIoU))))
                      {
                        //False class.
                        //Note that this does not necessarily mean that this detection
                        //would be a true positive if the class was changed. It could still be a duplicate.
                        hv_ResIsFPClass[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = HTuple(hv_ClassIDToClassIdx[hv_GTClassIDMaxIoU]);
                        //Store the absolute orientation difference.
                        if (0 != hv_EvaluateOrientation)
                        {
                          hv_ResAbsOrientationDiffClass[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = hv_AbsOrientationDiff;
                        }
                      }
                      else if (0 != (HTuple(int(hv_MaxIoU>=HTuple(hv_IoUThresholds[hv_ITIdx]))).TupleAnd(int(hv_CurrentClassID==hv_GTClassIDMaxIoU))))
                      {
                        //Duplicate detection. There must exist another detection with a higher confidence with the same ground truth.
                        hv_ResIsFPDuplicate[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = 1;
                        //Store the absolute orientation difference.
                        if (0 != hv_EvaluateOrientation)
                        {
                          hv_ResAbsOrientationDiffDuplicate[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = hv_AbsOrientationDiff;
                        }
                      }
                      else if (0 != (HTuple(int(hv_MaxIoU<HTuple(hv_IoUThresholds[hv_ITIdx]))).TupleAnd(int(hv_CurrentClassID==hv_GTClassIDMaxIoU))))
                      {
                        //Bad localization. Class is correct, but the IoU is too low.
                        hv_ResIsFPLocalization[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = 1;
                        //Store the absolute orientation difference.
                        if (0 != hv_EvaluateOrientation)
                        {
                          hv_ResAbsOrientationDiffLocalization[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = hv_AbsOrientationDiff;
                        }
                      }
                      else if (0 != (HTuple(int(hv_MaxIoU<HTuple(hv_IoUThresholds[hv_ITIdx]))).TupleAnd(int(hv_CurrentClassID!=hv_GTClassIDMaxIoU))))
                      {
                        //Wrong class and bad localization.
                        hv_ResIsFPMultiple[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = 1;
                        //Store the absolute orientation difference.
                        if (0 != hv_EvaluateOrientation)
                        {
                          hv_ResAbsOrientationDiffMultiple[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = hv_AbsOrientationDiff;
                        }
                      }
                      else
                      {
                        //This case should never occur.
                        throw HException("Fatal error during detailed evaluation.");
                      }
                    }
                  }
                  }
                }
                //
                //Overwrite the detailed running measures.
                GetDictTuple(hv_PerClassMeasures, "is_fp_class", &hv_IsFPClass);
                GetDictTuple(hv_PerClassMeasures, "is_fp_background", &hv_IsFPBackground);
                GetDictTuple(hv_PerClassMeasures, "is_fp_localization", &hv_IsFPLocalization);
                GetDictTuple(hv_PerClassMeasures, "is_fp_duplicate", &hv_IsFPDuplicate);
                GetDictTuple(hv_PerClassMeasures, "is_fp_multiple", &hv_IsFPMultiple);
                if (0 != hv_EvaluateOrientation)
                {
                  GetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_multiple", 
                      &hv_AbsOrientationDiffMultiple);
                  GetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_duplicate", 
                      &hv_AbsOrientationDiffDuplicate);
                  GetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_localization", 
                      &hv_AbsOrientationDiffLocalization);
                  GetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_class", 
                      &hv_AbsOrientationDiffClass);
                }
                //Allocate new blocks if necessary (all have the same length).
                if (0 != (int(HTuple(hv_PerClassNumPred[hv_ClsIdx])>(hv_IsFPClass.TupleLength()))))
                {
                  hv_IsFPClass = hv_IsFPClass.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                  hv_IsFPBackground = hv_IsFPBackground.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                  hv_IsFPLocalization = hv_IsFPLocalization.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                  hv_IsFPDuplicate = hv_IsFPDuplicate.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                  hv_IsFPMultiple = hv_IsFPMultiple.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                  if (0 != hv_EvaluateOrientation)
                  {
                    hv_AbsOrientationDiffMultiple = hv_AbsOrientationDiffMultiple.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                    hv_AbsOrientationDiffDuplicate = hv_AbsOrientationDiffDuplicate.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                    hv_AbsOrientationDiffLocalization = hv_AbsOrientationDiffLocalization.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                    hv_AbsOrientationDiffClass = hv_AbsOrientationDiffClass.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                  }
                }
                hv_IsFPClass[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResIsFPClass;
                hv_IsFPBackground[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResIsFPBackground;
                hv_IsFPLocalization[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResIsFPLocalization;
                hv_IsFPDuplicate[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResIsFPDuplicate;
                hv_IsFPMultiple[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResIsFPMultiple;
                if (0 != hv_EvaluateOrientation)
                {
                  hv_AbsOrientationDiffMultiple[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResAbsOrientationDiffMultiple;
                  hv_AbsOrientationDiffDuplicate[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResAbsOrientationDiffDuplicate;
                  hv_AbsOrientationDiffLocalization[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResAbsOrientationDiffLocalization;
                  hv_AbsOrientationDiffClass[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResAbsOrientationDiffClass;
                }
                SetDictTuple(hv_PerClassMeasures, "is_fp_class", hv_IsFPClass);
                SetDictTuple(hv_PerClassMeasures, "is_fp_background", hv_IsFPBackground);
                SetDictTuple(hv_PerClassMeasures, "is_fp_localization", hv_IsFPLocalization);
                SetDictTuple(hv_PerClassMeasures, "is_fp_duplicate", hv_IsFPDuplicate);
                SetDictTuple(hv_PerClassMeasures, "is_fp_multiple", hv_IsFPMultiple);
                if (0 != hv_EvaluateOrientation)
                {
                  SetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_multiple", 
                      hv_AbsOrientationDiffMultiple);
                  SetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_duplicate", 
                      hv_AbsOrientationDiffDuplicate);
                  SetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_localization", 
                      hv_AbsOrientationDiffLocalization);
                  SetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_class", 
                      hv_AbsOrientationDiffClass);
                }
              }
              //
              //End of detailed evaluation processing.
              //
            }
            }
          }
          else
          {
            if (0 != (hv_DetailedEvaluation.TupleAnd(int(hv_CurrentNumGtNoIgnore>0))))
            {
              //There are false negatives for this class.
              //Loop over IoU thresholds.
              {
              HTuple end_val427 = (hv_IoUThresholds.TupleLength())-1;
              HTuple step_val427 = 1;
              for (hv_ITIdx=0; hv_ITIdx.Continue(end_val427, step_val427); hv_ITIdx += step_val427)
              {
                hv_SampleHasFN[hv_ITIdx] = 1;
              }
              }
            }
          }
        }
        }
        //Update the confidences, num_gt and num_pred.
        SetDictTuple(hv_AreaRunningMeasures, "num_gt", hv_PerClassNumGt);
        SetDictTuple(hv_AreaRunningMeasures, "num_pred", hv_PerClassNumPred);
        SetDictTuple(hv_AreaRunningMeasures, "confidence", hv_PerClassConfidences);
        SetDictTuple(hv_AreaRunningMeasures, "num_gt_ignore", hv_PerClassNumGtIgnore);
        //
        if (0 != hv_DetailedEvaluation)
        {
          //Set values that are calculated over all classes (for each IoU threshold).
          {
          HTuple end_val441 = (hv_IoUThresholds.TupleLength())-1;
          HTuple step_val441 = 1;
          for (hv_ITIdx=0; hv_ITIdx.Continue(end_val441, step_val441); hv_ITIdx += step_val441)
          {
            GetDictTuple(hv_AreaRunningMeasures, "iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")), 
                &hv_PerIoUMeasure);
            //Set image IDs with false negatives
            if (0 != (HTuple(hv_SampleHasFN[hv_ITIdx])))
            {
              GetDictTuple(hv_CurrentSample, "image_id", &hv_CurrentImageID);
              GetDictTuple(hv_PerIoUMeasure, "image_ids_with_false_negatives", &hv_ImageIDsWithFN);
              GetDictTuple(hv_PerIoUMeasure, "num_image_ids_with_false_negatives", 
                  &hv_NumImageIDsWithFN);
              //Allocate a new block if necessary.
              if (0 != (int((hv_NumImageIDsWithFN+1)>(hv_ImageIDsWithFN.TupleLength()))))
              {
                hv_ImageIDsWithFN = hv_ImageIDsWithFN.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
              }
              hv_ImageIDsWithFN[hv_NumImageIDsWithFN] = hv_CurrentImageID;
              SetDictTuple(hv_PerIoUMeasure, "image_ids_with_false_negatives", hv_ImageIDsWithFN);
              SetDictTuple(hv_PerIoUMeasure, "num_image_ids_with_false_negatives", 
                  hv_NumImageIDsWithFN+1);
            }
            if (0 != (HTuple(hv_SampleHasFP[hv_ITIdx])))
            {
              GetDictTuple(hv_CurrentSample, "image_id", &hv_CurrentImageID);
              GetDictTuple(hv_PerIoUMeasure, "image_ids_with_false_positives", &hv_ImageIDsWithFP);
              GetDictTuple(hv_PerIoUMeasure, "num_image_ids_with_false_positives", 
                  &hv_NumImageIDsWithFP);
              //Allocate a new block if necessary.
              if (0 != (int((hv_NumImageIDsWithFP+1)>(hv_ImageIDsWithFP.TupleLength()))))
              {
                hv_ImageIDsWithFP = hv_ImageIDsWithFP.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
              }
              hv_ImageIDsWithFP[hv_NumImageIDsWithFP] = hv_CurrentImageID;
              SetDictTuple(hv_PerIoUMeasure, "image_ids_with_false_positives", hv_ImageIDsWithFP);
              SetDictTuple(hv_PerIoUMeasure, "num_image_ids_with_false_positives", 
                  hv_NumImageIDsWithFP+1);
            }
          }
          }
        }
      }
      }
      SetDictTuple(hv_CurrentRunningMeasures, "area_"+hv_AreaName, hv_AreaRunningMeasures);
    }
    }
  }
  }
  //
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Update running measures for an OCR recognition evaluation. 
void update_running_ocr_recognition_measures (HTuple hv_Samples, HTuple hv_Results, 
    HTuple hv_EvalParams, HTuple hv_RunningMeasures)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_N, hv_ImageIDsBatch, hv_WordsPredictionBatch;
  HTuple  hv_WordsGroundTruthBatch, hv_SampleIndex, hv_Sample;
  HTuple  hv_Result;

  //
  //This procedure updates the RunningMeasures for an evaluation for OCR recognition.
  //
  //These measures are stored in the dictionary RunningMeasures and
  //updated by incorporating the Results the model obtained for the Samples.
  //
  //
  hv_N = hv_Samples.TupleLength();
  TupleGenConst(hv_N, 0, &hv_ImageIDsBatch);
  TupleGenConst(hv_N, 0, &hv_WordsPredictionBatch);
  TupleGenConst(hv_N, 0, &hv_WordsGroundTruthBatch);
  //Loop over all samples and update running measures accordingly.
  {
  HTuple end_val12 = hv_N-1;
  HTuple step_val12 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val12, step_val12); hv_SampleIndex += step_val12)
  {
    hv_Sample = HTuple(hv_Samples[hv_SampleIndex]);
    hv_Result = HTuple(hv_Results[hv_SampleIndex]);
    hv_ImageIDsBatch[hv_SampleIndex] = hv_Sample.TupleGetDictTuple("image_id");
    hv_WordsPredictionBatch[hv_SampleIndex] = hv_Result.TupleGetDictTuple("word");
    hv_WordsGroundTruthBatch[hv_SampleIndex] = hv_Sample.TupleGetDictTuple("word");
  }
  }
  //
  //Update running measures
  SetDictTuple(hv_RunningMeasures, "image_ids", (hv_RunningMeasures.TupleGetDictTuple("image_ids")).TupleConcat(hv_ImageIDsBatch));
  SetDictTuple(hv_RunningMeasures, "words_prediction", (hv_RunningMeasures.TupleGetDictTuple("words_prediction")).TupleConcat(hv_WordsPredictionBatch));
  SetDictTuple(hv_RunningMeasures, "words_ground_truth", (hv_RunningMeasures.TupleGetDictTuple("words_ground_truth")).TupleConcat(hv_WordsGroundTruthBatch));
  //
  return;
}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Update running measures for a pixel-based evaluation. 
void update_running_pixel_measures (HTuple hv_Samples, HTuple hv_Results, HTuple hv_EvalParams, 
    HTuple hv_RunningMeasures)
{

  // Local iconic variables
  HObject  ho_Annot, ho_Result, ho_ClsIgnore, ho_ClsIgnoreTmp;
  HObject  ho_ClsAnnot, ho_ClsResult, ho_TPReg, ho_FPReg, ho_FNReg;

  // Local control variables
  HTuple  hv_EvaluationType, hv_Measures, hv_PixelMeasures;
  HTuple  hv_ClassIDs, hv_NumClasses, hv_IgnoreClassIDs, hv_CalcConfMatrix;
  HTuple  hv_SegmentationImageExists, hv_GrippingMapExists;
  HTuple  hv_ResultKey, hv_ClassIDsResult, hv_ConfMatrix;
  HTuple  hv_MapClassIDs, hv_ClsIdToClsIdx, hv_TP, hv_FP;
  HTuple  hv_FN, hv_SampleIndex, hv_Rows, hv_Columns, hv_AnnotVals;
  HTuple  hv_ResultVals, hv_ConfTuple, hv_ConfHist, hv_BinSize;
  HTuple  hv_ConfMatrixTmp, hv_IgnoreIndex, hv_ClsIndex, hv_ClsId;
  HTuple  hv_ClsIdRes, hv_ClsTP, hv_ClsFP, hv_ClsFN;

  //
  //This procedure updates the RunningMeasures for a pixel-
  //based evaluation for segmentation or 3D Gripping Point
  //Detection. These measures are stored in the dictionary
  //RunningMeasures and updated by incorporating the Results
  //the model obtained for the Samples.
  //
  //Get evaluation type.
  GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
  //Get evaluation measures.
  GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
  //Check if any pixel measures are requested.
  get_requested_pixel_measures(hv_Measures, hv_EvaluationType, &hv_PixelMeasures);
  if (0 != (int((hv_PixelMeasures.TupleLength())==0)))
  {
    return;
  }
  //
  //Get the class IDs.
  GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
  //Get the number of classes.
  GetDictTuple(hv_EvalParams, "num_classes", &hv_NumClasses);
  //Get the ignore class IDs.
  GetDictTuple(hv_EvalParams, "ignore_class_ids", &hv_IgnoreClassIDs);
  //
  //Check if we need to compute/update the confusion matrix.
  hv_CalcConfMatrix = int((hv_PixelMeasures.TupleFind("pixel_confusion_matrix"))>-1);
  //
  //Check and set result type and class IDs.
  GetDictParam(HTuple(hv_Results[0]), "key_exists", "segmentation_image", &hv_SegmentationImageExists);
  GetDictParam(HTuple(hv_Results[0]), "key_exists", "gripping_map", &hv_GrippingMapExists);
  if (0 != hv_SegmentationImageExists)
  {
    hv_ResultKey = "segmentation_image";
    //Class IDs in the result are the same as in the groundtruth.
    hv_ClassIDsResult = hv_ClassIDs;
  }
  else if (0 != hv_GrippingMapExists)
  {
    hv_ResultKey = "gripping_map";
    //Since the result is a binary gripping map, the class ID
    //is always 1.
    hv_ClassIDsResult = 1;
  }
  else
  {
    throw HException("No result available for evaluation");
  }
  //
  if (0 != hv_CalcConfMatrix)
  {
    //Get the current confusion matrix.
    GetDictTuple(hv_RunningMeasures, "pixel_confusion_matrix", &hv_ConfMatrix);
    //Check if we need to map the class IDs.
    GetDictParam(hv_EvalParams, "key_exists", "class_id_mapping", &hv_MapClassIDs);
    if (0 != hv_MapClassIDs)
    {
      GetDictTuple(hv_EvalParams, "class_id_mapping", &hv_ClsIdToClsIdx);
      hv_NumClasses = (hv_ClsIdToClsIdx.TupleMax())+1;
    }
  }
  else
  {
    //Get the tuples for TP/FP/FN
    GetDictTuple(hv_RunningMeasures, "tp", &hv_TP);
    GetDictTuple(hv_RunningMeasures, "fp", &hv_FP);
    GetDictTuple(hv_RunningMeasures, "fn", &hv_FN);
  }
  //
  //Loop over images, i.e. sample dictionaries.
  {
  HTuple end_val60 = (hv_Samples.TupleLength())-1;
  HTuple step_val60 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val60, step_val60); hv_SampleIndex += step_val60)
  {
    //Get annotation.
    GetDictObject(&ho_Annot, HTuple(hv_Samples[hv_SampleIndex]), "segmentation_image");
    //Get result.
    GetDictObject(&ho_Result, HTuple(hv_Results[hv_SampleIndex]), hv_ResultKey);
    //
    //Update the measures.
    if (0 != hv_CalcConfMatrix)
    {
      //Get the ground truth and predicted class IDs of all pixels.
      GetRegionPoints(ho_Annot, &hv_Rows, &hv_Columns);
      GetGrayval(ho_Annot, hv_Rows, hv_Columns, &hv_AnnotVals);
      GetGrayval(ho_Result, hv_Rows, hv_Columns, &hv_ResultVals);
      //Map the class IDs to class indices.
      if (0 != hv_MapClassIDs)
      {
        hv_AnnotVals = HTuple(hv_ClsIdToClsIdx[hv_AnnotVals]);
        hv_ResultVals = HTuple(hv_ClsIdToClsIdx[hv_ResultVals]);
      }
      //The ground truth and predicted IDs are accumulated
      //such that each confusion pair (class_i <-> class_j) gets a unique value.
      hv_ConfTuple = (hv_NumClasses*hv_AnnotVals)+hv_ResultVals;
      //Compute the histogram of this confusion tuple.
      TupleHistoRange(hv_ConfTuple, 0, (hv_NumClasses*hv_NumClasses)-1, hv_NumClasses*hv_NumClasses, 
          &hv_ConfHist, &hv_BinSize);
      CreateMatrix(hv_NumClasses, hv_NumClasses, hv_ConfHist, &hv_ConfMatrixTmp);
      TransposeMatrix(hv_ConfMatrixTmp, &hv_ConfMatrixTmp);
      AddMatrix(hv_ConfMatrix, hv_ConfMatrixTmp, &hv_ConfMatrix);
    }
    else
    {
      //Get the ignore region.
      GenEmptyRegion(&ho_ClsIgnore);
      {
      HTuple end_val88 = (hv_IgnoreClassIDs.TupleLength())-1;
      HTuple step_val88 = 1;
      for (hv_IgnoreIndex=0; hv_IgnoreIndex.Continue(end_val88, step_val88); hv_IgnoreIndex += step_val88)
      {
        Threshold(ho_Annot, &ho_ClsIgnoreTmp, HTuple(hv_IgnoreClassIDs[hv_IgnoreIndex]), 
            HTuple(hv_IgnoreClassIDs[hv_IgnoreIndex]));
        Union2(ho_ClsIgnore, ho_ClsIgnoreTmp, &ho_ClsIgnore);
      }
      }
      //
      //Go through model classes.
      {
      HTuple end_val94 = (hv_ClassIDs.TupleLength())-1;
      HTuple step_val94 = 1;
      for (hv_ClsIndex=0; hv_ClsIndex.Continue(end_val94, step_val94); hv_ClsIndex += step_val94)
      {
        hv_ClsId = HTuple(hv_ClassIDs[hv_ClsIndex]);
        hv_ClsIdRes = HTuple(hv_ClassIDsResult[hv_ClsIndex]);
        //Get the annotated region for this class.
        Threshold(ho_Annot, &ho_ClsAnnot, hv_ClsId, hv_ClsId);
        //Get the result region for this class.
        Threshold(ho_Result, &ho_ClsResult, hv_ClsIdRes, hv_ClsIdRes);
        //The pixels in the ignore region should not be considered.
        Difference(ho_ClsResult, ho_ClsIgnore, &ho_ClsResult);
        //Get TP/FP/FN.
        Intersection(ho_ClsAnnot, ho_ClsResult, &ho_TPReg);
        Difference(ho_ClsResult, ho_ClsAnnot, &ho_FPReg);
        //We define false negatives as pixels that have been labeled as this class,
        //but not been correctly predicted.
        Difference(ho_ClsAnnot, ho_ClsResult, &ho_FNReg);
        //Get corresponding pixel numbers and update.
        RegionFeatures(ho_TPReg, "area", &hv_ClsTP);
        RegionFeatures(ho_FPReg, "area", &hv_ClsFP);
        RegionFeatures(ho_FNReg, "area", &hv_ClsFN);
        hv_TP[hv_ClsIndex] = HTuple(hv_TP[hv_ClsIndex])+hv_ClsTP;
        hv_FP[hv_ClsIndex] = HTuple(hv_FP[hv_ClsIndex])+hv_ClsFP;
        hv_FN[hv_ClsIndex] = HTuple(hv_FN[hv_ClsIndex])+hv_ClsFN;
      }
      }
    }
  }
  }
  //
  //Update running measures.
  if (0 != hv_CalcConfMatrix)
  {
    SetDictTuple(hv_RunningMeasures, "pixel_confusion_matrix", hv_ConfMatrix);
  }
  else
  {
    SetDictTuple(hv_RunningMeasures, "tp", hv_TP);
    SetDictTuple(hv_RunningMeasures, "fp", hv_FP);
    SetDictTuple(hv_RunningMeasures, "fn", hv_FN);
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Update running measures for a region-based evaluation. 
void update_running_region_measures (HTuple hv_Samples, HTuple hv_Results, HTuple hv_EvalParams, 
    HTuple hv_RunningMeasures)
{

  // Local iconic variables
  HObject  ho_Annot, ho_Result, ho_ClsAnnot, ho_ClsResult;
  HObject  ho_ClsAnnotConnected, ho_ClsAnnotSelected, ho_RegionIntersection;

  // Local control variables
  HTuple  hv_Measures, hv_CalcRegionMeasures, hv_ClassIDs;
  HTuple  hv_GrippingMapExists, hv_ResultKey, hv_ClassIDsResult;
  HTuple  hv_SampleIndex, hv_ClsIndex, hv_ClsId, hv_ClsIdRes;
  HTuple  hv_NumRegions, hv_RegionIndex, hv_AreaIntersection;
  HTuple  hv_AreaGroundtruth, hv_RegionOverlap;

  //
  //This procedure updates the RunningMeasures for a region-
  //based evaluation for 3D Gripping Point Detection.
  //These measures are stored in the dictionary RunningMeasures
  //and updated by incorporating the Results the model obtained
  //for the Samples.
  //
  //Check if we need to compute any region measures.
  GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
  hv_CalcRegionMeasures = HTuple(int((hv_Measures.TupleFind("mean_pro"))>-1)).TupleOr(int((hv_Measures.TupleFind("all"))>-1));
  if (0 != (hv_CalcRegionMeasures.TupleNot()))
  {
    return;
  }
  //
  //Get the class IDs.
  GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
  //
  //Check and set result type and class IDs.
  GetDictParam(HTuple(hv_Results[0]), "key_exists", "gripping_map", &hv_GrippingMapExists);
  if (0 != hv_GrippingMapExists)
  {
    hv_ResultKey = "gripping_map";
    //Since the result is a binary gripping map, the class ID
    //is always 1.
    hv_ClassIDsResult = 1;
  }
  else
  {
    throw HException("No result available for evaluation");
  }
  //
  //Loop over images, i.e. sample dictionaries.
  {
  HTuple end_val29 = (hv_Samples.TupleLength())-1;
  HTuple step_val29 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val29, step_val29); hv_SampleIndex += step_val29)
  {
    //Get annotation.
    GetDictObject(&ho_Annot, HTuple(hv_Samples[hv_SampleIndex]), "segmentation_image");
    //Get result.
    GetDictObject(&ho_Result, HTuple(hv_Results[hv_SampleIndex]), hv_ResultKey);
    //
    //Go through model classes.
    {
    HTuple end_val36 = (hv_ClassIDs.TupleLength())-1;
    HTuple step_val36 = 1;
    for (hv_ClsIndex=0; hv_ClsIndex.Continue(end_val36, step_val36); hv_ClsIndex += step_val36)
    {
      hv_ClsId = HTuple(hv_ClassIDs[hv_ClsIndex]);
      hv_ClsIdRes = HTuple(hv_ClassIDsResult[hv_ClsIndex]);
      //Get the annotated region for this class.
      Threshold(ho_Annot, &ho_ClsAnnot, hv_ClsId, hv_ClsId);
      //Get the result region for this class.
      Threshold(ho_Result, &ho_ClsResult, hv_ClsIdRes, hv_ClsIdRes);
      //
      Connection(ho_ClsAnnot, &ho_ClsAnnotConnected);
      SelectShape(ho_ClsAnnotConnected, &ho_ClsAnnotConnected, "area", "and", 1, 
          "max");
      CountObj(ho_ClsAnnotConnected, &hv_NumRegions);
      {
      HTuple end_val47 = hv_NumRegions;
      HTuple step_val47 = 1;
      for (hv_RegionIndex=1; hv_RegionIndex.Continue(end_val47, step_val47); hv_RegionIndex += step_val47)
      {
        SelectObj(ho_ClsAnnotConnected, &ho_ClsAnnotSelected, hv_RegionIndex);
        Intersection(ho_ClsResult, ho_ClsAnnotSelected, &ho_RegionIntersection);
        RegionFeatures(ho_RegionIntersection, "area", &hv_AreaIntersection);
        RegionFeatures(ho_ClsAnnotSelected, "area", &hv_AreaGroundtruth);
        hv_RegionOverlap = (hv_AreaIntersection.TupleReal())/(hv_AreaGroundtruth.TupleReal());
        SetDictTupleAt(hv_RunningMeasures, "gt_overlap", hv_ClsIndex, HTuple((hv_RunningMeasures.TupleGetDictTuple("gt_overlap"))[hv_ClsIndex])+hv_RegionOverlap);
        SetDictTupleAt(hv_RunningMeasures, "num_gt_regions", hv_ClsIndex, HTuple((hv_RunningMeasures.TupleGetDictTuple("num_gt_regions"))[hv_ClsIndex])+1);
      }
      }
    }
    }
  }
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Check that all given entries in EvalParams are valid. 
void validate_evaluation_param (HTuple hv_EvalParams, HTuple *hv_Valid, HTuple *hv_Exception)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ClassIDsExist, hv_ClassIDs, hv_NumClassesExist;
  HTuple  hv_NumClasses, hv_EvalInstancesExists, hv_EvaluationTypeExists;
  HTuple  hv_EvaluationType, hv_Indices, hv_MeasuresExists;
  HTuple  hv_Measures, hv_ValidMeasures, hv_Ks, hv_KeysExist;
  HTuple  hv_ClassNames, hv_ClassesToEvaluate, hv_ClassIDsToEvaluate;
  HTuple  hv_IouThreshExists, hv_IouThresholds, hv_MaxNumDetectionsExists;
  HTuple  hv_MaxNumDetections, hv_AreaRangesExist, hv_AreaRanges;
  HTuple  hv_AreaKeysExist, hv_AreaNames, hv_MinAreas, hv_MaxAreas;
  HTuple  hv_InstanceTypeExists, hv_InstanceType, hv_ValidInstanceTypes;
  HTuple  hv_AllocationBlockLengthExists, hv_AllocationBlockLength;
  HTuple  hv_DetailedEvaluationExists, hv_DetailedEvaluation;
  HTuple  hv_KeyExists, hv_InterpolatePRCurves, hv_IgnoreClassIDsExist;
  HTuple  hv_ValidMeasuresString, hv_Idx, hv_ValidMeasure;

  //
  //This procedure checks if the dictionary EvalParams
  //contains all necessary parameters and if they are valid (type, range, ...).
  //
  (*hv_Valid) = 0;
  (*hv_Exception) = "";
  //Check class IDs.
  GetDictParam(hv_EvalParams, "key_exists", "class_ids", &hv_ClassIDsExist);
  if (0 != (hv_ClassIDsExist.TupleNot()))
  {
    (*hv_Exception) = "The evaluation parameters need a key-value pair for 'class_ids'";
    return;
  }
  else
  {
    GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
    if (0 != (int((hv_ClassIDs.TupleLength())<1)))
    {
      (*hv_Exception) = "'class_ids' should have at least length 1";
      return;
    }
    if (0 != (int((hv_ClassIDs.TupleIsIntElem())!=HTuple(hv_ClassIDs.TupleLength(),1))))
    {
      (*hv_Exception) = "'class_ids' should be of type int";
      return;
    }
    if (0 != (int(((hv_ClassIDs.TupleLessElem(0)).TupleFind(1))>-1)))
    {
      (*hv_Exception) = "'class_ids' should be positive or zero";
      return;
    }
  }
  //Check the entry num_classes.
  GetDictParam(hv_EvalParams, "key_exists", "num_classes", &hv_NumClassesExist);
  if (0 != (hv_NumClassesExist.TupleNot()))
  {
    (*hv_Exception) = "The evaluation parameters need a key-value pair for 'num_classes'";
    return;
  }
  else
  {
    GetDictTuple(hv_EvalParams, "num_classes", &hv_NumClasses);
    if (0 != (int((hv_NumClasses.TupleLength())!=1)))
    {
      (*hv_Exception) = "'num_classes' should have length 1";
      return;
    }
    if (0 != (int((hv_NumClasses.TupleType())!=(HTuple(HTuple(1).TupleInt()).TupleType()))))
    {
      (*hv_Exception) = "'num_classes' should be of type int";
      return;
    }
    if (0 != (int(hv_NumClasses<1)))
    {
      (*hv_Exception) = "'num_classes' should be at least 1";
      return;
    }
  }
  //Check that num_classes is equal to |class_ids|.
  if (0 != (int(hv_NumClasses!=(hv_ClassIDs.TupleLength()))))
  {
    (*hv_Exception) = "'num_classes' has to be set to the number of 'class_ids'";
    return;
  }
  //Check the entry 'evaluate_instances'.
  GetDictParam(hv_EvalParams, "key_exists", "evaluate_instances", &hv_EvalInstancesExists);
  if (0 != (hv_EvalInstancesExists.TupleNot()))
  {
    (*hv_Exception) = "The evaluation parameters need a key-value pair for 'evaluate_instances'";
    return;
  }
  //Check the entry 'evaluation_type'.
  GetDictParam(hv_EvalParams, "key_exists", "evaluation_type", &hv_EvaluationTypeExists);
  if (0 != (hv_EvaluationTypeExists.TupleNot()))
  {
    (*hv_Exception) = "The evaluation parameters need a key-value pair for 'evaluation_type'";
    return;
  }
  else
  {
    GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
    TupleFind((((((((HTuple("3d_gripping_point_detection").Append("anomaly_detection")).Append("classification")).Append("detection")).Append("gc_anomaly_detection")).Append("ocr_recognition")).Append("ocr_detection")).Append("segmentation")), 
        hv_EvaluationType, &hv_Indices);
    if (0 != (HTuple(int(hv_Indices==-1)).TupleOr(int(hv_Indices==HTuple()))))
    {
      (*hv_Exception) = "Invalid entry for 'evaluation_type': "+hv_EvaluationType;
      return;
    }
  }
  //Check the entry 'measures'.
  GetDictParam(hv_EvalParams, "key_exists", "measures", &hv_MeasuresExists);
  if (0 != (hv_MeasuresExists.TupleNot()))
  {
    (*hv_Exception) = "The evaluation parameters need a key-value pair for 'measures'";
    return;
  }
  else
  {
    GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
    if (0 != (int((hv_Measures.TupleLength())==0)))
    {
      (*hv_Exception) = "'measures' should contain at least one entry";
      return;
    }
  }
  //Check evaluation type specific entries of EvalParams.
  GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
  if (0 != (int(hv_EvaluationType==HTuple("3d_gripping_point_detection"))))
  {
    //Pixel- and region-based evaluation.
    get_valid_pixel_measures(hv_EvaluationType, &hv_ValidMeasures);
    hv_ValidMeasures = hv_ValidMeasures.TupleConcat(((((HTuple("mean_pro").Append("gripping_point_precision")).Append("gripping_point_recall")).Append("gripping_point_f_score")).Append("all")));
  }
  else if (0 != (HTuple(int(hv_EvaluationType==HTuple("anomaly_detection"))).TupleOr(int(hv_EvaluationType==HTuple("gc_anomaly_detection")))))
  {
    //
    //Check for correct number of classes.
    if (0 != (int((hv_ClassIDs.TupleLength())!=2)))
    {
      throw HException("The number of classes must be 2 for model type 'anomaly_detection' or 'gc_anomaly_detection'.");
    }
    //
    hv_ValidMeasures.Clear();
    hv_ValidMeasures[0] = "anomaly_score_histogram";
    hv_ValidMeasures[1] = "precision";
    hv_ValidMeasures[2] = "recall";
    hv_ValidMeasures[3] = "absolute_confusion_matrix";
    hv_ValidMeasures[4] = "relative_confusion_matrix";
    hv_ValidMeasures[5] = "all";
  }
  else if (0 != (int(hv_EvaluationType==HTuple("classification"))))
  {
    TupleGenSequence(1, hv_ClassIDs.TupleLength(), 1, &hv_Ks);
    hv_ValidMeasures.Clear();
    hv_ValidMeasures[0] = "all";
    hv_ValidMeasures.Append(("top"+hv_Ks)+"_error");
    hv_ValidMeasures = hv_ValidMeasures.TupleConcat(((((HTuple("precision").Append("recall")).Append("f_score")).Append("absolute_confusion_matrix")).Append("relative_confusion_matrix")));
    //
    //Check if not both of the two options to specify the evaluated classes are chosen.
    GetDictParam(hv_EvalParams, "key_exists", (HTuple("class_names_to_evaluate").Append("class_ids_to_evaluate")), 
        &hv_KeysExist);
    if (0 != (int((hv_KeysExist.TupleSum())==2)))
    {
      (*hv_Exception) = "No more than one option of 'class_names_to_evaluate' and 'class_ids_to_evaluate' is allowed";
      return;
    }
    if (0 != (HTuple(hv_KeysExist[0])))
    {
      GetDictTuple(hv_EvalParams, "class_names", &hv_ClassNames);
      GetDictTuple(hv_EvalParams, "class_names_to_evaluate", &hv_ClassesToEvaluate);
      if (0 != (int((hv_ClassesToEvaluate.TupleDifference(hv_ClassNames.TupleConcat("global")))!=HTuple())))
      {
        (*hv_Exception) = "Invalid entry in 'class_names_to_evaluate'";
        return;
      }
    }
    if (0 != (HTuple(hv_KeysExist[1])))
    {
      GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
      GetDictTuple(hv_EvalParams, "class_ids_to_evaluate", &hv_ClassIDsToEvaluate);
      if (0 != (int((hv_ClassIDsToEvaluate.TupleDifference(hv_ClassIDs.TupleConcat("global")))!=HTuple())))
      {
        (*hv_Exception) = "Invalid entry in 'class_ids_to_evaluate'";
        return;
      }
    }
  }
  else if (0 != (int(hv_EvaluationType==HTuple("detection"))))
  {
    //Instance-based evaluation.
    //Add instance measures.
    hv_ValidMeasures.Clear();
    hv_ValidMeasures[0] = "all";
    hv_ValidMeasures[1] = "mean_ap";
    //
    //Check if the entry 'iou_threshold' is present.
    GetDictParam(hv_EvalParams, "key_exists", "iou_threshold", &hv_IouThreshExists);
    if (0 != (hv_IouThreshExists.TupleNot()))
    {
      (*hv_Exception) = "The evaluation parameters need a key-value pair for 'iou_threshold'";
      return;
    }
    else
    {
      GetDictTuple(hv_EvalParams, "iou_threshold", &hv_IouThresholds);
      //Check the length of 'iou_threshold'.
      if (0 != (int((hv_IouThresholds.TupleLength())<1)))
      {
        (*hv_Exception) = "'iou_threshold' is empty";
        return;
      }
      if (0 != (int((hv_IouThresholds.TupleIsRealElem())!=HTuple(hv_IouThresholds.TupleLength(),1))))
      {
        (*hv_Exception) = "'iou_threshold' should be of type real";
        return;
      }
      //Check if the IoU thresholds are within (0.0, 1.0).
      if (0 != (HTuple(int((hv_IouThresholds.TupleMin())<=0.0)).TupleOr(int((hv_IouThresholds.TupleMax())>=1.0))))
      {
        (*hv_Exception) = HTuple("Invalid 'iou_threshold', not in range (0.0, 1.0)");
        return;
      }
    }
    //
    //Check if the entry 'max_num_detections' is present.
    GetDictParam(hv_EvalParams, "key_exists", "max_num_detections", &hv_MaxNumDetectionsExists);
    if (0 != (hv_MaxNumDetectionsExists.TupleNot()))
    {
      (*hv_Exception) = "The evaluation parameters need a key-value pair for 'max_num_detections'";
      return;
    }
    else
    {
      GetDictTuple(hv_EvalParams, "max_num_detections", &hv_MaxNumDetections);
      //Check the length of 'max_num_detections'.
      if (0 != (int((hv_MaxNumDetections.TupleLength())<1)))
      {
        (*hv_Exception) = "'max_num_detections' is empty";
        return;
      }
      if (0 != (int((hv_MaxNumDetections.TupleIsIntElem())!=HTuple(hv_MaxNumDetections.TupleLength(),1))))
      {
        (*hv_Exception) = "'max_num_detections' should be of type int";
        return;
      }
      //Check if 'max_num_detections' is -1 (to use all detections) or positive.
      if (0 != (HTuple(int((hv_MaxNumDetections.TupleMin())<-1)).TupleOr(int((hv_MaxNumDetections.TupleFind(0))>-1))))
      {
        (*hv_Exception) = "'max_num_detections' should be -1 or positive";
        return;
      }
    }
    //
    //Check if the entry 'area_ranges' is present.
    GetDictParam(hv_EvalParams, "key_exists", "area_ranges", &hv_AreaRangesExist);
    if (0 != (hv_AreaRangesExist.TupleNot()))
    {
      (*hv_Exception) = "The evaluation parameters need a key-value pair for 'area_ranges'";
      return;
    }
    else
    {
      //Check if the entry 'area_ranges' is a dict.
      GetDictTuple(hv_EvalParams, "area_ranges", &hv_AreaRanges);
      if (0 != (int((hv_AreaRanges.TupleSemType())!=HTuple("dict"))))
      {
        (*hv_Exception) = "'area_ranges' must be a dict";
        return;
      }
      //Check that the necessary keys exist.
      GetDictParam(hv_AreaRanges, "key_exists", ((HTuple("name").Append("min")).Append("max")), 
          &hv_AreaKeysExist);
      if (0 != (HTuple(hv_AreaKeysExist[0]).TupleNot()))
      {
        (*hv_Exception) = "'area_ranges' need a key-value pair for 'name'";
        return;
      }
      if (0 != (HTuple(hv_AreaKeysExist[1]).TupleNot()))
      {
        (*hv_Exception) = "'area_ranges' need a key-value pair for 'min'";
        return;
      }
      if (0 != (HTuple(hv_AreaKeysExist[2]).TupleNot()))
      {
        (*hv_Exception) = "'area_ranges' need a key-value pair for 'max'";
        return;
      }
      //Check the lengths of the area keys.
      GetDictTuple(hv_AreaRanges, "name", &hv_AreaNames);
      if (0 != (int((hv_AreaNames.TupleLength())<1)))
      {
        (*hv_Exception) = "'area_ranges': 'name' is empty";
        return;
      }
      GetDictTuple(hv_AreaRanges, "min", &hv_MinAreas);
      if (0 != (int((hv_MinAreas.TupleLength())<1)))
      {
        (*hv_Exception) = "'area_ranges': 'min' is empty";
        return;
      }
      GetDictTuple(hv_AreaRanges, "max", &hv_MaxAreas);
      if (0 != (int((hv_MaxAreas.TupleLength())<1)))
      {
        (*hv_Exception) = "'area_ranges': 'max' is empty";
        return;
      }
      if (0 != (HTuple(int((hv_AreaNames.TupleLength())!=(hv_MinAreas.TupleLength()))).TupleOr(int((hv_AreaNames.TupleLength())!=(hv_MaxAreas.TupleLength())))))
      {
        (*hv_Exception) = HTuple("'area_ranges': 'name', 'min' and 'max' must have the same length");
        return;
      }
      //Check values of min, max.
      if (0 != (int(((hv_MinAreas.TupleGreaterEqualElem(hv_MaxAreas)).TupleFind(1))>-1)))
      {
        (*hv_Exception) = "'area_ranges': 'min' must be elementwise smaller than 'max'";
        return;
      }
    }
    //
    //Check if instance-type is valid.
    GetDictParam(hv_EvalParams, "key_exists", "instance_type", &hv_InstanceTypeExists);
    if (0 != (hv_InstanceTypeExists.TupleNot()))
    {
      (*hv_Exception) = "The evaluation parameters need a key-value pair for 'instance_type'";
      return;
    }
    else
    {
      GetDictTuple(hv_EvalParams, "instance_type", &hv_InstanceType);
      hv_ValidInstanceTypes.Clear();
      hv_ValidInstanceTypes[0] = "rectangle1";
      hv_ValidInstanceTypes[1] = "rectangle2";
      hv_ValidInstanceTypes[2] = "mask";
      if (0 != (int((hv_ValidInstanceTypes.TupleFind(hv_InstanceType))==-1)))
      {
        (*hv_Exception) = ("Invalid instance type '"+hv_InstanceType)+"'";
        return;
      }
    }
    //
    //Check if the entry 'allocation_block_length' is present and valid.
    GetDictParam(hv_EvalParams, "key_exists", "allocation_block_length", &hv_AllocationBlockLengthExists);
    if (0 != (hv_AllocationBlockLengthExists.TupleNot()))
    {
      (*hv_Exception) = "The evaluation parameters need a key-value pair for 'allocation_block_length'";
      return;
    }
    else
    {
      GetDictTuple(hv_EvalParams, "allocation_block_length", &hv_AllocationBlockLength);
      //Check the length of 'allocation_block_length'.
      if (0 != (int((hv_AllocationBlockLength.TupleLength())!=1)))
      {
        (*hv_Exception) = "'allocation_block_length' should have length 1";
        return;
      }
      //Check the type of 'allocation_block_length'.
      if (0 != (int((hv_AllocationBlockLength.TupleType())!=(HTuple(HTuple(0).TupleInt()).TupleType()))))
      {
        (*hv_Exception) = "'allocation_block_length' should be of type int";
        return;
      }
      //Check if 'allocation_block_length' is larger than zero.
      if (0 != (int(hv_AllocationBlockLength<1)))
      {
        (*hv_Exception) = "'allocation_block_length' should be positive";
        return;
      }
    }
    //
    //Check if the entry 'detailed_evaluation' is valid if present.
    GetDictParam(hv_EvalParams, "key_exists", "detailed_evaluation", &hv_DetailedEvaluationExists);
    if (0 != (hv_DetailedEvaluationExists.TupleNot()))
    {
      (*hv_Exception) = "The evaluation parameters need a key-value pair for 'detailed_evaluation'";
      return;
    }
    else
    {
      GetDictTuple(hv_EvalParams, "detailed_evaluation", &hv_DetailedEvaluation);
      //Check the length of 'detailed_evaluation'.
      if (0 != (int((hv_DetailedEvaluation.TupleLength())!=1)))
      {
        (*hv_Exception) = "'detailed_evaluation' should have length 1";
        return;
      }
      //Check the type of 'detailed_evaluation'.
      if (0 != (int((hv_DetailedEvaluation.TupleType())!=(HTuple(1).TupleType()))))
      {
        (*hv_Exception) = "'detailed_evaluation' should be of type int";
        return;
      }
      //Check if 'detailed_evaluation' is true or false.
      if (0 != (HTuple(int(hv_DetailedEvaluation!=0)).TupleAnd(int(hv_DetailedEvaluation!=1))))
      {
        (*hv_Exception) = "'detailed_evaluation' should be zero or one";
        return;
      }
    }
    //
    //Check if the entry 'interpolate_pr_curves' is valid if present.
    GetDictParam(hv_EvalParams, "key_exists", "interpolate_pr_curves", &hv_KeyExists);
    if (0 != (hv_KeyExists.TupleNot()))
    {
      (*hv_Exception) = "The evaluation parameters need a key-value pair for 'interpolate_pr_curves'";
      return;
    }
    else
    {
      GetDictTuple(hv_EvalParams, "interpolate_pr_curves", &hv_InterpolatePRCurves);
      //Check the length of 'interpolate_pr_curves'.
      if (0 != (int((hv_InterpolatePRCurves.TupleLength())!=1)))
      {
        (*hv_Exception) = "'interpolate_pr_curves' should have length 1";
        return;
      }
      //Check the type of 'interpolate_pr_curves'.
      if (0 != (int((hv_InterpolatePRCurves.TupleType())!=(HTuple(1).TupleType()))))
      {
        (*hv_Exception) = "'interpolate_pr_curves' should be of type int";
        return;
      }
      //Check if 'interpolate_pr_curves' is true or false.
      if (0 != (HTuple(int(hv_InterpolatePRCurves!=0)).TupleAnd(int(hv_InterpolatePRCurves!=1))))
      {
        (*hv_Exception) = "'interpolate_pr_curves' should be zero or one";
        return;
      }
    }
    //
    //Add valid measure 'soap' if instance_type is 'rectangle2'.
    if (0 != (int(hv_InstanceType==HTuple("rectangle2"))))
    {
      hv_ValidMeasures = hv_ValidMeasures.TupleConcat("soap");
    }
  }
  else if (0 != (int(hv_EvaluationType==HTuple("segmentation"))))
  {
    //Pixel-based evaluation.
    get_valid_pixel_measures(hv_EvaluationType, &hv_ValidMeasures);
    hv_ValidMeasures = hv_ValidMeasures.TupleConcat("all");
    //
    //Check if the entry 'ignore_class_ids' exists.
    GetDictParam(hv_EvalParams, "key_exists", "ignore_class_ids", &hv_IgnoreClassIDsExist);
    if (0 != (hv_IgnoreClassIDsExist.TupleNot()))
    {
      (*hv_Exception) = "The evaluation parameters need a key-value pair for 'ignore_class_ids'";
      return;
    }
  }
  else if (0 != (int(hv_EvaluationType==HTuple("ocr_recognition"))))
  {
    //OCR recognition evaluation.
    hv_ValidMeasures = "accuracy";
  }
  else if (0 != (int(hv_EvaluationType==HTuple("ocr_detection"))))
  {
    //OCR detection evaluation.
    hv_ValidMeasures.Clear();
    hv_ValidMeasures[0] = "all";
    hv_ValidMeasures[1] = "recall";
    hv_ValidMeasures[2] = "precision";
    hv_ValidMeasures[3] = "f_score";
    hv_ValidMeasures[4] = "soap";
  }
  else
  {
    (*hv_Exception) = "Unknown evaluation_type: "+hv_EvaluationType;
    return;
  }
  //Check measures.
  hv_ValidMeasuresString = HTuple(((hv_ValidMeasures.TupleLength())*2)-1,HTuple("','"));
  hv_ValidMeasuresString[HTuple::TupleGenSequence(0,(hv_ValidMeasuresString.TupleLength())-1,2)] = hv_ValidMeasures;
  hv_ValidMeasuresString = hv_ValidMeasuresString.TupleSum();
  {
  HTuple end_val342 = (hv_Measures.TupleLength())-1;
  HTuple step_val342 = 1;
  for (hv_Idx=0; hv_Idx.Continue(end_val342, step_val342); hv_Idx += step_val342)
  {
    hv_ValidMeasure = (hv_ValidMeasures.TupleFind(HTuple(hv_Measures[hv_Idx]))).TupleGreaterElem(-1);
    if (0 != (hv_ValidMeasure.TupleNot()))
    {
      (*hv_Exception) = ((("Invalid measure '"+HTuple(hv_Measures[hv_Idx]))+HTuple("', choose one of ['"))+hv_ValidMeasuresString)+"']";
      return;
    }
  }
  }
  //
  //Done with checks.
  (*hv_Valid) = 1;
  return;
}


