///////////////////////////////////////////////////////////////////////////////
// File generated by HDevelop for HALCON/C++ Version 23.05.0.0
// Non-ASCII strings in this file are encoded in local-8-bit encoding (cp936).
// Ensure that the interface encoding is set to locale encoding by calling
// SetHcppInterfaceStringEncodingIsUtf8(false) at the beginning of the program.
// 
// Please note that non-ASCII characters in string constants are exported
// as octal codes in order to guarantee that the strings are correctly
// created on all systems, independent on any compiler settings.
// 
// Source files with different encoding should not be mixed in one project.
///////////////////////////////////////////////////////////////////////////////

#include "HalconCpp.h"
#include "HDevThread.h"



using namespace HalconCpp;


// Chapter: Deep Learning / Model
// Short Description: Check for devices supporting deep learning applications. 
void check_dl_devices (HTuple *hv_PossibleRuntimes)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_HalconArch, hv_ACLLoaded, hv_CUDADevices;
  HTuple  hv_CUDALoaded, hv_cuDNNLoaded, hv_cuBLASLoaded;

  //This procedure checks, which devices
  //fulfill the driver and library requirements
  //imposed by the deep learning application.
  //
  (*hv_PossibleRuntimes) = HTuple();
  //Check for CPU. These requirements depend on the system used.
  GetSystem("halcon_arch", &hv_HalconArch);
  if (0 != (hv_HalconArch.TupleRegexpTest("x64")))
  {
    (*hv_PossibleRuntimes) = (*hv_PossibleRuntimes).TupleConcat("cpu");
  }
  else if (0 != (hv_HalconArch.TupleRegexpTest("aarch64")))
  {
    GetSystem("arm_compute_loaded", &hv_ACLLoaded);
    if (0 != (int(hv_ACLLoaded==HTuple("true"))))
    {
      (*hv_PossibleRuntimes) = (*hv_PossibleRuntimes).TupleConcat("cpu");
    }
  }
  //Check for GPU.
  GetSystem("cuda_devices", &hv_CUDADevices);
  if (0 != (int((hv_CUDADevices.TupleLength())>0)))
  {
    GetSystem("cuda_loaded", &hv_CUDALoaded);
    GetSystem("cudnn_loaded", &hv_cuDNNLoaded);
    GetSystem("cublas_loaded", &hv_cuBLASLoaded);
    if (0 != (HTuple(HTuple(int(hv_CUDALoaded==HTuple("true"))).TupleAnd(int(hv_cuDNNLoaded==HTuple("true")))).TupleAnd(int(hv_cuBLASLoaded==HTuple("true")))))
    {
      (*hv_PossibleRuntimes) = (*hv_PossibleRuntimes).TupleConcat("gpu");
    }
  }
  //
  return;
}
