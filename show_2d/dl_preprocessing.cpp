///////////////////////////////////////////////////////////////////////////////
// File generated by HDevelop for HALCON/C++ Version 23.05.0.0
// Non-ASCII strings in this file are encoded in local-8-bit encoding (cp936).
// Ensure that the interface encoding is set to locale encoding by calling
// SetHcppInterfaceStringEncodingIsUtf8(false) at the beginning of the program.
// 
// Please note that non-ASCII characters in string constants are exported
// as octal codes in order to guarantee that the strings are correctly
// created on all systems, independent on any compiler settings.
// 
// Source files with different encoding should not be mixed in one project.
///////////////////////////////////////////////////////////////////////////////

#include "HalconCpp.h"
#include "HDevThread.h"



using namespace HalconCpp;

// Procedure declarations 
// Chapter: Deep Learning / Model
// Short Description: Create a dict which maps class IDs to class indices. 
extern void create_dl_class_id_mapping (HTuple hv_ClassIDs, HTuple *hv_ClassIDsToClassIndex);
// Chapter: System / Operating System
// Short Description: Estimate the remaining time for a task given the current progress. 
extern void estimate_progress (HTuple hv_SecondsStart, HTuple hv_ProgressMin, HTuple hv_ProgressCurrent, 
    HTuple hv_ProgressMax, HTuple *hv_SecondsElapsed, HTuple *hv_SecondsRemaining, 
    HTuple *hv_ProgressPercent, HTuple *hv_ProgressPerSecond);
// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set. 
extern void find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, 
    HTuple hv_Mode, HTuple *hv_SampleIndices);
// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set. 
extern void find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, 
    HTuple hv_Mode, HTuple *hv_SampleIndices);
// Chapter: Deep Learning / Model
// Short Description: Return the DLSample dictionaries for given sample indices of a DLDataset. 
extern void gen_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple hv_RestrictKeysDLSample, 
    HTuple hv_GenParam, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Model
// Short Description: Store the given images in a tuple of dictionaries DLSamples. 
extern void gen_dl_samples_from_images (HObject ho_Images, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Model
// Short Description: Read the dictionaries DLSamples from files. 
extern void read_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Model
// Short Description: Read the dictionaries DLSamples from files. 
extern void read_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple *hv_DLSampleBatch);
// Chapter: File / Misc
// Short Description: Remove a directory recursively. 
extern void remove_dir_recursively (HTuple hv_DirName);
// Chapter: System / Operating System
// Short Description: Create a formatted string of a time span. 
extern void timespan_string (HTuple hv_TotalSeconds, HTuple hv_Format, HTuple *hv_TimeString);
// Chapter: System / Operating System
// Short Description: Create a formatted string of a time span. 
extern void timespan_string (HTuple hv_TotalSeconds, HTuple hv_Format, HTuple *hv_TimeString);
// Chapter: Deep Learning / Model
// Short Description: Write the dictionaries of the samples in DLSampleBatch to hdict files and store the paths in DLDataset. 
extern void write_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple hv_DLSampleBatch, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue);
// Chapter: Deep Learning / Model
// Short Description: Write the dictionaries of the samples in DLSampleBatch to hdict files and store the paths in DLDataset. 
extern void write_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple hv_DLSampleBatch, 
    HTuple hv_GenParamName, HTuple hv_GenParamValue);
// Chapter: Deep Learning / Model
void augment_dl_sample_brightness_variation (HTuple hv_DLSample, HTuple hv_BrightnessVariation);
// Chapter: Deep Learning / Model
void augment_dl_sample_brightness_variation_spot (HTuple hv_DLSample, HTuple hv_BrightnessVariation);
// Chapter: Deep Learning / Model
void augment_dl_sample_contrast_variation (HTuple hv_DLSample, HTuple hv_ContrastVariation);
// Chapter: Deep Learning / Model
void augment_dl_sample_crop_percentage (HTuple hv_DLSample, HTuple hv_CropPercentage);
// Chapter: Deep Learning / Model
void augment_dl_sample_crop_pixel (HTuple hv_DLSample, HTuple hv_CropPixel);
// Chapter: Deep Learning / Model
void augment_dl_sample_mirror (HTuple hv_DLSample, HTuple hv_MirrorMethods, HTuple hv_ClassIDsNoOrientation, 
    HTuple hv_IgnoreDirection);
// Chapter: Deep Learning / Model
void augment_dl_sample_remove_pixel (HTuple hv_DLSample, HTuple hv_NumPixelsToRemoveX, 
    HTuple hv_NumPixelsToRemoveY);
// Chapter: Deep Learning / Model
void augment_dl_sample_rotate (HTuple hv_DLSample, HTuple hv_RotationStep, HTuple hv_ClassIDsNoOrientation, 
    HTuple hv_IgnoreDirection);
// Chapter: Deep Learning / Model
void augment_dl_sample_rotate_range (HTuple hv_DLSample, HTuple hv_RotateRange);
// Chapter: Deep Learning / Model
void augment_dl_sample_saturation_variation (HTuple hv_DLSample, HTuple hv_SaturationVariation);
// Chapter: Deep Learning / Model
// Short Description: Perform data augmentation on the given samples. 
void augment_dl_samples (HTuple hv_DLSampleBatch, HTuple hv_GenParam);
// Chapter: Deep Learning / OCR
// Short Description: Compute zoom factors to fit an image to a target size. 
void calculate_dl_image_zoom_factors (HTuple hv_ImageWidth, HTuple hv_ImageHeight, 
    HTuple hv_TargetWidth, HTuple hv_TargetHeight, HTuple hv_DLPreprocessParam, HTuple *hv_ZoomFactorWidth, 
    HTuple *hv_ZoomFactorHeight);
// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Calculate the class weights for a semantic segmentation dataset. 
void calculate_dl_segmentation_class_weights (HTuple hv_DLDataset, HTuple hv_MaxWeight, 
    HTuple hv_IgnoreClassIDs, HTuple *hv_ClassWeights);
// Chapter: Deep Learning / Model
// Short Description: Check and sanitize the parameters of augment_dl_samples. 
void check_augment_dl_samples_gen_param (HTuple hv_GenParam);
// Chapter: Deep Learning / Model
// Short Description: Check the content of the parameter dictionary DLPreprocessParam. 
void check_dl_preprocess_param (HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Model
// Short Description: Compute 3D normals. 
void compute_normals_xyz (HObject ho_x, HObject ho_y, HObject ho_z, HObject *ho_NXImage, 
    HObject *ho_NYImage, HObject *ho_NZImage, HTuple hv_Smoothing);
// Chapter: Tools / Geometry
// Short Description: Convert the parameters of rectangles with format rectangle2 to the coordinates of its 4 corner-points. 
void convert_rect2_5to8param (HTuple hv_Row, HTuple hv_Col, HTuple hv_Length1, HTuple hv_Length2, 
    HTuple hv_Phi, HTuple *hv_Row1, HTuple *hv_Col1, HTuple *hv_Row2, HTuple *hv_Col2, 
    HTuple *hv_Row3, HTuple *hv_Col3, HTuple *hv_Row4, HTuple *hv_Col4);
// Chapter: Tools / Geometry
// Short Description: Convert for four-sided figures the coordinates of the 4 corner-points to the parameters of format rectangle2. 
void convert_rect2_8to5param (HTuple hv_Row1, HTuple hv_Col1, HTuple hv_Row2, HTuple hv_Col2, 
    HTuple hv_Row3, HTuple hv_Col3, HTuple hv_Row4, HTuple hv_Col4, HTuple hv_ForceL1LargerL2, 
    HTuple *hv_Row, HTuple *hv_Col, HTuple *hv_Length1, HTuple *hv_Length2, HTuple *hv_Phi);
// Chapter: Deep Learning / Model
// Short Description: Create a dictionary with preprocessing parameters. 
void create_dl_preprocess_param (HTuple hv_DLModelType, HTuple hv_ImageWidth, HTuple hv_ImageHeight, 
    HTuple hv_ImageNumChannels, HTuple hv_ImageRangeMin, HTuple hv_ImageRangeMax, 
    HTuple hv_NormalizationType, HTuple hv_DomainHandling, HTuple hv_IgnoreClassIDs, 
    HTuple hv_SetBackgroundID, HTuple hv_ClassIDsBackground, HTuple hv_GenParam, 
    HTuple *hv_DLPreprocessParam);
// Chapter: Deep Learning / Model
// Short Description: Create a dictionary with the preprocessing parameters based on a given DL model. 
void create_dl_preprocess_param_from_model (HTuple hv_DLModelHandle, HTuple hv_NormalizationType, 
    HTuple hv_DomainHandling, HTuple hv_SetBackgroundID, HTuple hv_ClassIDsBackground, 
    HTuple hv_GenParam, HTuple *hv_DLPreprocessParam);
// Chapter: Deep Learning / Model
// Short Description: Crops a given image object based on the given domain handling. 
void crop_dl_sample_image (HObject ho_Domain, HTuple hv_DLSample, HTuple hv_Key, 
    HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Filter the instance segmentation masks of a DL sample based on a given selection. 
void filter_dl_sample_instance_segmentation_masks (HTuple hv_DLSample, HTuple hv_BBoxSelectionMask);
// Chapter: OCR / Deep OCR
// Short Description: Generate ground truth characters if they don't exist and words to characters mapping. 
void gen_dl_ocr_detection_gt_chars (HTuple hv_DLSampleTargets, HTuple hv_DLSample, 
    HTuple hv_ScaleWidth, HTuple hv_ScaleHeight, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_WordsCharsMapping);
// Chapter: OCR / Deep OCR
// Short Description: Generate target link score map for ocr detection training. 
void gen_dl_ocr_detection_gt_link_map (HObject *ho_GtLinkMap, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple hv_DLSampleTargets, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_WordToCharVec, 
    HTuple hv_Alpha);
// Chapter: OCR / Deep OCR
// Short Description: Generate target orientation score maps for ocr detection training. 
void gen_dl_ocr_detection_gt_orientation_map (HObject *ho_GtOrientationMaps, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple hv_DLSample);
// Chapter: OCR / Deep OCR
// Short Description: Generate target text score map for ocr detection training. 
void gen_dl_ocr_detection_gt_score_map (HObject *ho_TargetText, HTuple hv_DLSample, 
    HTuple hv_BoxCutoff, HTuple hv_RenderCutoff, HTuple hv_ImageWidth, HTuple hv_ImageHeight);
// Chapter: OCR / Deep OCR
// Short Description: Preprocess dl samples and generate targets and weights for ocr detection training. 
void gen_dl_ocr_detection_targets (HTuple hv_DLSampleOriginal, HTuple hv_DLPreprocessParam);
// Chapter: OCR / Deep OCR
// Short Description: Generate link score map weight for ocr detection training. 
void gen_dl_ocr_detection_weight_link_map (HObject ho_LinkMap, HObject ho_TargetWeight, 
    HObject *ho_TargetWeightLink, HTuple hv_LinkZeroWeightRadius);
// Chapter: OCR / Deep OCR
// Short Description: Generate orientation score map weight for ocr detection training. 
void gen_dl_ocr_detection_weight_orientation_map (HObject ho_InitialWeight, HObject *ho_OrientationTargetWeight, 
    HTuple hv_DLSample);
// Chapter: OCR / Deep OCR
// Short Description: Generate text score map weight for ocr detection training. 
void gen_dl_ocr_detection_weight_score_map (HObject *ho_TargetWeightText, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple hv_DLSample, HTuple hv_BoxCutoff, HTuple hv_WSWeightRenderThreshold, 
    HTuple hv_Confidence);
// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Store the given images in a tuple of dictionaries. 
void gen_dl_samples_3d_gripping_point_detection (HObject ho_Images, HObject ho_X, 
    HObject ho_Y, HObject ho_Z, HObject ho_Normals, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Generate weight images for the training dataset. 
void gen_dl_segmentation_weight_images (HTuple hv_DLDataset, HTuple hv_DLPreprocessParam, 
    HTuple hv_ClassWeights, HTuple hv_GenParam);
// Chapter: OCR / Deep OCR
// Short Description: Generate a word to characters mapping. 
void gen_words_chars_mapping (HTuple hv_DLSample, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_WordsCharsMapping);
// Chapter: Deep Learning / OCR
// Short Description: Determine the ocr type of the sample based on the sample structure. 
void get_dl_sample_ocr_type (HTuple hv_DLSample, HTuple *hv_OCRType);
// Chapter: Deep Learning / Model
// Short Description: Handle the 'auto' option of the 'overwrite_files' parameter in preprocess_dl_dataset. 
void handle_overwrite_files_auto_in_preprocess_dl_dataset (HTuple hv_DLDataset, HTuple hv_DLPreprocessParam, 
    HTuple hv_DLDatasetFileName, HTuple *hv_OverwriteFiles);
// Chapter: Deep Learning / Model
// Short Description: Preprocess the entire dataset declared in DLDataset. 
void preprocess_dl_dataset (HTuple hv_DLDataset, HTuple hv_DataDirectory, HTuple hv_DLPreprocessParam, 
    HTuple hv_GenParam, HTuple *hv_DLDatasetFileName);
// Chapter: Deep Learning / Model
// Short Description: Preprocess 3D data for deep-learning-based training and inference. 
void preprocess_dl_model_3d_data (HTuple hv_DLSample, HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Model
// Short Description: Preprocess anomaly images for evaluation and visualization of deep-learning-based anomaly detection or Global Context Anomaly Detection. 
void preprocess_dl_model_anomaly (HObject ho_AnomalyImages, HObject *ho_AnomalyImagesPreprocessed, 
    HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Model
// Short Description: Preprocess the provided DLSample image for augmentation purposes. 
void preprocess_dl_model_augmentation_data (HTuple hv_DLSample, HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Preprocess the bounding boxes of type 'rectangle1' for a given sample. 
void preprocess_dl_model_bbox_rect1 (HObject ho_ImageRaw, HTuple hv_DLSample, HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Preprocess the bounding boxes of type 'rectangle2' for a given sample. 
void preprocess_dl_model_bbox_rect2 (HObject ho_ImageRaw, HTuple hv_DLSample, HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Model
// Short Description: Preprocess images for deep-learning-based training and inference. 
void preprocess_dl_model_images (HObject ho_Images, HObject *ho_ImagesPreprocessed, 
    HTuple hv_DLPreprocessParam);
// Chapter: OCR / Deep OCR
// Short Description: Preprocess images for deep-learning-based training and inference of Deep OCR detection models. 
void preprocess_dl_model_images_ocr_detection (HObject ho_Images, HObject *ho_ImagesPreprocessed, 
    HTuple hv_DLPreprocessParam);
// Chapter: OCR / Deep OCR
// Short Description: Preprocess images for deep-learning-based training and inference of Deep OCR recognition models. 
void preprocess_dl_model_images_ocr_recognition (HObject ho_Images, HObject *ho_ImagesPreprocessed, 
    HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Preprocess the instance segmentation masks for a sample given by the dictionary DLSample. 
void preprocess_dl_model_instance_masks (HObject ho_ImageRaw, HTuple hv_DLSample, 
    HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Preprocess segmentation and weight images for deep-learning-based segmentation training and inference. 
void preprocess_dl_model_segmentations (HObject ho_ImagesRaw, HObject ho_Segmentations, 
    HObject *ho_SegmentationsPreprocessed, HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Model
// Short Description: Preprocess given DLSamples according to the preprocessing parameters given in DLPreprocessParam. 
void preprocess_dl_samples (HTuple hv_DLSampleBatch, HTuple hv_DLPreprocessParam);
// Chapter: Image / Manipulation
// Short Description: Change value of ValuesToChange in Image to NewValue. 
void reassign_pixel_values (HObject ho_Image, HObject *ho_ImageOut, HTuple hv_ValuesToChange, 
    HTuple hv_NewValue);
// Chapter: Deep Learning / Model
// Short Description: Remove invalid 3D pixels from a given domain. 
void remove_invalid_3d_pixels (HObject ho_ImageX, HObject ho_ImageY, HObject ho_ImageZ, 
    HObject ho_Domain, HObject *ho_DomainOut, HTuple hv_InvalidPixelValue);
// Chapter: Deep Learning / Model
// Short Description: Replace legacy preprocessing parameters or values. 
void replace_legacy_preprocessing_parameters (HTuple hv_DLPreprocessParam);
// Chapter: OCR / Deep OCR
// Short Description: Split rectangle2 into a number of rectangles. 
void split_rectangle2 (HTuple hv_Row, HTuple hv_Column, HTuple hv_Phi, HTuple hv_Length1, 
    HTuple hv_Length2, HTuple hv_NumSplits, HTuple *hv_SplitRow, HTuple *hv_SplitColumn, 
    HTuple *hv_SplitPhi, HTuple *hv_SplitLength1Out, HTuple *hv_SplitLength2Out);

// Procedures 
// Chapter: Deep Learning / Model
void augment_dl_sample_brightness_variation (HTuple hv_DLSample, HTuple hv_BrightnessVariation)
{

  // Local iconic variables
  HObject  ho_Image, ho_ImageScaled;

  // Local control variables
  HTuple  hv_OCRType, hv_BrightnessShift;

  //This procedure should not be used outside of the augment_dl_samples procedure!
  //The name, parameters, and functionality of this procedure are subject to change.
  //
  //*** Input validation ***
  //
  //For OCR Recognition samples, only a certain range is allowed for BrightnessVariation.
  get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
  if (0 != (HTuple(int(hv_OCRType==HTuple("ocr_recognition"))).TupleAnd(int(hv_BrightnessVariation>1))))
  {
    throw HException("Value of augmentation method 'brightness_variation' cannot be greater than 1 for ocr_recognition models.");
  }
  //
  //*** Augmentation ***
  //
  ho_Image = hv_DLSample.TupleGetDictObject("image");
  //
  //Add random brightness variation.
  hv_BrightnessShift = ((HTuple::TupleRand(1)*2)-1)*hv_BrightnessVariation;
  ScaleImage(ho_Image, &ho_ImageScaled, 1.0, hv_BrightnessShift);
  //
  //Set the augmented image to DLSample.
  SetDictObject(ho_ImageScaled, hv_DLSample, "image");
  return;
}

// Chapter: Deep Learning / Model
void augment_dl_sample_brightness_variation_spot (HTuple hv_DLSample, HTuple hv_BrightnessVariation)
{

  // Local iconic variables
  HObject  ho_Image, ho_Filter, ho_GaussImage, ho_GaussFilter;
  HObject  ho_Gauss, ho_GaussTargetType, ho_AddImage, ho_ImageSpot;

  // Local control variables
  HTuple  hv_OCRType, hv_ImageWidth, hv_ImageHeight;
  HTuple  hv_BrightnessShift, hv_SpotSize, hv_SpotRow, hv_SpotColumn;
  HTuple  hv_Direction, hv_ShiftRow, hv_ShiftCol, hv_Type;
  HTuple  hv_NChannels, hv__;

  //This procedure should not be used outside of the augment_dl_samples procedure!
  //The name, parameters, and functionality of this procedure are subject to change.
  //
  //*** Input validation ***
  //
  //This augmentation method should not be applied to OCR Recognition samples.
  get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
  if (0 != (int(hv_OCRType==HTuple("ocr_recognition"))))
  {
    throw HException("The augmentation method 'brightness_variation_spot' is not supported by ocr_recognition models.");
  }
  //
  //*** Augmentation ***
  //
  ho_Image = hv_DLSample.TupleGetDictObject("image");
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  //Determine random brightness variation.
  hv_BrightnessShift = ((HTuple::TupleRand(1)*2)-1)*hv_BrightnessVariation;
  //Determine random spot size between [0.5*ImageHeight, ImageWidth]
  hv_SpotSize = hv_ImageWidth*((HTuple::TupleRand(1)/2)+0.5);
  //Determine random spot position.
  hv_SpotRow = HTuple::TupleRand(1)*hv_ImageHeight;
  hv_SpotColumn = HTuple::TupleRand(1)*hv_ImageWidth;
  //
  if (0 != (int(hv_BrightnessShift<0)))
  {
    hv_Direction = 0;
    hv_BrightnessShift = -hv_BrightnessShift;
  }
  else
  {
    hv_Direction = 1;
  }
  //Generate Gauss filter that simulates an illumination spot of size 'SpotSize'.
  GenGaussFilter(&ho_Filter, 1, 1, 0, "none", "dc_center", hv_SpotSize, hv_SpotSize);
  //Shift the filter image to the given position.
  hv_ShiftRow = -((hv_SpotSize/2)-hv_SpotRow);
  hv_ShiftCol = -((hv_SpotSize/2)-hv_SpotColumn);
  TileImagesOffset(ho_Filter, &ho_GaussImage, hv_ShiftRow, hv_ShiftCol, -1, -1, -1, 
      -1, hv_ImageWidth, hv_ImageHeight);
  FullDomain(ho_GaussImage, &ho_GaussFilter);
  //Convert Gauss filter to target image type and apply brightness variation.
  GetImageType(ho_Image, &hv_Type);
  ScaleImage(ho_GaussFilter, &ho_Gauss, hv_BrightnessShift, 0);
  ConvertImageType(ho_Gauss, &ho_GaussTargetType, hv_Type);
  //Add channels to fit input image.
  CountChannels(ho_Image, &hv_NChannels);
  CopyObj(ho_GaussTargetType, &ho_AddImage, 1, 1);
  {
  HTuple end_val43 = hv_NChannels-1;
  HTuple step_val43 = 1;
  for (hv__=1; hv__.Continue(end_val43, step_val43); hv__ += step_val43)
  {
    AppendChannel(ho_AddImage, ho_GaussTargetType, &ho_AddImage);
  }
  }
  //Apply on image.
  if (0 != hv_Direction)
  {
    AddImage(ho_Image, ho_AddImage, &ho_ImageSpot, 1, 0);
  }
  else
  {
    SubImage(ho_Image, ho_AddImage, &ho_ImageSpot, 1, 0);
  }
  //
  //Set the augmented image to DLSample.
  SetDictObject(ho_ImageSpot, hv_DLSample, "image");
  return;
}

// Chapter: Deep Learning / Model
void augment_dl_sample_contrast_variation (HTuple hv_DLSample, HTuple hv_ContrastVariation)
{

  // Local iconic variables
  HObject  ho_Image, ho_GrayImage, ho_MeanImage;
  HObject  ho_MeanImageScaled, ho_ImageScaled, ho_ImageOut;

  // Local control variables
  HTuple  hv_OCRType, hv_Borders, hv_Factor, hv_NumChannels;
  HTuple  hv_MeanGray, hv__;

  //This procedure should not be used outside of the augment_dl_samples procedure!
  //The name, parameters, and functionality of this procedure are subject to change.
  //
  //*** Input validation ***
  //
  //This augmentation method should not be applied to OCR Recognition samples.
  get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
  if (0 != (int(hv_OCRType==HTuple("ocr_recognition"))))
  {
    throw HException(("The augmentation method 'contrast_variation' is not supported by "+hv_OCRType)+" models.");
  }
  //
  //*** Augmentation ***
  //
  //Adjust contrast of the input image by blending it with its mean image.
  //
  //Minimum and maximum blend factors.
  hv_Borders.Clear();
  hv_Borders.Append(HTuple(0.0).TupleMax2(1-hv_ContrastVariation));
  hv_Borders.Append(1+hv_ContrastVariation);
  //Random blend factor.
  hv_Factor = HTuple(hv_Borders[0])+((HTuple(hv_Borders[1])-HTuple(hv_Borders[0]))*HTuple::TupleRand(1));
  //
  if (0 != (int(hv_Factor==1.0)))
  {
    return;
  }
  //
  //Convert Image to a gray value image.
  ho_Image = hv_DLSample.TupleGetDictObject("image");
  CountChannels(ho_Image, &hv_NumChannels);
  if (0 != (int(hv_NumChannels==1)))
  {
    ho_GrayImage = ho_Image;
  }
  else if (0 != (int(hv_NumChannels==3)))
  {
    Rgb1ToGray(ho_Image, &ho_GrayImage);
  }
  else
  {
    throw HException("The augmentation method 'contrast_variation' can only be applied to gray scale and RGB images.");
  }
  //
  //Compute the mean of the gray value image.
  Intensity(ho_GrayImage, ho_GrayImage, &hv_MeanGray, &hv__);
  //Create a constant image with the gray value mean.
  GenImageProto(ho_GrayImage, &ho_MeanImage, hv_MeanGray);
  if (0 != (int(hv_NumChannels==3)))
  {
    Compose3(ho_MeanImage, ho_MeanImage, ho_MeanImage, &ho_MeanImage);
  }
  //
  //Blend Image and MeanImage.
  //The resulting ImageOut will have the same domain as Image.
  ScaleImage(ho_MeanImage, &ho_MeanImageScaled, 1.0-hv_Factor, 0.0);
  ScaleImage(ho_Image, &ho_ImageScaled, hv_Factor, 0.0);
  AddImage(ho_MeanImageScaled, ho_ImageScaled, &ho_ImageOut, 1.0, 0.0);
  //
  //Set the augmented image to DLSample.
  SetDictObject(ho_ImageOut, hv_DLSample, "image");
  return;
}

// Chapter: Deep Learning / Model
void augment_dl_sample_crop_percentage (HTuple hv_DLSample, HTuple hv_CropPercentage)
{

  // Local iconic variables
  HObject  ho_Image, ho_ImagePart;

  // Local control variables
  HTuple  hv_ClassificationLabelExists, hv_XKeyExists;
  HTuple  hv_SegmenationImageKeyExists, hv_GrippingPointKeysExists;
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_CropRate, hv_Row1;
  HTuple  hv_Row2, hv_Column1, hv_Column2, hv_Keys, hv_Index;
  HTuple  hv_Key;

  //This procedure should not be used outside of the augment_dl_samples procedure!
  //The name, parameters, and functionality of this procedure are subject to change.
  //
  //*** Input validation ***
  //
  //This augmentation can only be applied to samples from a classification or
  //3D Gripping Point Detection datasets.
  GetDictParam(hv_DLSample, "key_exists", "image_label_id", &hv_ClassificationLabelExists);
  GetDictParam(hv_DLSample, "key_exists", "x", &hv_XKeyExists);
  GetDictParam(hv_DLSample, "key_exists", "segmentation_image", &hv_SegmenationImageKeyExists);
  hv_GrippingPointKeysExists = hv_XKeyExists.TupleAnd(hv_SegmenationImageKeyExists);
  if (0 != (HTuple(hv_ClassificationLabelExists.TupleOr(hv_GrippingPointKeysExists)).TupleNot()))
  {
    throw HException("The augmentation method 'crop_percentage' is only supported by classification or 3D gripping point detection models.");
  }
  //
  //*** Augmentation ***
  //
  ho_Image = hv_DLSample.TupleGetDictObject("image");
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  //
  //Define cropping rectangle.
  hv_CropRate = hv_CropPercentage*0.01;
  hv_Row1 = (((1-hv_CropRate)*hv_ImageHeight)*HTuple::TupleRand(1)).TupleFloor();
  hv_Row2 = hv_Row1+(hv_CropRate*hv_ImageHeight);
  hv_Column1 = (((1-hv_CropRate)*hv_ImageWidth)*HTuple::TupleRand(1)).TupleFloor();
  hv_Column2 = hv_Column1+(hv_CropRate*hv_ImageWidth);
  //
  //Crop the image.
  CropRectangle1(ho_Image, &ho_ImagePart, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
  //
  //Scale image to the input size and set the augmented image to DLSample.
  ZoomImageSize(ho_ImagePart, &ho_ImagePart, hv_ImageWidth, hv_ImageHeight, "constant");
  SetDictObject(ho_ImagePart, hv_DLSample, "image");
  //
  //3D sensor data should not be interpolated to avoid introducing unwanted
  //interpolation effects. Therfore we use 'nearest_neighbor' interpolation.
  if (0 != hv_GrippingPointKeysExists)
  {
    hv_Keys.Clear();
    hv_Keys[0] = "x";
    hv_Keys[1] = "y";
    hv_Keys[2] = "z";
    hv_Keys[3] = "normals";
    hv_Keys[4] = "segmentation_image";
    hv_Keys[5] = "weight_image";
    {
    HTuple end_val38 = (hv_Keys.TupleLength())-1;
    HTuple step_val38 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val38, step_val38); hv_Index += step_val38)
    {
      hv_Key = HTuple(hv_Keys[hv_Index]);
      ho_Image = hv_DLSample.TupleGetDictObject(hv_Key);
      //
      //Crop the image.
      CropRectangle1(ho_Image, &ho_ImagePart, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
      //
      //Scale image to the input size and set the augmented image to DLSample.
      ZoomImageSize(ho_ImagePart, &ho_ImagePart, hv_ImageWidth, hv_ImageHeight, "nearest_neighbor");
      SetDictObject(ho_ImagePart, hv_DLSample, hv_Key);
    }
    }
  }
  return;
}

// Chapter: Deep Learning / Model
void augment_dl_sample_crop_pixel (HTuple hv_DLSample, HTuple hv_CropPixel)
{

  // Local iconic variables
  HObject  ho_Image, ho_ImagePart;

  // Local control variables
  HTuple  hv_ClassificationLabelExists, hv_ImageWidth;
  HTuple  hv_ImageHeight, hv_Length, hv_Row1, hv_Row2, hv_Column1;
  HTuple  hv_Column2;

  //This procedure should not be used outside of the augment_dl_samples procedure!
  //The name, parameters, and functionality of this procedure are subject to change.
  //
  //*** Input validation ***
  //
  //This augmentation can only be applied to samples from a classification dataset.
  GetDictParam(hv_DLSample, "key_exists", "image_label_id", &hv_ClassificationLabelExists);
  if (0 != (hv_ClassificationLabelExists.TupleNot()))
  {
    throw HException("The augmentation method 'crop_pixel' is only supported by classification models.");
  }
  //
  //*** Augmentation ***
  //
  ho_Image = hv_DLSample.TupleGetDictObject("image");
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  //
  //Define cropping rectangle.
  hv_Length = hv_CropPixel;
  hv_Row1 = HTuple::TupleRand(1)*(hv_ImageHeight-hv_Length);
  hv_Row2 = (hv_Row1+hv_Length)-1;
  hv_Column1 = HTuple::TupleRand(1)*(hv_ImageWidth-hv_Length);
  hv_Column2 = (hv_Column1+hv_Length)-1;
  //
  //Crop the image.
  CropRectangle1(ho_Image, &ho_ImagePart, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
  //
  //Scale the image to the input size and set the augmented image to DLSample.
  ZoomImageSize(ho_ImagePart, &ho_ImagePart, hv_ImageWidth, hv_ImageHeight, "constant");
  SetDictObject(ho_ImagePart, hv_DLSample, "image");
  return;
}

// Chapter: Deep Learning / Model
void augment_dl_sample_mirror (HTuple hv_DLSample, HTuple hv_MirrorMethods, HTuple hv_ClassIDsNoOrientation, 
    HTuple hv_IgnoreDirection)
{

  // Local iconic variables
  HObject  ho_Image, ho_Mask, ho_SegmentationImage;
  HObject  ho_WeightImage;

  // Local control variables
  HTuple  hv_OCRType, hv_Rectangle1ParamExist, hv_Rectangle2ParamExist;
  HTuple  hv_InstanceMaskExists, hv_SegmentationImageExists;
  HTuple  hv_WeightImageExists, hv_BBoxRow1, hv_BBoxCol1;
  HTuple  hv_BBoxRow2, hv_BBoxCol2, hv_BBoxRow, hv_BBoxCol;
  HTuple  hv_BBoxPhi, hv_BBoxLabelID, hv_NumMirrorMethods;
  HTuple  hv_ProbabilityMethods, hv_StrMirror, hv_StrIdx;
  HTuple  hv_SelectedChar, hv_ImageWidth, hv_ImageHeight;
  HTuple  hv_BBoxCol1Mirror, hv_BBoxCol2Mirror, hv_ObjIdx;
  HTuple  hv_BBoxRow1Mirror, hv_BBoxRow2Mirror;

  //This procedure should not be used outside of the augment_dl_samples procedure!
  //The name, parameters, and functionality of this procedure are subject to change.
  //
  //*** Input validation ***
  //
  //This augmentation method should not be applied to OCR Detection/Recognition samples.
  get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
  if (0 != (HTuple(int(hv_OCRType==HTuple("ocr_detection"))).TupleOr(int(hv_OCRType==HTuple("ocr_recognition")))))
  {
    throw HException(("The augmentation method 'mirror' is not supported by "+hv_OCRType)+" models.");
  }
  //
  //*** Augmentation ***
  //
  ho_Image = hv_DLSample.TupleGetDictObject("image");
  //Get the annotations from the sample that need to be
  //augmented together with the image.
  GetDictParam(hv_DLSample, "key_exists", "bbox_row1", &hv_Rectangle1ParamExist);
  GetDictParam(hv_DLSample, "key_exists", "bbox_phi", &hv_Rectangle2ParamExist);
  GetDictParam(hv_DLSample, "key_exists", "mask", &hv_InstanceMaskExists);
  GetDictParam(hv_DLSample, "key_exists", "segmentation_image", &hv_SegmentationImageExists);
  GetDictParam(hv_DLSample, "key_exists", "weight_image", &hv_WeightImageExists);
  if (0 != hv_Rectangle1ParamExist)
  {
    GetDictTuple(hv_DLSample, "bbox_row1", &hv_BBoxRow1);
    GetDictTuple(hv_DLSample, "bbox_col1", &hv_BBoxCol1);
    GetDictTuple(hv_DLSample, "bbox_row2", &hv_BBoxRow2);
    GetDictTuple(hv_DLSample, "bbox_col2", &hv_BBoxCol2);
  }
  else if (0 != hv_Rectangle2ParamExist)
  {
    GetDictTuple(hv_DLSample, "bbox_row", &hv_BBoxRow);
    GetDictTuple(hv_DLSample, "bbox_col", &hv_BBoxCol);
    GetDictTuple(hv_DLSample, "bbox_phi", &hv_BBoxPhi);
    if (0 != (int(hv_ClassIDsNoOrientation!=HTuple())))
    {
      GetDictTuple(hv_DLSample, "bbox_label_id", &hv_BBoxLabelID);
    }
  }
  if (0 != hv_InstanceMaskExists)
  {
    GetDictObject(&ho_Mask, hv_DLSample, "mask");
  }
  if (0 != hv_SegmentationImageExists)
  {
    GetDictObject(&ho_SegmentationImage, hv_DLSample, "segmentation_image");
  }
  if (0 != hv_WeightImageExists)
  {
    GetDictObject(&ho_WeightImage, hv_DLSample, "weight_image");
  }
  //
  //Mirroring
  //
  //If more than one axis is allowed,
  //choose mirror axis/axes to be applied.
  hv_NumMirrorMethods = hv_MirrorMethods.TupleStrlen();
  hv_ProbabilityMethods = 1.0/hv_NumMirrorMethods;
  hv_StrMirror = "";
  while (0 != (int(hv_StrMirror==HTuple(""))))
  {
    {
    HTuple end_val52 = hv_NumMirrorMethods-1;
    HTuple step_val52 = 1;
    for (hv_StrIdx=0; hv_StrIdx.Continue(end_val52, step_val52); hv_StrIdx += step_val52)
    {
      hv_SelectedChar = hv_MirrorMethods.TupleStrBitSelect(hv_StrIdx);
      if (0 != (int(HTuple::TupleRand(1)<hv_ProbabilityMethods)))
      {
        hv_StrMirror += hv_SelectedChar;
      }
    }
    }
  }
  //Apply the chosen mirror axis/axes to the given sample data.
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  if (0 != (hv_StrMirror.TupleRegexpTest("c")))
  {
    MirrorImage(ho_Image, &ho_Image, "column");
    if (0 != hv_Rectangle1ParamExist)
    {
      hv_BBoxCol1Mirror = (hv_ImageWidth-hv_BBoxCol2)-1;
      hv_BBoxCol2Mirror = (hv_ImageWidth-hv_BBoxCol1)-1;
      hv_BBoxCol1 = hv_BBoxCol1Mirror;
      hv_BBoxCol2 = hv_BBoxCol2Mirror;
    }
    else if (0 != hv_Rectangle2ParamExist)
    {
      hv_BBoxCol = (hv_ImageWidth-hv_BBoxCol)-1;
      //Check that BBoxPhi is only mirrored for classes with orientation.
      if (0 != (int(hv_ClassIDsNoOrientation!=HTuple())))
      {
        {
        HTuple end_val72 = (hv_BBoxLabelID.TupleLength())-1;
        HTuple step_val72 = 1;
        for (hv_ObjIdx=0; hv_ObjIdx.Continue(end_val72, step_val72); hv_ObjIdx += step_val72)
        {
          if (0 != (int((hv_ClassIDsNoOrientation.TupleFind(HTuple(hv_BBoxLabelID[hv_ObjIdx])))==-1)))
          {
            if (0 != hv_IgnoreDirection)
            {
              hv_BBoxPhi[hv_ObjIdx] = -HTuple(hv_BBoxPhi[hv_ObjIdx]);
            }
            else
            {
              hv_BBoxPhi[hv_ObjIdx] = (((-(HTuple(hv_BBoxPhi[hv_ObjIdx]).TupleLessElem(0.0)))+(HTuple(hv_BBoxPhi[hv_ObjIdx]).TupleGreaterEqualElem(0.0)))*(HTuple(180).TupleRad()))-HTuple(hv_BBoxPhi[hv_ObjIdx]);
            }
          }
        }
        }
      }
      else
      {
        if (0 != hv_IgnoreDirection)
        {
          hv_BBoxPhi = -hv_BBoxPhi;
        }
        else
        {
          hv_BBoxPhi = (((-(hv_BBoxPhi.TupleLessElem(0.0)))+(hv_BBoxPhi.TupleGreaterEqualElem(0.0)))*(HTuple(180).TupleRad()))-hv_BBoxPhi;
        }
      }
    }
    if (0 != hv_InstanceMaskExists)
    {
      MirrorRegion(ho_Mask, &ho_Mask, "column", hv_ImageWidth);
    }
    if (0 != hv_SegmentationImageExists)
    {
      MirrorImage(ho_SegmentationImage, &ho_SegmentationImage, "column");
    }
    if (0 != hv_WeightImageExists)
    {
      MirrorImage(ho_WeightImage, &ho_WeightImage, "column");
    }
  }
  //
  if (0 != (hv_StrMirror.TupleRegexpTest("r")))
  {
    MirrorImage(ho_Image, &ho_Image, "row");
    if (0 != hv_Rectangle1ParamExist)
    {
      hv_BBoxRow1Mirror = (hv_ImageHeight-hv_BBoxRow2)-1;
      hv_BBoxRow2Mirror = (hv_ImageHeight-hv_BBoxRow1)-1;
      hv_BBoxRow1 = hv_BBoxRow1Mirror;
      hv_BBoxRow2 = hv_BBoxRow2Mirror;
    }
    else if (0 != hv_Rectangle2ParamExist)
    {
      hv_BBoxRow = (hv_ImageHeight-hv_BBoxRow)-1;
      if (0 != (int(hv_ClassIDsNoOrientation!=HTuple())))
      {
        {
        HTuple end_val110 = (hv_BBoxLabelID.TupleLength())-1;
        HTuple step_val110 = 1;
        for (hv_ObjIdx=0; hv_ObjIdx.Continue(end_val110, step_val110); hv_ObjIdx += step_val110)
        {
          if (0 != (int((hv_ClassIDsNoOrientation.TupleFind(HTuple(hv_BBoxLabelID[hv_ObjIdx])))==-1)))
          {
            hv_BBoxPhi[hv_ObjIdx] = -HTuple(hv_BBoxPhi[hv_ObjIdx]);
          }
        }
        }
      }
      else
      {
        hv_BBoxPhi = -hv_BBoxPhi;
      }
    }
    if (0 != hv_InstanceMaskExists)
    {
      MirrorRegion(ho_Mask, &ho_Mask, "row", hv_ImageHeight);
    }
    if (0 != hv_SegmentationImageExists)
    {
      MirrorImage(ho_SegmentationImage, &ho_SegmentationImage, "row");
    }
    if (0 != hv_WeightImageExists)
    {
      MirrorImage(ho_WeightImage, &ho_WeightImage, "row");
    }
  }
  //
  //Set the mirrored data to DLSample.
  SetDictObject(ho_Image, hv_DLSample, "image");
  if (0 != hv_Rectangle1ParamExist)
  {
    SetDictTuple(hv_DLSample, "bbox_col1", hv_BBoxCol1);
    SetDictTuple(hv_DLSample, "bbox_row1", hv_BBoxRow1);
    SetDictTuple(hv_DLSample, "bbox_col2", hv_BBoxCol2);
    SetDictTuple(hv_DLSample, "bbox_row2", hv_BBoxRow2);
  }
  else if (0 != hv_Rectangle2ParamExist)
  {
    SetDictTuple(hv_DLSample, "bbox_row", hv_BBoxRow);
    SetDictTuple(hv_DLSample, "bbox_col", hv_BBoxCol);
    SetDictTuple(hv_DLSample, "bbox_phi", hv_BBoxPhi);
  }
  if (0 != hv_InstanceMaskExists)
  {
    SetDictObject(ho_Mask, hv_DLSample, "mask");
  }
  if (0 != hv_SegmentationImageExists)
  {
    SetDictObject(ho_SegmentationImage, hv_DLSample, "segmentation_image");
  }
  if (0 != hv_WeightImageExists)
  {
    SetDictObject(ho_WeightImage, hv_DLSample, "weight_image");
  }
  return;
}

// Chapter: Deep Learning / Model
void augment_dl_sample_remove_pixel (HTuple hv_DLSample, HTuple hv_NumPixelsToRemoveX, 
    HTuple hv_NumPixelsToRemoveY)
{

  // Local iconic variables
  HObject  ho_Image, ho_ImageHighRes, ho_Domain;
  HObject  ho_DomainHighRes, ho_ImagePart;

  // Local control variables
  HTuple  hv_OCRType, hv_IsOCRRecognition, hv_AugmentationDataExists;
  HTuple  hv_AugmentationData, hv_ImageHighResExists, hv_ImageWidth;
  HTuple  hv_ImageHeight, hv_Row1, hv_Column1, hv_Row2, hv_Column2;
  HTuple  hv_Width, hv_Height, hv_ImageHighResWidth, hv_ImageHighResHeight;

  //This procedure should not be used outside of the augment_dl_samples procedure!
  //The name, parameters, and functionality of this procedure are subject to change.
  //
  //*** Input validation ***
  //
  //This augmentation method applies only to OCR Recognition samples.
  get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
  hv_IsOCRRecognition = int(hv_OCRType==HTuple("ocr_recognition"));
  if (0 != (hv_IsOCRRecognition.TupleNot()))
  {
    throw HException("The augmentation method 'remove_pixel' is only supported by ocr_recognition models.");
  }
  //
  //*** Augmentation ***
  //
  ho_Image = hv_DLSample.TupleGetDictObject("image");
  //
  //Select the augmentation image with high resolution if available for ocr_recognition models.
  //Note the difference between Image and ImageHighRes.
  GetDictParam(hv_DLSample, "key_exists", "augmentation_data", &hv_AugmentationDataExists);
  if (0 != (hv_IsOCRRecognition.TupleAnd(hv_AugmentationDataExists)))
  {
    hv_AugmentationData = hv_DLSample.TupleGetDictTuple("augmentation_data");
    GetDictParam(hv_AugmentationData, "key_exists", "image_high_res", &hv_ImageHighResExists);
    if (0 != hv_ImageHighResExists)
    {
      ho_ImageHighRes = hv_AugmentationData.TupleGetDictObject("image_high_res");
    }
  }
  //
  //Get dimensions of the domain of the preprocessed image,
  //The domain is assumed to be a rectangle1 domain.
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  GetDomain(ho_Image, &ho_Domain);
  SmallestRectangle1(ho_Domain, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
  hv_Width = (hv_Column2-hv_Column1)+1;
  hv_Height = (hv_Row2-hv_Row1)+1;
  //Do nothing if no pixel would remain available.
  if (0 != (HTuple(int(hv_Width<=(2*hv_NumPixelsToRemoveX))).TupleOr(int(hv_Height<=(2*hv_NumPixelsToRemoveY)))))
  {
    return;
  }
  //In case of ocr_recognition use the high-resolution image if available.
  if (0 != (hv_IsOCRRecognition.TupleAnd(hv_AugmentationDataExists)))
  {
    GetImageSize(ho_ImageHighRes, &hv_ImageHighResWidth, &hv_ImageHighResHeight);
    hv_NumPixelsToRemoveX = ((hv_NumPixelsToRemoveX*hv_ImageHighResWidth)/(hv_Width.TupleReal())).TupleInt();
    hv_NumPixelsToRemoveY = ((hv_NumPixelsToRemoveY*hv_ImageHighResHeight)/(hv_Height.TupleReal())).TupleInt();
    ho_Image = ho_ImageHighRes;
    //The high-resolution image is expected to have full domain.
    GetDomain(ho_ImageHighRes, &ho_DomainHighRes);
    SmallestRectangle1(ho_DomainHighRes, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
  }
  //Define cropping rectangle.
  if (0 != (int(hv_NumPixelsToRemoveY>0)))
  {
    hv_Row1 += ((HTuple::TupleRand(1)*hv_NumPixelsToRemoveY).TupleInt())+1;
    hv_Row2 = hv_Row2-(((HTuple::TupleRand(1)*hv_NumPixelsToRemoveY).TupleInt())+1);
  }
  if (0 != (int(hv_NumPixelsToRemoveX>0)))
  {
    hv_Column1 += ((HTuple::TupleRand(1)*hv_NumPixelsToRemoveX).TupleInt())+1;
    hv_Column2 = hv_Column2-(((HTuple::TupleRand(1)*hv_NumPixelsToRemoveX).TupleInt())+1);
  }
  //Crop the image.
  CropRectangle1(ho_Image, &ho_ImagePart, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
  //Scale the image to the input size and set the augmented image to DLSample.
  if (0 != (hv_IsOCRRecognition.TupleAnd(hv_AugmentationDataExists)))
  {
    preprocess_dl_model_images_ocr_recognition(ho_ImagePart, &ho_ImagePart, hv_AugmentationData.TupleGetDictTuple("preprocess_params"));
  }
  else
  {
    ZoomImageSize(ho_ImagePart, &ho_ImagePart, hv_ImageWidth, hv_ImageHeight, "constant");
  }
  //Set the augmented image to DLSample.
  SetDictObject(ho_ImagePart, hv_DLSample, "image");
  return;
}

// Chapter: Deep Learning / Model
void augment_dl_sample_rotate (HTuple hv_DLSample, HTuple hv_RotationStep, HTuple hv_ClassIDsNoOrientation, 
    HTuple hv_IgnoreDirection)
{

  // Local iconic variables
  HObject  ho_Image, ho_Mask, ho_SegmentationImage;
  HObject  ho_WeightImage, ho_ImageRotate;

  // Local control variables
  HTuple  hv_OCRType, hv_Rectangle1ParamExist, hv_Rectangle2ParamExist;
  HTuple  hv_InstanceMaskExists, hv_SegmentationImageExists;
  HTuple  hv_WeightImageExists, hv_BBoxRow1, hv_BBoxCol1;
  HTuple  hv_BBoxRow2, hv_BBoxCol2, hv_BBoxRow, hv_BBoxCol;
  HTuple  hv_BBoxLength1, hv_BBoxLength2, hv_BBoxPhi, hv_BBoxLabelID;
  HTuple  hv_NumPossibleRotations, hv_CurrentRotation, hv_ImageWidth;
  HTuple  hv_ImageHeight, hv_HomMat2DIdentity, hv_HomMat2DTmp;
  HTuple  hv_HomMat2DAdapted, hv_Offset, hv_HomMat2DRotate;
  HTuple  hv_RowTrans1, hv_ColTrans1, hv_RowTrans2, hv_ColTrans2;
  HTuple  hv_RowTrans, hv_ColTrans, hv_MaxAngle, hv_DiffAngle;
  HTuple  hv_IndicesLarge, hv_ObjIdx, hv_BBoxLengthTmp;

  //This procedure should not be used outside of the augment_dl_samples procedure!
  //The name, parameters, and functionality of this procedure are subject to change.
  //
  //*** Input validation ***
  //
  //This augmentation method should not be applied to OCR Detection/Recognition samples.
  get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
  if (0 != (HTuple(int(hv_OCRType==HTuple("ocr_detection"))).TupleOr(int(hv_OCRType==HTuple("ocr_recognition")))))
  {
    throw HException(("The augmentation method 'rotate' is not supported by "+hv_OCRType)+" models.");
  }
  //
  //*** Augmentation ***
  //
  ho_Image = hv_DLSample.TupleGetDictObject("image");
  //Get the annotations from the sample that need to be
  //augmented together with the image.
  GetDictParam(hv_DLSample, "key_exists", "bbox_row1", &hv_Rectangle1ParamExist);
  GetDictParam(hv_DLSample, "key_exists", "bbox_phi", &hv_Rectangle2ParamExist);
  GetDictParam(hv_DLSample, "key_exists", "mask", &hv_InstanceMaskExists);
  GetDictParam(hv_DLSample, "key_exists", "segmentation_image", &hv_SegmentationImageExists);
  GetDictParam(hv_DLSample, "key_exists", "weight_image", &hv_WeightImageExists);
  if (0 != hv_Rectangle1ParamExist)
  {
    GetDictTuple(hv_DLSample, "bbox_row1", &hv_BBoxRow1);
    GetDictTuple(hv_DLSample, "bbox_col1", &hv_BBoxCol1);
    GetDictTuple(hv_DLSample, "bbox_row2", &hv_BBoxRow2);
    GetDictTuple(hv_DLSample, "bbox_col2", &hv_BBoxCol2);
  }
  else if (0 != hv_Rectangle2ParamExist)
  {
    GetDictTuple(hv_DLSample, "bbox_row", &hv_BBoxRow);
    GetDictTuple(hv_DLSample, "bbox_col", &hv_BBoxCol);
    GetDictTuple(hv_DLSample, "bbox_length1", &hv_BBoxLength1);
    GetDictTuple(hv_DLSample, "bbox_length2", &hv_BBoxLength2);
    GetDictTuple(hv_DLSample, "bbox_phi", &hv_BBoxPhi);
    if (0 != (int(hv_ClassIDsNoOrientation!=HTuple())))
    {
      GetDictTuple(hv_DLSample, "bbox_label_id", &hv_BBoxLabelID);
    }
  }
  if (0 != hv_InstanceMaskExists)
  {
    GetDictObject(&ho_Mask, hv_DLSample, "mask");
  }
  if (0 != hv_SegmentationImageExists)
  {
    GetDictObject(&ho_SegmentationImage, hv_DLSample, "segmentation_image");
  }
  if (0 != hv_WeightImageExists)
  {
    GetDictObject(&ho_WeightImage, hv_DLSample, "weight_image");
  }
  //
  //Rotation
  //
  //Determine rotation angle for distortion type 'rotate' (angle in range (0:RotationStep:360)).
  hv_NumPossibleRotations = (360.0/hv_RotationStep)-1;
  hv_CurrentRotation = hv_RotationStep*(((hv_NumPossibleRotations*HTuple::TupleRand(1)).TupleInt())+1);
  //
  if (0 != (int(hv_CurrentRotation!=0)))
  {
    GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
    if (0 != (HTuple(int(hv_ImageWidth!=hv_ImageHeight)).TupleAnd(int(hv_CurrentRotation!=180.0))))
    {
      //If an image is not quadratic, a rotation by 90 or 270 degrees is ignored.
      return;
    }
    //
    RotateImage(ho_Image, &ho_ImageRotate, hv_CurrentRotation, "constant");
    SetDictObject(ho_ImageRotate, hv_DLSample, "image");
    //
    if (0 != (hv_Rectangle1ParamExist.TupleOr(hv_Rectangle2ParamExist)))
    {
      //Create a transformation matrix for the rotation of the bounding boxes.
      GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
      HomMat2dIdentity(&hv_HomMat2DIdentity);
      HomMat2dTranslate(hv_HomMat2DIdentity, 0.5, 0.5, &hv_HomMat2DTmp);
      HomMat2dTranslateLocal(hv_HomMat2DTmp, -0.5, -0.5, &hv_HomMat2DAdapted);
      hv_Offset = ((hv_ImageHeight-hv_ImageWidth)*0.5)*((hv_CurrentRotation.TupleRad()).TupleSin());
      HomMat2dTranslate(hv_HomMat2DAdapted, hv_Offset, hv_Offset, &hv_HomMat2DAdapted);
      HomMat2dRotate(hv_HomMat2DAdapted, hv_CurrentRotation.TupleRad(), hv_ImageHeight*0.5, 
          hv_ImageWidth*0.5, &hv_HomMat2DRotate);
    }
    if (0 != hv_Rectangle1ParamExist)
    {
      AffineTransPixel(hv_HomMat2DRotate, hv_BBoxRow1, hv_BBoxCol1, &hv_RowTrans1, 
          &hv_ColTrans1);
      AffineTransPixel(hv_HomMat2DRotate, hv_BBoxRow2, hv_BBoxCol2, &hv_RowTrans2, 
          &hv_ColTrans2);
      if (0 != (int(hv_CurrentRotation==90)))
      {
        hv_BBoxRow1 = hv_RowTrans2;
        hv_BBoxCol1 = hv_ColTrans1;
        hv_BBoxRow2 = hv_RowTrans1;
        hv_BBoxCol2 = hv_ColTrans2;
      }
      else if (0 != (int(hv_CurrentRotation==180)))
      {
        hv_BBoxRow1 = hv_RowTrans2;
        hv_BBoxCol1 = hv_ColTrans2;
        hv_BBoxRow2 = hv_RowTrans1;
        hv_BBoxCol2 = hv_ColTrans1;
      }
      else if (0 != (int(hv_CurrentRotation==270)))
      {
        hv_BBoxRow1 = hv_RowTrans1;
        hv_BBoxCol1 = hv_ColTrans2;
        hv_BBoxRow2 = hv_RowTrans2;
        hv_BBoxCol2 = hv_ColTrans1;
      }
      //
      SetDictTuple(hv_DLSample, "bbox_row1", hv_BBoxRow1);
      SetDictTuple(hv_DLSample, "bbox_col1", hv_BBoxCol1);
      SetDictTuple(hv_DLSample, "bbox_row2", hv_BBoxRow2);
      SetDictTuple(hv_DLSample, "bbox_col2", hv_BBoxCol2);
    }
    else if (0 != hv_Rectangle2ParamExist)
    {
      AffineTransPixel(hv_HomMat2DRotate, hv_BBoxRow, hv_BBoxCol, &hv_RowTrans, &hv_ColTrans);
      //Write the bounding box angles phi in the expected interval:
      //-180бу < phi <= 180бу or if IgnoreDirection set to true -90бу < phi <= 90бу.
      if (0 != (hv_IgnoreDirection.TupleNot()))
      {
        hv_BBoxPhi += hv_CurrentRotation.TupleRad();
        hv_MaxAngle = 180;
        hv_DiffAngle = 360;
      }
      else
      {
        if (0 != (HTuple(int(hv_CurrentRotation==90)).TupleOr(int(hv_CurrentRotation==270))))
        {
          hv_BBoxPhi += HTuple(90).TupleRad();
        }
        hv_MaxAngle = 90;
        hv_DiffAngle = 180;
      }
      hv_IndicesLarge = (hv_BBoxPhi.TupleGreaterElem(hv_MaxAngle.TupleRad())).TupleFind(1);
      if (0 != (int(hv_IndicesLarge!=-1)))
      {
        hv_BBoxPhi[hv_IndicesLarge] = HTuple(hv_BBoxPhi[hv_IndicesLarge])-(hv_DiffAngle.TupleRad());
      }
      //Check that the angle BBoxPhi for objects without orientation is always set to 0.0.
      if (0 != (int(hv_ClassIDsNoOrientation!=HTuple())))
      {
        {
        HTuple end_val117 = (hv_BBoxLabelID.TupleLength())-1;
        HTuple step_val117 = 1;
        for (hv_ObjIdx=0; hv_ObjIdx.Continue(end_val117, step_val117); hv_ObjIdx += step_val117)
        {
          if (0 != (int((hv_ClassIDsNoOrientation.TupleFind(HTuple(hv_BBoxLabelID[hv_ObjIdx])))!=-1)))
          {
            hv_BBoxPhi[hv_ObjIdx] = 0.0;
            //These classes require Length1 <= Length2: exchange them for 90бу or 270бу rotations.
            if (0 != (HTuple(int(hv_CurrentRotation==90)).TupleOr(int(hv_CurrentRotation==270))))
            {
              hv_BBoxLengthTmp = HTuple(hv_BBoxLength1[hv_ObjIdx]);
              hv_BBoxLength1[hv_ObjIdx] = HTuple(hv_BBoxLength2[hv_ObjIdx]);
              hv_BBoxLength2[hv_ObjIdx] = hv_BBoxLengthTmp;
            }
          }
        }
        }
      }
      SetDictTuple(hv_DLSample, "bbox_row", hv_RowTrans);
      SetDictTuple(hv_DLSample, "bbox_col", hv_ColTrans);
      SetDictTuple(hv_DLSample, "bbox_phi", hv_BBoxPhi);
      SetDictTuple(hv_DLSample, "bbox_length1", hv_BBoxLength1);
      SetDictTuple(hv_DLSample, "bbox_length2", hv_BBoxLength2);
    }
    if (0 != hv_InstanceMaskExists)
    {
      AffineTransRegion(ho_Mask, &ho_Mask, hv_HomMat2DRotate, "nearest_neighbor");
      SetDictObject(ho_Mask, hv_DLSample, "mask");
    }
    if (0 != hv_SegmentationImageExists)
    {
      RotateImage(ho_SegmentationImage, &ho_SegmentationImage, hv_CurrentRotation.TupleInt(), 
          "constant");
      SetDictObject(ho_SegmentationImage, hv_DLSample, "segmentation_image");
    }
    if (0 != hv_WeightImageExists)
    {
      RotateImage(ho_WeightImage, &ho_WeightImage, hv_CurrentRotation.TupleInt(), 
          "constant");
      SetDictObject(ho_WeightImage, hv_DLSample, "weight_image");
    }
  }
  return;
}

// Chapter: Deep Learning / Model
void augment_dl_sample_rotate_range (HTuple hv_DLSample, HTuple hv_RotateRange)
{

  // Local iconic variables
  HObject  ho_Image, ho_DomainRotated;

  // Local control variables
  HTuple  hv_OCRType, hv_IsOCRDetection, hv_IsOCRRecognition;
  HTuple  hv_IsOCR, hv_RotateRangeMax, hv_Rectangle1ParamExist;
  HTuple  hv_Rectangle2ParamExist, hv_InstanceMaskExists;
  HTuple  hv_SegmentationImageExists, hv_WeightImageExists;
  HTuple  hv_ImageHighResExists, hv_AugmentationDataExists;
  HTuple  hv_AugmentationData, hv_SampleHighResExists, hv_SampleHighRes;
  HTuple  hv_PreprocessParams, hv_ImageWidth, hv_ImageHeight;
  HTuple  hv_RotationAngle, hv_HomMat2DIdentity, hv_HomMat2DRotate;
  HTuple  hv_Row1, hv_Column1, hv_Row2, hv_Column2, hv_PreprocessWidth;
  HTuple  hv_PreprocessHeight, hv_FactorWidth, hv_FactorHeight;
  HTuple  hv_TempWidth, hv_TempHeight, hv_HomMat2DTranslate;
  HTuple  hv_HomMat2DTransform, hv_BBoxRow1, hv_BBoxCol1;
  HTuple  hv_BBoxRow2, hv_BBoxCol2, hv_BBoxRow3, hv_BBoxCol3;
  HTuple  hv_BBoxRow4, hv_BBoxCol4, hv_Row1Trans, hv_Col1Trans;
  HTuple  hv_Row2Trans, hv_Col2Trans, hv_Row3Trans, hv_Col3Trans;
  HTuple  hv_Row4Trans, hv_Col4Trans, hv___Tmp_Ctrl_0, hv___Tmp_Ctrl_1;
  HTuple  hv___Tmp_Ctrl_2, hv___Tmp_Ctrl_3, hv___Tmp_Ctrl_4;

  //This procedure should not be used outside of the augment_dl_samples procedure!
  //The name, parameters, and functionality of this procedure are subject to change.
  //
  //*** Input validation ***
  //
  get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
  hv_IsOCRDetection = int(hv_OCRType==HTuple("ocr_detection"));
  hv_IsOCRRecognition = int(hv_OCRType==HTuple("ocr_recognition"));
  hv_IsOCR = hv_IsOCRDetection.TupleOr(hv_IsOCRRecognition);
  if (0 != hv_IsOCR)
  {
    //For OCR Recognition samples only a certain RotateRange is allowed.
    if (0 != hv_IsOCRRecognition)
    {
      hv_RotateRangeMax = 5;
      if (0 != (int(hv_RotateRange>hv_RotateRangeMax)))
      {
        throw HException(((("Value of augmentation method 'rotate_range' cannot be greater than "+hv_RotateRangeMax)+" for ")+hv_OCRType)+" models.");
      }
    }
  }
  else
  {
    //This augmentation method cannot be applied to samples with
    //object detection annotations or semantic segmentation annotations.
    GetDictParam(hv_DLSample, "key_exists", "bbox_row1", &hv_Rectangle1ParamExist);
    GetDictParam(hv_DLSample, "key_exists", "bbox_phi", &hv_Rectangle2ParamExist);
    GetDictParam(hv_DLSample, "key_exists", "mask", &hv_InstanceMaskExists);
    GetDictParam(hv_DLSample, "key_exists", "segmentation_image", &hv_SegmentationImageExists);
    GetDictParam(hv_DLSample, "key_exists", "weight_image", &hv_WeightImageExists);
    if (0 != (HTuple(HTuple(HTuple(hv_Rectangle1ParamExist.TupleOr(hv_Rectangle2ParamExist)).TupleOr(hv_InstanceMaskExists)).TupleOr(hv_SegmentationImageExists)).TupleOr(hv_WeightImageExists)))
    {
      throw HException(HTuple("The augmentation method 'rotate_range' is not supported for object detection, instance segmentation or semantic segmentation samples."));
    }
  }
  //
  //*** Augmentation ***
  //
  ho_Image = hv_DLSample.TupleGetDictObject("image");
  //
  //Select the augmentation image with high resolution if available for OCR Detection/Recognition models.
  hv_ImageHighResExists = 0;
  GetDictParam(hv_DLSample, "key_exists", "augmentation_data", &hv_AugmentationDataExists);
  if (0 != (hv_IsOCR.TupleAnd(hv_AugmentationDataExists)))
  {
    hv_AugmentationData = hv_DLSample.TupleGetDictTuple("augmentation_data");
    if (0 != hv_IsOCRDetection)
    {
      GetDictParam(hv_AugmentationData, "key_exists", "sample_high_res", &hv_SampleHighResExists);
      if (0 != hv_SampleHighResExists)
      {
        hv_SampleHighRes = hv_AugmentationData.TupleGetDictTuple("sample_high_res");
        GetDictParam(hv_SampleHighRes, "key_exists", "image", &hv_ImageHighResExists);
        if (0 != hv_ImageHighResExists)
        {
          ho_Image = hv_SampleHighRes.TupleGetDictObject("image");
        }
        hv_PreprocessParams = hv_AugmentationData.TupleGetDictTuple("preprocess_params");
      }
    }
    else
    {
      GetDictParam(hv_AugmentationData, "key_exists", "image_high_res", &hv_ImageHighResExists);
      if (0 != hv_ImageHighResExists)
      {
        ho_Image = hv_AugmentationData.TupleGetDictObject("image_high_res");
      }
    }
  }
  if (0 != (hv_IsOCRDetection.TupleAnd(hv_ImageHighResExists.TupleNot())))
  {
    throw HException("The augmentation method 'rotate_range' requires sample images with high resolution for ocr_detection models.");
  }
  //
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  //Determine rotation angle for method 'rotate_range': angle in range [1:RotateRange].
  hv_RotationAngle = ((hv_RotateRange*HTuple::TupleRand(1)).TupleInt())+1;
  //Select direction of rotation randomly.
  if (0 != (int(HTuple::TupleRand(1)<0.5)))
  {
    hv_RotationAngle = 360-hv_RotationAngle;
  }
  //For ocr_detection the transformation matrix is always needed so
  //the else-case is also used for angles multiple of 90 degrees.
  if (0 != (HTuple(int((hv_RotationAngle%90)==0)).TupleAnd(hv_IsOCRDetection.TupleNot())))
  {
    //Rotations around 90 degrees are faster with rotate_image.
    RotateImage(ho_Image, &ho_Image, hv_RotationAngle, "constant");
  }
  else
  {
    HomMat2dIdentity(&hv_HomMat2DIdentity);
    if (0 != (hv_IsOCRDetection.TupleNot()))
    {
      //Create rotation matrix and apply the rotation.
      HomMat2dRotate(hv_HomMat2DIdentity, hv_RotationAngle.TupleRad(), hv_ImageHeight/2.0, 
          hv_ImageWidth/2.0, &hv_HomMat2DRotate);
      AffineTransImage(ho_Image, &ho_Image, hv_HomMat2DRotate, "constant", "false");
      //Remove potential undefined domain.
      GetDomain(ho_Image, &ho_DomainRotated);
      InnerRectangle1(ho_DomainRotated, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      CropRectangle1(ho_Image, &ho_Image, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
    }
    else
    {
      //Calculate temporary image dimensions with the same aspect ratio
      //as the preprocessed image to enlarge the input image, such that
      //the rotation output fits most part of it without zooming the content.
      hv_PreprocessWidth = hv_PreprocessParams.TupleGetDictTuple("image_width");
      hv_PreprocessHeight = hv_PreprocessParams.TupleGetDictTuple("image_height");
      calculate_dl_image_zoom_factors(hv_ImageWidth, hv_ImageHeight, hv_PreprocessWidth, 
          hv_PreprocessHeight, hv_PreprocessParams, &hv_FactorWidth, &hv_FactorHeight);
      hv_TempWidth = hv_PreprocessWidth/(hv_FactorWidth.TupleReal());
      hv_TempHeight = hv_PreprocessHeight/(hv_FactorHeight.TupleReal());
      //Rotate image.
      HomMat2dTranslate(hv_HomMat2DIdentity, (-hv_ImageHeight)/2.0, (-hv_ImageWidth)/2.0, 
          &hv_HomMat2DTranslate);
      HomMat2dRotate(hv_HomMat2DTranslate, hv_RotationAngle.TupleRad(), 0, 0, &hv_HomMat2DRotate);
      HomMat2dTranslate(hv_HomMat2DRotate, hv_ImageHeight/2.0, hv_ImageWidth/2.0, 
          &hv_HomMat2DTransform);
      AffineTransImageSize(ho_Image, &ho_Image, hv_HomMat2DTransform, "constant", 
          hv_TempWidth, hv_TempHeight);
      //Rotate bounding boxes.
      convert_rect2_5to8param(hv_SampleHighRes.TupleGetDictTuple("bbox_row"), hv_SampleHighRes.TupleGetDictTuple("bbox_col"), 
          hv_SampleHighRes.TupleGetDictTuple("bbox_length1"), hv_SampleHighRes.TupleGetDictTuple("bbox_length2"), 
          hv_SampleHighRes.TupleGetDictTuple("bbox_phi"), &hv_BBoxRow1, &hv_BBoxCol1, 
          &hv_BBoxRow2, &hv_BBoxCol2, &hv_BBoxRow3, &hv_BBoxCol3, &hv_BBoxRow4, &hv_BBoxCol4);
      AffineTransPixel(hv_HomMat2DTransform, hv_BBoxRow1, hv_BBoxCol1, &hv_Row1Trans, 
          &hv_Col1Trans);
      AffineTransPixel(hv_HomMat2DTransform, hv_BBoxRow2, hv_BBoxCol2, &hv_Row2Trans, 
          &hv_Col2Trans);
      AffineTransPixel(hv_HomMat2DTransform, hv_BBoxRow3, hv_BBoxCol3, &hv_Row3Trans, 
          &hv_Col3Trans);
      AffineTransPixel(hv_HomMat2DTransform, hv_BBoxRow4, hv_BBoxCol4, &hv_Row4Trans, 
          &hv_Col4Trans);
      convert_rect2_8to5param(hv_Row1Trans, hv_Col1Trans, hv_Row2Trans, hv_Col2Trans, 
          hv_Row3Trans, hv_Col3Trans, hv_Row4Trans, hv_Col4Trans, 0, &hv___Tmp_Ctrl_0, 
          &hv___Tmp_Ctrl_1, &hv___Tmp_Ctrl_2, &hv___Tmp_Ctrl_3, &hv___Tmp_Ctrl_4);
      SetDictTuple(hv_DLSample, "bbox_phi", hv___Tmp_Ctrl_4);
      SetDictTuple(hv_DLSample, "bbox_length2", hv___Tmp_Ctrl_3);
      SetDictTuple(hv_DLSample, "bbox_length1", hv___Tmp_Ctrl_2);
      SetDictTuple(hv_DLSample, "bbox_col", hv___Tmp_Ctrl_1);
      SetDictTuple(hv_DLSample, "bbox_row", hv___Tmp_Ctrl_0);
    }
  }
  //Do model specific operations before scaling.
  if (0 != hv_IsOCRDetection)
  {
  }
  //Scale image to the input size.
  if (0 != (hv_IsOCR.TupleAnd(hv_ImageHighResExists)))
  {
    if (0 != hv_IsOCRDetection)
    {
      //Scale bounding boxes to the input size.
      preprocess_dl_model_bbox_rect2(ho_Image, hv_DLSample, hv_PreprocessParams);
      //Scale rotated image to the input size.
      preprocess_dl_model_images_ocr_detection(ho_Image, &ho_Image, hv_PreprocessParams);
      //Generate targets from the scaled rotated image.
      SetDictObject(ho_Image, hv_DLSample, "image");
      gen_dl_ocr_detection_targets(hv_DLSample, hv_PreprocessParams);
    }
    else
    {
      preprocess_dl_model_images_ocr_recognition(ho_Image, &ho_Image, hv_PreprocessParams);
    }
  }
  else
  {
    ZoomImageSize(ho_Image, &ho_Image, hv_ImageWidth, hv_ImageHeight, "constant");
  }
  //
  //Set the augmented image to DLSample.
  SetDictObject(ho_Image, hv_DLSample, "image");
  return;
}

// Chapter: Deep Learning / Model
void augment_dl_sample_saturation_variation (HTuple hv_DLSample, HTuple hv_SaturationVariation)
{

  // Local iconic variables
  HObject  ho_Image, ho_GrayImage, ho_GrayRGBChannelImage;
  HObject  ho_GrayRGBChannelImageScaled, ho_ImageScaled, ho_ImageOut;

  // Local control variables
  HTuple  hv_OCRType, hv_NumChannels, hv_Borders;
  HTuple  hv_Factor;

  //This procedure should not be used outside of the augment_dl_samples procedure!
  //The name, parameters, and functionality of this procedure are subject to change.
  //
  //*** Input validation ***
  //
  //This augmentation method should not be applied to OCR Recognition samples.
  get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
  if (0 != (int(hv_OCRType==HTuple("ocr_recognition"))))
  {
    throw HException("The augmentation method 'saturation_variation' is not supported by ocr_recognition models.");
  }
  //
  ho_Image = hv_DLSample.TupleGetDictObject("image");
  //
  //If the image has only one channel, this augmentation has no effect.
  CountChannels(ho_Image, &hv_NumChannels);
  if (0 != (int(hv_NumChannels==1)))
  {
    return;
  }
  else if (0 != (int(hv_NumChannels!=3)))
  {
    //Otherwise, only RGB images are allowed.
    throw HException("The augmentation method 'saturation_variation' can only be applied to gray scale and RGB images.");
  }
  //
  //*** Augmentation ***
  //
  //Adjust the saturation of the input image by blending it with its gray value version.
  //
  //Minimum and maximum blend factors.
  hv_Borders.Clear();
  hv_Borders.Append(HTuple(0.0).TupleMax2(1-hv_SaturationVariation));
  hv_Borders.Append(1+hv_SaturationVariation);
  hv_Factor = HTuple(hv_Borders[0])+((HTuple(hv_Borders[1])-HTuple(hv_Borders[0]))*HTuple::TupleRand(1));
  //
  if (0 != (int(hv_Factor==1.0)))
  {
    return;
  }
  //
  //Get the gray value image as an RGB image.
  Rgb1ToGray(ho_Image, &ho_GrayImage);
  Compose3(ho_GrayImage, ho_GrayImage, ho_GrayImage, &ho_GrayRGBChannelImage);
  //
  //Blend Image and GrayRGBChannelImage.
  ScaleImage(ho_GrayRGBChannelImage, &ho_GrayRGBChannelImageScaled, 1.0-hv_Factor, 
      0.0);
  ScaleImage(ho_Image, &ho_ImageScaled, hv_Factor, 0.0);
  AddImage(ho_GrayRGBChannelImageScaled, ho_ImageScaled, &ho_ImageOut, 1.0, 0.0);
  //
  //Set the augmented image to DLSample.
  SetDictObject(ho_ImageOut, hv_DLSample, "image");
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Perform data augmentation on the given samples. 
void augment_dl_samples (HTuple hv_DLSampleBatch, HTuple hv_GenParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumSamples, hv_AugParams, hv_GenKeys;
  HTuple  hv_KeyIndex, hv_GenKey, hv_AugMethodsToApply, hv_SampleIndex;
  HTuple  hv_DLSample, hv_ChosenIndex, hv_AugMethod, hv_AugMethodValue;
  HTuple  hv___Tmp_Ctrl_Dict_Init_1, hv___Tmp_Ctrl_Type;

  //
  //This procedure augments samples in the DLSampleBatch randomly.
  //The augmentation methods have to be specified using the dictionary GenParam.
  //
  //
  //*** Input validation ***
  //
  //If no augmentation parameter is given we return directly and the samples stay unchanged.
  if (0 != (int((hv_GenParam.TupleLength())==0)))
  {
    return;
  }
  //
  //Check number of samples to be augmented.
  hv_NumSamples = hv_DLSampleBatch.TupleLength();
  if (0 != (int(hv_NumSamples==0)))
  {
    throw HException("There are no DLSamples to be processed.");
  }
  //
  //Validate and sanitize the input.
  //Note that this is just a shallow check of the given GenParam dict.
  //The compatibility of the resulting augmentation parameters dict with the
  //DLSampleBatch at hand needs to be checked below.
  check_augment_dl_samples_gen_param(hv_GenParam);
  //
  //
  //*** Default augmentation values ***
  //
  CreateDict(&hv_AugParams);
  //
  //Augmentation methods:
  //
  //The absolute brightness change can vary in the range [-value, +value].
  SetDictTuple(hv_AugParams, "brightness_variation", 0);
  //The absolute brightness peak of a randomly positioned spot can vary in the range [-value, +value].
  SetDictTuple(hv_AugParams, "brightness_variation_spot", 0);
  //Contrast variation can be enabled by setting a value larger than zero, for example 0.2.
  SetDictTuple(hv_AugParams, "contrast_variation", 0);
  //Fraction of image length and width that remains after cropping (in %).
  SetDictTuple(hv_AugParams, "crop_percentage", "off");
  //Image length and width that remains after cropping (in pixel).
  SetDictTuple(hv_AugParams, "crop_pixel", "off");
  //Allowed mirroring types are coded by 'r' (row), 'c' (column).
  SetDictTuple(hv_AugParams, "mirror", "off");
  //In case of a ocr_recognition model:
  //Maximum amount of pixels that can be removed from the image borders: [x,y] => x:left,right and y:top,bottom.
  SetDictTuple(hv_AugParams, "remove_pixel", (HTuple(0).Append(0)));
  //Step size for possible rotations.
  //This parameter and augmentation method is independent from the 'rotate_range' parameter.
  SetDictTuple(hv_AugParams, "rotate", 0);
  //Step range for rotations with step size 1.
  //This parameter and augmentation method is independent from the 'rotate' parameter.
  SetDictTuple(hv_AugParams, "rotate_range", 0);
  //Saturation variation can be enabled by setting a value larger than zero, for example 0.2.
  SetDictTuple(hv_AugParams, "saturation_variation", 0);
  //
  //Other settings:
  //
  //The percentage of the images that are to be augmented.
  SetDictTuple(hv_AugParams, "augmentation_percentage", 50);
  //In case of a detection model of instance_type 'rectangle2': Use directions of instances within bounding boxes.
  SetDictTuple(hv_AugParams, "ignore_direction", 0);
  //In case of a detection model of instance_type 'rectangle2': Class IDs without orientation.
  //These are the IDs of the classes, for whose instances the orientation is not to be considered.
  SetDictTuple(hv_AugParams, "class_ids_no_orientation", HTuple());
  //
  //
  //*** Get the augmentation that should be applied ***
  //
  //Set user-defined parameters:
  GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenKeys);
  {
  HTuple end_val70 = (hv_GenKeys.TupleLength())-1;
  HTuple step_val70 = 1;
  for (hv_KeyIndex=0; hv_KeyIndex.Continue(end_val70, step_val70); hv_KeyIndex += step_val70)
  {
    hv_GenKey = HTuple(hv_GenKeys[hv_KeyIndex]);
    GetDictParam(hv_GenParam, "key_data_type", hv_GenKey, &hv___Tmp_Ctrl_Type);
    if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
    {
      SetDictObject(hv_GenParam.TupleGetDictObject(hv_GenKey), hv_AugParams, hv_GenKey);
    }
    else
    {
      SetDictTuple(hv_AugParams, hv_GenKey, hv_GenParam.TupleGetDictTuple(hv_GenKey));
    }
  }
  }
  //
  //Get all methods that would actually have an effect when applied with the
  //augmentation value stored in AugParams.
  hv_AugMethodsToApply = HTuple();
  //Brightness variation.
  if (0 != (int((hv_AugParams.TupleGetDictTuple("brightness_variation"))>0)))
  {
    hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("brightness_variation");
  }
  //Brightness variation spot.
  if (0 != (int((hv_AugParams.TupleGetDictTuple("brightness_variation_spot"))>0)))
  {
    hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("brightness_variation_spot");
  }
  //Contrast variation.
  if (0 != (int((hv_AugParams.TupleGetDictTuple("contrast_variation"))>0)))
  {
    hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("contrast_variation");
  }
  //Cropping percentage.
  if (0 != ((hv_AugParams.TupleGetDictTuple("crop_percentage")).TupleIsNumber()))
  {
    hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("crop_percentage");
  }
  //Cropping pixels.
  if (0 != ((hv_AugParams.TupleGetDictTuple("crop_pixel")).TupleIsNumber()))
  {
    hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("crop_pixel");
  }
  //Mirroring is allowed in row and column direction.
  if (0 != (HTuple((hv_AugParams.TupleGetDictTuple("mirror")).TupleRegexpTest("r")).TupleOr((hv_AugParams.TupleGetDictTuple("mirror")).TupleRegexpTest("c"))))
  {
    hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("mirror");
  }
  //Removing pixels.
  if (0 != (HTuple(int(HTuple((hv_AugParams.TupleGetDictTuple("remove_pixel"))[0])>0)).TupleOr(int(HTuple((hv_AugParams.TupleGetDictTuple("remove_pixel"))[1])>0))))
  {
    hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("remove_pixel");
  }
  //Rotation with a given angular step size.
  if (0 != (int((hv_AugParams.TupleGetDictTuple("rotate"))>0)))
  {
    hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("rotate");
  }
  //Rotation within a given range (step size 1).
  if (0 != (int((hv_AugParams.TupleGetDictTuple("rotate_range"))>0)))
  {
    hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("rotate_range");
  }
  //Saturation variation.
  if (0 != (int((hv_AugParams.TupleGetDictTuple("saturation_variation"))>0)))
  {
    hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("saturation_variation");
  }
  //
  //Exit early if there is nothing to be applied
  CreateDict(&hv___Tmp_Ctrl_Dict_Init_1);
  SetDictTuple(hv___Tmp_Ctrl_Dict_Init_1, "comp", 0);
  if (0 != (HTuple(int((hv_AugMethodsToApply.TupleLength())==0)).TupleOr((hv_AugParams.TupleConcat(hv___Tmp_Ctrl_Dict_Init_1)).TupleTestEqualDictItem("augmentation_percentage","comp"))))
  {
    return;
  }
  hv___Tmp_Ctrl_Dict_Init_1 = HTuple::TupleConstant("HNULL");
  //
  //
  //*** Augment the samples ***
  //
  {
  HTuple end_val135 = (hv_DLSampleBatch.TupleLength())-1;
  HTuple step_val135 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val135, step_val135); hv_SampleIndex += step_val135)
  {
    hv_DLSample = HTuple(hv_DLSampleBatch[hv_SampleIndex]);
    //Only augment the given percentage of samples.
    if (0 != (int((HTuple::TupleRand(1)*100)>(hv_AugParams.TupleGetDictTuple("augmentation_percentage")))))
    {
      continue;
    }
    //Select the augmentation method.
    hv_ChosenIndex = HTuple(HTuple::TupleRand(1)*(hv_AugMethodsToApply.TupleLength())).TupleInt();
    hv_AugMethod = HTuple(hv_AugMethodsToApply[hv_ChosenIndex]);
    hv_AugMethodValue = hv_AugParams.TupleGetDictTuple(hv_AugMethod);
    //
    if (0 != (int(hv_AugMethod==HTuple("brightness_variation"))))
    {
      augment_dl_sample_brightness_variation(hv_DLSample, hv_AugMethodValue);
    }
    else if (0 != (int(hv_AugMethod==HTuple("brightness_variation_spot"))))
    {
      augment_dl_sample_brightness_variation_spot(hv_DLSample, hv_AugMethodValue);
    }
    else if (0 != (int(hv_AugMethod==HTuple("contrast_variation"))))
    {
      augment_dl_sample_contrast_variation(hv_DLSample, hv_AugMethodValue);
    }
    else if (0 != (int(hv_AugMethod==HTuple("crop_percentage"))))
    {
      augment_dl_sample_crop_percentage(hv_DLSample, hv_AugMethodValue);
    }
    else if (0 != (int(hv_AugMethod==HTuple("crop_pixel"))))
    {
      augment_dl_sample_crop_pixel(hv_DLSample, hv_AugMethodValue);
    }
    else if (0 != (int(hv_AugMethod==HTuple("mirror"))))
    {
      augment_dl_sample_mirror(hv_DLSample, hv_AugMethodValue, hv_AugParams.TupleGetDictTuple("class_ids_no_orientation"), 
          hv_AugParams.TupleGetDictTuple("ignore_direction"));
    }
    else if (0 != (int(hv_AugMethod==HTuple("remove_pixel"))))
    {
      augment_dl_sample_remove_pixel(hv_DLSample, HTuple(hv_AugMethodValue[0]), HTuple(hv_AugMethodValue[1]));
    }
    else if (0 != (int(hv_AugMethod==HTuple("rotate"))))
    {
      augment_dl_sample_rotate(hv_DLSample, hv_AugMethodValue, hv_AugParams.TupleGetDictTuple("class_ids_no_orientation"), 
          hv_AugParams.TupleGetDictTuple("ignore_direction"));
    }
    else if (0 != (int(hv_AugMethod==HTuple("rotate_range"))))
    {
      augment_dl_sample_rotate_range(hv_DLSample, hv_AugMethodValue);
    }
    else if (0 != (int(hv_AugMethod==HTuple("saturation_variation"))))
    {
      augment_dl_sample_saturation_variation(hv_DLSample, hv_AugMethodValue);
    }
  }
  }
  return;
}

// Chapter: Deep Learning / OCR
// Short Description: Compute zoom factors to fit an image to a target size. 
void calculate_dl_image_zoom_factors (HTuple hv_ImageWidth, HTuple hv_ImageHeight, 
    HTuple hv_TargetWidth, HTuple hv_TargetHeight, HTuple hv_DLPreprocessParam, HTuple *hv_ZoomFactorWidth, 
    HTuple *hv_ZoomFactorHeight)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ScaleWidthUnit, hv_ScaleHeightUnit;
  HTuple  hv_PreserveAspectRatio, hv_Scale, hv___Tmp_Ctrl_Dict_Init_0;

  //Calculate the unit zoom factors, which zoom the input image to 1px.
  hv_ScaleWidthUnit = 1.0/(hv_ImageWidth.TupleReal());
  hv_ScaleHeightUnit = 1.0/(hv_ImageHeight.TupleReal());
  //
  //Calculate the required zoom factors for the available target size.
  (*hv_ZoomFactorWidth) = hv_TargetWidth*hv_ScaleWidthUnit;
  (*hv_ZoomFactorHeight) = hv_TargetHeight*hv_ScaleHeightUnit;
  //
  //Aspect-ratio preserving zoom is supported for model type 'ocr_detection' only.
  CreateDict(&hv___Tmp_Ctrl_Dict_Init_0);
  SetDictTuple(hv___Tmp_Ctrl_Dict_Init_0, "comp", "ocr_detection");
  hv_PreserveAspectRatio = (hv_DLPreprocessParam.TupleConcat(hv___Tmp_Ctrl_Dict_Init_0)).TupleTestEqualDictItem("model_type","comp");
  hv___Tmp_Ctrl_Dict_Init_0 = HTuple::TupleConstant("HNULL");
  //
  if (0 != hv_PreserveAspectRatio)
  {
    //
    //Use smaller scaling factor, which results in unfilled domain
    //on the respective other axis.
    hv_Scale = (*hv_ZoomFactorWidth).TupleMin2((*hv_ZoomFactorHeight));
    //Ensure that the zoom factors result in lengths of at least 1px.
    (*hv_ZoomFactorWidth) = hv_Scale.TupleMax2(hv_ScaleWidthUnit);
    (*hv_ZoomFactorHeight) = hv_Scale.TupleMax2(hv_ScaleHeightUnit);
  }
  return;
}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Calculate the class weights for a semantic segmentation dataset. 
void calculate_dl_segmentation_class_weights (HTuple hv_DLDataset, HTuple hv_MaxWeight, 
    HTuple hv_IgnoreClassIDs, HTuple *hv_ClassWeights)
{

  // Local iconic variables
  HObject  ho_SegmentationImage;

  // Local control variables
  HTuple  hv_KeysExists, hv_DLSamples, hv_SampleIndices;
  HTuple  hv_ClassIDs, hv_ClassIDsToClassIndex, hv_ClassAreas;
  HTuple  hv_SampleIndex, hv_DLSample, hv_ImageType, hv_AbsoluteHisto;
  HTuple  hv_IgnoreAreas, hv_TotalArea, hv_ValidClasses, hv_ClassFreq;
  HTuple  hv_IndicesToClip;

  //
  //This procedure calculates a weight for each class that is present in the Dataset.
  //The class weights are calculated according to the inverse class frequencies
  //in the training dataset.
  //Therefore, the dataset has to be split before calling this procedure.
  //
  //Check if the input is correct.
  GetDictParam(hv_DLDataset, "key_exists", (HTuple("samples").Append("class_ids")), 
      &hv_KeysExists);
  if (0 != (HTuple(hv_KeysExists[0]).TupleNot()))
  {
    throw HException("DLDataset must contain a key-value pair for 'samples'");
  }
  if (0 != (HTuple(hv_KeysExists[1]).TupleNot()))
  {
    throw HException("DLDataset must contain a key-value pair for 'class_ids'");
  }
  if (0 != (int(hv_MaxWeight<=0)))
  {
    throw HException("MaxWeight must be greater than 0");
  }
  //
  //Get the samples of the dataset.
  GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
  //Get the train samples.
  find_dl_samples(hv_DLSamples, "split", "train", "match", &hv_SampleIndices);
  if (0 != (int((hv_SampleIndices.TupleLength())==0)))
  {
    throw HException("The DLDataset does not contain any samples with value 'train' for key 'split'");
  }
  //
  //Get the class IDs of the dataset.
  GetDictTuple(hv_DLDataset, "class_ids", &hv_ClassIDs);
  //
  //Define mapping from class ID to class index.
  create_dl_class_id_mapping(hv_ClassIDs, &hv_ClassIDsToClassIndex);
  //
  //We want to collect the number of pixels for each class.
  hv_ClassAreas = HTuple(hv_ClassIDs.TupleLength(),0);
  //
  //Loop over the samples.
  {
  HTuple end_val36 = (hv_SampleIndices.TupleLength())-1;
  HTuple step_val36 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val36, step_val36); hv_SampleIndex += step_val36)
  {
    //
    //Read the sample.
    read_dl_samples(hv_DLDataset, HTuple(hv_SampleIndices[hv_SampleIndex]), &hv_DLSample);
    //
    //Get the segmentation image.
    GetDictObject(&ho_SegmentationImage, hv_DLSample, "segmentation_image");
    //
    //Convert the segmentation image if necessary.
    GetImageType(ho_SegmentationImage, &hv_ImageType);
    if (0 != (int(((((HTuple("int1").Append("int2")).Append("uint2")).Append("byte")).TupleFind(hv_ImageType))==-1)))
    {
      ConvertImageType(ho_SegmentationImage, &ho_SegmentationImage, "uint2");
    }
    //
    //Get the number of pixels for each class.
    GrayHistoAbs(ho_SegmentationImage, ho_SegmentationImage, 1, &hv_AbsoluteHisto);
    //
    //Accumulate the areas.
    hv_ClassAreas += HTuple(hv_AbsoluteHisto[hv_ClassIDs]);
  }
  }
  //
  //Get the total number of pixels without the area of ignore classes.
  GetDictTuple(hv_ClassIDsToClassIndex, hv_IgnoreClassIDs, &hv_IgnoreAreas);
  hv_ClassAreas[hv_IgnoreAreas] = 0;
  hv_TotalArea = hv_ClassAreas.TupleSum();
  //
  //Calculate the inverse class frequencies.
  (*hv_ClassWeights) = HTuple(hv_ClassIDs.TupleLength(),0.);
  hv_ValidClasses = (hv_ClassAreas.TupleNotEqualElem(0)).TupleFind(1);
  hv_ClassFreq = hv_ClassAreas/(hv_TotalArea.TupleReal());
  (*hv_ClassWeights)[hv_ValidClasses] = 1./(HTuple(hv_ClassFreq[hv_ValidClasses])+0.0001);
  //
  //Scale the weights to obtain a final output of 1.0 for the most frequent class.
  (*hv_ClassWeights) = (*hv_ClassWeights)/(HTuple((*hv_ClassWeights)[hv_ValidClasses]).TupleMin());
  //Clip the weights.
  hv_IndicesToClip = ((*hv_ClassWeights).TupleGreaterElem(hv_MaxWeight)).TupleFind(1);
  if (0 != (int(hv_IndicesToClip!=-1)))
  {
    (*hv_ClassWeights)[hv_IndicesToClip] = hv_MaxWeight;
  }

  return;
}

// Chapter: Deep Learning / Model
// Short Description: Check and sanitize the parameters of augment_dl_samples. 
void check_augment_dl_samples_gen_param (HTuple hv_GenParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_GenKeys, hv_ValidAugMethods, hv_ValidOtherKeys;
  HTuple  hv_ValidKeys, hv_InvalidKeys, hv_Exception, hv_KeyIndex;
  HTuple  hv_GenKey, hv_GenValue, hv_NumValues, hv_V, hv_Value;
  HTuple  hv_SanitizedValue;

  //This procedure validates and sanitizes the GenParam parameter of the
  //augment_dl_samples procedure.
  //
  //This procedure should not be used outside of the augment_dl_samples procedure!
  //The name, parameters, and functionality of this procedure are subject to change.
  //
  //Check that there are no unknown parameters.
  GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenKeys);
  hv_ValidAugMethods.Clear();
  hv_ValidAugMethods[0] = "brightness_variation";
  hv_ValidAugMethods[1] = "brightness_variation_spot";
  hv_ValidAugMethods[2] = "contrast_variation";
  hv_ValidAugMethods[3] = "crop_percentage";
  hv_ValidAugMethods[4] = "crop_pixel";
  hv_ValidAugMethods[5] = "mirror";
  hv_ValidAugMethods[6] = "remove_pixel";
  hv_ValidAugMethods[7] = "rotate";
  hv_ValidAugMethods[8] = "rotate_range";
  hv_ValidAugMethods[9] = "saturation_variation";
  hv_ValidOtherKeys.Clear();
  hv_ValidOtherKeys[0] = "augmentation_percentage";
  hv_ValidOtherKeys[1] = "class_ids_no_orientation";
  hv_ValidOtherKeys[2] = "ignore_direction";
  hv_ValidKeys.Clear();
  hv_ValidKeys.Append(hv_ValidAugMethods);
  hv_ValidKeys.Append(hv_ValidOtherKeys);
  TupleDifference(hv_GenKeys, hv_ValidKeys, &hv_InvalidKeys);
  if (0 != (int((hv_InvalidKeys.TupleLength())>0)))
  {
    hv_Exception = "These keys in GenParam are not supported by augment_dl_samples: '"+(hv_InvalidKeys.TupleJoin(HTuple("', '")+"'"));
    throw HException(hv_Exception);
  }
  //
  //Check each parameter.
  {
  HTuple end_val18 = (hv_GenKeys.TupleLength())-1;
  HTuple step_val18 = 1;
  for (hv_KeyIndex=0; hv_KeyIndex.Continue(end_val18, step_val18); hv_KeyIndex += step_val18)
  {
    //Get the key and value, for example 'rotate_range' and 3.
    hv_GenKey = HTuple(hv_GenKeys[hv_KeyIndex]);
    hv_GenValue = hv_GenParam.TupleGetDictTuple(hv_GenKey);
    //Perform validation
    if (0 != (int(hv_GenKey==HTuple("augmentation_percentage"))))
    {
      //Check if input value is in range of 0-100 %.
      hv_Exception = "The given value for 'augmentation_percentage' has to be in the range 0-100.";
      if (0 != (hv_GenValue.TupleIsNumber()))
      {
        if (0 != (HTuple(int(hv_GenValue<0)).TupleOr(int(hv_GenValue>100))))
        {
          throw HException(hv_Exception);
        }
      }
      else
      {
        throw HException(hv_Exception);
      }
    }
    if (0 != (int(hv_GenKey==HTuple("brightness_variation"))))
    {
      //Check if the input value is in range of 0-255.
      hv_Exception = "The given value for 'brightness_variation' has to be in the range 0-255.";
      if (0 != (hv_GenValue.TupleIsNumber()))
      {
        if (0 != (HTuple(int(hv_GenValue<0)).TupleOr(int(hv_GenValue>255))))
        {
          throw HException(hv_Exception);
        }
      }
      else
      {
        throw HException(hv_Exception);
      }
    }
    if (0 != (int(hv_GenKey==HTuple("brightness_variation_spot"))))
    {
      //Check if the input value is in range of 0-255.
      hv_Exception = "The given value for 'brightness_variation_spot' has to be in the range 0-255.";
      if (0 != (hv_GenValue.TupleIsNumber()))
      {
        if (0 != (HTuple(int(hv_GenValue<0)).TupleOr(int(hv_GenValue>255))))
        {
          throw HException(hv_Exception);
        }
      }
      else
      {
        throw HException(hv_Exception);
      }
    }
    if (0 != (int(hv_GenKey==HTuple("contrast_variation"))))
    {
      //Check if the input value is not negative.
      hv_Exception = "The given value for 'contrast_variation' has to be greater than or equal to zero.";
      if (0 != (hv_GenValue.TupleIsNumber()))
      {
        if (0 != (int(hv_GenValue<0)))
        {
          throw HException(hv_Exception);
        }
      }
      else
      {
        throw HException(hv_Exception);
      }
    }
    if (0 != (int(hv_GenKey==HTuple("crop_percentage"))))
    {
      //Check if the input value is in range of 1-100%.
      hv_Exception = "The given value for 'crop_percentage' has to be in the range 1-100.";
      if (0 != (hv_GenValue.TupleIsNumber()))
      {
        if (0 != (HTuple(int(hv_GenValue<1)).TupleOr(int(hv_GenValue>100))))
        {
          throw HException(hv_Exception);
        }
      }
      else
      {
        throw HException(hv_Exception);
      }
    }
    if (0 != (int(hv_GenKey==HTuple("crop_pixel"))))
    {
      //Check if the input value is greater 0.
      hv_Exception = "The given value for 'crop_pixel' has to be greater or equal to 1.";
      if (0 != (hv_GenValue.TupleIsNumber()))
      {
        if (0 != (int(hv_GenValue<1)))
        {
          throw HException(hv_Exception);
        }
      }
      else
      {
        throw HException(hv_Exception);
      }
    }
    if (0 != (int(hv_GenKey==HTuple("ignore_direction"))))
    {
      hv_Exception = HTuple("The value given for 'ignore_direction' has to be either 'true','false', true or false.");
      if (0 != (int(((((HTuple("true").Append("false")).Append(1)).Append(0)).TupleFind(hv_GenValue))==-1)))
      {
        throw HException(hv_Exception);
      }
      //Sanitize string values to Booleans.
      if (0 != (int(hv_GenValue==HTuple("false"))))
      {
        hv_GenValue = 0;
      }
      else if (0 != (int(hv_GenValue==HTuple("true"))))
      {
        hv_GenValue = 1;
      }
      //Overwrite the value in GenParam.
      SetDictTuple(hv_GenParam, hv_GenKey, hv_GenValue);
    }
    if (0 != (int(hv_GenKey==HTuple("mirror"))))
    {
      //Check if the input is a string and contains either 'off' or the mirroring code.
      if (0 != ((hv_GenValue.TupleIsNumber()).TupleOr(HTuple(HTuple(HTuple(HTuple(HTuple(int(hv_GenValue==HTuple("off"))).TupleOr(int(hv_GenValue==HTuple("c")))).TupleOr(int(hv_GenValue==HTuple("r")))).TupleOr(int(hv_GenValue==HTuple("cr")))).TupleOr(int(hv_GenValue==HTuple("rc")))).TupleNot())))
      {
        throw HException("Unknown type for mirroring.");
      }
    }
    if (0 != (int(hv_GenKey==HTuple("remove_pixel"))))
    {
      //Set pixels to remove.
      //Check if the input values are valid. Valid are either 1d-tuples with
      //the pixels to remove for both dimensions, or 2d-tuples with the pixels
      //to remove for each dimension [x,y].
      hv_NumValues = hv_GenValue.TupleLength();
      if (0 != (HTuple(int(hv_NumValues!=1)).TupleAnd(int(hv_NumValues!=2))))
      {
        throw HException("The number of values for 'remove_pixel' has to be 1 or 2.");
      }
      {
      HTuple end_val118 = hv_NumValues-1;
      HTuple step_val118 = 1;
      for (hv_V=0; hv_V.Continue(end_val118, step_val118); hv_V += step_val118)
      {
        hv_Value = HTuple(hv_GenValue[hv_V]);
        if (0 != ((hv_Value.TupleIsInt()).TupleNot()))
        {
          throw HException("The given value for 'remove_pixel' has to be an integer value.");
        }
        if (0 != (int(hv_Value<0)))
        {
          throw HException("The given value for 'remove_pixel' has to be equal or greater than 0.");
        }
      }
      }
      //Store the input values for each dimension [x,y].
      hv_SanitizedValue = ((const HTuple&)hv_GenValue)[0];
      if (0 != (int(hv_NumValues==1)))
      {
        hv_SanitizedValue[1] = HTuple(hv_GenValue[0]);
      }
      else
      {
        hv_SanitizedValue[1] = HTuple(hv_GenValue[1]);
      }
      //Overwrite the value in GenParam.
      SetDictTuple(hv_GenParam, hv_GenKey, hv_SanitizedValue);
    }
    if (0 != (int(hv_GenKey==HTuple("rotate"))))
    {
      //Check if the input value is either 0, 90, or 180.
      hv_Exception = HTuple("The value given for 'rotate' has to be either 0, 90, or 180.");
      if (0 != (hv_GenValue.TupleIsNumber()))
      {
        if (0 != (int((((HTuple(0).Append(90)).Append(180)).TupleFind(hv_GenValue))==-1)))
        {
          throw HException(hv_Exception);
        }
      }
      else
      {
        throw HException(hv_Exception);
      }
    }
    if (0 != (int(hv_GenKey==HTuple("rotate_range"))))
    {
      //Check if the input value is in range of 0-180.
      hv_Exception = "The given value for 'rotate_range' has to be in the range 0-180.";
      if (0 != (hv_GenValue.TupleIsNumber()))
      {
        if (0 != (HTuple(int(hv_GenValue<0)).TupleOr(int(hv_GenValue>180))))
        {
          throw HException(hv_Exception);
        }
      }
      else
      {
        throw HException(hv_Exception);
      }
    }
    if (0 != (int(hv_GenKey==HTuple("saturation_variation"))))
    {
      //Check if the input value is not negative.
      hv_Exception = "The given value for 'saturation_variation' has to be greater than or equal to zero.";
      if (0 != (hv_GenValue.TupleIsNumber()))
      {
        if (0 != (int(hv_GenValue<0)))
        {
          throw HException(hv_Exception);
        }
      }
      else
      {
        throw HException(hv_Exception);
      }
    }
  }
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Check the content of the parameter dictionary DLPreprocessParam. 
void check_dl_preprocess_param (HTuple hv_DLPreprocessParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CheckParams, hv_KeyExists, hv_DLModelType;
  HTuple  hv_Exception, hv_SupportedModelTypes, hv_Index;
  HTuple  hv_ParamNamesGeneral, hv_ParamNamesSegmentation;
  HTuple  hv_ParamNamesDetectionOptional, hv_ParamNamesPreprocessingOptional;
  HTuple  hv_ParamNames3DGrippingPointsOptional, hv_ParamNamesAll;
  HTuple  hv_ParamNames, hv_KeysExists, hv_I, hv_Exists, hv_InputKeys;
  HTuple  hv_Key, hv_Value, hv_Indices, hv_ValidValues, hv_ValidTypes;
  HTuple  hv_V, hv_T, hv_IsInt, hv_ValidTypesListing, hv_ValidValueListing;
  HTuple  hv_EmptyStrings, hv_ImageRangeMinExists, hv_ImageRangeMaxExists;
  HTuple  hv_ImageRangeMin, hv_ImageRangeMax, hv_IndexParam;
  HTuple  hv_SetBackgroundID, hv_ClassIDsBackground, hv_Intersection;
  HTuple  hv_IgnoreClassIDs, hv_KnownClasses, hv_IgnoreClassID;
  HTuple  hv_OptionalKeysExist, hv_InstanceType, hv_IsInstanceSegmentation;
  HTuple  hv_IgnoreDirection, hv_ClassIDsNoOrientation, hv_SemTypes;

  //
  //This procedure checks a dictionary with parameters for DL preprocessing.
  //
  hv_CheckParams = 1;
  //If check_params is set to false, do not check anything.
  GetDictParam(hv_DLPreprocessParam, "key_exists", "check_params", &hv_KeyExists);
  if (0 != hv_KeyExists)
  {
    GetDictTuple(hv_DLPreprocessParam, "check_params", &hv_CheckParams);
    if (0 != (hv_CheckParams.TupleNot()))
    {
      return;
    }
  }
  //
  try
  {
    GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_DLModelType);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    throw HException(HTuple(HTuple("DLPreprocessParam needs the parameter: '")+"model_type")+"'");
  }
  //
  //Check for correct model type.
  hv_SupportedModelTypes.Clear();
  hv_SupportedModelTypes[0] = "3d_gripping_point_detection";
  hv_SupportedModelTypes[1] = "anomaly_detection";
  hv_SupportedModelTypes[2] = "classification";
  hv_SupportedModelTypes[3] = "detection";
  hv_SupportedModelTypes[4] = "gc_anomaly_detection";
  hv_SupportedModelTypes[5] = "ocr_recognition";
  hv_SupportedModelTypes[6] = "ocr_detection";
  hv_SupportedModelTypes[7] = "segmentation";
  TupleFind(hv_SupportedModelTypes, hv_DLModelType, &hv_Index);
  if (0 != (HTuple(int(hv_Index==-1)).TupleOr(int(hv_Index==HTuple()))))
  {
    throw HException(HTuple("Only models of type '3d_gripping_point_detection', 'anomaly_detection', 'classification', 'detection', 'gc_anomaly_detection', 'ocr_recognition', 'ocr_detection' or 'segmentation' are supported"));
    return;
  }
  //
  //Parameter names that are required.
  //General parameters.
  hv_ParamNamesGeneral.Clear();
  hv_ParamNamesGeneral[0] = "model_type";
  hv_ParamNamesGeneral[1] = "image_width";
  hv_ParamNamesGeneral[2] = "image_height";
  hv_ParamNamesGeneral[3] = "image_num_channels";
  hv_ParamNamesGeneral[4] = "image_range_min";
  hv_ParamNamesGeneral[5] = "image_range_max";
  hv_ParamNamesGeneral[6] = "normalization_type";
  hv_ParamNamesGeneral[7] = "domain_handling";
  //Segmentation specific parameters.
  hv_ParamNamesSegmentation.Clear();
  hv_ParamNamesSegmentation[0] = "ignore_class_ids";
  hv_ParamNamesSegmentation[1] = "set_background_id";
  hv_ParamNamesSegmentation[2] = "class_ids_background";
  //Detection specific parameters.
  hv_ParamNamesDetectionOptional.Clear();
  hv_ParamNamesDetectionOptional[0] = "instance_type";
  hv_ParamNamesDetectionOptional[1] = "ignore_direction";
  hv_ParamNamesDetectionOptional[2] = "class_ids_no_orientation";
  hv_ParamNamesDetectionOptional[3] = "instance_segmentation";
  //Optional preprocessing parameters.
  hv_ParamNamesPreprocessingOptional.Clear();
  hv_ParamNamesPreprocessingOptional[0] = "mean_values_normalization";
  hv_ParamNamesPreprocessingOptional[1] = "deviation_values_normalization";
  hv_ParamNamesPreprocessingOptional[2] = "check_params";
  hv_ParamNamesPreprocessingOptional[3] = "augmentation";
  //3D Gripping Point Detection specific parameters.
  hv_ParamNames3DGrippingPointsOptional.Clear();
  hv_ParamNames3DGrippingPointsOptional[0] = "min_z";
  hv_ParamNames3DGrippingPointsOptional[1] = "max_z";
  hv_ParamNames3DGrippingPointsOptional[2] = "normal_image_width";
  hv_ParamNames3DGrippingPointsOptional[3] = "normal_image_height";
  //All parameters
  hv_ParamNamesAll.Clear();
  hv_ParamNamesAll.Append(hv_ParamNamesGeneral);
  hv_ParamNamesAll.Append(hv_ParamNamesSegmentation);
  hv_ParamNamesAll.Append(hv_ParamNamesDetectionOptional);
  hv_ParamNamesAll.Append(hv_ParamNames3DGrippingPointsOptional);
  hv_ParamNamesAll.Append(hv_ParamNamesPreprocessingOptional);
  hv_ParamNames = hv_ParamNamesGeneral;
  if (0 != (HTuple(int(hv_DLModelType==HTuple("segmentation"))).TupleOr(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
  {
    //Extend ParamNames for models of type segmentation.
    hv_ParamNames = hv_ParamNames.TupleConcat(hv_ParamNamesSegmentation);
  }
  //
  //Check if legacy parameter exist.
  //Otherwise map it to the legal parameter.
  replace_legacy_preprocessing_parameters(hv_DLPreprocessParam);
  //
  //Check that all necessary parameters are included.
  //
  GetDictParam(hv_DLPreprocessParam, "key_exists", hv_ParamNames, &hv_KeysExists);
  if (0 != (int(((hv_KeysExists.TupleEqualElem(0)).TupleSum())>0)))
  {
    {
    HTuple end_val54 = hv_KeysExists.TupleLength();
    HTuple step_val54 = 1;
    for (hv_I=0; hv_I.Continue(end_val54, step_val54); hv_I += step_val54)
    {
      hv_Exists = HTuple(hv_KeysExists[hv_I]);
      if (0 != (hv_Exists.TupleNot()))
      {
        throw HException(("DLPreprocessParam needs the parameter: '"+HTuple(hv_ParamNames[hv_I]))+"'");
      }
    }
    }
  }
  //
  //Check the keys provided.
  GetDictParam(hv_DLPreprocessParam, "keys", HTuple(), &hv_InputKeys);
  {
  HTuple end_val64 = (hv_InputKeys.TupleLength())-1;
  HTuple step_val64 = 1;
  for (hv_I=0; hv_I.Continue(end_val64, step_val64); hv_I += step_val64)
  {
    hv_Key = HTuple(hv_InputKeys[hv_I]);
    GetDictTuple(hv_DLPreprocessParam, hv_Key, &hv_Value);
    //Check that the key is known.
    TupleFind(hv_ParamNamesAll, hv_Key, &hv_Indices);
    if (0 != (int(hv_Indices==-1)))
    {
      throw HException(("Unknown key for DLPreprocessParam: '"+HTuple(hv_InputKeys[hv_I]))+"'");
      return;
    }
    //Set expected values and types.
    hv_ValidValues = HTuple();
    hv_ValidTypes = HTuple();
    if (0 != (int(hv_Key==HTuple("normalization_type"))))
    {
      hv_ValidValues.Clear();
      hv_ValidValues[0] = "all_channels";
      hv_ValidValues[1] = "first_channel";
      hv_ValidValues[2] = "constant_values";
      hv_ValidValues[3] = "none";
    }
    else if (0 != (int(hv_Key==HTuple("domain_handling"))))
    {
      if (0 != (int(hv_DLModelType==HTuple("anomaly_detection"))))
      {
        hv_ValidValues.Clear();
        hv_ValidValues[0] = "full_domain";
        hv_ValidValues[1] = "crop_domain";
        hv_ValidValues[2] = "keep_domain";
      }
      else if (0 != (int(hv_DLModelType==HTuple("3d_gripping_point_detection"))))
      {
        hv_ValidValues.Clear();
        hv_ValidValues[0] = "full_domain";
        hv_ValidValues[1] = "crop_domain";
        hv_ValidValues[2] = "keep_domain";
      }
      else
      {
        hv_ValidValues.Clear();
        hv_ValidValues[0] = "full_domain";
        hv_ValidValues[1] = "crop_domain";
      }
    }
    else if (0 != (int(hv_Key==HTuple("model_type"))))
    {
      hv_ValidValues.Clear();
      hv_ValidValues[0] = "3d_gripping_point_detection";
      hv_ValidValues[1] = "anomaly_detection";
      hv_ValidValues[2] = "classification";
      hv_ValidValues[3] = "detection";
      hv_ValidValues[4] = "gc_anomaly_detection";
      hv_ValidValues[5] = "ocr_recognition";
      hv_ValidValues[6] = "ocr_detection";
      hv_ValidValues[7] = "segmentation";
    }
    else if (0 != (int(hv_Key==HTuple("augmentation"))))
    {
      hv_ValidValues.Clear();
      hv_ValidValues[0] = "true";
      hv_ValidValues[1] = "false";
    }
    else if (0 != (int(hv_Key==HTuple("set_background_id"))))
    {
      hv_ValidTypes = "int";
    }
    else if (0 != (int(hv_Key==HTuple("class_ids_background"))))
    {
      hv_ValidTypes = "int";
    }
    //Check that type is valid.
    if (0 != (int((hv_ValidTypes.TupleLength())>0)))
    {
      {
      HTuple end_val97 = (hv_ValidTypes.TupleLength())-1;
      HTuple step_val97 = 1;
      for (hv_V=0; hv_V.Continue(end_val97, step_val97); hv_V += step_val97)
      {
        hv_T = HTuple(hv_ValidTypes[hv_V]);
        if (0 != (int(hv_T==HTuple("int"))))
        {
          TupleIsInt(hv_Value, &hv_IsInt);
          if (0 != (hv_IsInt.TupleNot()))
          {
            hv_ValidTypes = ("'"+hv_ValidTypes)+"'";
            if (0 != (int((hv_ValidTypes.TupleLength())<2)))
            {
              hv_ValidTypesListing = hv_ValidTypes;
            }
            else
            {
              hv_ValidTypesListing = (((hv_ValidTypes.TupleSelectRange(0,HTuple(0).TupleMax2((hv_ValidTypes.TupleLength())-2)))+HTuple(", "))+HTuple(hv_ValidTypes[(hv_ValidTypes.TupleLength())-1])).TupleSum();
            }
            throw HException(((((("The value given in the key '"+hv_Key)+"' of DLPreprocessParam is invalid. Valid types are: ")+hv_ValidTypesListing)+". The given value was '")+hv_Value)+"'.");
            return;
          }
        }
        else
        {
          throw HException("Internal error. Unknown valid type.");
        }
      }
      }
    }
    //Check that value is valid.
    if (0 != (int((hv_ValidValues.TupleLength())>0)))
    {
      TupleFindFirst(hv_ValidValues, hv_Value, &hv_Index);
      if (0 != (int(hv_Index==-1)))
      {
        hv_ValidValues = ("'"+hv_ValidValues)+"'";
        if (0 != (int((hv_ValidValues.TupleLength())<2)))
        {
          hv_ValidValueListing = hv_ValidValues;
        }
        else
        {
          hv_EmptyStrings = HTuple((hv_ValidValues.TupleLength())-2,"");
          hv_ValidValueListing = (((hv_ValidValues.TupleSelectRange(0,HTuple(0).TupleMax2((hv_ValidValues.TupleLength())-2)))+HTuple(", "))+(hv_EmptyStrings.TupleConcat(HTuple(hv_ValidValues[(hv_ValidValues.TupleLength())-1])))).TupleSum();
        }
        throw HException(((((("The value given in the key '"+hv_Key)+"' of DLPreprocessParam is invalid. Valid values are: ")+hv_ValidValueListing)+". The given value was '")+hv_Value)+"'.");
      }
    }
  }
  }
  //
  //Check the correct setting of ImageRangeMin and ImageRangeMax.
  if (0 != (HTuple(int(hv_DLModelType==HTuple("classification"))).TupleOr(int(hv_DLModelType==HTuple("detection")))))
  {
    //Check ImageRangeMin and ImageRangeMax.
    GetDictParam(hv_DLPreprocessParam, "key_exists", "image_range_min", &hv_ImageRangeMinExists);
    GetDictParam(hv_DLPreprocessParam, "key_exists", "image_range_max", &hv_ImageRangeMaxExists);
    //If they are present, check that they are set correctly.
    if (0 != hv_ImageRangeMinExists)
    {
      GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
      if (0 != (int(hv_ImageRangeMin!=-127)))
      {
        throw HException(("For model type "+hv_DLModelType)+" ImageRangeMin has to be -127.");
      }
    }
    if (0 != hv_ImageRangeMaxExists)
    {
      GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
      if (0 != (int(hv_ImageRangeMax!=128)))
      {
        throw HException(("For model type "+hv_DLModelType)+" ImageRangeMax has to be 128.");
      }
    }
  }
  //
  //Check segmentation specific parameters.
  if (0 != (HTuple(int(hv_DLModelType==HTuple("segmentation"))).TupleOr(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
  {
    //Check if detection specific parameters are set.
    GetDictParam(hv_DLPreprocessParam, "key_exists", hv_ParamNamesDetectionOptional, 
        &hv_KeysExists);
    //If they are present, check that they are [].
    {
    HTuple end_val157 = (hv_ParamNamesDetectionOptional.TupleLength())-1;
    HTuple step_val157 = 1;
    for (hv_IndexParam=0; hv_IndexParam.Continue(end_val157, step_val157); hv_IndexParam += step_val157)
    {
      if (0 != (HTuple(hv_KeysExists[hv_IndexParam])))
      {
        GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[hv_IndexParam]), 
            &hv_Value);
        if (0 != (int(hv_Value!=HTuple())))
        {
          throw HException(((("The preprocessing parameter '"+HTuple(hv_ParamNamesDetectionOptional[hv_IndexParam]))+"' was set to ")+hv_Value)+HTuple(" but for segmentation it should be set to [], as it is not used for this method."));
        }
      }
    }
    }
    //Check 'set_background_id'.
    GetDictTuple(hv_DLPreprocessParam, "set_background_id", &hv_SetBackgroundID);
    if (0 != (HTuple(int(hv_SetBackgroundID!=HTuple())).TupleAnd(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
    {
      throw HException(HTuple(HTuple("The preprocessing parameter '")+"set_background_id")+HTuple("' should be set to [] for 3d_gripping_point_detection, as it is not used for this method."));
    }
    if (0 != (int((hv_SetBackgroundID.TupleLength())>1)))
    {
      throw HException("Only one class_id as 'set_background_id' allowed.");
    }
    //Check 'class_ids_background'.
    GetDictTuple(hv_DLPreprocessParam, "class_ids_background", &hv_ClassIDsBackground);
    if (0 != (HTuple(int(hv_ClassIDsBackground!=HTuple())).TupleAnd(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
    {
      throw HException(HTuple(HTuple("The preprocessing parameter '")+"class_ids_background")+HTuple("' should be set to [] for 3d_gripping_point_detection, as it is not used for this method."));
    }
    if (0 != (HTuple(HTuple(int((hv_SetBackgroundID.TupleLength())>0)).TupleAnd(HTuple(int((hv_ClassIDsBackground.TupleLength())>0)).TupleNot())).TupleOr(HTuple(int((hv_ClassIDsBackground.TupleLength())>0)).TupleAnd(HTuple(int((hv_SetBackgroundID.TupleLength())>0)).TupleNot()))))
    {
      throw HException("Both keys 'set_background_id' and 'class_ids_background' are required.");
    }
    //Check that 'class_ids_background' and 'set_background_id' are disjoint.
    if (0 != (int((hv_SetBackgroundID.TupleLength())>0)))
    {
      TupleIntersection(hv_SetBackgroundID, hv_ClassIDsBackground, &hv_Intersection);
      if (0 != (hv_Intersection.TupleLength()))
      {
        throw HException("Class IDs in 'set_background_id' and 'class_ids_background' need to be disjoint.");
      }
    }
    //Check 'ignore_class_ids'.
    GetDictTuple(hv_DLPreprocessParam, "ignore_class_ids", &hv_IgnoreClassIDs);
    if (0 != (HTuple(int(hv_IgnoreClassIDs!=HTuple())).TupleAnd(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
    {
      throw HException(HTuple(HTuple("The preprocessing parameter '")+"ignore_class_ids")+HTuple("' should be set to [] for 3d_gripping_point_detection, as it is not used for this method."));
    }
    hv_KnownClasses.Clear();
    hv_KnownClasses.Append(hv_SetBackgroundID);
    hv_KnownClasses.Append(hv_ClassIDsBackground);
    {
    HTuple end_val194 = (hv_IgnoreClassIDs.TupleLength())-1;
    HTuple step_val194 = 1;
    for (hv_I=0; hv_I.Continue(end_val194, step_val194); hv_I += step_val194)
    {
      hv_IgnoreClassID = HTuple(hv_IgnoreClassIDs[hv_I]);
      TupleFindFirst(hv_KnownClasses, hv_IgnoreClassID, &hv_Index);
      if (0 != (HTuple(int((hv_Index.TupleLength())>0)).TupleAnd(int(hv_Index!=-1))))
      {
        throw HException("The given 'ignore_class_ids' must not be included in the 'class_ids_background' or 'set_background_id'.");
      }
    }
    }
  }
  else if (0 != (int(hv_DLModelType==HTuple("detection"))))
  {
    //Check if segmentation specific parameters are set.
    GetDictParam(hv_DLPreprocessParam, "key_exists", hv_ParamNamesSegmentation, &hv_KeysExists);
    //If they are present, check that they are [].
    {
    HTuple end_val205 = (hv_ParamNamesSegmentation.TupleLength())-1;
    HTuple step_val205 = 1;
    for (hv_IndexParam=0; hv_IndexParam.Continue(end_val205, step_val205); hv_IndexParam += step_val205)
    {
      if (0 != (HTuple(hv_KeysExists[hv_IndexParam])))
      {
        GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesSegmentation[hv_IndexParam]), 
            &hv_Value);
        if (0 != (int(hv_Value!=HTuple())))
        {
          throw HException(((("The preprocessing parameter '"+HTuple(hv_ParamNamesSegmentation[hv_IndexParam]))+"' was set to ")+hv_Value)+HTuple(" but for detection it should be set to [], as it is not used for this method."));
        }
      }
    }
    }
    //Check optional parameters.
    GetDictParam(hv_DLPreprocessParam, "key_exists", hv_ParamNamesDetectionOptional, 
        &hv_OptionalKeysExist);
    if (0 != (HTuple(hv_OptionalKeysExist[0])))
    {
      //Check 'instance_type'.
      GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[0]), 
          &hv_InstanceType);
      if (0 != (int((((HTuple("rectangle1").Append("rectangle2")).Append("mask")).TupleFind(hv_InstanceType))==-1)))
      {
        throw HException(("Invalid generic parameter for 'instance_type': "+hv_InstanceType)+HTuple(", only 'rectangle1' and 'rectangle2' are allowed"));
      }
    }
    //If instance_segmentation is set we might overwrite the instance_type for the preprocessing.
    if (0 != (HTuple(hv_OptionalKeysExist[3])))
    {
      GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[3]), 
          &hv_IsInstanceSegmentation);
      if (0 != (int(((((HTuple(1).Append(0)).Append("true")).Append("false")).TupleFind(hv_IsInstanceSegmentation))==-1)))
      {
        throw HException(("Invalid generic parameter for 'instance_segmentation': "+hv_IsInstanceSegmentation)+HTuple(", only true, false, 'true' and 'false' are allowed"));
      }
    }
    if (0 != (HTuple(hv_OptionalKeysExist[1])))
    {
      //Check 'ignore_direction'.
      GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[1]), 
          &hv_IgnoreDirection);
      if (0 != (int(((HTuple(1).Append(0)).TupleFind(hv_IgnoreDirection))==-1)))
      {
        throw HException(("Invalid generic parameter for 'ignore_direction': "+hv_IgnoreDirection)+HTuple(", only true and false are allowed"));
      }
    }
    if (0 != (HTuple(hv_OptionalKeysExist[2])))
    {
      //Check 'class_ids_no_orientation'.
      GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[2]), 
          &hv_ClassIDsNoOrientation);
      TupleSemTypeElem(hv_ClassIDsNoOrientation, &hv_SemTypes);
      if (0 != (HTuple(int(hv_ClassIDsNoOrientation!=HTuple())).TupleAnd(int(((hv_SemTypes.TupleEqualElem("integer")).TupleSum())!=(hv_ClassIDsNoOrientation.TupleLength())))))
      {
        throw HException(("Invalid generic parameter for 'class_ids_no_orientation': "+hv_ClassIDsNoOrientation)+HTuple(", only integers are allowed"));
      }
      else
      {
        if (0 != (HTuple(int(hv_ClassIDsNoOrientation!=HTuple())).TupleAnd(int(((hv_ClassIDsNoOrientation.TupleGreaterEqualElem(0)).TupleSum())!=(hv_ClassIDsNoOrientation.TupleLength())))))
        {
          throw HException(("Invalid generic parameter for 'class_ids_no_orientation': "+hv_ClassIDsNoOrientation)+HTuple(", only non-negative integers are allowed"));
        }
      }
    }
  }
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Compute 3D normals. 
void compute_normals_xyz (HObject ho_x, HObject ho_y, HObject ho_z, HObject *ho_NXImage, 
    HObject *ho_NYImage, HObject *ho_NZImage, HTuple hv_Smoothing)
{

  // Local iconic variables
  HObject  ho_xScaled, ho_yScaled, ho_zScaled, ho_xDiffRow;
  HObject  ho_xDiffCol, ho_yDiffRow, ho_yDiffCol, ho_zDiffRow;
  HObject  ho_zDiffCol, ho_ImageResult, ho_ImageResult2, ho_NXRaw;
  HObject  ho_NYRaw, ho_NZRaw, ho_NXSquare, ho_NYSquare, ho_NZSquare;
  HObject  ho_ImageResult1, ho_SqrtImage;

  // Local control variables
  HTuple  hv_Factor, hv_MaskRow, hv_MaskCol;

  //For numerical reasons we scale the input data
  hv_Factor = 1e6;
  ScaleImage(ho_x, &ho_xScaled, hv_Factor, 0);
  ScaleImage(ho_y, &ho_yScaled, hv_Factor, 0);
  ScaleImage(ho_z, &ho_zScaled, hv_Factor, 0);

  //Filter for diffs in row/col direction
  hv_MaskRow.Clear();
  hv_MaskRow[0] = 2;
  hv_MaskRow[1] = 1;
  hv_MaskRow[2] = 1.0;
  hv_MaskRow[3] = 1;
  hv_MaskRow[4] = -1;
  hv_MaskCol.Clear();
  hv_MaskCol[0] = 1;
  hv_MaskCol[1] = 2;
  hv_MaskCol[2] = 1.0;
  hv_MaskCol[3] = -1;
  hv_MaskCol[4] = 1;
  ConvolImage(ho_xScaled, &ho_xDiffRow, hv_MaskRow, "continued");
  ConvolImage(ho_xScaled, &ho_xDiffCol, hv_MaskCol, "continued");
  ConvolImage(ho_yScaled, &ho_yDiffRow, hv_MaskRow, "continued");
  ConvolImage(ho_yScaled, &ho_yDiffCol, hv_MaskCol, "continued");
  ConvolImage(ho_zScaled, &ho_zDiffRow, hv_MaskRow, "continued");
  ConvolImage(ho_zScaled, &ho_zDiffCol, hv_MaskCol, "continued");
  //
  //Calculate normal as cross product
  MultImage(ho_yDiffRow, ho_zDiffCol, &ho_ImageResult, 1.0, 0);
  MultImage(ho_zDiffRow, ho_yDiffCol, &ho_ImageResult2, -1.0, 0);
  AddImage(ho_ImageResult, ho_ImageResult2, &ho_NXRaw, 1.0, 0);
  //
  MultImage(ho_xDiffRow, ho_zDiffCol, &ho_ImageResult, -1.0, 0);
  MultImage(ho_zDiffRow, ho_xDiffCol, &ho_ImageResult2, 1.0, 0);
  AddImage(ho_ImageResult, ho_ImageResult2, &ho_NYRaw, 1.0, 0);
  //
  MultImage(ho_xDiffRow, ho_yDiffCol, &ho_ImageResult, 1.0, 0);
  MultImage(ho_yDiffRow, ho_xDiffCol, &ho_ImageResult2, -1.0, 0);
  AddImage(ho_ImageResult, ho_ImageResult2, &ho_NZRaw, 1.0, 0);

  //Smooth
  //-> 5 is used as it is used in surface_normals_object_model_3d - 'xyz_mapping'
  if (0 != hv_Smoothing)
  {
    MeanImage(ho_NXRaw, &ho_NXRaw, 5, 5);
    MeanImage(ho_NYRaw, &ho_NYRaw, 5, 5);
    MeanImage(ho_NZRaw, &ho_NZRaw, 5, 5);
  }

  //Normalize
  MultImage(ho_NXRaw, ho_NXRaw, &ho_NXSquare, 1.0, 0);
  MultImage(ho_NYRaw, ho_NYRaw, &ho_NYSquare, 1.0, 0);
  MultImage(ho_NZRaw, ho_NZRaw, &ho_NZSquare, 1.0, 0);
  AddImage(ho_NXSquare, ho_NYSquare, &ho_ImageResult1, 1.0, 0);
  AddImage(ho_ImageResult1, ho_NZSquare, &ho_ImageResult2, 1.0, 0);
  SqrtImage(ho_ImageResult2, &ho_SqrtImage);
  //
  DivImage(ho_NXRaw, ho_SqrtImage, &(*ho_NXImage), 1.0, 0);
  DivImage(ho_NYRaw, ho_SqrtImage, &(*ho_NYImage), 1.0, 0);
  DivImage(ho_NZRaw, ho_SqrtImage, &(*ho_NZImage), 1.0, 0);
  return;
}

// Chapter: Tools / Geometry
// Short Description: Convert the parameters of rectangles with format rectangle2 to the coordinates of its 4 corner-points. 
void convert_rect2_5to8param (HTuple hv_Row, HTuple hv_Col, HTuple hv_Length1, HTuple hv_Length2, 
    HTuple hv_Phi, HTuple *hv_Row1, HTuple *hv_Col1, HTuple *hv_Row2, HTuple *hv_Col2, 
    HTuple *hv_Row3, HTuple *hv_Col3, HTuple *hv_Row4, HTuple *hv_Col4)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Co1, hv_Co2, hv_Si1, hv_Si2;

  //This procedure takes the parameters for a rectangle of type 'rectangle2'
  //and returns the coordinates of the four corners.
  //
  hv_Co1 = (hv_Phi.TupleCos())*hv_Length1;
  hv_Co2 = (hv_Phi.TupleCos())*hv_Length2;
  hv_Si1 = (hv_Phi.TupleSin())*hv_Length1;
  hv_Si2 = (hv_Phi.TupleSin())*hv_Length2;

  (*hv_Col1) = (hv_Co1-hv_Si2)+hv_Col;
  (*hv_Row1) = ((-hv_Si1)-hv_Co2)+hv_Row;
  (*hv_Col2) = ((-hv_Co1)-hv_Si2)+hv_Col;
  (*hv_Row2) = (hv_Si1-hv_Co2)+hv_Row;
  (*hv_Col3) = ((-hv_Co1)+hv_Si2)+hv_Col;
  (*hv_Row3) = (hv_Si1+hv_Co2)+hv_Row;
  (*hv_Col4) = (hv_Co1+hv_Si2)+hv_Col;
  (*hv_Row4) = ((-hv_Si1)+hv_Co2)+hv_Row;

  return;
}

// Chapter: Tools / Geometry
// Short Description: Convert for four-sided figures the coordinates of the 4 corner-points to the parameters of format rectangle2. 
void convert_rect2_8to5param (HTuple hv_Row1, HTuple hv_Col1, HTuple hv_Row2, HTuple hv_Col2, 
    HTuple hv_Row3, HTuple hv_Col3, HTuple hv_Row4, HTuple hv_Col4, HTuple hv_ForceL1LargerL2, 
    HTuple *hv_Row, HTuple *hv_Col, HTuple *hv_Length1, HTuple *hv_Length2, HTuple *hv_Phi)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Hor, hv_Vert, hv_IdxSwap, hv_Tmp;

  //This procedure takes the corners of four-sided figures
  //and returns the parameters of type 'rectangle2'.
  //
  //Calculate center row and column.
  (*hv_Row) = (((hv_Row1+hv_Row2)+hv_Row3)+hv_Row4)/4.0;
  (*hv_Col) = (((hv_Col1+hv_Col2)+hv_Col3)+hv_Col4)/4.0;
  //Length1 and Length2.
  (*hv_Length1) = ((((hv_Row1-hv_Row2)*(hv_Row1-hv_Row2))+((hv_Col1-hv_Col2)*(hv_Col1-hv_Col2))).TupleSqrt())/2.0;
  (*hv_Length2) = ((((hv_Row2-hv_Row3)*(hv_Row2-hv_Row3))+((hv_Col2-hv_Col3)*(hv_Col2-hv_Col3))).TupleSqrt())/2.0;
  //Calculate the angle phi.
  hv_Hor = hv_Col1-hv_Col2;
  hv_Vert = hv_Row2-hv_Row1;
  if (0 != hv_ForceL1LargerL2)
  {
    //Swap length1 and length2 if necessary.
    hv_IdxSwap = (((*hv_Length2)-(*hv_Length1)).TupleGreaterElem(1e-9)).TupleFind(1);
    if (0 != (int(hv_IdxSwap!=-1)))
    {
      hv_Tmp = HTuple((*hv_Length1)[hv_IdxSwap]);
      (*hv_Length1)[hv_IdxSwap] = HTuple((*hv_Length2)[hv_IdxSwap]);
      (*hv_Length2)[hv_IdxSwap] = hv_Tmp;
      hv_Hor[hv_IdxSwap] = HTuple(hv_Col2[hv_IdxSwap])-HTuple(hv_Col3[hv_IdxSwap]);
      hv_Vert[hv_IdxSwap] = HTuple(hv_Row3[hv_IdxSwap])-HTuple(hv_Row2[hv_IdxSwap]);
    }
  }
  (*hv_Phi) = hv_Vert.TupleAtan2(hv_Hor);
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Create a dictionary with preprocessing parameters. 
void create_dl_preprocess_param (HTuple hv_DLModelType, HTuple hv_ImageWidth, HTuple hv_ImageHeight, 
    HTuple hv_ImageNumChannels, HTuple hv_ImageRangeMin, HTuple hv_ImageRangeMax, 
    HTuple hv_NormalizationType, HTuple hv_DomainHandling, HTuple hv_IgnoreClassIDs, 
    HTuple hv_SetBackgroundID, HTuple hv_ClassIDsBackground, HTuple hv_GenParam, 
    HTuple *hv_DLPreprocessParam)
{

  // Local control variables
  HTuple  hv_GenParamNames, hv_GenParamIndex, hv_GenParamValue;
  HTuple  hv_KeysExist, hv_InstanceType, hv_IsInstanceSegmentation;

  //
  //This procedure creates a dictionary with all parameters needed for preprocessing.
  //
  CreateDict(&(*hv_DLPreprocessParam));
  SetDictTuple((*hv_DLPreprocessParam), "model_type", hv_DLModelType);
  SetDictTuple((*hv_DLPreprocessParam), "image_width", hv_ImageWidth);
  SetDictTuple((*hv_DLPreprocessParam), "image_height", hv_ImageHeight);
  SetDictTuple((*hv_DLPreprocessParam), "image_num_channels", hv_ImageNumChannels);
  if (0 != (int(hv_ImageRangeMin==HTuple())))
  {
    SetDictTuple((*hv_DLPreprocessParam), "image_range_min", -127);
  }
  else
  {
    SetDictTuple((*hv_DLPreprocessParam), "image_range_min", hv_ImageRangeMin);
  }
  if (0 != (int(hv_ImageRangeMax==HTuple())))
  {
    SetDictTuple((*hv_DLPreprocessParam), "image_range_max", 128);
  }
  else
  {
    SetDictTuple((*hv_DLPreprocessParam), "image_range_max", hv_ImageRangeMax);
  }
  SetDictTuple((*hv_DLPreprocessParam), "normalization_type", hv_NormalizationType);
  //Replace possible legacy parameters.
  replace_legacy_preprocessing_parameters((*hv_DLPreprocessParam));
  SetDictTuple((*hv_DLPreprocessParam), "domain_handling", hv_DomainHandling);
  //
  //Set segmentation and '3d_gripping_point_detection' parameters.
  if (0 != (HTuple(int(hv_DLModelType==HTuple("segmentation"))).TupleOr(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
  {
    SetDictTuple((*hv_DLPreprocessParam), "ignore_class_ids", hv_IgnoreClassIDs);
    SetDictTuple((*hv_DLPreprocessParam), "set_background_id", hv_SetBackgroundID);
    SetDictTuple((*hv_DLPreprocessParam), "class_ids_background", hv_ClassIDsBackground);
  }
  //
  //Set default values of generic parameters.
  SetDictTuple((*hv_DLPreprocessParam), "augmentation", "false");
  //
  //Set generic parameters.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenParamNames);
    {
    HTuple end_val36 = (hv_GenParamNames.TupleLength())-1;
    HTuple step_val36 = 1;
    for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val36, step_val36); hv_GenParamIndex += step_val36)
    {
      GetDictTuple(hv_GenParam, HTuple(hv_GenParamNames[hv_GenParamIndex]), &hv_GenParamValue);
      SetDictTuple((*hv_DLPreprocessParam), HTuple(hv_GenParamNames[hv_GenParamIndex]), 
          hv_GenParamValue);
    }
    }
  }
  //
  //Set necessary default values.
  if (0 != (int(hv_DLModelType==HTuple("detection"))))
  {
    GetDictParam((*hv_DLPreprocessParam), "key_exists", ((HTuple("instance_type").Append("ignore_direction")).Append("instance_segmentation")), 
        &hv_KeysExist);
    if (0 != (HTuple(hv_KeysExist[0]).TupleNot()))
    {
      SetDictTuple((*hv_DLPreprocessParam), "instance_type", "rectangle1");
    }
    //Set default for 'ignore_direction' only if instance_type is 'rectangle2'.
    GetDictTuple((*hv_DLPreprocessParam), "instance_type", &hv_InstanceType);
    if (0 != (HTuple(int(hv_InstanceType==HTuple("rectangle2"))).TupleAnd(HTuple(hv_KeysExist[1]).TupleNot())))
    {
      SetDictTuple((*hv_DLPreprocessParam), "ignore_direction", 0);
    }
    //In case of instance_segmentation we overwrite the instance_type to mask.
    if (0 != (HTuple(hv_KeysExist[2])))
    {
      GetDictTuple((*hv_DLPreprocessParam), "instance_segmentation", &hv_IsInstanceSegmentation);
      if (0 != (int(((((HTuple(1).Append(0)).Append("true")).Append("false")).TupleFind(hv_IsInstanceSegmentation))==-1)))
      {
        throw HException(("Invalid generic parameter for 'instance_segmentation': "+hv_IsInstanceSegmentation)+HTuple(", only true and false are allowed"));
      }
      if (0 != (HTuple(int(hv_IsInstanceSegmentation==HTuple("true"))).TupleOr(int(hv_IsInstanceSegmentation==1))))
      {
        SetDictTuple((*hv_DLPreprocessParam), "instance_type", "mask");
      }
    }
  }
  //
  //Check the validity of the preprocessing parameters.
  check_dl_preprocess_param((*hv_DLPreprocessParam));
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Create a dictionary with the preprocessing parameters based on a given DL model. 
void create_dl_preprocess_param_from_model (HTuple hv_DLModelHandle, HTuple hv_NormalizationType, 
    HTuple hv_DomainHandling, HTuple hv_SetBackgroundID, HTuple hv_ClassIDsBackground, 
    HTuple hv_GenParam, HTuple *hv_DLPreprocessParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ModelType, hv_ImageWidth, hv_ImageHeight;
  HTuple  hv_ImageNumChannels, hv_ImageRangeMin, hv_ImageRangeMax;
  HTuple  hv_IgnoreClassIDs, hv_InstanceType, hv_IsInstanceSegmentation;
  HTuple  hv_IgnoreDirection, hv_ClassIDsNoOrientation;

  //
  //This procedure creates a dictionary with all parameters needed for preprocessing
  //according to a model provided through DLModelHandle.
  //
  //Get the relevant model parameters.
  GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
  GetDlModelParam(hv_DLModelHandle, "image_width", &hv_ImageWidth);
  GetDlModelParam(hv_DLModelHandle, "image_height", &hv_ImageHeight);
  GetDlModelParam(hv_DLModelHandle, "image_num_channels", &hv_ImageNumChannels);
  GetDlModelParam(hv_DLModelHandle, "image_range_min", &hv_ImageRangeMin);
  GetDlModelParam(hv_DLModelHandle, "image_range_max", &hv_ImageRangeMax);
  hv_IgnoreClassIDs = HTuple();
  //
  //Get model specific parameters.
  if (0 != (HTuple(int(hv_ModelType==HTuple("anomaly_detection"))).TupleOr(int(hv_ModelType==HTuple("gc_anomaly_detection")))))
  {
    //No specific parameters for both anomaly detection
    //and Global Context Anomaly Detection model types.
  }
  else if (0 != (int(hv_ModelType==HTuple("classification"))))
  {
    //No classification specific parameters.
  }
  else if (0 != (int(hv_ModelType==HTuple("detection"))))
  {
    //Get detection specific parameters.
    //If GenParam has not been created yet, create it to add new generic parameters.
    if (0 != (int((hv_GenParam.TupleLength())==0)))
    {
      CreateDict(&hv_GenParam);
    }
    //Add instance_type.
    GetDlModelParam(hv_DLModelHandle, "instance_type", &hv_InstanceType);
    //If the model can do instance segmentation, the preprocessing instance_type
    //needs to be 'mask'.
    GetDlModelParam(hv_DLModelHandle, "instance_segmentation", &hv_IsInstanceSegmentation);
    if (0 != (int(hv_IsInstanceSegmentation==HTuple("true"))))
    {
      SetDictTuple(hv_GenParam, "instance_type", "mask");
    }
    else
    {
      SetDictTuple(hv_GenParam, "instance_type", hv_InstanceType);
    }
    //For instance_type 'rectangle2', add the boolean ignore_direction and class IDs without orientation.
    if (0 != (int(hv_InstanceType==HTuple("rectangle2"))))
    {
      GetDlModelParam(hv_DLModelHandle, "ignore_direction", &hv_IgnoreDirection);
      if (0 != (int(hv_IgnoreDirection==HTuple("true"))))
      {
        SetDictTuple(hv_GenParam, "ignore_direction", 1);
      }
      else if (0 != (int(hv_IgnoreDirection==HTuple("false"))))
      {
        SetDictTuple(hv_GenParam, "ignore_direction", 0);
      }
      GetDlModelParam(hv_DLModelHandle, "class_ids_no_orientation", &hv_ClassIDsNoOrientation);
      SetDictTuple(hv_GenParam, "class_ids_no_orientation", hv_ClassIDsNoOrientation);
    }
  }
  else if (0 != (HTuple(int(hv_ModelType==HTuple("ocr_detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_recognition")))))
  {
    //No ocr specific parameters.
  }
  else if (0 != (int(hv_ModelType==HTuple("segmentation"))))
  {
    //Get segmentation specific parameters.
    GetDlModelParam(hv_DLModelHandle, "ignore_class_ids", &hv_IgnoreClassIDs);
  }
  else if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
  {
    //The input image is expected to be a single channel image.
    hv_ImageNumChannels = 1;
  }
  else
  {
    throw HException(("Current model type is not supported: \""+hv_ModelType)+"\"");
  }
  //
  //Create the dictionary with the preprocessing parameters returned by this procedure.
  create_dl_preprocess_param(hv_ModelType, hv_ImageWidth, hv_ImageHeight, hv_ImageNumChannels, 
      hv_ImageRangeMin, hv_ImageRangeMax, hv_NormalizationType, hv_DomainHandling, 
      hv_IgnoreClassIDs, hv_SetBackgroundID, hv_ClassIDsBackground, hv_GenParam, 
      &(*hv_DLPreprocessParam));
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Crops a given image object based on the given domain handling. 
void crop_dl_sample_image (HObject ho_Domain, HTuple hv_DLSample, HTuple hv_Key, 
    HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho___Tmp_Obj_0;

  // Local control variables
  HTuple  hv_KeyExists, hv_Row1, hv_Column1, hv_Row2;
  HTuple  hv_Column2, hv___Tmp_Ctrl_Dict_Init_0;

  GetDictParam(hv_DLSample, "key_exists", hv_Key, &hv_KeyExists);
  if (0 != hv_KeyExists)
  {
    CreateDict(&hv___Tmp_Ctrl_Dict_Init_0);
    SetDictTuple(hv___Tmp_Ctrl_Dict_Init_0, "comp", "crop_domain");
    if (0 != ((hv_DLPreprocessParam.TupleConcat(hv___Tmp_Ctrl_Dict_Init_0)).TupleTestEqualDictItem("domain_handling","comp")))
    {
      SmallestRectangle1(ho_Domain, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      CropPart(hv_DLSample.TupleGetDictObject(hv_Key), &ho___Tmp_Obj_0, hv_Row1, 
          hv_Column1, (hv_Column2-hv_Column1)+1, (hv_Row2-hv_Row1)+1);
      SetDictObject(ho___Tmp_Obj_0, hv_DLSample, hv_Key);
    }
    hv___Tmp_Ctrl_Dict_Init_0 = HTuple::TupleConstant("HNULL");
  }
  return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Filter the instance segmentation masks of a DL sample based on a given selection. 
void filter_dl_sample_instance_segmentation_masks (HTuple hv_DLSample, HTuple hv_BBoxSelectionMask)
{

  // Local iconic variables
  HObject  ho_EmptyMasks, ho_Masks;

  // Local control variables
  HTuple  hv_MaskKeyExists, hv_Indices;

  GetDictParam(hv_DLSample, "key_exists", "mask", &hv_MaskKeyExists);
  if (0 != hv_MaskKeyExists)
  {
    //Only if masks exist (-> instance segmentation).
    TupleFind(hv_BBoxSelectionMask, 1, &hv_Indices);
    if (0 != (int(hv_Indices==-1)))
    {
      //We define here that this case will result in an empty object value
      //for the mask key. Another option would be to remove the
      //key 'mask'. However, this would be an unwanted big change in the dictionary.
      GenEmptyObj(&ho_EmptyMasks);
      SetDictObject(ho_EmptyMasks, hv_DLSample, "mask");
    }
    else
    {
      GetDictObject(&ho_Masks, hv_DLSample, "mask");
      //Remove all unused masks.
      SelectObj(ho_Masks, &ho_Masks, hv_Indices+1);
      SetDictObject(ho_Masks, hv_DLSample, "mask");
    }
  }
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate ground truth characters if they don't exist and words to characters mapping. 
void gen_dl_ocr_detection_gt_chars (HTuple hv_DLSampleTargets, HTuple hv_DLSample, 
    HTuple hv_ScaleWidth, HTuple hv_ScaleHeight, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_WordsCharsMapping)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CharBoxIndex, hv_WordLengths, hv_J;
  HTuple  hv_Start, hv_End, hv_SplitRow, hv_SplitColumn, hv_SplitPhi;
  HTuple  hv_SplitLength1, hv_SplitLength2, hv_CharsIds, hv_EmptyWordStrings;

  (*hvec_WordsCharsMapping)[0] = HTupleVector(HTuple());
  if (0 != (int(((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())>0)))
  {
    //Check if chars GT exist otherwise generate them.
    TupleFindFirst(hv_DLSample.TupleGetDictTuple("bbox_label_id"), 1, &hv_CharBoxIndex);
    if (0 != (int(hv_CharBoxIndex==-1)))
    {
      hv_WordLengths = (hv_DLSample.TupleGetDictTuple("word")).TupleStrlen();
      (*hvec_WordsCharsMapping)[((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())-1] = HTupleVector(HTuple());
      {
      HTuple end_val7 = ((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())-1;
      HTuple step_val7 = 1;
      for (hv_J=0; hv_J.Continue(end_val7, step_val7); hv_J += step_val7)
      {
        //For each word box
        if (0 != (int(HTuple((hv_DLSample.TupleGetDictTuple("bbox_label_id"))[hv_J])==0)))
        {
          if (0 != (int(HTuple(hv_WordLengths[hv_J])!=0)))
          {
            hv_Start = (hv_DLSampleTargets.TupleGetDictTuple("bbox_label_id")).TupleLength();
            hv_End = (((hv_DLSampleTargets.TupleGetDictTuple("bbox_label_id")).TupleLength())-1)+HTuple(hv_WordLengths[hv_J]);
            (*hvec_WordsCharsMapping)[hv_J] = HTupleVector(HTuple::TupleGenSequence(hv_Start,hv_End,1));
            split_rectangle2(HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_J]), 
                HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_J]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_J]), 
                HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_J]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_J]), 
                HTuple(hv_WordLengths[hv_J]), &hv_SplitRow, &hv_SplitColumn, &hv_SplitPhi, 
                &hv_SplitLength1, &hv_SplitLength2);
            TupleGenConst(HTuple(hv_WordLengths[hv_J]), 1, &hv_CharsIds);
            TupleGenConst(HTuple(hv_WordLengths[hv_J]), "", &hv_EmptyWordStrings);
            SetDictTuple(hv_DLSampleTargets, "bbox_label_id", (hv_DLSampleTargets.TupleGetDictTuple("bbox_label_id")).TupleConcat(hv_CharsIds));
            SetDictTuple(hv_DLSampleTargets, "bbox_row", (hv_DLSampleTargets.TupleGetDictTuple("bbox_row")).TupleConcat(hv_SplitRow));
            SetDictTuple(hv_DLSampleTargets, "bbox_col", (hv_DLSampleTargets.TupleGetDictTuple("bbox_col")).TupleConcat(hv_SplitColumn));
            SetDictTuple(hv_DLSampleTargets, "bbox_phi", (hv_DLSampleTargets.TupleGetDictTuple("bbox_phi")).TupleConcat(hv_SplitPhi));
            SetDictTuple(hv_DLSampleTargets, "bbox_length1", (hv_DLSampleTargets.TupleGetDictTuple("bbox_length1")).TupleConcat(hv_SplitLength1*hv_ScaleWidth));
            SetDictTuple(hv_DLSampleTargets, "bbox_length2", (hv_DLSampleTargets.TupleGetDictTuple("bbox_length2")).TupleConcat(hv_SplitLength2*hv_ScaleHeight));
            SetDictTuple(hv_DLSampleTargets, "word", (hv_DLSampleTargets.TupleGetDictTuple("word")).TupleConcat(hv_EmptyWordStrings));
          }
          else
          {
            throw HException(((("Sample with image id "+(hv_DLSample.TupleGetDictTuple("image_id")))+" is not valid. The word bounding box at index ")+hv_J)+" has an empty string as the ground truth. This is not allowed. Please assign a word label to every word bounding box.");
          }
        }
      }
      }
    }
    else
    {
      gen_words_chars_mapping(hv_DLSample, &(*hvec_WordsCharsMapping));
    }
  }
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate target link score map for ocr detection training. 
void gen_dl_ocr_detection_gt_link_map (HObject *ho_GtLinkMap, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple hv_DLSampleTargets, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_WordToCharVec, 
    HTuple hv_Alpha)
{

  // Local iconic variables
  HObject  ho_Lines, ho_Line, ho_LineDilated;

  // Local control variables
  HTuple  hv_InitImage, hv_CRow, hv_CCol, hv_DiameterC;
  HTuple  hv_IndexW, hv_CharBoxIndices, hv_CharCRows, hv_CharCCols;
  HTuple  hv_CharDistToWordCenter, hv_ExtremeCharIndex, hv_DistToExtreme;
  HTuple  hv_CharIndexSorted, hv_Box1Idx, hv_Box2Idx, hv_Diameter1;
  HTuple  hv_Diameter2, hv_DilationRadius, hv_NumLines, hv_Index;

  GenImageConst(&(*ho_GtLinkMap), "real", hv_ImageWidth, hv_ImageHeight);
  GetSystem("init_new_image", &hv_InitImage);
  if (0 != (int(hv_InitImage==HTuple("false"))))
  {
    OverpaintRegion((*ho_GtLinkMap), (*ho_GtLinkMap), 0.0, "fill");
  }
  //Compute box centers.
  hv_CRow = hv_DLSampleTargets.TupleGetDictTuple("bbox_row");
  hv_CCol = hv_DLSampleTargets.TupleGetDictTuple("bbox_col");
  hv_DiameterC = 2*((hv_DLSampleTargets.TupleGetDictTuple("bbox_length1")).TupleHypot(hv_DLSampleTargets.TupleGetDictTuple("bbox_length2")));
  //Loop over word boxes.
  {
  HTuple end_val10 = ((hv_DLSampleTargets.TupleGetDictTuple("bbox_label_id")).TupleLength())-1;
  HTuple step_val10 = 1;
  for (hv_IndexW=0; hv_IndexW.Continue(end_val10, step_val10); hv_IndexW += step_val10)
  {
    //For each word box
    if (0 != (int(HTuple((hv_DLSampleTargets.TupleGetDictTuple("bbox_label_id"))[hv_IndexW])==0)))
    {
      hv_CharBoxIndices = hvec_WordToCharVec[hv_IndexW].T();
      if (0 != (int((hv_CharBoxIndices.TupleLength())==0)))
      {
        continue;
      }
      else if (0 != (int((hv_CharBoxIndices.TupleLength())==1)))
      {
        //Generate a dot in the char center.
        GenCircle(&ho_Lines, HTuple(hv_CRow[hv_CharBoxIndices]), HTuple(hv_CCol[hv_CharBoxIndices]), 
            (((0.5*hv_Alpha)*HTuple(hv_DiameterC[hv_CharBoxIndices])).TupleRound())+0.5);
      }
      else
      {
        //Generate link lines between chars.
        hv_CharCRows = HTuple(hv_CRow[hv_CharBoxIndices]);
        hv_CharCCols = HTuple(hv_CCol[hv_CharBoxIndices]);
        //Sort the char boxes within the word.
        hv_CharDistToWordCenter = (hv_CharCRows-HTuple(hv_CRow[hv_IndexW])).TupleHypot(hv_CharCCols-HTuple(hv_CCol[hv_IndexW]));
        hv_ExtremeCharIndex = ((const HTuple&)HTuple(hv_CharDistToWordCenter.TupleSortIndex()))[(hv_CharDistToWordCenter.TupleLength())-1];
        hv_DistToExtreme = (hv_CharCRows-HTuple(hv_CharCRows[hv_ExtremeCharIndex])).TupleHypot(hv_CharCCols-HTuple(hv_CharCCols[hv_ExtremeCharIndex]));
        hv_CharIndexSorted = hv_DistToExtreme.TupleSortIndex();
        //Get the indices of adjacent characters.
        hv_Box1Idx = hv_CharIndexSorted.TupleSelectRange(0,(hv_CharIndexSorted.TupleLength())-2);
        hv_Box2Idx = hv_CharIndexSorted.TupleSelectRange(1,(hv_CharIndexSorted.TupleLength())-1);
        //Generate link lines between each pair of adjacent characters.
        GenRegionLine(&ho_Lines, HTuple(hv_CharCRows[hv_Box1Idx]), HTuple(hv_CharCCols[hv_Box1Idx]), 
            HTuple(hv_CharCRows[hv_Box2Idx]), HTuple(hv_CharCCols[hv_Box2Idx]));
        //Dilate the lines by 0.5/1.5/2.5/... pixels, such that the line thickness is approximately Alpha*mean(D1, D2)
        hv_Diameter1 = HTuple(hv_DiameterC[HTuple(hv_CharBoxIndices[hv_Box1Idx])]);
        hv_Diameter2 = HTuple(hv_DiameterC[HTuple(hv_CharBoxIndices[hv_Box2Idx])]);
        hv_DilationRadius = (((0.25*hv_Alpha)*(hv_Diameter1+hv_Diameter2)).TupleRound())+0.5;
        //dilation_circle only accepts a single radius, so we need to loop over the lines.
        CountObj(ho_Lines, &hv_NumLines);
        {
        HTuple end_val39 = hv_NumLines;
        HTuple step_val39 = 1;
        for (hv_Index=1; hv_Index.Continue(end_val39, step_val39); hv_Index += step_val39)
        {
          SelectObj(ho_Lines, &ho_Line, hv_Index);
          DilationCircle(ho_Line, &ho_LineDilated, HTuple(hv_DilationRadius[hv_Index-1]));
          ReplaceObj(ho_Lines, ho_LineDilated, &ho_Lines, hv_Index);
        }
        }
      }
      OverpaintRegion((*ho_GtLinkMap), ho_Lines, 1.0, "fill");
    }
  }
  }
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate target orientation score maps for ocr detection training. 
void gen_dl_ocr_detection_gt_orientation_map (HObject *ho_GtOrientationMaps, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple hv_DLSample)
{

  // Local iconic variables
  HObject  ho_GtOrientationSin, ho_GtOrientationCos;
  HObject  ho_Region;

  // Local control variables
  HTuple  hv_InitImage, hv_Indices, hv_Phi;

  GenImageConst(&ho_GtOrientationSin, "real", hv_ImageWidth, hv_ImageHeight);
  GenImageConst(&ho_GtOrientationCos, "real", hv_ImageWidth, hv_ImageHeight);
  GetSystem("init_new_image", &hv_InitImage);
  if (0 != (int(hv_InitImage==HTuple("false"))))
  {
    OverpaintRegion(ho_GtOrientationSin, ho_GtOrientationSin, 0.0, "fill");
    OverpaintRegion(ho_GtOrientationCos, ho_GtOrientationCos, 0.0, "fill");
  }
  if (0 != (int(((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())>0)))
  {
    //Process char boxes
    TupleFind(hv_DLSample.TupleGetDictTuple("bbox_label_id"), 1, &hv_Indices);
    if (0 != (int(hv_Indices!=-1)))
    {
      hv_Phi = hv_DLSample.TupleGetDictTuple("bbox_phi");
      GenRectangle2(&ho_Region, HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_Indices]), 
          HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_Indices]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_Indices]), 
          HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_Indices]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_Indices]));
      OverpaintRegion(ho_GtOrientationSin, ho_Region, HTuple(hv_Phi[hv_Indices]).TupleSin(), 
          "fill");
      OverpaintRegion(ho_GtOrientationCos, ho_Region, HTuple(hv_Phi[hv_Indices]).TupleCos(), 
          "fill");
    }
  }
  Compose2(ho_GtOrientationSin, ho_GtOrientationCos, &(*ho_GtOrientationMaps));
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate target text score map for ocr detection training. 
void gen_dl_ocr_detection_gt_score_map (HObject *ho_TargetText, HTuple hv_DLSample, 
    HTuple hv_BoxCutoff, HTuple hv_RenderCutoff, HTuple hv_ImageWidth, HTuple hv_ImageHeight)
{

  // Local iconic variables
  HObject  ho_ExtendedRectangle;

  // Local control variables
  HTuple  hv_InitImage, hv_Index, hv_Sigma1, hv_Sigma2;
  HTuple  hv_ExtendedLength1, hv_ExtendedLength2, hv_Rows;
  HTuple  hv_Columns, hv_Area, hv_Row, hv_Column, hv_HomMat2D;
  HTuple  hv_DistRow, hv_DistCol, hv_ScaledGaussian, hv_Grayval;

  GenImageConst(&(*ho_TargetText), "real", hv_ImageWidth, hv_ImageHeight);
  GetSystem("init_new_image", &hv_InitImage);
  if (0 != (int(hv_InitImage==HTuple("false"))))
  {
    OverpaintRegion((*ho_TargetText), (*ho_TargetText), 0.0, "fill");
  }
  {
  HTuple end_val5 = ((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())-1;
  HTuple step_val5 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val5, step_val5); hv_Index += step_val5)
  {
    //For each char box
    if (0 != (HTuple(int(HTuple((hv_DLSample.TupleGetDictTuple("bbox_label_id"))[hv_Index])==1)).TupleAnd(int(hv_BoxCutoff!=0))))
    {
      //Compute the sigma of an unnormalized normal distribution, such that
      //a certain threshold value is reached at the interval of a certain size.
      hv_Sigma1 = HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_Index])*((-0.5/(hv_BoxCutoff.TupleLog())).TupleSqrt());
      hv_Sigma2 = HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_Index])*((-0.5/(hv_BoxCutoff.TupleLog())).TupleSqrt());
      if (0 != (HTuple(HTuple(int(hv_Sigma1!=0)).TupleAnd(int(hv_Sigma2!=0))).TupleAnd(int(hv_RenderCutoff!=0))))
      {
        //Compute the radius of an unnormalized normal distribution,
        //where a certain threshold value is reached at the end.
        hv_ExtendedLength1 = hv_Sigma1*((-2*(hv_RenderCutoff.TupleLog())).TupleSqrt());
        hv_ExtendedLength2 = hv_Sigma2*((-2*(hv_RenderCutoff.TupleLog())).TupleSqrt());
        GenRectangle2(&ho_ExtendedRectangle, HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_Index]), 
            HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_Index]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_Index]), 
            hv_ExtendedLength1, hv_ExtendedLength2);
        ClipRegion(ho_ExtendedRectangle, &ho_ExtendedRectangle, 0, 0, hv_ImageHeight-1, 
            hv_ImageWidth-1);
        GetRegionPoints(ho_ExtendedRectangle, &hv_Rows, &hv_Columns);
        //Verify that the bounding box has an area to plot a gaussian
        AreaCenter(ho_ExtendedRectangle, &hv_Area, &hv_Row, &hv_Column);
        if (0 != (int(hv_Area>1)))
        {
          HomMat2dIdentity(&hv_HomMat2D);
          HomMat2dTranslate(hv_HomMat2D, -HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_Index]), 
              -HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_Index]), &hv_HomMat2D);
          HomMat2dRotate(hv_HomMat2D, -HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_Index]), 
              0, 0, &hv_HomMat2D);
          AffineTransPoint2d(hv_HomMat2D, hv_Rows, hv_Columns, &hv_DistRow, &hv_DistCol);
          hv_ScaledGaussian = (-0.5*(((hv_DistCol*hv_DistCol)/(hv_Sigma1*hv_Sigma1))+((hv_DistRow*hv_DistRow)/(hv_Sigma2*hv_Sigma2)))).TupleExp();
          GetGrayval((*ho_TargetText), hv_Rows, hv_Columns, &hv_Grayval);
          SetGrayval((*ho_TargetText), hv_Rows, hv_Columns, hv_ScaledGaussian.TupleMax2(hv_Grayval));
        }
      }
    }
  }
  }
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Preprocess dl samples and generate targets and weights for ocr detection training. 
void gen_dl_ocr_detection_targets (HTuple hv_DLSampleOriginal, HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_TargetText, ho_TargetLink, ho_TargetOrientation;
  HObject  ho_TargetWeightText, ho_TargetWeightLink, ho_WeightedCharScore;
  HObject  ho_TargetWeightOrientation, ho_OriginalDomain, ho_Image;
  HObject  ho_DomainWeight, ho_Domain, ho_TargetOrientationOut;
  HObject  ho_TargetWeightOrientationOut, ho_TargetOrientationChannel;
  HObject  ho_TargetWeightOrientationChannel;

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_Stride;
  HTuple  hv_ScaleHeight, hv_ScaleWidth, hv_BoxCutoff, hv_RenderCutoff;
  HTuple  hv_Alpha, hv_WSWeightRenderThreshold, hv_LinkZeroWeightRadius;
  HTuple  hv_Confidence, hv_ScoreMapsWidth, hv_ScoreMapsHeight;
  HTuple  hv_DLSample, hv_HomMat2DIdentity, hv_HomMat2DScale;
  HTuple  hv_DLSampleTargets, hv_OriginalDomainArea, hv__;
  HTuple  hv_OriginalWidth, hv_OriginalHeight, hv_IsOriginalDomainFull;
  HTuple  hv_ChannelIdx, hv___Tmp_Ctrl_0, hv___Tmp_Ctrl_1;
  HTupleVector  hvec_WordsCharsMapping(1);

  check_dl_preprocess_param(hv_DLPreprocessParam);
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  hv_Stride = 2;
  //Parameters used in the fallback weak supervision case.
  //They make the the uniformly sized char boxes a bit smaller, as we can expect a spacing between the characters.
  hv_ScaleHeight = 0.9;
  hv_ScaleWidth = 0.8;
  //Parameters relevant to plot the gaussian blobs in the score map.
  hv_BoxCutoff = 0.3;
  hv_RenderCutoff = 0.01;
  //Parameter used to determine the dilation of lines in link map.
  hv_Alpha = 0.1;
  //Parameter used to determine the dilation radius of word boxes in the weight score map.
  hv_WSWeightRenderThreshold = 0.05;
  //Parameter represents the dilation radius of word lines in the weight link map.
  hv_LinkZeroWeightRadius = 2.5;
  //Confidence is here only a place holder for the fallback weak supervision case.
  hv_Confidence = 1.0;
  if (0 != (int(hv_Stride==0)))
  {
    throw HException("Stride must be greater than 0.");
  }
  //Calculate the size of score maps.
  hv_ScoreMapsWidth = hv_ImageWidth/hv_Stride;
  hv_ScoreMapsHeight = hv_ImageHeight/hv_Stride;
  //Copy DLSample to maintain the original bounding boxes dimensions.
  CopyDict(hv_DLSampleOriginal, HTuple(), HTuple(), &hv_DLSample);
  //Preprocess bounding boxes to match targets dimensions.
  HomMat2dIdentity(&hv_HomMat2DIdentity);
  HomMat2dScale(hv_HomMat2DIdentity, 1.0/hv_Stride, 1.0/hv_Stride, 0, 0, &hv_HomMat2DScale);
  AffineTransPoint2d(hv_HomMat2DScale, hv_DLSample.TupleGetDictTuple("bbox_col"), 
      hv_DLSample.TupleGetDictTuple("bbox_row"), &hv___Tmp_Ctrl_0, &hv___Tmp_Ctrl_1);
  SetDictTuple(hv_DLSample, "bbox_row", hv___Tmp_Ctrl_1);
  SetDictTuple(hv_DLSample, "bbox_col", hv___Tmp_Ctrl_0);
  SetDictTuple(hv_DLSample, "bbox_length1", (hv_DLSample.TupleGetDictTuple("bbox_length1"))/hv_Stride);
  SetDictTuple(hv_DLSample, "bbox_length2", (hv_DLSample.TupleGetDictTuple("bbox_length2"))/hv_Stride);
  CopyDict(hv_DLSample, HTuple(), HTuple(), &hv_DLSampleTargets);
  gen_dl_ocr_detection_gt_chars(hv_DLSampleTargets, hv_DLSample, hv_ScaleWidth, hv_ScaleHeight, 
      &hvec_WordsCharsMapping);
  //Generate target maps from WordRegions and CharBoxes.
  gen_dl_ocr_detection_gt_score_map(&ho_TargetText, hv_DLSampleTargets, hv_BoxCutoff, 
      hv_RenderCutoff, hv_ScoreMapsWidth, hv_ScoreMapsHeight);
  gen_dl_ocr_detection_gt_link_map(&ho_TargetLink, hv_ScoreMapsWidth, hv_ScoreMapsHeight, 
      hv_DLSampleTargets, hvec_WordsCharsMapping, hv_Alpha);
  gen_dl_ocr_detection_gt_orientation_map(&ho_TargetOrientation, hv_ScoreMapsWidth, 
      hv_ScoreMapsHeight, hv_DLSampleTargets);
  //Generate weight maps from WordRegions and CharBoxes.
  gen_dl_ocr_detection_weight_score_map(&ho_TargetWeightText, hv_ScoreMapsWidth, 
      hv_ScoreMapsHeight, hv_DLSampleTargets, hv_BoxCutoff, hv_WSWeightRenderThreshold, 
      hv_Confidence);
  gen_dl_ocr_detection_weight_link_map(ho_TargetLink, ho_TargetWeightText, &ho_TargetWeightLink, 
      hv_LinkZeroWeightRadius);
  MultImage(ho_TargetText, ho_TargetWeightText, &ho_WeightedCharScore, 1, 0);
  gen_dl_ocr_detection_weight_orientation_map(ho_WeightedCharScore, &ho_TargetWeightOrientation, 
      hv_DLSampleTargets);
  //Take account of the image domain in DLSampleOriginal.
  GetDomain(hv_DLSampleOriginal.TupleGetDictObject("image"), &ho_OriginalDomain);
  AreaCenter(ho_OriginalDomain, &hv_OriginalDomainArea, &hv__, &hv__);
  GetImageSize(hv_DLSampleOriginal.TupleGetDictObject("image"), &hv_OriginalWidth, 
      &hv_OriginalHeight);
  hv_IsOriginalDomainFull = int(hv_OriginalDomainArea==(hv_OriginalWidth*hv_OriginalHeight));
  if (0 != (hv_IsOriginalDomainFull.TupleNot()))
  {
    //Calculate the domain weight.
    GenImageConst(&ho_Image, "real", hv_OriginalWidth, hv_OriginalHeight);
    ChangeDomain(ho_Image, ho_OriginalDomain, &ho_Image);
    ZoomImageSize(ho_Image, &ho_DomainWeight, hv_ScoreMapsWidth, hv_ScoreMapsHeight, 
        "constant");
    GetDomain(ho_DomainWeight, &ho_Domain);
    FullDomain(ho_DomainWeight, &ho_DomainWeight);
    OverpaintRegion(ho_DomainWeight, ho_DomainWeight, 0.0, "fill");
    OverpaintRegion(ho_DomainWeight, ho_Domain, 1.0, "fill");
    //Apply the domain weight.
    MultImage(ho_DomainWeight, ho_TargetText, &ho_TargetText, 1, 0);
    MultImage(ho_DomainWeight, ho_TargetLink, &ho_TargetLink, 1, 0);
    MultImage(ho_DomainWeight, ho_TargetWeightText, &ho_TargetWeightText, 1, 0);
    MultImage(ho_DomainWeight, ho_TargetWeightLink, &ho_TargetWeightLink, 1, 0);
    GenEmptyObj(&ho_TargetOrientationOut);
    GenEmptyObj(&ho_TargetWeightOrientationOut);
    for (hv_ChannelIdx=1; hv_ChannelIdx<=2; hv_ChannelIdx+=1)
    {
      AccessChannel(ho_TargetOrientation, &ho_TargetOrientationChannel, hv_ChannelIdx);
      AccessChannel(ho_TargetWeightOrientation, &ho_TargetWeightOrientationChannel, 
          hv_ChannelIdx);
      MultImage(ho_DomainWeight, ho_TargetOrientationChannel, &ho_TargetOrientationChannel, 
          1, 0);
      MultImage(ho_DomainWeight, ho_TargetWeightOrientationChannel, &ho_TargetWeightOrientationChannel, 
          1, 0);
      AppendChannel(ho_TargetOrientationOut, ho_TargetOrientationChannel, &ho_TargetOrientationOut
          );
      AppendChannel(ho_TargetWeightOrientationOut, ho_TargetWeightOrientationChannel, 
          &ho_TargetWeightOrientationOut);
    }
    ho_TargetOrientation = ho_TargetOrientationOut;
    ho_TargetWeightOrientation = ho_TargetWeightOrientationOut;
  }
  //Set targets in output sample.
  SetDictObject(ho_TargetText, hv_DLSampleOriginal, "target_text");
  SetDictObject(ho_TargetLink, hv_DLSampleOriginal, "target_link");
  SetDictObject(ho_TargetOrientation, hv_DLSampleOriginal, "target_orientation");
  SetDictObject(ho_TargetWeightText, hv_DLSampleOriginal, "target_weight_text");
  SetDictObject(ho_TargetWeightLink, hv_DLSampleOriginal, "target_weight_link");
  SetDictObject(ho_TargetWeightOrientation, hv_DLSampleOriginal, "target_weight_orientation");
}

// Chapter: OCR / Deep OCR
// Short Description: Generate link score map weight for ocr detection training. 
void gen_dl_ocr_detection_weight_link_map (HObject ho_LinkMap, HObject ho_TargetWeight, 
    HObject *ho_TargetWeightLink, HTuple hv_LinkZeroWeightRadius)
{

  // Local iconic variables
  HObject  ho_LinkRegion, ho_RegionDilation, ho_RegionComplement;
  HObject  ho_RegionUnion, ho_RegionBorder;

  // Local control variables
  HTuple  hv_Width, hv_Height;

  if (0 != (int(hv_LinkZeroWeightRadius>0)))
  {
    //Set zero weight around the link regions.
    Threshold(ho_LinkMap, &ho_LinkRegion, 0.01, "max");
    DilationCircle(ho_LinkRegion, &ho_RegionDilation, hv_LinkZeroWeightRadius);
    Complement(ho_RegionDilation, &ho_RegionComplement);
    GetImageSize(ho_TargetWeight, &hv_Width, &hv_Height);
    ClipRegion(ho_RegionComplement, &ho_RegionComplement, 0, 0, hv_Height-1, hv_Width-1);
    Union2(ho_LinkRegion, ho_RegionComplement, &ho_RegionUnion);
    Complement(ho_RegionUnion, &ho_RegionBorder);
    PaintRegion(ho_RegionBorder, ho_TargetWeight, &(*ho_TargetWeightLink), 0, "fill");
  }
  else
  {
    //Just copy the original weight map.
    CopyObj(ho_TargetWeight, &(*ho_TargetWeightLink), 1, 1);
  }
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate orientation score map weight for ocr detection training. 
void gen_dl_ocr_detection_weight_orientation_map (HObject ho_InitialWeight, HObject *ho_OrientationTargetWeight, 
    HTuple hv_DLSample)
{

  // Local iconic variables
  HObject  ho_CharRegions, ho_CharRegion, ho_BackgroundRegion;

  // Local control variables
  HTuple  hv_Indices;

  //Inside the valid regions, the inital weight is set to the initial weight.
  CopyImage(ho_InitialWeight, &(*ho_OrientationTargetWeight));
  FullDomain((*ho_OrientationTargetWeight), &(*ho_OrientationTargetWeight));
  //Set orientation weight to 0 outside the valid regions.
  if (0 != (int(((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())>0)))
  {
    //Process char boxes
    TupleFind(hv_DLSample.TupleGetDictTuple("bbox_label_id"), 1, &hv_Indices);
    if (0 != (int(hv_Indices!=-1)))
    {
      GenRectangle2(&ho_CharRegions, HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_Indices]), 
          HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_Indices]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_Indices]), 
          HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_Indices]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_Indices]));
      Union1(ho_CharRegions, &ho_CharRegion);
      Complement(ho_CharRegion, &ho_BackgroundRegion);
      OverpaintRegion((*ho_OrientationTargetWeight), ho_BackgroundRegion, 0, "fill");
    }
  }
  //We need two channels: for Sin and Cos
  Compose2((*ho_OrientationTargetWeight), (*ho_OrientationTargetWeight), &(*ho_OrientationTargetWeight)
      );
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate text score map weight for ocr detection training. 
void gen_dl_ocr_detection_weight_score_map (HObject *ho_TargetWeightText, HTuple hv_ImageWidth, 
    HTuple hv_ImageHeight, HTuple hv_DLSample, HTuple hv_BoxCutoff, HTuple hv_WSWeightRenderThreshold, 
    HTuple hv_Confidence)
{

  // Local iconic variables
  HObject  ho_IgnoreRegion, ho_WordRegion, ho_WordRegionDilated;

  // Local control variables
  HTuple  hv_Indices, hv_WordIndex, hv_SigmaL2;
  HTuple  hv_WordLength2Ext, hv_DilationRadius;

  GenImageConst(&(*ho_TargetWeightText), "real", hv_ImageWidth, hv_ImageHeight);
  OverpaintRegion((*ho_TargetWeightText), (*ho_TargetWeightText), 1.0, "fill");
  if (0 != (int(((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())>0)))
  {
    //Process ignore boxes
    TupleFind(hv_DLSample.TupleGetDictTuple("bbox_label_id"), 2, &hv_Indices);
    if (0 != (int(hv_Indices!=-1)))
    {
      GenRectangle2(&ho_IgnoreRegion, HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_Indices]), 
          HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_Indices]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_Indices]), 
          HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_Indices]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_Indices]));
      OverpaintRegion((*ho_TargetWeightText), ho_IgnoreRegion, 0.0, "fill");
    }
    {
    HTuple end_val9 = ((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())-1;
    HTuple step_val9 = 1;
    for (hv_WordIndex=0; hv_WordIndex.Continue(end_val9, step_val9); hv_WordIndex += step_val9)
    {
      //For each word box
      if (0 != (int(HTuple((hv_DLSample.TupleGetDictTuple("bbox_label_id"))[hv_WordIndex])==0)))
      {
        if (0 != (HTuple(HTuple(int(hv_BoxCutoff==0)).TupleOr(int(hv_WSWeightRenderThreshold==0))).TupleNot()))
        {
          hv_SigmaL2 = HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_WordIndex])*((-0.5/(hv_BoxCutoff.TupleLog())).TupleSqrt());
          hv_WordLength2Ext = hv_SigmaL2*((-2*(hv_WSWeightRenderThreshold.TupleLog())).TupleSqrt());
          hv_DilationRadius = hv_WordLength2Ext-HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_WordIndex]);
        }
        else
        {
          hv_DilationRadius = 0;
        }
        GenRectangle2(&ho_WordRegion, HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_WordIndex]), 
            HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_WordIndex]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_WordIndex]), 
            HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_WordIndex]), 
            HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_WordIndex]));
        //Slightly enlarge the weight region to suppress halos at the box borders.
        if (0 != (int(hv_DilationRadius>=0.5)))
        {
          DilationCircle(ho_WordRegion, &ho_WordRegionDilated, hv_DilationRadius);
        }
        else
        {
          ho_WordRegionDilated = ho_WordRegion;
        }
        //Set the confidence as weight for the word region.
        OverpaintRegion((*ho_TargetWeightText), ho_WordRegionDilated, hv_Confidence, 
            "fill");
      }
    }
    }
  }
  return;
}

// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Store the given images in a tuple of dictionaries. 
void gen_dl_samples_3d_gripping_point_detection (HObject ho_Images, HObject ho_X, 
    HObject ho_Y, HObject ho_Z, HObject ho_Normals, HTuple *hv_DLSampleBatch)
{

  // Local iconic variables
  HObject  ho___Tmp_Obj_0;

  // Local control variables
  HTuple  hv_NumImages, hv_NumX, hv_NumY, hv_NumZ;
  HTuple  hv_NumNormals, hv_HasNormals, hv_HasX, hv_HasY;
  HTuple  hv_HasZ, hv_CheckedInput, hv_NumToCheck, hv_LengthFit;
  HTuple  hv_Msg, hv_Indices, hv_I, hv_Num, hv_Name, hv_DLSample;

  //
  //This procedure creates DLSampleBatch,
  //a tuple containing a dictionary DLSample
  //for every image given in Images, together
  //with its corresponding X, Y, Z, and Normals
  //image.
  //
  //Initialize output tuple.
  CountObj(ho_Images, &hv_NumImages);
  CountObj(ho_X, &hv_NumX);
  CountObj(ho_Y, &hv_NumY);
  CountObj(ho_Z, &hv_NumZ);
  CountObj(ho_Normals, &hv_NumNormals);
  hv_HasNormals = int(hv_NumNormals!=0);
  hv_HasX = int(hv_NumX!=0);
  hv_HasY = int(hv_NumY!=0);
  hv_HasZ = int(hv_NumZ!=0);
  //
  //Check the given input tuples for consistency.
  //
  hv_CheckedInput.Clear();
  hv_CheckedInput[0] = "Images";
  hv_CheckedInput[1] = "Z";
  hv_NumToCheck.Clear();
  hv_NumToCheck.Append(hv_NumImages);
  hv_NumToCheck.Append(hv_NumZ);
  if (0 != (hv_HasNormals.TupleNot()))
  {
    if (0 != (HTuple(HTuple(hv_HasX.TupleNot()).TupleOr(hv_HasY.TupleNot())).TupleOr(hv_HasZ.TupleNot())))
    {
      throw HException(HTuple("The given input object tuples does not contain necessary images 'X','Y' and 'Z'. This is required if no normals are provided."));
    }
    hv_CheckedInput = hv_CheckedInput.TupleConcat((HTuple("X").Append("Y")));
    hv_NumToCheck = (hv_NumToCheck.TupleConcat(hv_NumX)).TupleConcat(hv_NumY);
  }
  else
  {
    hv_CheckedInput = hv_CheckedInput.TupleConcat("Normals");
    hv_NumToCheck = hv_NumToCheck.TupleConcat(hv_NumNormals);
    if (0 != (hv_HasZ.TupleNot()))
    {
      throw HException(HTuple("The given input object tuples does not contain at least the depth image 'Z'. This is required because normals are provided. Optionally, 'X' and 'Y' images might be provided additionally."));
    }
    if (0 != hv_HasX)
    {
      hv_CheckedInput = hv_CheckedInput.TupleConcat("X");
      hv_NumToCheck = hv_NumToCheck.TupleConcat(hv_NumX);
    }
    if (0 != hv_HasY)
    {
      hv_CheckedInput = hv_CheckedInput.TupleConcat("Y");
      hv_NumToCheck = hv_NumToCheck.TupleConcat(hv_NumY);
    }
  }
  //
  //Check that all object tuples have the same length.
  hv_LengthFit = int((hv_NumToCheck.TupleMin())==(hv_NumToCheck.TupleMax()));
  if (0 != (hv_LengthFit.TupleNot()))
  {
    hv_Msg = "The given input object tuples do not have the same length. ";
    TupleSortIndex(hv_CheckedInput, &hv_Indices);
    {
    HTuple end_val49 = (hv_NumToCheck.TupleLength())-1;
    HTuple step_val49 = 1;
    for (hv_I=0; hv_I.Continue(end_val49, step_val49); hv_I += step_val49)
    {
      hv_Num = HTuple(hv_NumToCheck[HTuple(hv_Indices[hv_I])]);
      hv_Name = HTuple(hv_CheckedInput[HTuple(hv_Indices[hv_I])]);
      if (0 != (int(hv_I>0)))
      {
        hv_Msg += HTuple(HTuple(", "));
      }
      hv_Msg = (((hv_Msg+"")+hv_Name)+": ")+hv_Num;
    }
    }
    throw HException(hv_Msg);
  }
  //
  //Create the batch based on input images first.
  gen_dl_samples_from_images(ho_Images, &(*hv_DLSampleBatch));
  //
  //Add additional images.
  //
  //Loop through all given images.
  {
  HTuple end_val66 = (*hv_DLSampleBatch).TupleLength();
  HTuple step_val66 = 1;
  for (hv_I=1; hv_I.Continue(end_val66, step_val66); hv_I += step_val66)
  {
    hv_DLSample = HTuple((*hv_DLSampleBatch)[hv_I-1]);
    if (0 != hv_HasX)
    {
      SelectObj(ho_X, &ho___Tmp_Obj_0, hv_I);
      SetDictObject(ho___Tmp_Obj_0, hv_DLSample, "x");
    }
    if (0 != hv_HasY)
    {
      SelectObj(ho_Y, &ho___Tmp_Obj_0, hv_I);
      SetDictObject(ho___Tmp_Obj_0, hv_DLSample, "y");
    }
    //
    SelectObj(ho_Z, &ho___Tmp_Obj_0, hv_I);
    SetDictObject(ho___Tmp_Obj_0, hv_DLSample, "z");
    if (0 != hv_HasNormals)
    {
      SelectObj(ho_Normals, &ho___Tmp_Obj_0, hv_I);
      SetDictObject(ho___Tmp_Obj_0, hv_DLSample, "normals");
    }
  }
  }

}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Generate weight images for the training dataset. 
void gen_dl_segmentation_weight_images (HTuple hv_DLDataset, HTuple hv_DLPreprocessParam, 
    HTuple hv_ClassWeights, HTuple hv_GenParam)
{

  // Local iconic variables
  HObject  ho_SegmentationImage, ho_WeightImage;
  HObject  ho_IgnoreRegion, ho_IgnoreRegionTmp, ho_ClassRegion;

  // Local control variables
  HTuple  hv_KeyExists, hv_ClassIDs, hv_OverwriteFiles;
  HTuple  hv_GenParamKeys, hv_GenParamIndex, hv_IgnoreClassIDs;
  HTuple  hv_Exception, hv_DLSamples, hv_SampleIndices, hv_InitNewImage;
  HTuple  hv_SampleIndex, hv_DLSample, hv_WeightImageExists;
  HTuple  hv_SampleImageID, hv_ImageWidth, hv_ImageHeight;
  HTuple  hv_IgnoreIndex, hv_IgnoreClassID, hv_ClassIndex;
  HTuple  hv_ClassID, hv_Weight;

  //
  //This procedure generates for each training sample in DLDataset a weight image,
  //that is used as input to the loss in a segmentation model.
  //The dictionary DLDataset needs a key 'dlsample_dir', assigning a directory
  //in which for every sample a dictionary DLSample has to exist.
  //The procedure reads for each training sample the dictionary DLSample,
  //generates a weight image according to the specified ClassWeights
  //and overwrites the DLSample with the updated sample including the weight image.
  //
  //Check input data.
  GetDictParam(hv_DLDataset, "key_exists", ((HTuple("dlsample_dir").Append("samples")).Append("class_ids")), 
      &hv_KeyExists);
  if (0 != (HTuple(hv_KeyExists[0]).TupleNot()))
  {
    throw HException("DLDataset needs a key-value pair for 'dlsample_dir'");
  }
  if (0 != (HTuple(hv_KeyExists[1]).TupleNot()))
  {
    throw HException("DLDataset needs a key-value pair for 'samples'");
  }
  if (0 != (HTuple(hv_KeyExists[2]).TupleNot()))
  {
    throw HException("DLDataset needs a key-value pair for 'class_ids'");
  }
  //
  GetDictTuple(hv_DLDataset, "class_ids", &hv_ClassIDs);
  if (0 != (int(hv_ClassWeights==HTuple())))
  {
    throw HException("ClassWeights is empty");
  }
  else if (0 != (HTuple(int((hv_ClassWeights.TupleLength())!=(hv_ClassIDs.TupleLength()))).TupleAnd(int((hv_ClassWeights.TupleLength())!=1))))
  {
    throw HException("ClassWeights must be either a single value or of the same length as the DLDataset ClassIDs.");
  }
  //
  if (0 != (int(((hv_ClassWeights.TupleLessElem(0)).TupleFind(1))>-1)))
  {
    throw HException("ClassWeights must be greater or equal zero.");
  }
  else if (0 != (HTuple(int((hv_ClassWeights.TupleLength())==1)).TupleAnd(int(hv_ClassWeights<=0))))
  {
    throw HException(HTuple("If only a single weight is given as ClassWeights, this must be greater than zero."));
  }
  //
  //Check the validity of the preprocessing parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Set defaults.
  hv_OverwriteFiles = 0;
  //
  //Overwrite defaults specified in GenParam.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenParamKeys);
    {
    HTuple end_val43 = (hv_GenParamKeys.TupleLength())-1;
    HTuple step_val43 = 1;
    for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val43, step_val43); hv_GenParamIndex += step_val43)
    {
      if (0 != (int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("overwrite_files"))))
      {
        //Set parameter for overwriting files.
        GetDictTuple(hv_GenParam, "overwrite_files", &hv_OverwriteFiles);
        if (0 != (HTuple(int(hv_OverwriteFiles!=0)).TupleAnd(int(hv_OverwriteFiles!=1))))
        {
          throw HException("'overwrite_files' must be either true or false");
        }
      }
      else
      {
        throw HException(("Unknown parameter: '"+HTuple(hv_GenParamKeys[hv_GenParamIndex]))+"'");
      }
    }
    }
  }
  //
  //Get the IDs of the classes to be ignored.
  try
  {
    GetDictTuple(hv_DLPreprocessParam, "ignore_class_ids", &hv_IgnoreClassIDs);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_IgnoreClassIDs = HTuple();
  }
  //
  //Get the samples from the dataset.
  GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
  //
  //Get the indices of the samples belonging to the defined split.
  find_dl_samples(hv_DLSamples, "split", "train", "or", &hv_SampleIndices);
  //
  //Get system info on init_new_image.
  GetSystem("init_new_image", &hv_InitNewImage);
  //
  //Loop over training samples.
  {
  HTuple end_val73 = (hv_SampleIndices.TupleLength())-1;
  HTuple step_val73 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val73, step_val73); hv_SampleIndex += step_val73)
  {
    //
    //Read the DLSample.
    read_dl_samples(hv_DLDataset, HTuple(hv_SampleIndices[hv_SampleIndex]), &hv_DLSample);
    //
    //Check if there is already a weight image in the DLSample.
    GetDictParam(hv_DLSample, "key_exists", "weight_image", &hv_WeightImageExists);
    if (0 != (hv_WeightImageExists.TupleAnd(hv_OverwriteFiles.TupleNot())))
    {
      GetDictTuple(hv_DLSample, "image_id", &hv_SampleImageID);
      throw HException(("The DLSample with image_id "+hv_SampleImageID)+" already contains a weight image. Force overwriting using the parameter 'overwrite_files' to true.");
    }
    //
    //Get the segmentation image.
    GetDictObject(&ho_SegmentationImage, hv_DLSample, "segmentation_image");
    //
    //Generate the weight image.
    //
    //Initialize the weight image with 0.
    GetImageSize(ho_SegmentationImage, &hv_ImageWidth, &hv_ImageHeight);
    GenImageConst(&ho_WeightImage, "real", hv_ImageWidth, hv_ImageHeight);
    //Clear image.
    if (0 != (int(hv_InitNewImage==HTuple("false"))))
    {
      OverpaintRegion(ho_WeightImage, ho_WeightImage, 0, "fill");
    }
    //
    if (0 != (int((hv_ClassWeights.TupleLength())==1)))
    {
      //Constant class weight.
      OverpaintRegion(ho_WeightImage, ho_WeightImage, HTuple(hv_ClassWeights[0]), 
          "fill");
      //
      if (0 != (int((hv_IgnoreClassIDs.TupleLength())>0)))
      {
        //Set ignore region to 0.
        GenEmptyRegion(&ho_IgnoreRegion);
        {
        HTuple end_val105 = (hv_IgnoreClassIDs.TupleLength())-1;
        HTuple step_val105 = 1;
        for (hv_IgnoreIndex=0; hv_IgnoreIndex.Continue(end_val105, step_val105); hv_IgnoreIndex += step_val105)
        {
          hv_IgnoreClassID = HTuple(hv_IgnoreClassIDs[hv_IgnoreIndex]);
          Threshold(ho_SegmentationImage, &ho_IgnoreRegionTmp, hv_IgnoreClassID, 
              hv_IgnoreClassID);
          Union2(ho_IgnoreRegion, ho_IgnoreRegionTmp, &ho_IgnoreRegion);
        }
        }
        OverpaintRegion(ho_WeightImage, ho_IgnoreRegion, 0., "fill");
      }
    }
    else
    {
      //Loop over model ClassIDs.
      {
      HTuple end_val114 = (hv_ClassIDs.TupleLength())-1;
      HTuple step_val114 = 1;
      for (hv_ClassIndex=0; hv_ClassIndex.Continue(end_val114, step_val114); hv_ClassIndex += step_val114)
      {
        if (0 != (HTuple(int(hv_IgnoreClassIDs==HTuple())).TupleOr(int((hv_IgnoreClassIDs.TupleFind(HTuple(hv_ClassIDs[hv_ClassIndex])))==-1))))
        {
          //Set the pixel values of the weight image according to ClassWeights.
          hv_ClassID = HTuple(hv_ClassIDs[hv_ClassIndex]);
          hv_Weight = HTuple(hv_ClassWeights[hv_ClassIndex]);
          Threshold(ho_SegmentationImage, &ho_ClassRegion, hv_ClassID, hv_ClassID);
          OverpaintRegion(ho_WeightImage, ho_ClassRegion, hv_Weight, "fill");
        }
        else
        {
          //Ignore class has weight 0 which is already set.
        }
      }
      }
    }
    //
    //Add the weight image to DLSample.
    SetDictObject(ho_WeightImage, hv_DLSample, "weight_image");
    //
    //Write the updated DLSample.
    write_dl_samples(hv_DLDataset, HTuple(hv_SampleIndices[hv_SampleIndex]), hv_DLSample, 
        HTuple(), HTuple());
  }
  }
  //
  //On success we store the class weights for later reference in the DLDataset.
  SetDictTuple(hv_DLDataset, "class_weights", hv_ClassWeights);
  //
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate a word to characters mapping. 
void gen_words_chars_mapping (HTuple hv_DLSample, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_WordsCharsMapping)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_WordsIndices, hv_CharsIndices, hv_WordLengths;
  HTuple  hv_WordArea, hv_CharArea, hv_CharAreaThreshold;
  HTuple  hv_WordIndex, hv_AreaIntersection, hv_CIsInsideW;
  HTuple  hv_CIndex;

  //Procedure to generate the mapping: gen_words_chars_mapping
  if (0 != (int(((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())>0)))
  {
    TupleFind(hv_DLSample.TupleGetDictTuple("bbox_label_id"), 0, &hv_WordsIndices);
    TupleFind(hv_DLSample.TupleGetDictTuple("bbox_label_id"), 1, &hv_CharsIndices);
    if (0 != (HTuple(int(hv_CharsIndices!=-1)).TupleAnd(int(hv_WordsIndices!=-1))))
    {
      hv_WordLengths = HTuple((hv_DLSample.TupleGetDictTuple("word"))[hv_WordsIndices]).TupleStrlen();
      //Init vector.
      (*hvec_WordsCharsMapping)[((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())-1] = HTupleVector(HTuple());
      hv_WordArea = (4*HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_WordsIndices]))*HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_WordsIndices]);
      hv_CharArea = (4*HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_CharsIndices]))*HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_CharsIndices]);
      //TODO: This threshold is quite arbitrary and not stable.
      hv_CharAreaThreshold = hv_CharArea*0.8;
      {
      HTuple end_val12 = (hv_WordsIndices.TupleLength())-1;
      HTuple step_val12 = 1;
      for (hv_WordIndex=0; hv_WordIndex.Continue(end_val12, step_val12); hv_WordIndex += step_val12)
      {
        if (0 != (int(HTuple(hv_WordLengths[hv_WordIndex])!=0)))
        {
          AreaIntersectionRectangle2(HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[HTuple(hv_WordsIndices[hv_WordIndex])]), 
              HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[HTuple(hv_WordsIndices[hv_WordIndex])]), 
              HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[HTuple(hv_WordsIndices[hv_WordIndex])]), 
              HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[HTuple(hv_WordsIndices[hv_WordIndex])]), 
              HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[HTuple(hv_WordsIndices[hv_WordIndex])]), 
              HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_CharsIndices]), 
              HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_CharsIndices]), 
              HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_CharsIndices]), 
              HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_CharsIndices]), 
              HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_CharsIndices]), 
              &hv_AreaIntersection);
          hv_CIsInsideW = hv_AreaIntersection.TupleGreaterElem(hv_CharAreaThreshold);
          hv_CIndex = hv_CIsInsideW.TupleFind(1);
          if (0 != (int(hv_CIndex!=-1)))
          {
            (*hvec_WordsCharsMapping)[HTuple(hv_WordsIndices[hv_WordIndex])] = HTupleVector(HTuple(hv_CharsIndices[hv_CIndex]));
          }
        }
        else
        {
          throw HException(((("Sample with image id "+(hv_DLSample.TupleGetDictTuple("image_id")))+" is not valid. The word bounding box at index ")+hv_WordIndex)+" has an empty string as the ground truth. This is not allowed. Please assign a word label to every word bounding box.");
        }
      }
      }
    }
  }
  return;
}

// Chapter: Deep Learning / OCR
// Short Description: Determine the ocr type of the sample based on the sample structure. 
void get_dl_sample_ocr_type (HTuple hv_DLSample, HTuple *hv_OCRType)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_WordExists, hv_BoundingBoxExists;

  (*hv_OCRType) = "non_ocr";
  GetDictParam(hv_DLSample, "key_exists", "word", &hv_WordExists);
  if (0 != hv_WordExists)
  {
    GetDictParam(hv_DLSample, "key_exists", "bbox_label_id", &hv_BoundingBoxExists);
    if (0 != hv_BoundingBoxExists)
    {
      (*hv_OCRType) = "ocr_detection";
    }
    else
    {
      (*hv_OCRType) = "ocr_recognition";
    }
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Handle the 'auto' option of the 'overwrite_files' parameter in preprocess_dl_dataset. 
void handle_overwrite_files_auto_in_preprocess_dl_dataset (HTuple hv_DLDataset, HTuple hv_DLPreprocessParam, 
    HTuple hv_DLDatasetFileName, HTuple *hv_OverwriteFiles)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ExistingDLDataset, hv_Exception, hv_ExistingDLPreprocessParam;
  HTuple  hv_ExistingKeys, hv_Keys, hv_Equal, hv_I, hv_Key;
  HTuple  hv_Value, hv_ExistingValue, hv_ExistingNormType;
  HTuple  hv_NormType, hv_Samples, hv_ExistingSamples, hv_Sample;
  HTuple  hv_ExistingSample, hv_ExistingImageId, hv_ImageId;
  HTuple  hv_SplitExists, hv_SplitExistsSample, hv_SplitExisting;
  HTuple  hv_SplitSample, hv_KeyIdx;

  //Check if the given preprocessed dataset matches with the
  //given DLDataset and DLPreprocessParam.
  (*hv_OverwriteFiles) = "true";
  while (true)
  {
    try
    {
      //Read the preprocessed dataset.
      ReadDict(hv_DLDatasetFileName, HTuple(), HTuple(), &hv_ExistingDLDataset);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      break;
    }
    //Check if preprocess parameters are equal.
    GetDictTuple(hv_ExistingDLDataset, "preprocess_param", &hv_ExistingDLPreprocessParam);
    //Check if preprocessing keys are equal.
    GetDictParam(hv_ExistingDLPreprocessParam, "keys", HTuple(), &hv_ExistingKeys);
    GetDictParam(hv_DLPreprocessParam, "keys", HTuple(), &hv_Keys);
    hv_ExistingKeys = hv_ExistingKeys.TupleSort();
    hv_Keys = hv_Keys.TupleSort();
    TupleEqual(hv_Keys, hv_ExistingKeys, &hv_Equal);
    if (0 != (hv_Equal.TupleNot()))
    {
      break;
    }
    //Check if preprocessing values are equal.
    hv_Equal = 1;
    {
    HTuple end_val23 = (hv_Keys.TupleLength())-1;
    HTuple step_val23 = 1;
    for (hv_I=0; hv_I.Continue(end_val23, step_val23); hv_I += step_val23)
    {
      hv_Key = HTuple(hv_Keys[hv_I]);
      GetDictTuple(hv_DLPreprocessParam, HTuple(hv_Keys[hv_I]), &hv_Value);
      GetDictTuple(hv_ExistingDLPreprocessParam, HTuple(hv_Keys[hv_I]), &hv_ExistingValue);
      TupleEqual(hv_Value, hv_ExistingValue, &hv_Equal);
      if (0 != (hv_Equal.TupleNot()))
      {
        if (0 != (HTuple(int(hv_Key==HTuple("image_range_min"))).TupleOr(int(hv_Key==HTuple("image_range_max")))))
        {
          try
          {
            GetDictTuple(hv_ExistingDLPreprocessParam, "normalization_type", &hv_ExistingNormType);
            GetDictTuple(hv_ExistingDLPreprocessParam, "normalization_type", &hv_NormType);
            //If the normalization type is constant_values the range is fixed no matter what
            //values are given in image_range_min/max.
            if (0 != (HTuple(int(hv_ExistingNormType==hv_NormType)).TupleAnd(int(hv_NormType==HTuple("constant_values")))))
            {
              hv_Equal = 1;
              continue;
            }
          }
          // catch (Exception) 
          catch (HException &HDevExpDefaultException)
          {
            HDevExpDefaultException.ToHTuple(&hv_Exception);
            break;
          }
        }
        break;
      }
    }
    }
    if (0 != (hv_Equal.TupleNot()))
    {
      break;
    }
    //Check if samples are plausible.
    try
    {
      GetDictTuple(hv_DLDataset, "samples", &hv_Samples);
      GetDictTuple(hv_ExistingDLDataset, "samples", &hv_ExistingSamples);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      break;
    }

    //Are the number of samples equal?
    if (0 != (int((hv_Samples.TupleLength())!=(hv_ExistingSamples.TupleLength()))))
    {
      break;
    }
    hv_Equal = 1;
    {
    HTuple end_val62 = (hv_Samples.TupleLength())-1;
    HTuple step_val62 = 1;
    for (hv_I=0; hv_I.Continue(end_val62, step_val62); hv_I += step_val62)
    {
      hv_Sample = HTuple(hv_Samples[hv_I]);
      hv_ExistingSample = HTuple(hv_ExistingSamples[hv_I]);
      try
      {
        GetDictTuple(hv_ExistingSample, "image_id", &hv_ExistingImageId);
        GetDictTuple(hv_Sample, "image_id", &hv_ImageId);

        //Are the image_id entries exactly the same?
        hv_Equal = int(hv_ImageId==hv_ExistingImageId);
        if (0 != (hv_Equal.TupleNot()))
        {
          break;
        }
        GetDictParam(hv_ExistingSample, "key_exists", "split", &hv_SplitExists);
        GetDictParam(hv_Sample, "key_exists", "split", &hv_SplitExistsSample);
        if (0 != (int((hv_SplitExistsSample.TupleNot())==hv_SplitExists)))
        {
          hv_Equal = 0;
          break;
        }
        if (0 != hv_SplitExistsSample)
        {
          GetDictTuple(hv_ExistingSample, "split", &hv_SplitExisting);
          GetDictTuple(hv_Sample, "split", &hv_SplitSample);
          if (0 != (int(hv_SplitExisting!=hv_SplitSample)))
          {
            hv_Equal = 0;
            break;
          }
        }
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        hv_Equal = 0;
        break;
      }
    }
    }
    if (0 != (hv_Equal.TupleNot()))
    {
      break;
    }
    (*hv_OverwriteFiles) = "auto";
    break;
  }
  if (0 != (int((*hv_OverwriteFiles)==HTuple("auto"))))
  {
    //Finally overwrite all the key/values in the input dataset with the preprocessed entries.
    GetDictParam(hv_ExistingDLDataset, "keys", HTuple(), &hv_Keys);
    {
    HTuple end_val102 = (hv_Keys.TupleLength())-1;
    HTuple step_val102 = 1;
    for (hv_KeyIdx=0; hv_KeyIdx.Continue(end_val102, step_val102); hv_KeyIdx += step_val102)
    {
      hv_Key = HTuple(hv_Keys[hv_KeyIdx]);
      try
      {
        GetDictTuple(hv_ExistingDLDataset, hv_Key, &hv_Value);
        SetDictTuple(hv_DLDataset, hv_Key, hv_Value);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
      }
    }
    }
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Preprocess the entire dataset declared in DLDataset. 
void preprocess_dl_dataset (HTuple hv_DLDataset, HTuple hv_DataDirectory, HTuple hv_DLPreprocessParam, 
    HTuple hv_GenParam, HTuple *hv_DLDatasetFileName)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OverwriteFiles, hv_ShowProgress, hv_ClassWeightsSegmentation;
  HTuple  hv_MaxWeight, hv_DLModelType, hv_GenParamGenDLSamples;
  HTuple  hv_ClassIDsDataset, hv_ClassNamesDataset, hv_Indices;
  HTuple  hv_SetBackgroundID, hv_KeyExists, hv_InstanceType;
  HTuple  hv_GenParamName, hv_GenParamIndex, hv_FileExists;
  HTuple  hv_DLSampleDir, hv_DLDatasetSamples, hv_Progress;
  HTuple  hv_SecondsStart, hv_SampleIndex, hv_DLSampleBatch;
  HTuple  hv_SecondsElapsed, hv_SecondsRemaining, hv_ProgressPercent;
  HTuple  hv_ProgressPerSecond, hv_TimeElapsedString, hv_TimeRemainingString;
  HTuple  hv_IgnoreClassIDs, hv_NormType, hv_DLDatasetPreprocessParam;

  //
  //This procedure preprocesses the samples in the dictionary DLDataset.
  //
  //** Parameters values: ***
  //
  //Set the default values.
  //Overwrite existing DLDataset file and DLSample directory.
  hv_OverwriteFiles = "false";
  //By default we show the progress of preprocessing.
  hv_ShowProgress = 1;
  //Class weights specified by user (needed for segmentation).
  hv_ClassWeightsSegmentation = HTuple();
  //Set max weight. Parameter for calculating the weights (needed for segmentation).
  hv_MaxWeight = 1000;
  //
  //Check the validity of the preprocessing parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Preprocessing parameters have been checked. Therefore, avoid possible subsequent checks.
  SetDictTuple(hv_DLPreprocessParam, "check_params", 0);
  //
  //Get the model type.
  GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_DLModelType);
  //
  //Initialize the generic parameters for gen_dl_samples.
  hv_GenParamGenDLSamples = HTuple();
  //Check if the DLDataset class IDs are two and one named 'gripping_map'
  if (0 != (int(hv_DLModelType==HTuple("3d_gripping_point_detection"))))
  {
    GetDictTuple(hv_DLDataset, "class_ids", &hv_ClassIDsDataset);
    GetDictTuple(hv_DLDataset, "class_names", &hv_ClassNamesDataset);
    if (0 != (HTuple(int((hv_ClassIDsDataset.TupleLength())!=2)).TupleOr(int((hv_ClassNamesDataset.TupleLength())!=2))))
    {
      throw HException("The DLDataset 'class_ids' and 'class_names' needs to of size two.");
    }
    TupleFind(hv_ClassNamesDataset, "gripping_map", &hv_Indices);
    if (0 != (int(hv_Indices==-1)))
    {
      throw HException("The DLDataset 'class_names' needs to include the 'gripping_map' name.");
    }
  }
  //Check if the background class ID is part of the DLDataset class IDs.
  if (0 != (int(hv_DLModelType==HTuple("segmentation"))))
  {
    GetDictTuple(hv_DLDataset, "class_ids", &hv_ClassIDsDataset);
    GetDictTuple(hv_DLPreprocessParam, "set_background_id", &hv_SetBackgroundID);
    if (0 != (int((hv_SetBackgroundID.TupleLength())>0)))
    {
      TupleFind(hv_ClassIDsDataset, hv_SetBackgroundID, &hv_Indices);
      if (0 != (int(hv_Indices==-1)))
      {
        throw HException(("The 'set_background_id':'"+hv_SetBackgroundID)+"' needs to be part of the DLDataset 'class_ids' tuple.");
      }
    }
  }
  else if (0 != (int(hv_DLModelType==HTuple("detection"))))
  {
    CreateDict(&hv_GenParamGenDLSamples);
    GetDictParam(hv_DLPreprocessParam, "key_exists", "instance_type", &hv_KeyExists);
    if (0 != hv_KeyExists)
    {
      GetDictTuple(hv_DLPreprocessParam, "instance_type", &hv_InstanceType);
      SetDictTuple(hv_GenParamGenDLSamples, "instance_type", hv_InstanceType);
    }
    else
    {
      SetDictTuple(hv_GenParamGenDLSamples, "instance_type", "rectangle1");
    }
  }
  //
  //Set the parameters for preprocess_dl_samples.
  SetDictTuple(hv_DLDataset, "preprocess_param", hv_DLPreprocessParam);
  //
  //Transfer generic parameters.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenParamName);
    {
    HTuple end_val65 = (hv_GenParamName.TupleLength())-1;
    HTuple step_val65 = 1;
    for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val65, step_val65); hv_GenParamIndex += step_val65)
    {
      if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("overwrite_files"))))
      {
        GetDictTuple(hv_GenParam, "overwrite_files", &hv_OverwriteFiles);
        if (0 != (int(hv_OverwriteFiles==1)))
        {
          hv_OverwriteFiles = "true";
        }
        else if (0 != (int(hv_OverwriteFiles==0)))
        {
          hv_OverwriteFiles = "false";
        }
        if (0 != (HTuple(HTuple(int(hv_OverwriteFiles!=HTuple("true"))).TupleAnd(int(hv_OverwriteFiles!=HTuple("false")))).TupleAnd(int(hv_OverwriteFiles!=HTuple("auto")))))
        {
          throw HException(HTuple("The preprocessing parameter 'overwrite_files' only allows the following values: ['true', 'false', 'auto']."));
        }
      }
      else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("show_progress"))))
      {
        GetDictTuple(hv_GenParam, "show_progress", &hv_ShowProgress);
        hv_ShowProgress = HTuple(int(hv_ShowProgress==HTuple("true"))).TupleOr(int(hv_ShowProgress==1));
      }
      else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("max_weight"))))
      {
        GetDictTuple(hv_GenParam, "max_weight", &hv_MaxWeight);
        if (0 != (HTuple(int(hv_DLModelType!=HTuple("segmentation"))).TupleOr(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
        {
          throw HException("The preprocessing parameter 'max_weight' only applies for segmentation and 3d_gripping_point_detection models.");
        }
      }
      else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("class_weights"))))
      {
        GetDictTuple(hv_GenParam, "class_weights", &hv_ClassWeightsSegmentation);
        if (0 != (HTuple(int(hv_DLModelType!=HTuple("segmentation"))).TupleOr(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
        {
          throw HException("The preprocessing parameter 'class_weights' only applies for segmentation and 3d_gripping_point_detection models.");
        }
      }
      else
      {
        throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
      }
    }
    }
  }
  //
  //** Clean/Create data directory: ***
  TupleRegexpReplace(hv_DataDirectory, "/+$", "", &hv_DataDirectory);
  FileExists(hv_DataDirectory, &hv_FileExists);
  if (0 != (hv_FileExists.TupleAnd(int(hv_OverwriteFiles==HTuple("false")))))
  {
    throw HException(("The folder "+hv_DataDirectory)+" already exists. Either give a different directory or force overwriting using the parameter 'overwrite_files'.");
  }
  //Preprocessed dataset file.
  (*hv_DLDatasetFileName) = hv_DataDirectory+"/dl_dataset.hdict";
  //Sample directory name.
  hv_DLSampleDir = hv_DataDirectory+"/samples";
  //
  if (0 != (hv_FileExists.TupleAnd(int(hv_OverwriteFiles==HTuple("auto")))))
  {
    //OverwriteFiles == 'auto':
    handle_overwrite_files_auto_in_preprocess_dl_dataset(hv_DLDataset, hv_DLPreprocessParam, 
        (*hv_DLDatasetFileName), &hv_OverwriteFiles);
    if (0 != (int(hv_OverwriteFiles==HTuple("auto"))))
    {
      //DLDataset has been updated. It is safe to exit.
      return;
    }
  }
  //
  //Wipe data directory if needed.
  if (0 != (hv_FileExists.TupleAnd(int(hv_OverwriteFiles==HTuple("true")))))
  {
    remove_dir_recursively(hv_DataDirectory);
  }
  MakeDir(hv_DataDirectory);
  //
  //Create the directory for the DLSamples, if it does not exist.
  MakeDir(hv_DLSampleDir);
  //
  //Set the output path.
  SetDictTuple(hv_DLDataset, "dlsample_dir", hv_DLSampleDir);
  //
  //** Preprocess all images in the dataset: ***
  //During training/validation and testing those preprocessed images
  //will be used for performance reasons.
  //
  //Get the samples to be preprocessed.
  GetDictTuple(hv_DLDataset, "samples", &hv_DLDatasetSamples);
  //
  //Initialize progress variables.
  if (0 != hv_ShowProgress)
  {
    hv_Progress.Clear();
    hv_Progress[0] = "Procedure: preprocess_dl_dataset";
    hv_Progress[1] = "";
    hv_Progress[2] = "";
    hv_Progress[3] = "";
    if (0 != (HTuple(int(hv_DLModelType==HTuple("segmentation"))).TupleOr(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
    {
      hv_Progress = hv_Progress.TupleConcat("Task: 1/2: image preprocessing");
    }
    CountSeconds(&hv_SecondsStart);
    // dev_inspect_ctrl(...); only in hdevelop
  }
  //
  //Loop over all samples.
  {
  HTuple end_val145 = (hv_DLDatasetSamples.TupleLength())-1;
  HTuple step_val145 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val145, step_val145); hv_SampleIndex += step_val145)
  {
    //
    //Generate the dictionary DLSample.
    gen_dl_samples(hv_DLDataset, hv_SampleIndex, hv_DLModelType, hv_GenParamGenDLSamples, 
        &hv_DLSampleBatch);
    //
    //Preprocess the DLSample.
    preprocess_dl_samples(hv_DLSampleBatch, hv_DLPreprocessParam);
    //
    //Write the preprocessed images.
    write_dl_samples(hv_DLDataset, hv_SampleIndex, hv_DLSampleBatch, HTuple(), HTuple());
    //
    //Provide progress information.
    if (0 != hv_ShowProgress)
    {
      if (0 != (HTuple(int((hv_SampleIndex%10)==1)).TupleOr(int(hv_SampleIndex==((hv_DLDatasetSamples.TupleLength())-1)))))
      {
        estimate_progress(hv_SecondsStart, 0, hv_SampleIndex, (hv_DLDatasetSamples.TupleLength())-1, 
            &hv_SecondsElapsed, &hv_SecondsRemaining, &hv_ProgressPercent, &hv_ProgressPerSecond);
        timespan_string(hv_SecondsElapsed, "auto", &hv_TimeElapsedString);
        timespan_string(hv_SecondsRemaining, "top2", &hv_TimeRemainingString);
        hv_Progress[1] = ("Progress: "+(hv_ProgressPercent.TupleRound()))+" %";
        hv_Progress[2] = "Time elapsed: "+hv_TimeElapsedString;
        hv_Progress[3] = "Time left: "+hv_TimeRemainingString;
      }
    }
  }
  }
  //
  //If the model is of type segmentation, or 3d_gripping_point_detection generate weight images.
  if (0 != (HTuple(int(hv_DLModelType==HTuple("segmentation"))).TupleOr(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
  {
    //
    if (0 != hv_ShowProgress)
    {
      hv_Progress.Clear();
      hv_Progress[0] = "Procedure: preprocess_dl_dataset";
      hv_Progress[1] = "";
      hv_Progress[2] = "";
      hv_Progress[1] = "Please wait...";
      hv_Progress[2] = "Task: 2/2: calculating class weights";
    }
    if (0 != (int((hv_ClassWeightsSegmentation.TupleLength())==0)))
    {
      //Calculate the class weights for segmentation.
      GetDictTuple(hv_DLPreprocessParam, "ignore_class_ids", &hv_IgnoreClassIDs);
      calculate_dl_segmentation_class_weights(hv_DLDataset, hv_MaxWeight, hv_IgnoreClassIDs, 
          &hv_ClassWeightsSegmentation);
    }
    //
    //Generate the weight images.
    gen_dl_segmentation_weight_images(hv_DLDataset, hv_DLPreprocessParam, hv_ClassWeightsSegmentation, 
        HTuple());
  }
  if (0 != hv_ShowProgress)
  {
    hv_Progress = "Done.";
    // dev_close_inspect_ctrl(...); only in hdevelop
  }
  //
  //In case of normalization type 'constant_values' save proper image_range_min/max to DLDataset dictionary 'preprocess_param'.
  GetDictParam(hv_DLPreprocessParam, "key_exists", "normalization_type", &hv_KeyExists);
  if (0 != hv_KeyExists)
  {
    GetDictTuple(hv_DLPreprocessParam, "normalization_type", &hv_NormType);
    if (0 != (int(hv_NormType==HTuple("constant_values"))))
    {
      GetDictParam(hv_DLDataset, "key_exists", "preprocess_param", &hv_KeyExists);
      if (0 != hv_KeyExists)
      {
        GetDictTuple(hv_DLDataset, "preprocess_param", &hv_DLDatasetPreprocessParam);
        SetDictTuple(hv_DLDatasetPreprocessParam, "image_range_min", -2.0);
        SetDictTuple(hv_DLDatasetPreprocessParam, "image_range_max", 2.0);
      }
    }
  }
  //
  //Write the preprocessed DLDataset dictionary.
  WriteDict(hv_DLDataset, (*hv_DLDatasetFileName), HTuple(), HTuple());
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Preprocess 3D data for deep-learning-based training and inference. 
void preprocess_dl_model_3d_data (HTuple hv_DLSample, HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_ImageZ, ho_Domain, ho_Region, ho_ImageReduced;
  HObject  ho_DomainComplement, ho_ImageX, ho_ImageY, ho_ImageXYZ;
  HObject  ho_NXImage, ho_NYImage, ho_NZImage, ho_MultiChannelImage;
  HObject  ho___Tmp_Obj_0;

  // Local control variables
  HTuple  hv_HasNormals, hv_XYZKeys, hv_HasXYZ;
  HTuple  hv_HasX, hv_HasY, hv_HasZ, hv_HasFullXYZ, hv_NumChannels;
  HTuple  hv_Type, hv_Index, hv_Key, hv_ZMinMaxExist, hv_GrayvalOutsideInit;
  HTuple  hv_NormalSizeExists, hv_NormalWidth, hv_NormalHeight;
  HTuple  hv_WidthZ, hv_HeightZ, hv_ZoomNormals, hv_Width;
  HTuple  hv_Height, hv_ScaleWidth, hv_ScaleHeight, hv_XIndex;
  HTuple  hv_YIndex;

  //
  //This procedure preprocesses 3D data of a DLSample.
  //
  //Check presence of inputs in DLSample.
  //
  GetDictParam(hv_DLSample, "key_exists", "normals", &hv_HasNormals);
  hv_XYZKeys.Clear();
  hv_XYZKeys[0] = "x";
  hv_XYZKeys[1] = "y";
  hv_XYZKeys[2] = "z";
  GetDictParam(hv_DLSample, "key_exists", hv_XYZKeys, &hv_HasXYZ);
  hv_HasX = ((const HTuple&)hv_HasXYZ)[0];
  hv_HasY = ((const HTuple&)hv_HasXYZ)[1];
  hv_HasZ = ((const HTuple&)hv_HasXYZ)[2];
  TupleMin(hv_HasXYZ, &hv_HasFullXYZ);
  if (0 != (hv_HasNormals.TupleNot()))
  {
    //XYZ are required because normals would need to be computed.
    if (0 != (hv_HasFullXYZ.TupleNot()))
    {
      throw HException(HTuple("The given input DLSample does not contain necessary images 'x','y' and 'z'. This is required if no normals are provided."));
    }
  }
  else
  {
    //At least Z is required if normals are given.
    if (0 != (hv_HasZ.TupleNot()))
    {
      throw HException(HTuple("The given input DLSample does not contain at least the depth image 'z'. This is required because normals are provided. Optionally, 'x' and 'y' images might be provided additionally."));
    }
    CountChannels(hv_DLSample.TupleGetDictObject("normals"), &hv_NumChannels);
    if (0 != (int(hv_NumChannels!=3)))
    {
      throw HException("The given input DLSample.normals has to have three channels.");
    }
    GetImageType(hv_DLSample.TupleGetDictObject("normals"), &hv_Type);
    if (0 != (int(hv_Type!=HTuple("real"))))
    {
      throw HException("The given input DLSample.normals is not a real image.");
    }
  }
  {
  HTuple end_val31 = (hv_HasXYZ.TupleLength())-1;
  HTuple step_val31 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val31, step_val31); hv_Index += step_val31)
  {
    if (0 != (HTuple(hv_HasXYZ[hv_Index])))
    {
      hv_Key = HTuple(hv_XYZKeys[hv_Index]);
      CountChannels(hv_DLSample.TupleGetDictObject(hv_Key), &hv_NumChannels);
      if (0 != (int(hv_NumChannels!=1)))
      {
        throw HException(("The given input DLSample."+hv_Key)+" needs to have a single channel.");
      }
      GetImageType(hv_DLSample.TupleGetDictObject(hv_Key), &hv_Type);
      if (0 != (int(hv_Type!=HTuple("real"))))
      {
        throw HException(("The given input DLSample."+hv_Key)+" is not a real image.");
      }
    }
  }
  }
  //
  ho_ImageZ = hv_DLSample.TupleGetDictObject("z");
  GetDomain(ho_ImageZ, &ho_Domain);
  //Reduce Z domain to user-defined min/max values for Z.
  GetDictParam(hv_DLPreprocessParam, "key_exists", (HTuple("min_z").Append("max_z")), 
      &hv_ZMinMaxExist);
  if (0 != (HTuple(hv_ZMinMaxExist[0])))
  {
    Threshold(ho_ImageZ, &ho_Region, "min", hv_DLPreprocessParam.TupleGetDictTuple("min_z"));
    Difference(ho_Domain, ho_Region, &ho_Domain);
  }
  if (0 != (HTuple(hv_ZMinMaxExist[1])))
  {
    Threshold(ho_ImageZ, &ho_Region, hv_DLPreprocessParam.TupleGetDictTuple("max_z"), 
        "max");
    Difference(ho_Domain, ho_Region, &ho_Domain);
  }
  //Reduce domain because it might have changed
  if (0 != (hv_ZMinMaxExist.TupleMax()))
  {
    ReduceDomain(ho_ImageZ, ho_Domain, &ho_ImageReduced);
  }
  Complement(ho_Domain, &ho_DomainComplement);
  //
  //Before we zoom any 3D images we want to set all pixels outside of the domain to
  //an invalid value.
  hv_GrayvalOutsideInit = 0;

  if (0 != hv_HasFullXYZ)
  {
    ho_ImageX = hv_DLSample.TupleGetDictObject("x");
    ho_ImageY = hv_DLSample.TupleGetDictObject("y");
    ho_ImageZ = hv_DLSample.TupleGetDictObject("z");

    FullDomain(ho_ImageX, &ho_ImageX);
    FullDomain(ho_ImageY, &ho_ImageY);
    FullDomain(ho_ImageZ, &ho_ImageZ);

    OverpaintRegion(ho_ImageX, ho_DomainComplement, hv_GrayvalOutsideInit, "fill");
    OverpaintRegion(ho_ImageY, ho_DomainComplement, hv_GrayvalOutsideInit, "fill");
    OverpaintRegion(ho_ImageZ, ho_DomainComplement, hv_GrayvalOutsideInit, "fill");

    ReduceDomain(ho_ImageX, ho_Domain, &ho_ImageX);
    ReduceDomain(ho_ImageY, ho_Domain, &ho_ImageY);
    ReduceDomain(ho_ImageZ, ho_Domain, &ho_ImageZ);

    if (0 != (hv_HasNormals.TupleNot()))
    {
      //Get optional user-defined resolution of normal computation.
      GetDictParam(hv_DLPreprocessParam, "key_exists", (HTuple("normal_image_width").Append("normal_image_height")), 
          &hv_NormalSizeExists);
      if (0 != (HTuple(hv_NormalSizeExists[0]).TupleNot()))
      {
        hv_NormalWidth = ((hv_DLPreprocessParam.TupleGetDictTuple("image_width"))*1.5).TupleInt();
      }
      else
      {
        hv_NormalWidth = hv_DLPreprocessParam.TupleGetDictTuple("normal_image_width");
      }
      if (0 != (HTuple(hv_NormalSizeExists[1]).TupleNot()))
      {
        hv_NormalHeight = ((hv_DLPreprocessParam.TupleGetDictTuple("image_height"))*1.5).TupleInt();
      }
      else
      {
        hv_NormalHeight = hv_DLPreprocessParam.TupleGetDictTuple("normal_image_height");
      }

      GetImageSize(ho_ImageZ, &hv_WidthZ, &hv_HeightZ);
      hv_ZoomNormals = HTuple(int(hv_NormalWidth!=hv_WidthZ)).TupleOr(int(hv_NormalHeight!=hv_HeightZ));

      if (0 != hv_ZoomNormals)
      {
        Compose3(ho_ImageX, ho_ImageY, ho_ImageZ, &ho_ImageXYZ);
        GetImageSize(ho_ImageXYZ, &hv_Width, &hv_Height);
        ZoomImageSize(ho_ImageXYZ, &ho_ImageXYZ, hv_NormalWidth, hv_NormalHeight, 
            "nearest_neighbor");
        AccessChannel(ho_ImageXYZ, &ho_ImageX, 1);
        AccessChannel(ho_ImageXYZ, &ho_ImageY, 2);
        AccessChannel(ho_ImageXYZ, &ho_ImageZ, 3);
        hv_ScaleWidth = hv_NormalWidth/(hv_Width.TupleReal());
        hv_ScaleHeight = hv_NormalHeight/(hv_Height.TupleReal());
        ZoomRegion(ho_Domain, &ho_Domain, hv_ScaleWidth, hv_ScaleHeight);
        remove_invalid_3d_pixels(ho_ImageX, ho_ImageY, ho_ImageZ, ho_Domain, &ho_Domain, 
            hv_GrayvalOutsideInit);
        Complement(ho_Domain, &ho_DomainComplement);
      }

      compute_normals_xyz(ho_ImageX, ho_ImageY, ho_ImageZ, &ho_NXImage, &ho_NYImage, 
          &ho_NZImage, 1);
    }
    else
    {
      AccessChannel(hv_DLSample.TupleGetDictObject("normals"), &ho_NXImage, 1);
      AccessChannel(hv_DLSample.TupleGetDictObject("normals"), &ho_NYImage, 2);
      AccessChannel(hv_DLSample.TupleGetDictObject("normals"), &ho_NZImage, 3);
    }
  }
  else
  {
    GenEmptyObj(&ho_ImageX);
    GenEmptyObj(&ho_ImageY);

    AccessChannel(hv_DLSample.TupleGetDictObject("normals"), &ho_NXImage, 1);
    AccessChannel(hv_DLSample.TupleGetDictObject("normals"), &ho_NYImage, 2);
    AccessChannel(hv_DLSample.TupleGetDictObject("normals"), &ho_NZImage, 3);
  }

  FullDomain(ho_ImageZ, &ho_ImageZ);

  FullDomain(ho_NXImage, &ho_NXImage);
  FullDomain(ho_NYImage, &ho_NYImage);
  FullDomain(ho_NZImage, &ho_NZImage);

  //full_domain does not change the pixels outside of the existing domain.
  //Hence we have to set a specific value
  OverpaintRegion(ho_NXImage, ho_DomainComplement, hv_GrayvalOutsideInit, "fill");
  OverpaintRegion(ho_NYImage, ho_DomainComplement, hv_GrayvalOutsideInit, "fill");
  OverpaintRegion(ho_NZImage, ho_DomainComplement, hv_GrayvalOutsideInit, "fill");
  OverpaintRegion(ho_ImageZ, ho_DomainComplement, hv_GrayvalOutsideInit, "fill");

  Compose4(ho_NXImage, ho_NYImage, ho_NZImage, ho_ImageZ, &ho_MultiChannelImage);

  CountObj(ho_ImageX, &hv_HasX);
  if (0 != hv_HasX)
  {
    FullDomain(ho_ImageX, &ho_ImageX);
    AppendChannel(ho_MultiChannelImage, ho_ImageX, &ho_MultiChannelImage);
    CountChannels(ho_MultiChannelImage, &hv_XIndex);
  }
  CountObj(ho_ImageY, &hv_HasY);
  if (0 != hv_HasY)
  {
    FullDomain(ho_ImageY, &ho_ImageY);
    AppendChannel(ho_MultiChannelImage, ho_ImageY, &ho_MultiChannelImage);
    CountChannels(ho_MultiChannelImage, &hv_YIndex);
  }
  GetImageSize(ho_MultiChannelImage, &hv_Width, &hv_Height);
  ZoomImageSize(ho_MultiChannelImage, &ho_MultiChannelImage, hv_DLPreprocessParam.TupleGetDictTuple("image_width"), 
      hv_DLPreprocessParam.TupleGetDictTuple("image_height"), "nearest_neighbor");

  Decompose4(ho_MultiChannelImage, &ho_NXImage, &ho_NYImage, &ho_NZImage, &ho_ImageZ
      );
  if (0 != hv_HasX)
  {
    AccessChannel(ho_MultiChannelImage, &ho_ImageX, hv_XIndex);
  }
  if (0 != hv_HasY)
  {
    AccessChannel(ho_MultiChannelImage, &ho_ImageY, hv_YIndex);
  }


  //Zoom the domain
  hv_ScaleWidth = (hv_DLPreprocessParam.TupleGetDictTuple("image_width"))/(hv_Width.TupleReal());
  hv_ScaleHeight = (hv_DLPreprocessParam.TupleGetDictTuple("image_height"))/(hv_Height.TupleReal());
  ZoomRegion(ho_Domain, &ho_Domain, hv_ScaleWidth, hv_ScaleHeight);
  remove_invalid_3d_pixels(ho_NXImage, ho_NYImage, ho_NZImage, ho_Domain, &ho_Domain, 
      hv_GrayvalOutsideInit);

  ReduceDomain(ho_ImageX, ho_Domain, &ho_ImageX);
  ReduceDomain(ho_ImageY, ho_Domain, &ho_ImageY);
  ReduceDomain(ho_ImageZ, ho_Domain, &ho_ImageZ);
  Compose3(ho_NXImage, ho_NYImage, ho_NZImage, &ho___Tmp_Obj_0);
  SetDictObject(ho___Tmp_Obj_0, hv_DLSample, "normals");
  ReduceDomain(hv_DLSample.TupleGetDictObject("normals"), ho_Domain, &ho___Tmp_Obj_0
      );
  SetDictObject(ho___Tmp_Obj_0, hv_DLSample, "normals");

  //Overwrite preprocessed 3D data
  if (0 != hv_HasX)
  {
    SetDictObject(ho_ImageX, hv_DLSample, "x");
  }
  if (0 != hv_HasY)
  {
    SetDictObject(ho_ImageY, hv_DLSample, "y");
  }
  if (0 != hv_HasZ)
  {
    SetDictObject(ho_ImageZ, hv_DLSample, "z");
  }

  return;
}

// Chapter: Deep Learning / Model
// Short Description: Preprocess anomaly images for evaluation and visualization of deep-learning-based anomaly detection or Global Context Anomaly Detection. 
void preprocess_dl_model_anomaly (HObject ho_AnomalyImages, HObject *ho_AnomalyImagesPreprocessed, 
    HTuple hv_DLPreprocessParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_ImageRangeMin;
  HTuple  hv_ImageRangeMax, hv_DomainHandling, hv_ModelType;
  HTuple  hv_ImageNumChannels, hv_Min, hv_Max, hv_Range, hv_ImageWidthInput;
  HTuple  hv_ImageHeightInput, hv_EqualWidth, hv_EqualHeight;
  HTuple  hv_Type, hv_NumMatches, hv_NumImages, hv_EqualByte;
  HTuple  hv_NumChannelsAllImages, hv_ImageNumChannelsTuple;
  HTuple  hv_IndicesWrongChannels;

  //
  //This procedure preprocesses the anomaly images given by AnomalyImages
  //according to the parameters in the dictionary DLPreprocessParam.
  //Note that depending on the images,
  //additional preprocessing steps might be beneficial.
  //
  //Check the validity of the preprocessing parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get the preprocessing parameters.
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
  GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
  GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
  GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_ModelType);
  //
  hv_ImageNumChannels = 1;
  //
  //Preprocess the images.
  //
  if (0 != (int(hv_DomainHandling==HTuple("full_domain"))))
  {
    FullDomain(ho_AnomalyImages, &ho_AnomalyImages);
  }
  else if (0 != (int(hv_DomainHandling==HTuple("crop_domain"))))
  {
    CropDomain(ho_AnomalyImages, &ho_AnomalyImages);
  }
  else if (0 != (HTuple(int(hv_DomainHandling==HTuple("keep_domain"))).TupleAnd(int(hv_ModelType==HTuple("anomaly_detection")))))
  {
    //The option 'keep_domain' is only supported for models of 'type' = 'anomaly_detection'
  }
  else
  {
    throw HException("Unsupported parameter value for 'domain_handling'");
  }
  //
  MinMaxGray(ho_AnomalyImages, ho_AnomalyImages, 0, &hv_Min, &hv_Max, &hv_Range);
  if (0 != (int(hv_Min<0.0)))
  {
    throw HException("Values of anomaly image must not be smaller than 0.0.");
  }
  //
  //Zoom images only if they have a different size than the specified size.
  GetImageSize(ho_AnomalyImages, &hv_ImageWidthInput, &hv_ImageHeightInput);
  hv_EqualWidth = hv_ImageWidth.TupleEqualElem(hv_ImageWidthInput);
  hv_EqualHeight = hv_ImageHeight.TupleEqualElem(hv_ImageHeightInput);
  if (0 != (HTuple(int((hv_EqualWidth.TupleMin())==0)).TupleOr(int((hv_EqualHeight.TupleMin())==0))))
  {
    ZoomImageSize(ho_AnomalyImages, &ho_AnomalyImages, hv_ImageWidth, hv_ImageHeight, 
        "nearest_neighbor");
  }
  //
  //Check the type of the input images.
  GetImageType(ho_AnomalyImages, &hv_Type);
  TupleRegexpTest(hv_Type, "byte|real", &hv_NumMatches);
  CountObj(ho_AnomalyImages, &hv_NumImages);
  if (0 != (int(hv_NumMatches!=hv_NumImages)))
  {
    throw HException("Please provide only images of type 'byte' or 'real'.");
  }
  //
  //If the type is 'byte', convert it to 'real' and scale it.
  //The gray value scaling does not work on 'byte' images.
  //For 'real' images it is assumed that the range is already correct.
  hv_EqualByte = hv_Type.TupleEqualElem("byte");
  if (0 != (int((hv_EqualByte.TupleMax())==1)))
  {
    if (0 != (int((hv_EqualByte.TupleMin())==0)))
    {
      throw HException("Passing mixed type images is not supported.");
    }
    //Convert the image type from 'byte' to 'real',
    //because the model expects 'real' images.
    ConvertImageType(ho_AnomalyImages, &ho_AnomalyImages, "real");
  }
  //
  //Check the number of channels.
  CountObj(ho_AnomalyImages, &hv_NumImages);
  //Check all images for number of channels.
  CountChannels(ho_AnomalyImages, &hv_NumChannelsAllImages);
  TupleGenConst(hv_NumImages, hv_ImageNumChannels, &hv_ImageNumChannelsTuple);
  TupleFind(hv_NumChannelsAllImages.TupleNotEqualElem(hv_ImageNumChannelsTuple), 
      1, &hv_IndicesWrongChannels);
  //
  //Check for anomaly image channels.
  //Only single channel images are accepted.
  if (0 != (int(hv_IndicesWrongChannels!=-1)))
  {
    throw HException("Number of channels in anomaly image is not supported. Please check for anomaly images with a number of channels different from 1.");
  }
  //
  //Write preprocessed image to output variable.
  (*ho_AnomalyImagesPreprocessed) = ho_AnomalyImages;
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Preprocess the provided DLSample image for augmentation purposes. 
void preprocess_dl_model_augmentation_data (HTuple hv_DLSample, HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_InputImage, ho_ImageHighRes;

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_ImageNumChannels;
  HTuple  hv_ModelType, hv_AugmentationKeyExists, hv_ImageKeyExists;
  HTuple  hv_NumImages, hv_NumChannels, hv_ImageType, hv_InputImageWidth;
  HTuple  hv_InputImageHeight, hv_InputImageWidthHeightRatio;
  HTuple  hv_ZoomHeight, hv_ZoomWidth, hv_HasPadding, hv_ZoomFactorWidth;
  HTuple  hv_ZoomFactorHeight, hv_UseZoomImage, hv_DLSampleHighRes;
  HTuple  hv_DLPreprocessParamHighRes, hv___Tmp_Ctrl_Dict_Init_0;
  HTuple  hv___Tmp_Ctrl_Dict_Init_1, hv___Tmp_Ctrl_Dict_Init_2;

  //This procedure preprocesses the provided DLSample image for augmentation purposes.
  //
  //Check the validity of the preprocessing parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get the required preprocessing parameters.
  hv_ImageWidth = hv_DLPreprocessParam.TupleGetDictTuple("image_width");
  hv_ImageHeight = hv_DLPreprocessParam.TupleGetDictTuple("image_height");
  hv_ImageNumChannels = hv_DLPreprocessParam.TupleGetDictTuple("image_num_channels");
  hv_ModelType = hv_DLPreprocessParam.TupleGetDictTuple("model_type");
  //
  //Determine whether the preprocessing is required or not.
  GetDictParam(hv_DLPreprocessParam, "key_exists", "augmentation", &hv_AugmentationKeyExists);
  if (0 != (hv_AugmentationKeyExists.TupleNot()))
  {
    return;
  }
  CreateDict(&hv___Tmp_Ctrl_Dict_Init_0);
  SetDictTuple(hv___Tmp_Ctrl_Dict_Init_0, "comp", "true");
  if (0 != (((hv_DLPreprocessParam.TupleConcat(hv___Tmp_Ctrl_Dict_Init_0)).TupleTestEqualDictItem("augmentation","comp")).TupleNot()))
  {
    return;
  }
  hv___Tmp_Ctrl_Dict_Init_0 = HTuple::TupleConstant("HNULL");
  if (0 != (HTuple(int(hv_ModelType!=HTuple("ocr_detection"))).TupleAnd(int(hv_ModelType!=HTuple("ocr_recognition")))))
  {
    return;
  }
  //
  //Get the input image and its properties.
  GetDictParam(hv_DLSample, "key_exists", "image", &hv_ImageKeyExists);
  if (0 != (hv_ImageKeyExists.TupleNot()))
  {
    throw HException("The sample to process needs to include an image.");
  }
  ho_InputImage = hv_DLSample.TupleGetDictObject("image");
  CountObj(ho_InputImage, &hv_NumImages);
  if (0 != (int(hv_NumImages!=1)))
  {
    throw HException("The sample to process needs to include exactly 1 image.");
  }
  CountChannels(ho_InputImage, &hv_NumChannels);
  GetImageType(ho_InputImage, &hv_ImageType);
  GetImageSize(ho_InputImage, &hv_InputImageWidth, &hv_InputImageHeight);
  //
  //Execute model specific preprocessing.
  if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
  {
    if (0 != (int(hv_ImageNumChannels!=1)))
    {
      throw HException("The only 'image_num_channels' value supported for ocr_recognition models is 1.");
    }
    if (0 != (int((hv_ImageType.TupleRegexpTest("byte|real"))!=1)))
    {
      throw HException("Please provide only images of type 'byte' or 'real' for ocr_recognition models.");
    }
    if (0 != (int((HTuple((hv_NumChannels.TupleEqualElem(1)).TupleOr(hv_NumChannels.TupleEqualElem(3))).TupleSum())!=1)))
    {
      throw HException("Please provide only 1- or 3-channels images for ocr_recognition models.");
    }
    //
    FullDomain(ho_InputImage, &ho_ImageHighRes);
    if (0 != (int(hv_NumChannels==3)))
    {
      Rgb1ToGray(ho_ImageHighRes, &ho_ImageHighRes);
    }
    hv_InputImageWidthHeightRatio = hv_InputImageWidth/(hv_InputImageHeight.TupleReal());
    hv_ZoomHeight = hv_InputImageHeight.TupleMin2(2*hv_ImageHeight);
    hv_ZoomWidth = (hv_ZoomHeight*hv_InputImageWidthHeightRatio).TupleInt();
    hv_HasPadding = int(((hv_ImageHeight*hv_InputImageWidthHeightRatio).TupleInt())<hv_ImageWidth);
    if (0 != (HTuple(int(hv_ZoomHeight>hv_ImageHeight)).TupleOr(hv_HasPadding)))
    {
      ZoomImageSize(ho_ImageHighRes, &ho_ImageHighRes, hv_ZoomWidth, hv_ZoomHeight, 
          "constant");
      CreateDict(&hv___Tmp_Ctrl_Dict_Init_1);
      SetDictTuple(hv_DLSample, "augmentation_data", hv___Tmp_Ctrl_Dict_Init_1);
      hv___Tmp_Ctrl_Dict_Init_1 = HTuple::TupleConstant("HNULL");
      SetDictObject(ho_ImageHighRes, hv_DLSample.TupleGetDictTuple("augmentation_data"), 
          "image_high_res");
      SetDictTuple(hv_DLSample.TupleGetDictTuple("augmentation_data"), "preprocess_params", 
          hv_DLPreprocessParam);
    }
  }
  else if (0 != (int(hv_ModelType==HTuple("ocr_detection"))))
  {
    if (0 != (int(hv_ImageNumChannels!=3)))
    {
      throw HException("The only 'image_num_channels' value supported for ocr_detection models is 3.");
    }
    if (0 != (int((hv_ImageType.TupleRegexpTest("byte|real"))!=1)))
    {
      throw HException("Please provide only images of type 'byte' or 'real' for ocr_detection models.");
    }
    if (0 != (int((HTuple((hv_NumChannels.TupleEqualElem(1)).TupleOr(hv_NumChannels.TupleEqualElem(3))).TupleSum())!=1)))
    {
      throw HException("Please provide only 1- or 3-channels images for ocr_detection models.");
    }
    //
    //Calculate aspect-ratio preserving zoom dimensions for high resolution.
    calculate_dl_image_zoom_factors(hv_InputImageWidth, hv_InputImageHeight, 2*hv_ImageWidth, 
        2*hv_ImageHeight, hv_DLPreprocessParam, &hv_ZoomFactorWidth, &hv_ZoomFactorHeight);
    hv_ZoomHeight = (hv_ZoomFactorHeight*hv_InputImageHeight).TupleRound();
    hv_ZoomWidth = (hv_ZoomFactorWidth*hv_InputImageWidth).TupleRound();
    //
    //Use the better size for high resolution: 2x resolution size of preprocess image or input image size.
    hv_UseZoomImage = HTuple(int(hv_ZoomWidth<hv_InputImageWidth)).TupleOr(int(hv_ZoomHeight<hv_InputImageHeight));
    CopyDict(hv_DLSample, HTuple(), HTuple(), &hv_DLSampleHighRes);
    CopyDict(hv_DLPreprocessParam, HTuple(), HTuple(), &hv_DLPreprocessParamHighRes);
    //
    FullDomain(ho_InputImage, &ho_ImageHighRes);
    if (0 != hv_UseZoomImage)
    {
      SetDictTuple(hv_DLPreprocessParamHighRes, "image_width", hv_ZoomWidth);
      SetDictTuple(hv_DLPreprocessParamHighRes, "image_height", hv_ZoomHeight);
      preprocess_dl_model_bbox_rect2(ho_ImageHighRes, hv_DLSampleHighRes, hv_DLPreprocessParamHighRes);
      gen_dl_ocr_detection_targets(hv_DLSampleHighRes, hv_DLPreprocessParamHighRes);
      ZoomImageSize(ho_ImageHighRes, &ho_ImageHighRes, hv_ZoomWidth, hv_ZoomHeight, 
          "constant");
    }
    else
    {
      SetDictTuple(hv_DLPreprocessParamHighRes, "image_width", hv_InputImageWidth);
      SetDictTuple(hv_DLPreprocessParamHighRes, "image_height", hv_InputImageHeight);
      gen_dl_ocr_detection_targets(hv_DLSampleHighRes, hv_DLPreprocessParamHighRes);
    }
    SetDictObject(ho_ImageHighRes, hv_DLSampleHighRes, "image");
    //
    CreateDict(&hv___Tmp_Ctrl_Dict_Init_2);
    SetDictTuple(hv_DLSample, "augmentation_data", hv___Tmp_Ctrl_Dict_Init_2);
    hv___Tmp_Ctrl_Dict_Init_2 = HTuple::TupleConstant("HNULL");
    SetDictTuple(hv_DLSample.TupleGetDictTuple("augmentation_data"), "sample_high_res", 
        hv_DLSampleHighRes);
    SetDictTuple(hv_DLSample.TupleGetDictTuple("augmentation_data"), "preprocess_params", 
        hv_DLPreprocessParam);
  }
  //
  return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Preprocess the bounding boxes of type 'rectangle1' for a given sample. 
void preprocess_dl_model_bbox_rect1 (HObject ho_ImageRaw, HTuple hv_DLSample, HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_DomainRaw;

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_DomainHandling;
  HTuple  hv_BBoxCol1, hv_BBoxCol2, hv_BBoxRow1, hv_BBoxRow2;
  HTuple  hv_BBoxLabel, hv_Exception, hv_ImageId, hv_ExceptionMessage;
  HTuple  hv_BoxesInvalid, hv_DomainRow1, hv_DomainColumn1;
  HTuple  hv_DomainRow2, hv_DomainColumn2, hv_WidthRaw, hv_HeightRaw;
  HTuple  hv_Row1, hv_Col1, hv_Row2, hv_Col2, hv_MaskDelete;
  HTuple  hv_MaskNewBbox, hv_BBoxCol1New, hv_BBoxCol2New;
  HTuple  hv_BBoxRow1New, hv_BBoxRow2New, hv_BBoxLabelNew;
  HTuple  hv_FactorResampleWidth, hv_FactorResampleHeight;

  //
  //This procedure preprocesses the bounding boxes of type 'rectangle1' for a given sample.
  //
  //Check the validity of the preprocessing parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get the preprocessing parameters.
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
  //
  //Get bounding box coordinates and labels.
  try
  {
    GetDictTuple(hv_DLSample, "bbox_col1", &hv_BBoxCol1);
    GetDictTuple(hv_DLSample, "bbox_col2", &hv_BBoxCol2);
    GetDictTuple(hv_DLSample, "bbox_row1", &hv_BBoxRow1);
    GetDictTuple(hv_DLSample, "bbox_row2", &hv_BBoxRow2);
    GetDictTuple(hv_DLSample, "bbox_label_id", &hv_BBoxLabel);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    GetDictTuple(hv_DLSample, "image_id", &hv_ImageId);
    if (0 != (int(HTuple(hv_Exception[0])==1302)))
    {
      hv_ExceptionMessage = "A bounding box coordinate key is missing.";
    }
    else
    {
      hv_ExceptionMessage = ((const HTuple&)hv_Exception)[2];
    }
    throw HException((("An error has occurred during preprocessing image_id "+hv_ImageId)+" when getting bounding box coordinates : ")+hv_ExceptionMessage);
  }
  //
  //Check that there are no invalid boxes.
  if (0 != (int((hv_BBoxRow1.TupleLength())>0)))
  {
    hv_BoxesInvalid = (hv_BBoxRow1.TupleGreaterEqualElem(hv_BBoxRow2)).TupleOr(hv_BBoxCol1.TupleGreaterEqualElem(hv_BBoxCol2));
    if (0 != (int((hv_BoxesInvalid.TupleSum())>0)))
    {
      GetDictTuple(hv_DLSample, "image_id", &hv_ImageId);
      throw HException(("An error has occurred during preprocessing image_id "+hv_ImageId)+HTuple(": Sample contains at least one box with zero-area, i.e. bbox_col1 >= bbox_col2 or bbox_row1 >= bbox_row2."));
    }
  }
  else
  {
    //There are no bounding boxes, hence nothing to do.
    return;
  }
  //
  //If the domain is cropped, crop bounding boxes.
  if (0 != (int(hv_DomainHandling==HTuple("crop_domain"))))
  {
    //
    //Get domain.
    GetDomain(ho_ImageRaw, &ho_DomainRaw);
    //
    //Set the size of the raw image to the domain extensions.
    SmallestRectangle1(ho_DomainRaw, &hv_DomainRow1, &hv_DomainColumn1, &hv_DomainRow2, 
        &hv_DomainColumn2);
    //The domain is always given as a pixel-precise region.
    hv_WidthRaw = (hv_DomainColumn2-hv_DomainColumn1)+1.0;
    hv_HeightRaw = (hv_DomainRow2-hv_DomainRow1)+1.0;
    //
    //Crop the bounding boxes.
    hv_Row1 = hv_BBoxRow1.TupleMax2(hv_DomainRow1-.5);
    hv_Col1 = hv_BBoxCol1.TupleMax2(hv_DomainColumn1-.5);
    hv_Row2 = hv_BBoxRow2.TupleMin2(hv_DomainRow2+.5);
    hv_Col2 = hv_BBoxCol2.TupleMin2(hv_DomainColumn2+.5);
    hv_MaskDelete = (hv_Row1.TupleGreaterEqualElem(hv_Row2)).TupleOr(hv_Col1.TupleGreaterEqualElem(hv_Col2));
    hv_MaskNewBbox = 1-hv_MaskDelete;
    //Store the preprocessed bounding box entries.
    hv_BBoxCol1New = (hv_Col1.TupleSelectMask(hv_MaskNewBbox))-hv_DomainColumn1;
    hv_BBoxCol2New = (hv_Col2.TupleSelectMask(hv_MaskNewBbox))-hv_DomainColumn1;
    hv_BBoxRow1New = (hv_Row1.TupleSelectMask(hv_MaskNewBbox))-hv_DomainRow1;
    hv_BBoxRow2New = (hv_Row2.TupleSelectMask(hv_MaskNewBbox))-hv_DomainRow1;
    hv_BBoxLabelNew = hv_BBoxLabel.TupleSelectMask(hv_MaskNewBbox);
    //
    //If we remove/select bounding boxes we also need to filter the corresponding
    //instance segmentation masks if they exist.
    filter_dl_sample_instance_segmentation_masks(hv_DLSample, hv_MaskNewBbox);
  }
  else if (0 != (int(hv_DomainHandling==HTuple("full_domain"))))
  {
    //If the entire image is used, set the variables accordingly.
    //Get the original size.
    GetImageSize(ho_ImageRaw, &hv_WidthRaw, &hv_HeightRaw);
    //Set new coordinates to input coordinates.
    hv_BBoxCol1New = hv_BBoxCol1;
    hv_BBoxCol2New = hv_BBoxCol2;
    hv_BBoxRow1New = hv_BBoxRow1;
    hv_BBoxRow2New = hv_BBoxRow2;
    hv_BBoxLabelNew = hv_BBoxLabel;
  }
  else
  {
    throw HException("Unsupported parameter value for 'domain_handling'");
  }
  //
  //Rescale the bounding boxes.
  //
  //Get required images width and height.
  //
  //Only rescale bounding boxes if the required image dimensions are not the raw dimensions.
  if (0 != (HTuple(int(hv_ImageHeight!=hv_HeightRaw)).TupleOr(int(hv_ImageWidth!=hv_WidthRaw))))
  {
    //Calculate rescaling factor.
    hv_FactorResampleWidth = (hv_ImageWidth.TupleReal())/hv_WidthRaw;
    hv_FactorResampleHeight = (hv_ImageHeight.TupleReal())/hv_HeightRaw;
    //Rescale the bounding box coordinates.
    //As we use XLD-coordinates we temporarily move the boxes by (.5,.5) for rescaling.
    //Doing so, the center of the XLD-coordinate system (-0.5,-0.5) is used
    //for scaling, hence the scaling is performed w.r.t. the pixel coordinate system.
    hv_BBoxCol1New = ((hv_BBoxCol1New+.5)*hv_FactorResampleWidth)-.5;
    hv_BBoxCol2New = ((hv_BBoxCol2New+.5)*hv_FactorResampleWidth)-.5;
    hv_BBoxRow1New = ((hv_BBoxRow1New+.5)*hv_FactorResampleHeight)-.5;
    hv_BBoxRow2New = ((hv_BBoxRow2New+.5)*hv_FactorResampleHeight)-.5;
    //
  }
  //
  //Make a final check and remove bounding boxes that have zero area.
  if (0 != (int((hv_BBoxRow1New.TupleLength())>0)))
  {
    hv_MaskDelete = (hv_BBoxRow1New.TupleGreaterEqualElem(hv_BBoxRow2New)).TupleOr(hv_BBoxCol1New.TupleGreaterEqualElem(hv_BBoxCol2New));
    hv_BBoxCol1New = hv_BBoxCol1New.TupleSelectMask(1-hv_MaskDelete);
    hv_BBoxCol2New = hv_BBoxCol2New.TupleSelectMask(1-hv_MaskDelete);
    hv_BBoxRow1New = hv_BBoxRow1New.TupleSelectMask(1-hv_MaskDelete);
    hv_BBoxRow2New = hv_BBoxRow2New.TupleSelectMask(1-hv_MaskDelete);
    hv_BBoxLabelNew = hv_BBoxLabelNew.TupleSelectMask(1-hv_MaskDelete);
    //
    //If we remove/select bounding boxes we also need to filter the corresponding
    //instance segmentation masks if they exist.
    filter_dl_sample_instance_segmentation_masks(hv_DLSample, 1-hv_MaskDelete);
  }
  //
  //Set new bounding box coordinates in the dictionary.
  SetDictTuple(hv_DLSample, "bbox_col1", hv_BBoxCol1New);
  SetDictTuple(hv_DLSample, "bbox_col2", hv_BBoxCol2New);
  SetDictTuple(hv_DLSample, "bbox_row1", hv_BBoxRow1New);
  SetDictTuple(hv_DLSample, "bbox_row2", hv_BBoxRow2New);
  SetDictTuple(hv_DLSample, "bbox_label_id", hv_BBoxLabelNew);
  //
  return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Preprocess the bounding boxes of type 'rectangle2' for a given sample. 
void preprocess_dl_model_bbox_rect2 (HObject ho_ImageRaw, HTuple hv_DLSample, HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_DomainRaw, ho_Rectangle2XLD, ho_Rectangle2XLDSheared;

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_DomainHandling;
  HTuple  hv_IgnoreDirection, hv_ClassIDsNoOrientation, hv_KeyExists;
  HTuple  hv_BBoxRow, hv_BBoxCol, hv_BBoxLength1, hv_BBoxLength2;
  HTuple  hv_BBoxPhi, hv_BBoxLabel, hv_Exception, hv_ImageId;
  HTuple  hv_ExceptionMessage, hv_BoxesInvalid, hv_DomainRow1;
  HTuple  hv_DomainColumn1, hv_DomainRow2, hv_DomainColumn2;
  HTuple  hv_WidthRaw, hv_HeightRaw, hv_MaskDelete, hv_MaskNewBbox;
  HTuple  hv_BBoxRowNew, hv_BBoxColNew, hv_BBoxLength1New;
  HTuple  hv_BBoxLength2New, hv_BBoxPhiNew, hv_BBoxLabelNew;
  HTuple  hv_ClassIDsNoOrientationIndices, hv_Index, hv_ClassIDsNoOrientationIndicesTmp;
  HTuple  hv_DirectionLength1Row, hv_DirectionLength1Col;
  HTuple  hv_DirectionLength2Row, hv_DirectionLength2Col;
  HTuple  hv_Corner1Row, hv_Corner1Col, hv_Corner2Row, hv_Corner2Col;
  HTuple  hv_FactorResampleWidth, hv_FactorResampleHeight;
  HTuple  hv_BBoxRow1, hv_BBoxCol1, hv_BBoxRow2, hv_BBoxCol2;
  HTuple  hv_BBoxRow3, hv_BBoxCol3, hv_BBoxRow4, hv_BBoxCol4;
  HTuple  hv_BBoxCol1New, hv_BBoxCol2New, hv_BBoxCol3New;
  HTuple  hv_BBoxCol4New, hv_BBoxRow1New, hv_BBoxRow2New;
  HTuple  hv_BBoxRow3New, hv_BBoxRow4New, hv_HomMat2DIdentity;
  HTuple  hv_HomMat2DScale, hv__, hv_BBoxPhiTmp, hv_PhiDelta;
  HTuple  hv_PhiDeltaNegativeIndices, hv_IndicesRot90, hv_IndicesRot180;
  HTuple  hv_IndicesRot270, hv_SwapIndices, hv_Tmp, hv_BBoxPhiNewIndices;
  HTuple  hv_PhiThreshold, hv_PhiToCorrect, hv_NumCorrections;

  //This procedure preprocesses the bounding boxes of type 'rectangle2' for a given sample.
  //
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get preprocess parameters.
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
  //The keys 'ignore_direction' and 'class_ids_no_orientation' are optional.
  hv_IgnoreDirection = 0;
  hv_ClassIDsNoOrientation = HTuple();
  GetDictParam(hv_DLPreprocessParam, "key_exists", (HTuple("ignore_direction").Append("class_ids_no_orientation")), 
      &hv_KeyExists);
  if (0 != (HTuple(hv_KeyExists[0])))
  {
    GetDictTuple(hv_DLPreprocessParam, "ignore_direction", &hv_IgnoreDirection);
    if (0 != (int(hv_IgnoreDirection==HTuple("true"))))
    {
      hv_IgnoreDirection = 1;
    }
    else if (0 != (int(hv_IgnoreDirection==HTuple("false"))))
    {
      hv_IgnoreDirection = 0;
    }
  }
  if (0 != (HTuple(hv_KeyExists[1])))
  {
    GetDictTuple(hv_DLPreprocessParam, "class_ids_no_orientation", &hv_ClassIDsNoOrientation);
  }
  //
  //Get bounding box coordinates and labels.
  try
  {
    GetDictTuple(hv_DLSample, "bbox_row", &hv_BBoxRow);
    GetDictTuple(hv_DLSample, "bbox_col", &hv_BBoxCol);
    GetDictTuple(hv_DLSample, "bbox_length1", &hv_BBoxLength1);
    GetDictTuple(hv_DLSample, "bbox_length2", &hv_BBoxLength2);
    GetDictTuple(hv_DLSample, "bbox_phi", &hv_BBoxPhi);
    GetDictTuple(hv_DLSample, "bbox_label_id", &hv_BBoxLabel);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    GetDictTuple(hv_DLSample, "image_id", &hv_ImageId);
    if (0 != (int(HTuple(hv_Exception[0])==1302)))
    {
      hv_ExceptionMessage = "A bounding box coordinate key is missing.";
    }
    else
    {
      hv_ExceptionMessage = ((const HTuple&)hv_Exception)[2];
    }
    throw HException((("An error has occurred during preprocessing image_id "+hv_ImageId)+" when getting bounding box coordinates : ")+hv_ExceptionMessage);
  }
  //
  //Check that there are no invalid boxes.
  if (0 != (int((hv_BBoxRow.TupleLength())>0)))
  {
    hv_BoxesInvalid = ((hv_BBoxLength1.TupleEqualElem(0)).TupleSum())+((hv_BBoxLength2.TupleEqualElem(0)).TupleSum());
    if (0 != (int(hv_BoxesInvalid>0)))
    {
      GetDictTuple(hv_DLSample, "image_id", &hv_ImageId);
      throw HException(("An error has occurred during preprocessing image_id "+hv_ImageId)+HTuple(": Sample contains at least one bounding box with zero-area, i.e. bbox_length1 == 0 or bbox_length2 == 0!"));
    }
  }
  else
  {
    //There are no bounding boxes, hence nothing to do.
    return;
  }
  //
  //If the domain is cropped, crop bounding boxes.
  if (0 != (int(hv_DomainHandling==HTuple("crop_domain"))))
  {
    //
    //Get domain.
    GetDomain(ho_ImageRaw, &ho_DomainRaw);
    //
    //Set the size of the raw image to the domain extensions.
    SmallestRectangle1(ho_DomainRaw, &hv_DomainRow1, &hv_DomainColumn1, &hv_DomainRow2, 
        &hv_DomainColumn2);
    hv_WidthRaw = (hv_DomainColumn2-hv_DomainColumn1)+1;
    hv_HeightRaw = (hv_DomainRow2-hv_DomainRow1)+1;
    //
    //Crop the bounding boxes.
    //Remove the boxes with center outside of the domain.
    hv_MaskDelete = HTuple(HTuple((hv_BBoxRow.TupleLessElem(hv_DomainRow1)).TupleOr(hv_BBoxCol.TupleLessElem(hv_DomainColumn1))).TupleOr(hv_BBoxRow.TupleGreaterElem(hv_DomainRow2))).TupleOr(hv_BBoxCol.TupleGreaterElem(hv_DomainColumn2));
    hv_MaskNewBbox = 1-hv_MaskDelete;
    //Store the preprocessed bounding box entries.
    hv_BBoxRowNew = (hv_BBoxRow.TupleSelectMask(hv_MaskNewBbox))-hv_DomainRow1;
    hv_BBoxColNew = (hv_BBoxCol.TupleSelectMask(hv_MaskNewBbox))-hv_DomainColumn1;
    hv_BBoxLength1New = hv_BBoxLength1.TupleSelectMask(hv_MaskNewBbox);
    hv_BBoxLength2New = hv_BBoxLength2.TupleSelectMask(hv_MaskNewBbox);
    hv_BBoxPhiNew = hv_BBoxPhi.TupleSelectMask(hv_MaskNewBbox);
    hv_BBoxLabelNew = hv_BBoxLabel.TupleSelectMask(hv_MaskNewBbox);
    //
    //If we remove/select bounding boxes we also need to filter the corresponding
    //instance segmentation masks if they exist.
    filter_dl_sample_instance_segmentation_masks(hv_DLSample, hv_MaskNewBbox);
    //
  }
  else if (0 != (int(hv_DomainHandling==HTuple("full_domain"))))
  {
    //If the entire image is used, set the variables accordingly.
    //Get the original size.
    GetImageSize(ho_ImageRaw, &hv_WidthRaw, &hv_HeightRaw);
    //Set new coordinates to input coordinates.
    hv_BBoxRowNew = hv_BBoxRow;
    hv_BBoxColNew = hv_BBoxCol;
    hv_BBoxLength1New = hv_BBoxLength1;
    hv_BBoxLength2New = hv_BBoxLength2;
    hv_BBoxPhiNew = hv_BBoxPhi;
    hv_BBoxLabelNew = hv_BBoxLabel;
  }
  else
  {
    throw HException("Unsupported parameter value for 'domain_handling'");
  }
  //
  //Generate smallest enclosing axis-aligned bounding box for classes in ClassIDsNoOrientation.
  hv_ClassIDsNoOrientationIndices = HTuple();
  {
  HTuple end_val98 = (hv_ClassIDsNoOrientation.TupleLength())-1;
  HTuple step_val98 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val98, step_val98); hv_Index += step_val98)
  {
    hv_ClassIDsNoOrientationIndicesTmp = (hv_BBoxLabelNew.TupleEqualElem(HTuple(hv_ClassIDsNoOrientation[hv_Index]))).TupleFind(1);
    if (0 != (int(hv_ClassIDsNoOrientationIndicesTmp!=-1)))
    {
      hv_ClassIDsNoOrientationIndices = hv_ClassIDsNoOrientationIndices.TupleConcat(hv_ClassIDsNoOrientationIndicesTmp);
    }
  }
  }
  if (0 != (int((hv_ClassIDsNoOrientationIndices.TupleLength())>0)))
  {
    //Calculate length1 and length2 using position of corners.
    hv_DirectionLength1Row = -(HTuple(hv_BBoxPhiNew[hv_ClassIDsNoOrientationIndices]).TupleSin());
    hv_DirectionLength1Col = HTuple(hv_BBoxPhiNew[hv_ClassIDsNoOrientationIndices]).TupleCos();
    hv_DirectionLength2Row = -hv_DirectionLength1Col;
    hv_DirectionLength2Col = hv_DirectionLength1Row;
    hv_Corner1Row = (HTuple(hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength1Row)+(HTuple(hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength2Row);
    hv_Corner1Col = (HTuple(hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength1Col)+(HTuple(hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength2Col);
    hv_Corner2Row = (HTuple(hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength1Row)-(HTuple(hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength2Row);
    hv_Corner2Col = (HTuple(hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength1Col)-(HTuple(hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength2Col);
    //
    hv_BBoxPhiNew[hv_ClassIDsNoOrientationIndices] = 0.0;
    hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices] = (hv_Corner1Col.TupleAbs()).TupleMax2(hv_Corner2Col.TupleAbs());
    hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices] = (hv_Corner1Row.TupleAbs()).TupleMax2(hv_Corner2Row.TupleAbs());
  }
  //
  //Rescale bounding boxes.
  //
  //Get required images width and height.
  //
  //Only rescale bounding boxes if the required image dimensions are not the raw dimensions.
  if (0 != (HTuple(int(hv_ImageHeight!=hv_HeightRaw)).TupleOr(int(hv_ImageWidth!=hv_WidthRaw))))
  {
    //
    //Calculate rescaling factor.
    calculate_dl_image_zoom_factors(hv_WidthRaw, hv_HeightRaw, hv_ImageWidth, hv_ImageHeight, 
        hv_DLPreprocessParam, &hv_FactorResampleWidth, &hv_FactorResampleHeight);
    //
    if (0 != (HTuple(int(hv_FactorResampleHeight!=hv_FactorResampleWidth)).TupleAnd(int((hv_BBoxRowNew.TupleLength())>0))))
    {
      //In order to preserve the correct orientation we have to transform the points individually.
      //Get the coordinates of the four corner points.
      convert_rect2_5to8param(hv_BBoxRowNew, hv_BBoxColNew, hv_BBoxLength1New, hv_BBoxLength2New, 
          hv_BBoxPhiNew, &hv_BBoxRow1, &hv_BBoxCol1, &hv_BBoxRow2, &hv_BBoxCol2, 
          &hv_BBoxRow3, &hv_BBoxCol3, &hv_BBoxRow4, &hv_BBoxCol4);
      //
      //Rescale the coordinates.
      hv_BBoxCol1New = hv_BBoxCol1*hv_FactorResampleWidth;
      hv_BBoxCol2New = hv_BBoxCol2*hv_FactorResampleWidth;
      hv_BBoxCol3New = hv_BBoxCol3*hv_FactorResampleWidth;
      hv_BBoxCol4New = hv_BBoxCol4*hv_FactorResampleWidth;
      hv_BBoxRow1New = hv_BBoxRow1*hv_FactorResampleHeight;
      hv_BBoxRow2New = hv_BBoxRow2*hv_FactorResampleHeight;
      hv_BBoxRow3New = hv_BBoxRow3*hv_FactorResampleHeight;
      hv_BBoxRow4New = hv_BBoxRow4*hv_FactorResampleHeight;
      //
      //The rectangles will get sheared, that is why new rectangles have to be found.
      //Generate homography to scale rectangles.
      HomMat2dIdentity(&hv_HomMat2DIdentity);
      HomMat2dScale(hv_HomMat2DIdentity, hv_FactorResampleHeight, hv_FactorResampleWidth, 
          0, 0, &hv_HomMat2DScale);
      //Generate XLD contours for the rectangles.
      GenRectangle2ContourXld(&ho_Rectangle2XLD, hv_BBoxRowNew, hv_BBoxColNew, hv_BBoxPhiNew, 
          hv_BBoxLength1New, hv_BBoxLength2New);
      //Scale the XLD contours --> results in sheared regions.
      AffineTransContourXld(ho_Rectangle2XLD, &ho_Rectangle2XLDSheared, hv_HomMat2DScale);
      SmallestRectangle2Xld(ho_Rectangle2XLDSheared, &hv_BBoxRowNew, &hv_BBoxColNew, 
          &hv_BBoxPhiNew, &hv_BBoxLength1New, &hv_BBoxLength2New);
      //
      //smallest_rectangle2_xld might change the orientation of the bounding box.
      //Hence, take the orientation that is closest to the one obtained out of the 4 corner points.
      convert_rect2_8to5param(hv_BBoxRow1New, hv_BBoxCol1New, hv_BBoxRow2New, hv_BBoxCol2New, 
          hv_BBoxRow3New, hv_BBoxCol3New, hv_BBoxRow4New, hv_BBoxCol4New, hv_IgnoreDirection, 
          &hv__, &hv__, &hv__, &hv__, &hv_BBoxPhiTmp);
      hv_PhiDelta = (hv_BBoxPhiTmp-hv_BBoxPhiNew).TupleFmod(HTuple(360).TupleRad());
      //Guarantee that angles are positive.
      hv_PhiDeltaNegativeIndices = (hv_PhiDelta.TupleLessElem(0.0)).TupleFind(1);
      if (0 != (int(hv_PhiDeltaNegativeIndices!=-1)))
      {
        hv_PhiDelta[hv_PhiDeltaNegativeIndices] = HTuple(hv_PhiDelta[hv_PhiDeltaNegativeIndices])+(HTuple(360).TupleRad());
      }
      hv_IndicesRot90 = HTuple((hv_PhiDelta.TupleGreaterElem(HTuple(45).TupleRad())).TupleAnd(hv_PhiDelta.TupleLessEqualElem(HTuple(135).TupleRad()))).TupleFind(1);
      hv_IndicesRot180 = HTuple((hv_PhiDelta.TupleGreaterElem(HTuple(135).TupleRad())).TupleAnd(hv_PhiDelta.TupleLessEqualElem(HTuple(225).TupleRad()))).TupleFind(1);
      hv_IndicesRot270 = HTuple((hv_PhiDelta.TupleGreaterElem(HTuple(225).TupleRad())).TupleAnd(hv_PhiDelta.TupleLessEqualElem(HTuple(315).TupleRad()))).TupleFind(1);
      hv_SwapIndices = HTuple();
      if (0 != (int(hv_IndicesRot90!=-1)))
      {
        hv_BBoxPhiNew[hv_IndicesRot90] = HTuple(hv_BBoxPhiNew[hv_IndicesRot90])+(HTuple(90).TupleRad());
        hv_SwapIndices = hv_SwapIndices.TupleConcat(hv_IndicesRot90);
      }
      if (0 != (int(hv_IndicesRot180!=-1)))
      {
        hv_BBoxPhiNew[hv_IndicesRot180] = HTuple(hv_BBoxPhiNew[hv_IndicesRot180])+(HTuple(180).TupleRad());
      }
      if (0 != (int(hv_IndicesRot270!=-1)))
      {
        hv_BBoxPhiNew[hv_IndicesRot270] = HTuple(hv_BBoxPhiNew[hv_IndicesRot270])+(HTuple(270).TupleRad());
        hv_SwapIndices = hv_SwapIndices.TupleConcat(hv_IndicesRot270);
      }
      if (0 != (int(hv_SwapIndices!=HTuple())))
      {
        hv_Tmp = HTuple(hv_BBoxLength1New[hv_SwapIndices]);
        hv_BBoxLength1New[hv_SwapIndices] = HTuple(hv_BBoxLength2New[hv_SwapIndices]);
        hv_BBoxLength2New[hv_SwapIndices] = hv_Tmp;
      }
      //Change angles such that they lie in the range (-180бу, 180бу].
      hv_BBoxPhiNewIndices = (hv_BBoxPhiNew.TupleGreaterElem(HTuple(180).TupleRad())).TupleFind(1);
      if (0 != (int(hv_BBoxPhiNewIndices!=-1)))
      {
        hv_BBoxPhiNew[hv_BBoxPhiNewIndices] = HTuple(hv_BBoxPhiNew[hv_BBoxPhiNewIndices])-(HTuple(360).TupleRad());
      }
      //
    }
    else
    {
      hv_BBoxColNew = hv_BBoxColNew*hv_FactorResampleWidth;
      hv_BBoxRowNew = hv_BBoxRowNew*hv_FactorResampleWidth;
      hv_BBoxLength1New = hv_BBoxLength1New*hv_FactorResampleWidth;
      hv_BBoxLength2New = hv_BBoxLength2New*hv_FactorResampleWidth;
      //Phi stays the same.
    }
    //
  }
  //
  //Adapt the bounding box angles such that they are within the correct range,
  //which is (-180бу,180бу] for 'ignore_direction'==false and (-90бу,90бу] else.
  hv_PhiThreshold = (HTuple(180).TupleRad())-(hv_IgnoreDirection*(HTuple(90).TupleRad()));
  hv_PhiDelta = 2*hv_PhiThreshold;
  //Correct angles that are too large.
  hv_PhiToCorrect = (hv_BBoxPhiNew.TupleGreaterElem(hv_PhiThreshold)).TupleFind(1);
  if (0 != (HTuple(int(hv_PhiToCorrect!=-1)).TupleAnd(int(hv_PhiToCorrect!=HTuple()))))
  {
    hv_NumCorrections = (((HTuple(hv_BBoxPhiNew[hv_PhiToCorrect])-hv_PhiThreshold)/hv_PhiDelta).TupleInt())+1;
    hv_BBoxPhiNew[hv_PhiToCorrect] = HTuple(hv_BBoxPhiNew[hv_PhiToCorrect])-(hv_NumCorrections*hv_PhiDelta);
  }
  //Correct angles that are too small.
  hv_PhiToCorrect = (hv_BBoxPhiNew.TupleLessEqualElem(-hv_PhiThreshold)).TupleFind(1);
  if (0 != (HTuple(int(hv_PhiToCorrect!=-1)).TupleAnd(int(hv_PhiToCorrect!=HTuple()))))
  {
    hv_NumCorrections = ((((HTuple(hv_BBoxPhiNew[hv_PhiToCorrect])+hv_PhiThreshold).TupleAbs())/hv_PhiDelta).TupleInt())+1;
    hv_BBoxPhiNew[hv_PhiToCorrect] = HTuple(hv_BBoxPhiNew[hv_PhiToCorrect])+(hv_NumCorrections*hv_PhiDelta);
  }
  //
  //Check that there are no invalid boxes.
  if (0 != (int((hv_BBoxRowNew.TupleLength())>0)))
  {
    hv_BoxesInvalid = ((hv_BBoxLength1New.TupleEqualElem(0)).TupleSum())+((hv_BBoxLength2New.TupleEqualElem(0)).TupleSum());
    if (0 != (int(hv_BoxesInvalid>0)))
    {
      GetDictTuple(hv_DLSample, "image_id", &hv_ImageId);
      throw HException(("An error has occurred during preprocessing image_id "+hv_ImageId)+HTuple(": Sample contains at least one box with zero-area, i.e. bbox_length1 == 0 or bbox_length2 == 0!"));
    }
  }
  SetDictTuple(hv_DLSample, "bbox_row", hv_BBoxRowNew);
  SetDictTuple(hv_DLSample, "bbox_col", hv_BBoxColNew);
  SetDictTuple(hv_DLSample, "bbox_length1", hv_BBoxLength1New);
  SetDictTuple(hv_DLSample, "bbox_length2", hv_BBoxLength2New);
  SetDictTuple(hv_DLSample, "bbox_phi", hv_BBoxPhiNew);
  SetDictTuple(hv_DLSample, "bbox_label_id", hv_BBoxLabelNew);
  //
  return;

}

// Chapter: Deep Learning / Model
// Short Description: Preprocess images for deep-learning-based training and inference. 
void preprocess_dl_model_images (HObject ho_Images, HObject *ho_ImagesPreprocessed, 
    HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_PreservedDomains, ho_ImageSelected;
  HObject  ho_DomainSelected, ho_ImagesScaled, ho_ImageScaled;
  HObject  ho_Channel, ho_ChannelScaled, ho_ThreeChannelImage;
  HObject  ho_SingleChannelImage;

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_ImageNumChannels;
  HTuple  hv_ImageRangeMin, hv_ImageRangeMax, hv_DomainHandling;
  HTuple  hv_NormalizationType, hv_ModelType, hv_NumImages;
  HTuple  hv_Type, hv_NumMatches, hv_InputNumChannels, hv_OutputNumChannels;
  HTuple  hv_NumChannels1, hv_NumChannels3, hv_AreInputNumChannels1;
  HTuple  hv_AreInputNumChannels3, hv_AreInputNumChannels1Or3;
  HTuple  hv_ValidNumChannels, hv_ValidNumChannelsText, hv_PreserveDomain;
  HTuple  hv_Row1, hv_Column1, hv_Row2, hv_Column2, hv_UniqRow1;
  HTuple  hv_UniqColumn1, hv_UniqRow2, hv_UniqColumn2, hv_RectangleIndex;
  HTuple  hv_OriginalWidth, hv_OriginalHeight, hv_UniqWidth;
  HTuple  hv_UniqHeight, hv_ScaleWidth, hv_ScaleHeight, hv_ScaleIndex;
  HTuple  hv_ImageIndex, hv_NumChannels, hv_ChannelIndex;
  HTuple  hv_Min, hv_Max, hv_Range, hv_Scale, hv_Shift, hv_MeanValues;
  HTuple  hv_DeviationValues, hv_UseDefaultNormalizationValues;
  HTuple  hv_Exception, hv_Indices, hv_RescaleRange, hv_CurrentNumChannels;
  HTuple  hv_DiffNumChannelsIndices, hv_Index, hv_DiffNumChannelsIndex;
  HTuple  hv_NumDomains, hv_DomainIndex;

  //
  //This procedure preprocesses the provided Images according to the parameters in
  //the dictionary DLPreprocessParam. Note that depending on the images, additional
  //preprocessing steps might be beneficial.
  //
  //Validate the preprocessing parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get the preprocessing parameters.
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  GetDictTuple(hv_DLPreprocessParam, "image_num_channels", &hv_ImageNumChannels);
  GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
  GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
  GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
  GetDictTuple(hv_DLPreprocessParam, "normalization_type", &hv_NormalizationType);
  GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_ModelType);
  //
  //Validate the type of the input images.
  CountObj(ho_Images, &hv_NumImages);
  if (0 != (int(hv_NumImages==0)))
  {
    throw HException("Please provide some images to preprocess.");
  }
  GetImageType(ho_Images, &hv_Type);
  TupleRegexpTest(hv_Type, "byte|int|real", &hv_NumMatches);
  if (0 != (int(hv_NumMatches!=hv_NumImages)))
  {
    throw HException(HTuple("Please provide only images of type 'byte', 'int1', 'int2', 'uint2', 'int4', 'int8', or 'real'."));
  }
  //
  //Handle ocr_recognition models.
  if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
  {
    preprocess_dl_model_images_ocr_recognition(ho_Images, &(*ho_ImagesPreprocessed), 
        hv_DLPreprocessParam);
    return;
  }
  //
  //Handle ocr_detection models.
  if (0 != (int(hv_ModelType==HTuple("ocr_detection"))))
  {
    preprocess_dl_model_images_ocr_detection(ho_Images, &(*ho_ImagesPreprocessed), 
        hv_DLPreprocessParam);
    return;
  }
  //
  //Validate the number channels of the input images.
  CountChannels(ho_Images, &hv_InputNumChannels);
  hv_OutputNumChannels = HTuple(hv_NumImages,hv_ImageNumChannels);
  //Only for 'image_num_channels' 1 and 3 combinations of 1- and 3-channel images are allowed.
  if (0 != (HTuple(int(hv_ImageNumChannels==1)).TupleOr(int(hv_ImageNumChannels==3))))
  {
    hv_NumChannels1 = HTuple(hv_NumImages,1);
    hv_NumChannels3 = HTuple(hv_NumImages,3);
    hv_AreInputNumChannels1 = hv_InputNumChannels.TupleEqualElem(hv_NumChannels1);
    hv_AreInputNumChannels3 = hv_InputNumChannels.TupleEqualElem(hv_NumChannels3);
    hv_AreInputNumChannels1Or3 = hv_AreInputNumChannels1+hv_AreInputNumChannels3;
    hv_ValidNumChannels = int(hv_AreInputNumChannels1Or3==hv_NumChannels1);
    hv_ValidNumChannelsText = "Valid numbers of channels for the specified model are 1 or 3.";
  }
  else
  {
    hv_ValidNumChannels = int(hv_InputNumChannels==hv_OutputNumChannels);
    hv_ValidNumChannelsText = ("Valid number of channels for the specified model is "+hv_ImageNumChannels)+".";
  }
  if (0 != (hv_ValidNumChannels.TupleNot()))
  {
    throw HException("Please provide images with a valid number of channels. "+hv_ValidNumChannelsText);
  }
  //Preprocess the images.
  //
  //For models of type '3d_gripping_point_detection', the preprocessing steps need to be performed on full
  //domain images while the domains are preserved and set back into the images after the preprocessing.
  hv_PreserveDomain = 0;
  if (0 != (HTuple(int(hv_ModelType==HTuple("3d_gripping_point_detection"))).TupleAnd(HTuple(int(hv_DomainHandling==HTuple("crop_domain"))).TupleOr(int(hv_DomainHandling==HTuple("keep_domain"))))))
  {
    hv_PreserveDomain = 1;
    GetDomain(ho_Images, &ho_PreservedDomains);
    FullDomain(ho_Images, &ho_Images);
  }
  //
  //Apply the domain to the images.
  if (0 != (int(hv_DomainHandling==HTuple("full_domain"))))
  {
    FullDomain(ho_Images, &ho_Images);
  }
  else if (0 != (int(hv_DomainHandling==HTuple("crop_domain"))))
  {
    if (0 != hv_PreserveDomain)
    {
      //In case of preserved domain, the crop is performed with the smallest rectangle of the
      //domain to avoid out of domain pixels being set to 0.
      SmallestRectangle1(ho_PreservedDomains, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
      TupleUniq(hv_Row1, &hv_UniqRow1);
      TupleUniq(hv_Column1, &hv_UniqColumn1);
      TupleUniq(hv_Row2, &hv_UniqRow2);
      TupleUniq(hv_Column2, &hv_UniqColumn2);
      if (0 != (HTuple(HTuple(HTuple(int((hv_UniqRow1.TupleLength())==1)).TupleAnd(int((hv_UniqColumn1.TupleLength())==1))).TupleAnd(int((hv_UniqRow2.TupleLength())==1))).TupleAnd(int((hv_UniqColumn2.TupleLength())==1))))
      {
        CropRectangle1(ho_Images, &ho_Images, hv_UniqRow1, hv_UniqColumn1, hv_UniqRow2, 
            hv_UniqColumn2);
        MoveRegion(ho_PreservedDomains, &ho_PreservedDomains, -hv_UniqRow1, -hv_UniqColumn1);
      }
      else
      {
        {
        HTuple end_val87 = (hv_Row1.TupleLength())-1;
        HTuple step_val87 = 1;
        for (hv_RectangleIndex=0; hv_RectangleIndex.Continue(end_val87, step_val87); hv_RectangleIndex += step_val87)
        {
          SelectObj(ho_Images, &ho_ImageSelected, hv_RectangleIndex+1);
          CropRectangle1(ho_ImageSelected, &ho_ImageSelected, HTuple(hv_Row1[hv_RectangleIndex]), 
              HTuple(hv_Column1[hv_RectangleIndex]), HTuple(hv_Row2[hv_RectangleIndex]), 
              HTuple(hv_Column2[hv_RectangleIndex]));
          ReplaceObj(ho_Images, ho_ImageSelected, &ho_Images, hv_RectangleIndex+1);
          SelectObj(ho_PreservedDomains, &ho_DomainSelected, hv_RectangleIndex+1);
          MoveRegion(ho_DomainSelected, &ho_DomainSelected, -HTuple(hv_Row1[hv_RectangleIndex]), 
              -HTuple(hv_Column1[hv_RectangleIndex]));
          ReplaceObj(ho_PreservedDomains, ho_DomainSelected, &ho_PreservedDomains, 
              hv_RectangleIndex+1);
        }
        }
      }
    }
    else
    {
      CropDomain(ho_Images, &ho_Images);
    }
  }
  else if (0 != (HTuple(int(hv_DomainHandling==HTuple("keep_domain"))).TupleAnd(HTuple(int(hv_ModelType==HTuple("anomaly_detection"))).TupleOr(int(hv_ModelType==HTuple("3d_gripping_point_detection"))))))
  {
    //The option 'keep_domain' is only supported for models of 'type' = 'anomaly_detection' or '3d_gripping_point_detection'.
  }
  else
  {
    throw HException("Unsupported parameter value for 'domain_handling'.");
  }
  //
  //Zoom preserved domains before zooming the images.
  if (0 != hv_PreserveDomain)
  {
    GetImageSize(ho_Images, &hv_OriginalWidth, &hv_OriginalHeight);
    TupleUniq(hv_OriginalWidth, &hv_UniqWidth);
    TupleUniq(hv_OriginalHeight, &hv_UniqHeight);
    if (0 != (HTuple(int((hv_UniqWidth.TupleLength())==1)).TupleAnd(int((hv_UniqHeight.TupleLength())==1))))
    {
      hv_ScaleWidth = hv_ImageWidth/(hv_UniqWidth.TupleReal());
      hv_ScaleHeight = hv_ImageHeight/(hv_UniqHeight.TupleReal());
      ZoomRegion(ho_PreservedDomains, &ho_PreservedDomains, hv_ScaleWidth, hv_ScaleHeight);
    }
    else
    {
      hv_ScaleWidth = hv_ImageWidth/(hv_OriginalWidth.TupleReal());
      hv_ScaleHeight = hv_ImageHeight/(hv_OriginalHeight.TupleReal());
      {
      HTuple end_val117 = (hv_ScaleWidth.TupleLength())-1;
      HTuple step_val117 = 1;
      for (hv_ScaleIndex=0; hv_ScaleIndex.Continue(end_val117, step_val117); hv_ScaleIndex += step_val117)
      {
        SelectObj(ho_PreservedDomains, &ho_DomainSelected, hv_ScaleIndex+1);
        ZoomRegion(ho_DomainSelected, &ho_DomainSelected, HTuple(hv_ScaleWidth[hv_ScaleIndex]), 
            HTuple(hv_ScaleHeight[hv_ScaleIndex]));
        ReplaceObj(ho_PreservedDomains, ho_DomainSelected, &ho_PreservedDomains, 
            hv_ScaleIndex+1);
      }
      }
    }
  }
  //
  //Convert the images to real and zoom the images.
  //Zoom first to speed up if all image types are supported by zoom_image_size.
  if (0 != (int((hv_Type.TupleRegexpTest("int1|int4|int8"))==0)))
  {
    ZoomImageSize(ho_Images, &ho_Images, hv_ImageWidth, hv_ImageHeight, "constant");
    ConvertImageType(ho_Images, &ho_Images, "real");
  }
  else
  {
    ConvertImageType(ho_Images, &ho_Images, "real");
    ZoomImageSize(ho_Images, &ho_Images, hv_ImageWidth, hv_ImageHeight, "constant");
  }
  //
  if (0 != (int(hv_NormalizationType==HTuple("all_channels"))))
  {
    //Scale for each image the gray values of all channels to ImageRangeMin-ImageRangeMax.
    GenEmptyObj(&ho_ImagesScaled);
    {
    HTuple end_val138 = hv_NumImages;
    HTuple step_val138 = 1;
    for (hv_ImageIndex=1; hv_ImageIndex.Continue(end_val138, step_val138); hv_ImageIndex += step_val138)
    {
      SelectObj(ho_Images, &ho_ImageSelected, hv_ImageIndex);
      CountChannels(ho_ImageSelected, &hv_NumChannels);
      GenEmptyObj(&ho_ImageScaled);
      {
      HTuple end_val142 = hv_NumChannels;
      HTuple step_val142 = 1;
      for (hv_ChannelIndex=1; hv_ChannelIndex.Continue(end_val142, step_val142); hv_ChannelIndex += step_val142)
      {
        AccessChannel(ho_ImageSelected, &ho_Channel, hv_ChannelIndex);
        MinMaxGray(ho_Channel, ho_Channel, 0, &hv_Min, &hv_Max, &hv_Range);
        if (0 != (int((hv_Max-hv_Min)==0)))
        {
          hv_Scale = 1;
        }
        else
        {
          hv_Scale = (hv_ImageRangeMax-hv_ImageRangeMin)/(hv_Max-hv_Min);
        }
        hv_Shift = ((-hv_Scale)*hv_Min)+hv_ImageRangeMin;
        ScaleImage(ho_Channel, &ho_ChannelScaled, hv_Scale, hv_Shift);
        AppendChannel(ho_ImageScaled, ho_ChannelScaled, &ho_ImageScaled);
      }
      }
      ConcatObj(ho_ImagesScaled, ho_ImageScaled, &ho_ImagesScaled);
    }
    }
    ho_Images = ho_ImagesScaled;
  }
  else if (0 != (int(hv_NormalizationType==HTuple("first_channel"))))
  {
    //Scale for each image the gray values of first channel to ImageRangeMin-ImageRangeMax.
    GenEmptyObj(&ho_ImagesScaled);
    {
    HTuple end_val160 = hv_NumImages;
    HTuple step_val160 = 1;
    for (hv_ImageIndex=1; hv_ImageIndex.Continue(end_val160, step_val160); hv_ImageIndex += step_val160)
    {
      SelectObj(ho_Images, &ho_ImageSelected, hv_ImageIndex);
      MinMaxGray(ho_ImageSelected, ho_ImageSelected, 0, &hv_Min, &hv_Max, &hv_Range);
      if (0 != (int((hv_Max-hv_Min)==0)))
      {
        hv_Scale = 1;
      }
      else
      {
        hv_Scale = (hv_ImageRangeMax-hv_ImageRangeMin)/(hv_Max-hv_Min);
      }
      hv_Shift = ((-hv_Scale)*hv_Min)+hv_ImageRangeMin;
      ScaleImage(ho_ImageSelected, &ho_ImageSelected, hv_Scale, hv_Shift);
      ConcatObj(ho_ImagesScaled, ho_ImageSelected, &ho_ImagesScaled);
    }
    }
    ho_Images = ho_ImagesScaled;
  }
  else if (0 != (int(hv_NormalizationType==HTuple("constant_values"))))
  {
    //Scale for each image the gray values of all channels to the corresponding channel DeviationValues[].
    try
    {
      GetDictTuple(hv_DLPreprocessParam, "mean_values_normalization", &hv_MeanValues);
      GetDictTuple(hv_DLPreprocessParam, "deviation_values_normalization", &hv_DeviationValues);
      hv_UseDefaultNormalizationValues = 0;
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      hv_MeanValues.Clear();
      hv_MeanValues[0] = 123.675;
      hv_MeanValues[1] = 116.28;
      hv_MeanValues[2] = 103.53;
      hv_DeviationValues.Clear();
      hv_DeviationValues[0] = 58.395;
      hv_DeviationValues[1] = 57.12;
      hv_DeviationValues[2] = 57.375;
      hv_UseDefaultNormalizationValues = 1;
    }
    GenEmptyObj(&ho_ImagesScaled);
    {
    HTuple end_val185 = hv_NumImages;
    HTuple step_val185 = 1;
    for (hv_ImageIndex=1; hv_ImageIndex.Continue(end_val185, step_val185); hv_ImageIndex += step_val185)
    {
      SelectObj(ho_Images, &ho_ImageSelected, hv_ImageIndex);
      CountChannels(ho_ImageSelected, &hv_NumChannels);
      //Ensure that the number of channels is equal |DeviationValues| and |MeanValues|
      if (0 != hv_UseDefaultNormalizationValues)
      {
        if (0 != (int(hv_NumChannels==1)))
        {
          Compose3(ho_ImageSelected, ho_ImageSelected, ho_ImageSelected, &ho_ImageSelected
              );
          CountChannels(ho_ImageSelected, &hv_NumChannels);
        }
        else if (0 != (int(hv_NumChannels!=3)))
        {
          throw HException("Using default values for normalization type 'constant_values' is allowed only for 1- and 3-channel images.");
        }
      }
      if (0 != (HTuple(int((hv_MeanValues.TupleLength())!=hv_NumChannels)).TupleOr(int((hv_DeviationValues.TupleLength())!=hv_NumChannels))))
      {
        throw HException("The length of mean and deviation values for normalization type 'constant_values' have to be the same size as the number of channels of the image.");
      }
      GenEmptyObj(&ho_ImageScaled);
      {
      HTuple end_val201 = hv_NumChannels;
      HTuple step_val201 = 1;
      for (hv_ChannelIndex=1; hv_ChannelIndex.Continue(end_val201, step_val201); hv_ChannelIndex += step_val201)
      {
        AccessChannel(ho_ImageSelected, &ho_Channel, hv_ChannelIndex);
        hv_Scale = 1.0/HTuple(hv_DeviationValues[hv_ChannelIndex-1]);
        hv_Shift = (-hv_Scale)*HTuple(hv_MeanValues[hv_ChannelIndex-1]);
        ScaleImage(ho_Channel, &ho_ChannelScaled, hv_Scale, hv_Shift);
        AppendChannel(ho_ImageScaled, ho_ChannelScaled, &ho_ImageScaled);
      }
      }
      ConcatObj(ho_ImagesScaled, ho_ImageScaled, &ho_ImagesScaled);
    }
    }
    ho_Images = ho_ImagesScaled;
  }
  else if (0 != (int(hv_NormalizationType==HTuple("none"))))
  {
    TupleFind(hv_Type, "byte", &hv_Indices);
    if (0 != (int(hv_Indices!=-1)))
    {
      //Shift the gray values from [0-255] to the expected range for byte images.
      hv_RescaleRange = (hv_ImageRangeMax-hv_ImageRangeMin)/255.0;
      SelectObj(ho_Images, &ho_ImageSelected, hv_Indices+1);
      ScaleImage(ho_ImageSelected, &ho_ImageSelected, hv_RescaleRange, hv_ImageRangeMin);
      ReplaceObj(ho_Images, ho_ImageSelected, &ho_Images, hv_Indices+1);
    }
  }
  else if (0 != (int(hv_NormalizationType!=HTuple("none"))))
  {
    throw HException("Unsupported parameter value for 'normalization_type'");
  }
  //
  //Ensure that the number of channels of the resulting images is consistent with the
  //number of channels of the given model. The only exceptions that are adapted below
  //are combinations of 1- and 3-channel images if ImageNumChannels is either 1 or 3.
  if (0 != (HTuple(int(hv_ImageNumChannels==1)).TupleOr(int(hv_ImageNumChannels==3))))
  {
    CountChannels(ho_Images, &hv_CurrentNumChannels);
    TupleFind(hv_CurrentNumChannels.TupleNotEqualElem(hv_OutputNumChannels), 1, &hv_DiffNumChannelsIndices);
    if (0 != (int(hv_DiffNumChannelsIndices!=-1)))
    {
      {
      HTuple end_val231 = (hv_DiffNumChannelsIndices.TupleLength())-1;
      HTuple step_val231 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val231, step_val231); hv_Index += step_val231)
      {
        hv_DiffNumChannelsIndex = HTuple(hv_DiffNumChannelsIndices[hv_Index]);
        hv_ImageIndex = hv_DiffNumChannelsIndex+1;
        hv_NumChannels = HTuple(hv_CurrentNumChannels[hv_ImageIndex-1]);
        SelectObj(ho_Images, &ho_ImageSelected, hv_ImageIndex);
        if (0 != (HTuple(int(hv_NumChannels==1)).TupleAnd(int(hv_ImageNumChannels==3))))
        {
          //Conversion from 1- to 3-channel image required
          Compose3(ho_ImageSelected, ho_ImageSelected, ho_ImageSelected, &ho_ThreeChannelImage
              );
          ReplaceObj(ho_Images, ho_ThreeChannelImage, &ho_Images, hv_ImageIndex);
        }
        else if (0 != (HTuple(int(hv_NumChannels==3)).TupleAnd(int(hv_ImageNumChannels==1))))
        {
          //Conversion from 3- to 1-channel image required
          Rgb1ToGray(ho_ImageSelected, &ho_SingleChannelImage);
          ReplaceObj(ho_Images, ho_SingleChannelImage, &ho_Images, hv_ImageIndex);
        }
        else
        {
          throw HException(((("Unexpected error adapting the number of channels. The number of channels of the resulting image is "+hv_NumChannels)+HTuple(", but the number of channels of the model is "))+hv_ImageNumChannels)+".");
        }
      }
      }
    }
  }
  //
  //In case the image domains were preserved, they need to be set back into the images.
  if (0 != hv_PreserveDomain)
  {
    CountObj(ho_PreservedDomains, &hv_NumDomains);
    {
    HTuple end_val254 = hv_NumDomains;
    HTuple step_val254 = 1;
    for (hv_DomainIndex=1; hv_DomainIndex.Continue(end_val254, step_val254); hv_DomainIndex += step_val254)
    {
      SelectObj(ho_Images, &ho_ImageSelected, hv_DomainIndex);
      SelectObj(ho_PreservedDomains, &ho_DomainSelected, hv_DomainIndex);
      ReduceDomain(ho_ImageSelected, ho_DomainSelected, &ho_ImageSelected);
      ReplaceObj(ho_Images, ho_ImageSelected, &ho_Images, hv_DomainIndex);
    }
    }
  }
  //
  //Write preprocessed images to output variable.
  (*ho_ImagesPreprocessed) = ho_Images;
  //
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Preprocess images for deep-learning-based training and inference of Deep OCR detection models. 
void preprocess_dl_model_images_ocr_detection (HObject ho_Images, HObject *ho_ImagesPreprocessed, 
    HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_Image, ho_ImageScaled, ho_Channel;
  HObject  ho_ChannelScaled, ho_ImageG, ho_ImageB;

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_ImageNumChannels;
  HTuple  hv_ImageRangeMin, hv_ImageRangeMax, hv_DomainHandling;
  HTuple  hv_NormalizationType, hv_ModelType, hv_NumImages;
  HTuple  hv_NumChannels, hv_ImageTypes, hv_InputImageWidths;
  HTuple  hv_InputImageHeights, hv_ImageRange, hv_I, hv_InputImageWidth;
  HTuple  hv_InputImageHeight, hv_ZoomFactorWidth, hv_ZoomFactorHeight;
  HTuple  hv_ZoomHeight, hv_ZoomWidth, hv_ChannelIndex, hv_Min;
  HTuple  hv_Max, hv_Range, hv_Scale, hv_Shift;

  //This procedure preprocesses the provided images according to the parameters
  //in the dictionary DLPreprocessParam for an ocr_detection model.
  //
  //Check the validity of the preprocessing parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get the preprocessing parameters.
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  GetDictTuple(hv_DLPreprocessParam, "image_num_channels", &hv_ImageNumChannels);
  GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
  GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
  GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
  GetDictTuple(hv_DLPreprocessParam, "normalization_type", &hv_NormalizationType);
  GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_ModelType);
  //
  //Check the preprocessing parameters.
  if (0 != (int(hv_ModelType!=HTuple("ocr_detection"))))
  {
    throw HException("The only 'model_type' value supported is'ocr_detection'.");
  }
  if (0 != (int(hv_ImageNumChannels!=3)))
  {
    throw HException("The only 'image_num_channels' value supported for ocr_detection models is 3.");
  }
  if (0 != (int(hv_DomainHandling!=HTuple("full_domain"))))
  {
    throw HException("The only 'domain_handling' value supported for ocr_detection models is 'full_domain'.");
  }
  if (0 != (HTuple(int(hv_NormalizationType!=HTuple("none"))).TupleAnd(int(hv_NormalizationType!=HTuple("all_channels")))))
  {
    throw HException("The 'normalization_type' values supported for ocr_detection models are 'all_channels' and 'none'.");
  }
  //
  //Get the image properties.
  CountObj(ho_Images, &hv_NumImages);
  CountChannels(ho_Images, &hv_NumChannels);
  GetImageType(ho_Images, &hv_ImageTypes);
  GetImageSize(ho_Images, &hv_InputImageWidths, &hv_InputImageHeights);
  //
  //Check the image properties.
  if (0 != (int(hv_NumImages==0)))
  {
    throw HException("Please provide some images to preprocess.");
  }
  if (0 != (int(hv_NumImages!=(hv_ImageTypes.TupleRegexpTest("byte")))))
  {
    throw HException("Please provide only images of type 'byte'.");
  }
  if (0 != (int(hv_NumImages!=(HTuple((hv_NumChannels.TupleEqualElem(1)).TupleOr(hv_NumChannels.TupleEqualElem(3))).TupleSum()))))
  {
    throw HException("Please provide only 1- or 3-channels images for ocr_detection models.");
  }
  //
  //Preprocess the images.
  hv_ImageRange = (hv_ImageRangeMax-hv_ImageRangeMin).TupleReal();
  {
  HTuple end_val49 = hv_NumImages-1;
  HTuple step_val49 = 1;
  for (hv_I=0; hv_I.Continue(end_val49, step_val49); hv_I += step_val49)
  {
    hv_InputImageWidth = HTuple(hv_InputImageWidths[hv_I]);
    hv_InputImageHeight = HTuple(hv_InputImageHeights[hv_I]);
    //
    SelectObj(ho_Images, &ho_Image, hv_I+1);
    //
    //Calculate aspect-ratio preserving zoom factors
    calculate_dl_image_zoom_factors(hv_InputImageWidth, hv_InputImageHeight, hv_ImageWidth, 
        hv_ImageHeight, hv_DLPreprocessParam, &hv_ZoomFactorWidth, &hv_ZoomFactorHeight);
    //
    //Zoom image
    hv_ZoomHeight = (hv_ZoomFactorHeight*hv_InputImageHeight).TupleRound();
    hv_ZoomWidth = (hv_ZoomFactorWidth*hv_InputImageWidth).TupleRound();
    ZoomImageSize(ho_Image, &ho_Image, hv_ZoomWidth, hv_ZoomHeight, "constant");
    //
    //Convert to real and normalize
    ConvertImageType(ho_Image, &ho_Image, "real");
    if (0 != (int(hv_NormalizationType==HTuple("all_channels"))))
    {
      GenEmptyObj(&ho_ImageScaled);
      {
      HTuple end_val67 = HTuple(hv_NumChannels[hv_I]);
      HTuple step_val67 = 1;
      for (hv_ChannelIndex=1; hv_ChannelIndex.Continue(end_val67, step_val67); hv_ChannelIndex += step_val67)
      {
        AccessChannel(ho_Image, &ho_Channel, hv_ChannelIndex);
        MinMaxGray(ho_Channel, ho_Channel, 0, &hv_Min, &hv_Max, &hv_Range);
        if (0 != (int((hv_Max-hv_Min)==0)))
        {
          hv_Scale = 1;
        }
        else
        {
          hv_Scale = (hv_ImageRangeMax-hv_ImageRangeMin)/(hv_Max-hv_Min);
        }
        hv_Shift = ((-hv_Scale)*hv_Min)+hv_ImageRangeMin;
        ScaleImage(ho_Channel, &ho_ChannelScaled, hv_Scale, hv_Shift);
        AppendChannel(ho_ImageScaled, ho_ChannelScaled, &ho_ImageScaled);
      }
      }
      ho_Image = ho_ImageScaled;
    }
    else if (0 != (int(hv_NormalizationType==HTuple("none"))))
    {
      ScaleImage(ho_Image, &ho_Image, hv_ImageRange/255.0, hv_ImageRangeMin);
    }
    //
    //Obtain an RGB image.
    if (0 != (int(HTuple(hv_NumChannels[hv_I])==1)))
    {
      CopyImage(ho_Image, &ho_ImageG);
      CopyImage(ho_Image, &ho_ImageB);
      Compose3(ho_Image, ho_ImageG, ho_ImageB, &ho_Image);
    }
    //
    //Apply padding to fit the desired image size.
    //The padding value is zero, corresponding to the
    //border handling of the convolution layers.
    ChangeFormat(ho_Image, &ho_Image, hv_ImageWidth, hv_ImageHeight);
    ReplaceObj(ho_Images, ho_Image, &ho_Images, hv_I+1);
  }
  }
  //
  //Return the preprocessed images.
  (*ho_ImagesPreprocessed) = ho_Images;
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Preprocess images for deep-learning-based training and inference of Deep OCR recognition models. 
void preprocess_dl_model_images_ocr_recognition (HObject ho_Images, HObject *ho_ImagesPreprocessed, 
    HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_TargetImage, ho_Image;

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_ImageNumChannels;
  HTuple  hv_ImageRangeMin, hv_ImageRangeMax, hv_DomainHandling;
  HTuple  hv_NormalizationType, hv_ModelType, hv_NumImages;
  HTuple  hv_NumChannels, hv_ImageTypes, hv_InputImageWidths;
  HTuple  hv_InputImageHeights, hv_PaddingGrayval, hv_ImageRange;
  HTuple  hv_I, hv_InputImageWidth, hv_InputImageHeight, hv_InputImageWidthHeightRatio;
  HTuple  hv_ZoomHeight, hv_ZoomWidth, hv_GrayvalMin, hv_GrayvalMax;
  HTuple  hv_Range, hv_GrayvalRange, hv_Scale, hv_Shift;

  //This procedure preprocesses the provided Images according to the parameters
  //in the dictionary DLPreprocessParam for an ocr_recognition model.
  //
  //Check the validity of the preprocessing parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get the preprocessing parameters.
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  GetDictTuple(hv_DLPreprocessParam, "image_num_channels", &hv_ImageNumChannels);
  GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
  GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
  GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
  GetDictTuple(hv_DLPreprocessParam, "normalization_type", &hv_NormalizationType);
  GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_ModelType);
  //
  //Check the preprocessing parameters.
  if (0 != (int(hv_ModelType!=HTuple("ocr_recognition"))))
  {
    throw HException("The only 'model_type' value supported is'ocr_recognition'.");
  }
  if (0 != (int(hv_ImageNumChannels!=1)))
  {
    throw HException("The only 'image_num_channels' value supported for ocr_recognition models is 1.");
  }
  if (0 != (int(hv_DomainHandling!=HTuple("full_domain"))))
  {
    throw HException("The only 'domain_handling' value supported for ocr_recognition models is 'full_domain'.");
  }
  if (0 != (HTuple(HTuple(int(hv_NormalizationType!=HTuple("none"))).TupleAnd(int(hv_NormalizationType!=HTuple("first_channel")))).TupleAnd(int(hv_NormalizationType!=HTuple("all_channels")))))
  {
    throw HException(HTuple("The 'normalization_type' values supported for ocr_recognition models are 'first_channel', 'all_channels' and 'none'."));
  }
  //
  //Get the image properties.
  CountObj(ho_Images, &hv_NumImages);
  CountChannels(ho_Images, &hv_NumChannels);
  GetImageType(ho_Images, &hv_ImageTypes);
  GetImageSize(ho_Images, &hv_InputImageWidths, &hv_InputImageHeights);
  //
  //Check the image properties.
  if (0 != (int(hv_NumImages==0)))
  {
    throw HException("Please provide some images to preprocess.");
  }
  if (0 != (int(hv_NumImages!=(hv_ImageTypes.TupleRegexpTest("byte|real")))))
  {
    throw HException("Please provide only images of type 'byte' or 'real'.");
  }
  if (0 != (int(hv_NumImages!=(HTuple((hv_NumChannels.TupleEqualElem(1)).TupleOr(hv_NumChannels.TupleEqualElem(3))).TupleSum()))))
  {
    throw HException("Please provide only 1- or 3-channels images for ocr_recognition models.");
  }
  //
  //Preprocess the images.
  hv_PaddingGrayval = 0.0;
  hv_ImageRange = (hv_ImageRangeMax-hv_ImageRangeMin).TupleReal();
  GenImageConst(&ho_TargetImage, "real", hv_ImageWidth, hv_ImageHeight);
  OverpaintRegion(ho_TargetImage, ho_TargetImage, hv_PaddingGrayval, "fill");
  {
  HTuple end_val52 = hv_NumImages-1;
  HTuple step_val52 = 1;
  for (hv_I=0; hv_I.Continue(end_val52, step_val52); hv_I += step_val52)
  {
    hv_InputImageWidth = HTuple(hv_InputImageWidths[hv_I]);
    hv_InputImageHeight = HTuple(hv_InputImageHeights[hv_I]);
    hv_InputImageWidthHeightRatio = hv_InputImageWidth/(hv_InputImageHeight.TupleReal());
    //
    SelectObj(ho_Images, &ho_Image, hv_I+1);
    FullDomain(ho_Image, &ho_Image);
    if (0 != (int(HTuple(hv_NumChannels[hv_I])==3)))
    {
      Rgb1ToGray(ho_Image, &ho_Image);
    }
    //
    hv_ZoomHeight = hv_ImageHeight;
    hv_ZoomWidth = hv_ImageWidth.TupleMin2((hv_ImageHeight*hv_InputImageWidthHeightRatio).TupleInt());
    ZoomImageSize(ho_Image, &ho_Image, hv_ZoomWidth, hv_ZoomHeight, "constant");
    if (0 != (int(HTuple(hv_ImageTypes[hv_I])==HTuple("byte"))))
    {
      ConvertImageType(ho_Image, &ho_Image, "real");
    }
    if (0 != (HTuple(int(hv_NormalizationType==HTuple("first_channel"))).TupleOr(int(hv_NormalizationType==HTuple("all_channels")))))
    {
      MinMaxGray(ho_Image, ho_Image, 0, &hv_GrayvalMin, &hv_GrayvalMax, &hv_Range);
      hv_GrayvalRange = (hv_GrayvalMax-hv_GrayvalMin).TupleReal();
      if (0 != (int(hv_GrayvalRange==0.0)))
      {
        hv_Scale = 1.0;
      }
      else
      {
        hv_Scale = hv_ImageRange/hv_GrayvalRange;
      }
      hv_Shift = ((-hv_Scale)*hv_GrayvalMin)+hv_ImageRangeMin;
      ScaleImage(ho_Image, &ho_Image, hv_Scale, hv_Shift);
    }
    else if (0 != (int(hv_NormalizationType==HTuple("none"))))
    {
      if (0 != (int(HTuple(hv_ImageTypes[hv_I])==HTuple("byte"))))
      {
        ScaleImage(ho_Image, &ho_Image, hv_ImageRange/255.0, hv_ImageRangeMin);
      }
    }
    //
    OverpaintGray(ho_TargetImage, ho_Image);
    ReduceDomain(ho_TargetImage, ho_Image, &ho_TargetImage);
    ReplaceObj(ho_Images, ho_TargetImage, &ho_Images, hv_I+1);
  }
  }
  //
  //Return the preprocessed images.
  (*ho_ImagesPreprocessed) = ho_Images;
  return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Preprocess the instance segmentation masks for a sample given by the dictionary DLSample. 
void preprocess_dl_model_instance_masks (HObject ho_ImageRaw, HTuple hv_DLSample, 
    HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_InstanceMasks, ho_Domain;

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_DomainHandling;
  HTuple  hv_NumMasks, hv_WidthRaw, hv_HeightRaw, hv_DomainRow1;
  HTuple  hv_DomainColumn1, hv_DomainRow2, hv_DomainColumn2;
  HTuple  hv_FactorResampleWidth, hv_FactorResampleHeight;

  //
  //This procedure preprocesses the instance masks of a DLSample.
  //
  //Check preprocess parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get relevant preprocess parameters.
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
  //
  //Get the preprocessed instance masks.
  GetDictObject(&ho_InstanceMasks, hv_DLSample, "mask");
  //
  //Get the number of instance masks.
  CountObj(ho_InstanceMasks, &hv_NumMasks);
  //
  //Domain handling of the image to be preprocessed.
  //
  GetImageSize(ho_ImageRaw, &hv_WidthRaw, &hv_HeightRaw);
  if (0 != (int(hv_DomainHandling==HTuple("crop_domain"))))
  {
    //Clip and translate masks w.r.t. the image domain
    GetDomain(ho_ImageRaw, &ho_Domain);
    SmallestRectangle1(ho_Domain, &hv_DomainRow1, &hv_DomainColumn1, &hv_DomainRow2, 
        &hv_DomainColumn2);
    //
    //Clip the remaining regions to the domain.
    ClipRegion(ho_InstanceMasks, &ho_InstanceMasks, hv_DomainRow1, hv_DomainColumn1, 
        hv_DomainRow2, hv_DomainColumn2);
    hv_WidthRaw = (hv_DomainColumn2-hv_DomainColumn1)+1.0;
    hv_HeightRaw = (hv_DomainRow2-hv_DomainRow1)+1.0;
    //We need to move the remaining regions back to the origin,
    //because crop_domain will be applied to the image
    MoveRegion(ho_InstanceMasks, &ho_InstanceMasks, -hv_DomainRow1, -hv_DomainColumn1);
  }
  else if (0 != (int(hv_DomainHandling!=HTuple("full_domain"))))
  {
    throw HException("Unsupported parameter value for 'domain_handling'");
  }
  //
  //Zoom masks only if the image has a different size than the specified size.
  if (0 != ((hv_ImageWidth.TupleNotEqualElem(hv_WidthRaw)).TupleOr(hv_ImageHeight.TupleNotEqualElem(hv_HeightRaw))))
  {
    //Calculate rescaling factor.
    hv_FactorResampleWidth = (hv_ImageWidth.TupleReal())/hv_WidthRaw;
    hv_FactorResampleHeight = (hv_ImageHeight.TupleReal())/hv_HeightRaw;

    //Zoom the masks.
    ZoomRegion(ho_InstanceMasks, &ho_InstanceMasks, hv_FactorResampleWidth, hv_FactorResampleHeight);
  }
  //
  //Set the preprocessed instance masks.
  SetDictObject(ho_InstanceMasks, hv_DLSample, "mask");
  //
  //
  return;
}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Preprocess segmentation and weight images for deep-learning-based segmentation training and inference. 
void preprocess_dl_model_segmentations (HObject ho_ImagesRaw, HObject ho_Segmentations, 
    HObject *ho_SegmentationsPreprocessed, HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_Domain, ho_SelectedSeg, ho_SelectedDomain;

  // Local control variables
  HTuple  hv_NumberImages, hv_NumberSegmentations;
  HTuple  hv_Width, hv_Height, hv_WidthSeg, hv_HeightSeg;
  HTuple  hv_DLModelType, hv_ImageWidth, hv_ImageHeight, hv_ImageNumChannels;
  HTuple  hv_ImageRangeMin, hv_ImageRangeMax, hv_DomainHandling;
  HTuple  hv_SetBackgroundID, hv_ClassesToBackground, hv_IgnoreClassIDs;
  HTuple  hv_IsInt, hv_IndexImage, hv_ImageWidthRaw, hv_ImageHeightRaw;
  HTuple  hv_EqualWidth, hv_EqualHeight, hv_Type, hv_EqualReal;

  //
  //This procedure preprocesses the segmentation or weight images
  //given by Segmentations so that they can be handled by
  //train_dl_model_batch and apply_dl_model.
  //
  //Check input data.
  //Examine number of images.
  CountObj(ho_ImagesRaw, &hv_NumberImages);
  CountObj(ho_Segmentations, &hv_NumberSegmentations);
  if (0 != (int(hv_NumberImages!=hv_NumberSegmentations)))
  {
    throw HException("Equal number of images given in ImagesRaw and Segmentations required");
  }
  //Size of images.
  GetImageSize(ho_ImagesRaw, &hv_Width, &hv_Height);
  GetImageSize(ho_Segmentations, &hv_WidthSeg, &hv_HeightSeg);
  if (0 != (HTuple(int(hv_Width!=hv_WidthSeg)).TupleOr(int(hv_Height!=hv_HeightSeg))))
  {
    throw HException("Equal size of the images given in ImagesRaw and Segmentations required.");
  }
  //Check the validity of the preprocessing parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get the relevant preprocessing parameters.
  GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_DLModelType);
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  GetDictTuple(hv_DLPreprocessParam, "image_num_channels", &hv_ImageNumChannels);
  GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
  GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
  GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
  //Segmentation specific parameters.
  GetDictTuple(hv_DLPreprocessParam, "set_background_id", &hv_SetBackgroundID);
  GetDictTuple(hv_DLPreprocessParam, "class_ids_background", &hv_ClassesToBackground);
  GetDictTuple(hv_DLPreprocessParam, "ignore_class_ids", &hv_IgnoreClassIDs);
  //
  //Check the input parameter for setting the background ID.
  if (0 != (int(hv_SetBackgroundID!=HTuple())))
  {
    //Check that the model is a segmentation model.
    if (0 != (int(hv_DLModelType!=HTuple("segmentation"))))
    {
      throw HException("Setting class IDs to background is only implemented for segmentation.");
    }
    //Check the background ID.
    TupleIsIntElem(hv_SetBackgroundID, &hv_IsInt);
    if (0 != (int((hv_SetBackgroundID.TupleLength())!=1)))
    {
      throw HException("Only one class_id as 'set_background_id' allowed.");
    }
    else if (0 != (hv_IsInt.TupleNot()))
    {
      //Given class_id has to be of type int.
      throw HException("The class_id given as 'set_background_id' has to be of type int.");
    }
    //Check the values of ClassesToBackground.
    if (0 != (int((hv_ClassesToBackground.TupleLength())==0)))
    {
      //Check that the given classes are of length > 0.
      throw HException(HTuple("If 'set_background_id' is given, 'class_ids_background' must at least contain this class ID."));
    }
    else if (0 != (int((hv_ClassesToBackground.TupleIntersection(hv_IgnoreClassIDs))!=HTuple())))
    {
      //Check that class_ids_background is not included in the ignore_class_ids of the DLModel.
      throw HException("The given 'class_ids_background' must not be included in the 'ignore_class_ids' of the model.");
    }
  }
  //
  //Domain handling of the image to be preprocessed.
  //
  if (0 != (HTuple(int(hv_DomainHandling==HTuple("full_domain"))).TupleOr(int(hv_DomainHandling==HTuple("keep_domain")))))
  {
    FullDomain(ho_Segmentations, &ho_Segmentations);
  }
  else if (0 != (int(hv_DomainHandling==HTuple("crop_domain"))))
  {
    //If the domain should be cropped the domain has to be transferred
    //from the raw image to the segmentation image.
    GetDomain(ho_ImagesRaw, &ho_Domain);
    {
    HTuple end_val66 = hv_NumberImages;
    HTuple step_val66 = 1;
    for (hv_IndexImage=1; hv_IndexImage.Continue(end_val66, step_val66); hv_IndexImage += step_val66)
    {
      SelectObj(ho_Segmentations, &ho_SelectedSeg, hv_IndexImage);
      SelectObj(ho_Domain, &ho_SelectedDomain, hv_IndexImage);
      ChangeDomain(ho_SelectedSeg, ho_SelectedDomain, &ho_SelectedSeg);
      ReplaceObj(ho_Segmentations, ho_SelectedSeg, &ho_Segmentations, hv_IndexImage);
    }
    }
    CropDomain(ho_Segmentations, &ho_Segmentations);
  }
  else
  {
    throw HException("Unsupported parameter value for 'domain_handling'");
  }
  //
  //Preprocess the segmentation images.
  //
  //Set all background classes to the given background class ID.
  if (0 != (int(hv_SetBackgroundID!=HTuple())))
  {
    reassign_pixel_values(ho_Segmentations, &ho_Segmentations, hv_ClassesToBackground, 
        hv_SetBackgroundID);
  }
  //
  //Zoom images only if they have a different size than the specified size.
  GetImageSize(ho_Segmentations, &hv_ImageWidthRaw, &hv_ImageHeightRaw);
  hv_EqualWidth = hv_ImageWidth.TupleEqualElem(hv_ImageWidthRaw);
  hv_EqualHeight = hv_ImageHeight.TupleEqualElem(hv_ImageHeightRaw);
  if (0 != (HTuple(int((hv_EqualWidth.TupleMin())==0)).TupleOr(int((hv_EqualHeight.TupleMin())==0))))
  {
    ZoomImageSize(ho_Segmentations, &ho_Segmentations, hv_ImageWidth, hv_ImageHeight, 
        "nearest_neighbor");
  }
  //
  //Check the type of the input images
  //and convert if necessary.
  GetImageType(ho_Segmentations, &hv_Type);
  hv_EqualReal = hv_Type.TupleEqualElem("real");
  //
  if (0 != (int((hv_EqualReal.TupleMin())==0)))
  {
    //Convert the image type to 'real',
    //because the model expects 'real' images.
    ConvertImageType(ho_Segmentations, &ho_Segmentations, "real");
  }
  //
  //Write preprocessed Segmentations to output variable.
  (*ho_SegmentationsPreprocessed) = ho_Segmentations;
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Preprocess given DLSamples according to the preprocessing parameters given in DLPreprocessParam. 
void preprocess_dl_samples (HTuple hv_DLSampleBatch, HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_ImageRaw, ho_ImagePreprocessed, ho_AnomalyImageRaw;
  HObject  ho_AnomalyImagePreprocessed, ho_SegmentationRaw;
  HObject  ho_SegmentationPreprocessed, ho_ImageRawDomain;

  // Local control variables
  HTuple  hv_SampleIndex, hv_DLSample, hv_ImageExists;
  HTuple  hv_KeysExists, hv_AnomalyParamExist, hv_Rectangle1ParamExist;
  HTuple  hv_Rectangle2ParamExist, hv_InstanceMaskParamExist;
  HTuple  hv_SegmentationParamExist, hv_OCRParamExist;

  //
  //This procedure preprocesses all images of the sample dictionaries
  //in the tuple DLSampleBatch.
  //The images are preprocessed according to the parameters provided
  //in DLPreprocessParam.
  //
  //Check the validity of the preprocessing parameters.
  //The procedure check_dl_preprocess_param might change DLPreprocessParam.
  //To avoid race conditions when preprocess_dl_samples is used from
  //multiple threads with the same DLPreprocessParam dictionary,
  //work on a copy.
  CopyDict(hv_DLPreprocessParam, HTuple(), HTuple(), &hv_DLPreprocessParam);
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //
  //
  //Preprocess the sample entries.
  //
  {
  HTuple end_val18 = (hv_DLSampleBatch.TupleLength())-1;
  HTuple step_val18 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val18, step_val18); hv_SampleIndex += step_val18)
  {
    hv_DLSample = HTuple(hv_DLSampleBatch[hv_SampleIndex]);
    //
    //Preprocess augmentation data.
    preprocess_dl_model_augmentation_data(hv_DLSample, hv_DLPreprocessParam);
    //
    //Check the existence of the sample keys.
    GetDictParam(hv_DLSample, "key_exists", "image", &hv_ImageExists);
    //
    //Preprocess the images.
    if (0 != hv_ImageExists)
    {
      //
      //Get the image.
      GetDictObject(&ho_ImageRaw, hv_DLSample, "image");
      //
      //Preprocess the image.
      preprocess_dl_model_images(ho_ImageRaw, &ho_ImagePreprocessed, hv_DLPreprocessParam);
      //
      //Replace the image in the dictionary.
      SetDictObject(ho_ImagePreprocessed, hv_DLSample, "image");
      //
      //Check existence of model specific sample keys:
      //- 'anomaly_ground_truth':
      //  For model 'type' = 'anomaly_detection' and
      //  model 'type' = 'gc_anomaly_detection'
      //- 'bbox_row1':
      //  For 'instance_type' = 'rectangle1' and
      //  model 'type' = 'detection'
      //- 'bbox_phi':
      //  For 'instance_type' = 'rectangle2' and
      //  model 'type' = 'detection'
      //- 'mask':
      //  For 'instance_type' = 'rectangle1',
      //  model 'type' = 'detection', and
      //  'instance_segmentation' = true
      //- 'segmentation_image':
      //  For model 'type' = 'segmentation'
      GetDictParam(hv_DLSample, "key_exists", (((((HTuple("anomaly_ground_truth").Append("bbox_row1")).Append("bbox_phi")).Append("mask")).Append("segmentation_image")).Append("word")), 
          &hv_KeysExists);
      hv_AnomalyParamExist = ((const HTuple&)hv_KeysExists)[0];
      hv_Rectangle1ParamExist = ((const HTuple&)hv_KeysExists)[1];
      hv_Rectangle2ParamExist = ((const HTuple&)hv_KeysExists)[2];
      hv_InstanceMaskParamExist = ((const HTuple&)hv_KeysExists)[3];
      hv_SegmentationParamExist = ((const HTuple&)hv_KeysExists)[4];
      hv_OCRParamExist = ((const HTuple&)hv_KeysExists)[5];
      //
      //Preprocess the anomaly ground truth for
      //model 'type' = 'anomaly_detection' or
      //model 'type' = 'gc_anomaly_detection' if present.
      if (0 != hv_AnomalyParamExist)
      {
        //
        //Get the anomaly image.
        GetDictObject(&ho_AnomalyImageRaw, hv_DLSample, "anomaly_ground_truth");
        //
        //Preprocess the anomaly image.
        preprocess_dl_model_anomaly(ho_AnomalyImageRaw, &ho_AnomalyImagePreprocessed, 
            hv_DLPreprocessParam);
        //
        //Set preprocessed anomaly image.
        SetDictObject(ho_AnomalyImagePreprocessed, hv_DLSample, "anomaly_ground_truth");
      }
      //
      //Preprocess depending on the model type.
      //If bounding boxes are given, rescale them as well.
      if (0 != hv_Rectangle1ParamExist)
      {
        //
        //Preprocess the bounding boxes of type 'rectangle1'.
        preprocess_dl_model_bbox_rect1(ho_ImageRaw, hv_DLSample, hv_DLPreprocessParam);
      }
      else if (0 != hv_Rectangle2ParamExist)
      {
        //
        //Preprocess the bounding boxes of type 'rectangle2'.
        preprocess_dl_model_bbox_rect2(ho_ImageRaw, hv_DLSample, hv_DLPreprocessParam);
      }
      if (0 != hv_InstanceMaskParamExist)
      {
        //
        //Preprocess the instance masks.
        preprocess_dl_model_instance_masks(ho_ImageRaw, hv_DLSample, hv_DLPreprocessParam);
      }
      //
      //Preprocess the segmentation image if present.
      if (0 != hv_SegmentationParamExist)
      {
        //
        //Get the segmentation image.
        GetDictObject(&ho_SegmentationRaw, hv_DLSample, "segmentation_image");
        //
        //Preprocess the segmentation image.
        preprocess_dl_model_segmentations(ho_ImageRaw, ho_SegmentationRaw, &ho_SegmentationPreprocessed, 
            hv_DLPreprocessParam);
        //
        //Set preprocessed segmentation image.
        SetDictObject(ho_SegmentationPreprocessed, hv_DLSample, "segmentation_image");
      }
      //
      //Preprocess the word bounding boxes and generate targets.
      if (0 != (hv_OCRParamExist.TupleAnd(hv_Rectangle2ParamExist)))
      {
        //
        //Preprocess Sample.
        gen_dl_ocr_detection_targets(hv_DLSample, hv_DLPreprocessParam);
      }
      //
      //Preprocess 3D relevant data if present.
      GetDictParam(hv_DLSample, "key_exists", (((HTuple("x").Append("y")).Append("z")).Append("normals")), 
          &hv_KeysExists);
      if (0 != (hv_KeysExists.TupleMax()))
      {
        //We need to handle crop_domain before preprocess_dl_model_3d_data
        //if it is necessary.
        //Note, we are not cropping the image of DLSample because it has
        //been done by preprocess_dl_model_images.
        //Since we always keep the domain of 3D data we do not need to handle
        //'keep_domain' or 'full_domain'.
        GetDomain(ho_ImageRaw, &ho_ImageRawDomain);
        crop_dl_sample_image(ho_ImageRawDomain, hv_DLSample, "x", hv_DLPreprocessParam);
        crop_dl_sample_image(ho_ImageRawDomain, hv_DLSample, "y", hv_DLPreprocessParam);
        crop_dl_sample_image(ho_ImageRawDomain, hv_DLSample, "z", hv_DLPreprocessParam);
        crop_dl_sample_image(ho_ImageRawDomain, hv_DLSample, "normals", hv_DLPreprocessParam);
        //
        preprocess_dl_model_3d_data(hv_DLSample, hv_DLPreprocessParam);
      }
    }
    else
    {
      throw HException((HTuple("All samples processed need to include an image, but the sample with index ")+hv_SampleIndex)+" does not.");
    }
  }
  }
  //
  return;
}

// Chapter: Image / Manipulation
// Short Description: Change value of ValuesToChange in Image to NewValue. 
void reassign_pixel_values (HObject ho_Image, HObject *ho_ImageOut, HTuple hv_ValuesToChange, 
    HTuple hv_NewValue)
{

  // Local iconic variables
  HObject  ho_RegionToChange, ho_RegionClass;

  // Local control variables
  HTuple  hv_IndexReset;

  //
  //This procedure sets all pixels of Image
  //with the values given in ValuesToChange to the given value NewValue.
  //
  GenEmptyRegion(&ho_RegionToChange);
  {
  HTuple end_val5 = (hv_ValuesToChange.TupleLength())-1;
  HTuple step_val5 = 1;
  for (hv_IndexReset=0; hv_IndexReset.Continue(end_val5, step_val5); hv_IndexReset += step_val5)
  {
    Threshold(ho_Image, &ho_RegionClass, HTuple(hv_ValuesToChange[hv_IndexReset]), 
        HTuple(hv_ValuesToChange[hv_IndexReset]));
    Union2(ho_RegionToChange, ho_RegionClass, &ho_RegionToChange);
  }
  }
  OverpaintRegion(ho_Image, ho_RegionToChange, hv_NewValue, "fill");
  (*ho_ImageOut) = ho_Image;
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Remove invalid 3D pixels from a given domain. 
void remove_invalid_3d_pixels (HObject ho_ImageX, HObject ho_ImageY, HObject ho_ImageZ, 
    HObject ho_Domain, HObject *ho_DomainOut, HTuple hv_InvalidPixelValue)
{

  // Local iconic variables
  HObject  ho_ImageXOut, ho_ImageYOut, ho_ImageZOut;
  HObject  ho_RegionInvalX, ho_RegionInvalY, ho_RegionInvalZ;
  HObject  ho_RegionInvalXY, ho_RegionInval, ho_RegionInvalComplement;

  (*ho_DomainOut) = ho_Domain;
  ho_ImageXOut = ho_ImageX;
  ho_ImageYOut = ho_ImageY;
  ho_ImageZOut = ho_ImageZ;
  ReduceDomain(ho_ImageXOut, (*ho_DomainOut), &ho_ImageXOut);
  ReduceDomain(ho_ImageYOut, (*ho_DomainOut), &ho_ImageYOut);
  ReduceDomain(ho_ImageZOut, (*ho_DomainOut), &ho_ImageZOut);
  Threshold(ho_ImageXOut, &ho_RegionInvalX, hv_InvalidPixelValue, hv_InvalidPixelValue);
  Threshold(ho_ImageYOut, &ho_RegionInvalY, hv_InvalidPixelValue, hv_InvalidPixelValue);
  Threshold(ho_ImageZOut, &ho_RegionInvalZ, hv_InvalidPixelValue, hv_InvalidPixelValue);
  Intersection(ho_RegionInvalX, ho_RegionInvalY, &ho_RegionInvalXY);
  Intersection(ho_RegionInvalXY, ho_RegionInvalZ, &ho_RegionInval);
  Complement(ho_RegionInval, &ho_RegionInvalComplement);
  Intersection((*ho_DomainOut), ho_RegionInvalComplement, &(*ho_DomainOut));
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Replace legacy preprocessing parameters or values. 
void replace_legacy_preprocessing_parameters (HTuple hv_DLPreprocessParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Exception, hv_NormalizationTypeExists;
  HTuple  hv_NormalizationType, hv_LegacyNormalizationKeyExists;
  HTuple  hv_ContrastNormalization;

  //
  //This procedure adapts the dictionary DLPreprocessParam
  //if a legacy preprocessing parameter is set.
  //
  //Map legacy value set to new parameter.
  hv_Exception = 0;
  try
  {
    GetDictParam(hv_DLPreprocessParam, "key_exists", "normalization_type", &hv_NormalizationTypeExists);
    //
    if (0 != hv_NormalizationTypeExists)
    {
      GetDictTuple(hv_DLPreprocessParam, "normalization_type", &hv_NormalizationType);
      if (0 != (int(hv_NormalizationType==HTuple("true"))))
      {
        hv_NormalizationType = "first_channel";
      }
      else if (0 != (int(hv_NormalizationType==HTuple("false"))))
      {
        hv_NormalizationType = "none";
      }
      SetDictTuple(hv_DLPreprocessParam, "normalization_type", hv_NormalizationType);
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }
  //
  //Map legacy parameter to new parameter and corresponding value.
  hv_Exception = 0;
  try
  {
    GetDictParam(hv_DLPreprocessParam, "key_exists", "contrast_normalization", &hv_LegacyNormalizationKeyExists);
    if (0 != hv_LegacyNormalizationKeyExists)
    {
      GetDictTuple(hv_DLPreprocessParam, "contrast_normalization", &hv_ContrastNormalization);
      //Replace 'contrast_normalization' by 'normalization_type'.
      if (0 != (int(hv_ContrastNormalization==HTuple("false"))))
      {
        SetDictTuple(hv_DLPreprocessParam, "normalization_type", "none");
      }
      else if (0 != (int(hv_ContrastNormalization==HTuple("true"))))
      {
        SetDictTuple(hv_DLPreprocessParam, "normalization_type", "first_channel");
      }
      RemoveDictKey(hv_DLPreprocessParam, "contrast_normalization");
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Split rectangle2 into a number of rectangles. 
void split_rectangle2 (HTuple hv_Row, HTuple hv_Column, HTuple hv_Phi, HTuple hv_Length1, 
    HTuple hv_Length2, HTuple hv_NumSplits, HTuple *hv_SplitRow, HTuple *hv_SplitColumn, 
    HTuple *hv_SplitPhi, HTuple *hv_SplitLength1Out, HTuple *hv_SplitLength2Out)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_SplitLength, hv_TRow, hv_TCol, hv_HomMat2D;

  if (0 != (int(hv_NumSplits>0)))
  {
    hv_SplitLength = hv_Length1/(hv_NumSplits.TupleReal());
    //Assume center (0,0), transform afterwards.
    hv_TRow = HTuple(hv_NumSplits,0.0);
    hv_TCol = ((-hv_Length1)+hv_SplitLength)+((HTuple::TupleGenSequence(0,hv_NumSplits-1,1)*2)*hv_SplitLength);
    HomMat2dIdentity(&hv_HomMat2D);
    HomMat2dRotate(hv_HomMat2D, hv_Phi, 0, 0, &hv_HomMat2D);
    HomMat2dTranslate(hv_HomMat2D, hv_Row, hv_Column, &hv_HomMat2D);
    (*hv_SplitLength1Out) = HTuple(hv_NumSplits,hv_SplitLength);
    (*hv_SplitLength2Out) = HTuple(hv_NumSplits,hv_Length2);
    (*hv_SplitPhi) = HTuple(hv_NumSplits,hv_Phi);
    AffineTransPoint2d(hv_HomMat2D, hv_TRow, hv_TCol, &(*hv_SplitRow), &(*hv_SplitColumn));
  }
  else
  {
    throw HException("Number of splits must be greater than 0.");
  }
  return;
}


